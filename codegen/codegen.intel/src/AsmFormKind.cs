namespace Z0.Asm
{
    /// <summary>
    /// Defines asm form classifiers
    /// </summary>
    [SymSource("asm")]
    public enum AsmFormKind : ushort
    {
        None = 0,

        /// <summary>
        /// adc AL, imm8 | 14 ib | Add with carry imm8 to AL.
        /// </summary>
        [Symbol("adc AL, imm8","14 ib")]
        adc_AL_imm8 = 1,

        /// <summary>
        /// adc AX, imm16 | 15 iw | Add with carry imm16 to AX.
        /// </summary>
        [Symbol("adc AX, imm16","15 iw")]
        adc_AX_imm16 = 2,

        /// <summary>
        /// adc EAX, imm32 | 15 id | Add with carry imm32 to EAX.
        /// </summary>
        [Symbol("adc EAX, imm32","15 id")]
        adc_EAX_imm32 = 3,

        /// <summary>
        /// adc m16, imm16 | 81 /2 iw | Add with carry imm16 to r/m16.
        /// </summary>
        [Symbol("adc m16, imm16","81 /2 iw")]
        adc_m16_imm16 = 4,

        /// <summary>
        /// adc m16, imm8 | 83 /2 ib | Add with CF sign-extended imm8 to r/m16.
        /// </summary>
        [Symbol("adc m16, imm8","83 /2 ib")]
        adc_m16_imm8 = 5,

        /// <summary>
        /// adc m16, r16 | 11 /r | Add with carry r16 to r/m16.
        /// </summary>
        [Symbol("adc m16, r16","11 /r")]
        adc_m16_r16 = 6,

        /// <summary>
        /// adc m32, imm32 | 81 /2 id | Add with CF imm32 to r/m32.
        /// </summary>
        [Symbol("adc m32, imm32","81 /2 id")]
        adc_m32_imm32 = 7,

        /// <summary>
        /// adc m32, imm8 | 83 /2 ib | Add with CF sign-extended imm8 into r/m32.
        /// </summary>
        [Symbol("adc m32, imm8","83 /2 ib")]
        adc_m32_imm8 = 8,

        /// <summary>
        /// adc m32, r32 | 11 /r | Add with CF r32 to r/m32.
        /// </summary>
        [Symbol("adc m32, r32","11 /r")]
        adc_m32_r32 = 9,

        /// <summary>
        /// adc m64, imm32 | REX.W + 81 /2 id | Add with CF imm32 sign extended to 64-bits to r/m64.
        /// </summary>
        [Symbol("adc m64, imm32","REX.W + 81 /2 id")]
        adc_m64_imm32 = 10,

        /// <summary>
        /// adc m64, imm8 | REX.W + 83 /2 ib | Add with CF sign-extended imm8 into r/m64.
        /// </summary>
        [Symbol("adc m64, imm8","REX.W + 83 /2 ib")]
        adc_m64_imm8 = 11,

        /// <summary>
        /// adc m64, r64 | REX.W + 11 /r | Add with CF r64 to r/m64.
        /// </summary>
        [Symbol("adc m64, r64","REX.W + 11 /r")]
        adc_m64_r64 = 12,

        /// <summary>
        /// adc m8, imm8 | 80 /2 ib | Add with carry imm8 to r/m8.
        /// </summary>
        [Symbol("adc m8, imm8","80 /2 ib")]
        adc_m8_imm8 = 13,

        /// <summary>
        /// adc m8, imm8 | REX + 80 /2 ib | Add with carry imm8 to r/m8.
        /// </summary>
        [Symbol("adc m8, imm8","REX + 80 /2 ib")]
        adc_m8_imm8_rex = 14,

        /// <summary>
        /// adc m8, r8 | 10 /r | Add with carry byte register to r/m8.
        /// </summary>
        [Symbol("adc m8, r8","10 /r")]
        adc_m8_r8 = 15,

        /// <summary>
        /// adc m8, r8 | REX + 10 /r | Add with carry byte register to r/m64.
        /// </summary>
        [Symbol("adc m8, r8","REX + 10 /r")]
        adc_m8_r8_rex = 16,

        /// <summary>
        /// adc r16, imm16 | 81 /2 iw | Add with carry imm16 to r/m16.
        /// </summary>
        [Symbol("adc r16, imm16","81 /2 iw")]
        adc_r16_imm16 = 17,

        /// <summary>
        /// adc r16, imm8 | 83 /2 ib | Add with CF sign-extended imm8 to r/m16.
        /// </summary>
        [Symbol("adc r16, imm8","83 /2 ib")]
        adc_r16_imm8 = 18,

        /// <summary>
        /// adc r16, m16 | 13 /r | Add with carry r/m16 to r16.
        /// </summary>
        [Symbol("adc r16, m16","13 /r")]
        adc_r16_m16 = 19,

        /// <summary>
        /// adc r16, r16 | 11 /r | Add with carry r16 to r/m16.
        /// </summary>
        [Symbol("adc r16, r16","11 /r")]
        adc_r16_r16 = 20,

        /// <summary>
        /// adc r16, r16 | 13 /r | Add with carry r/m16 to r16.
        /// </summary>
        [Symbol("adc r16, r16","13 /r")]
        adc_r16_r16_x13 = 21,

        /// <summary>
        /// adc r32, imm32 | 81 /2 id | Add with CF imm32 to r/m32.
        /// </summary>
        [Symbol("adc r32, imm32","81 /2 id")]
        adc_r32_imm32 = 22,

        /// <summary>
        /// adc r32, imm8 | 83 /2 ib | Add with CF sign-extended imm8 into r/m32.
        /// </summary>
        [Symbol("adc r32, imm8","83 /2 ib")]
        adc_r32_imm8 = 23,

        /// <summary>
        /// adc r32, m32 | 13 /r | Add with CF r/m32 to r32.
        /// </summary>
        [Symbol("adc r32, m32","13 /r")]
        adc_r32_m32 = 24,

        /// <summary>
        /// adc r32, r32 | 11 /r | Add with CF r32 to r/m32.
        /// </summary>
        [Symbol("adc r32, r32","11 /r")]
        adc_r32_r32 = 25,

        /// <summary>
        /// adc r32, r32 | 13 /r | Add with CF r/m32 to r32.
        /// </summary>
        [Symbol("adc r32, r32","13 /r")]
        adc_r32_r32_x13 = 26,

        /// <summary>
        /// adc r64, imm32 | REX.W + 81 /2 id | Add with CF imm32 sign extended to 64-bits to r/m64.
        /// </summary>
        [Symbol("adc r64, imm32","REX.W + 81 /2 id")]
        adc_r64_imm32 = 27,

        /// <summary>
        /// adc r64, imm8 | REX.W + 83 /2 ib | Add with CF sign-extended imm8 into r/m64.
        /// </summary>
        [Symbol("adc r64, imm8","REX.W + 83 /2 ib")]
        adc_r64_imm8 = 28,

        /// <summary>
        /// adc r64, m64 | REX.W + 13 /r | Add with CF r/m64 to r64.
        /// </summary>
        [Symbol("adc r64, m64","REX.W + 13 /r")]
        adc_r64_m64 = 29,

        /// <summary>
        /// adc r64, r64 | REX.W + 11 /r | Add with CF r64 to r/m64.
        /// </summary>
        [Symbol("adc r64, r64","REX.W + 11 /r")]
        adc_r64_r64 = 30,

        /// <summary>
        /// adc r64, r64 | REX.W + 13 /r | Add with CF r/m64 to r64.
        /// </summary>
        [Symbol("adc r64, r64","REX.W + 13 /r")]
        adc_r64_r64_x13 = 31,

        /// <summary>
        /// adc r8, imm8 | 80 /2 ib | Add with carry imm8 to r/m8.
        /// </summary>
        [Symbol("adc r8, imm8","80 /2 ib")]
        adc_r8_imm8 = 32,

        /// <summary>
        /// adc r8, imm8 | REX + 80 /2 ib | Add with carry imm8 to r/m8.
        /// </summary>
        [Symbol("adc r8, imm8","REX + 80 /2 ib")]
        adc_r8_imm8_rex = 33,

        /// <summary>
        /// adc r8, m8 | 12 /r | Add with carry r/m8 to byte register.
        /// </summary>
        [Symbol("adc r8, m8","12 /r")]
        adc_r8_m8 = 34,

        /// <summary>
        /// adc r8, m8 | REX + 12 /r | Add with carry r/m64 to byte register.
        /// </summary>
        [Symbol("adc r8, m8","REX + 12 /r")]
        adc_r8_m8_rex = 35,

        /// <summary>
        /// adc r8, r8 | 10 /r | Add with carry byte register to r/m8.
        /// </summary>
        [Symbol("adc r8, r8","10 /r")]
        adc_r8_r8 = 36,

        /// <summary>
        /// adc r8, r8 | REX + 10 /r | Add with carry byte register to r/m64.
        /// </summary>
        [Symbol("adc r8, r8","REX + 10 /r")]
        adc_r8_r8_rex = 37,

        /// <summary>
        /// adc r8, r8 | 12 /r | Add with carry r/m8 to byte register.
        /// </summary>
        [Symbol("adc r8, r8","12 /r")]
        adc_r8_r8_x12 = 38,

        /// <summary>
        /// adc RAX, imm32 | REX.W + 15 id | Add with carry imm32 sign extended to 64-bits to RAX.
        /// </summary>
        [Symbol("adc RAX, imm32","REX.W + 15 id")]
        adc_RAX_imm32 = 39,

        /// <summary>
        /// adcx r32, m32 | 66 0F 38 F6 /r | Unsigned addition of r32 with CF, r/m32 to r32, writes CF.
        /// </summary>
        [Symbol("adcx r32, m32","66 0F 38 F6 /r")]
        adcx_r32_m32 = 40,

        /// <summary>
        /// adcx r32, r32 | 66 0F 38 F6 /r | Unsigned addition of r32 with CF, r/m32 to r32, writes CF.
        /// </summary>
        [Symbol("adcx r32, r32","66 0F 38 F6 /r")]
        adcx_r32_r32 = 41,

        /// <summary>
        /// adcx r64, m64 | 66 REX.W 0F 38 F6 /r | Unsigned addition of r64 with CF, r/m64 to r64, writes CF.
        /// </summary>
        [Symbol("adcx r64, m64","66 REX.W 0F 38 F6 /r")]
        adcx_r64_m64 = 42,

        /// <summary>
        /// adcx r64, r64 | 66 REX.W 0F 38 F6 /r | Unsigned addition of r64 with CF, r/m64 to r64, writes CF.
        /// </summary>
        [Symbol("adcx r64, r64","66 REX.W 0F 38 F6 /r")]
        adcx_r64_r64 = 43,

        /// <summary>
        /// add AL, imm8 | 04 ib | Add imm8 to AL.
        /// </summary>
        [Symbol("add AL, imm8","04 ib")]
        add_AL_imm8 = 44,

        /// <summary>
        /// add AX, imm16 | 05 iw | Add imm16 to AX.
        /// </summary>
        [Symbol("add AX, imm16","05 iw")]
        add_AX_imm16 = 45,

        /// <summary>
        /// add EAX, imm32 | 05 id | Add imm32 to EAX.
        /// </summary>
        [Symbol("add EAX, imm32","05 id")]
        add_EAX_imm32 = 46,

        /// <summary>
        /// add m16, imm16 | 81 /0 iw | Add imm16 to r/m16.
        /// </summary>
        [Symbol("add m16, imm16","81 /0 iw")]
        add_m16_imm16 = 47,

        /// <summary>
        /// add m16, imm8 | 83 /0 ib | Add sign-extended imm8 to r/m16.
        /// </summary>
        [Symbol("add m16, imm8","83 /0 ib")]
        add_m16_imm8 = 48,

        /// <summary>
        /// add m16, r16 | 01 /r | Add r16 to r/m16.
        /// </summary>
        [Symbol("add m16, r16","01 /r")]
        add_m16_r16 = 49,

        /// <summary>
        /// add m32, imm32 | 81 /0 id | Add imm32 to r/m32.
        /// </summary>
        [Symbol("add m32, imm32","81 /0 id")]
        add_m32_imm32 = 50,

        /// <summary>
        /// add m32, imm8 | 83 /0 ib | Add sign-extended imm8 to r/m32.
        /// </summary>
        [Symbol("add m32, imm8","83 /0 ib")]
        add_m32_imm8 = 51,

        /// <summary>
        /// add m32, r32 | 01 /r | Add r32 to r/m32.
        /// </summary>
        [Symbol("add m32, r32","01 /r")]
        add_m32_r32 = 52,

        /// <summary>
        /// add m64, imm32 | REX.W + 81 /0 id | Add imm32 sign-extended to 64-bits to r/m64.
        /// </summary>
        [Symbol("add m64, imm32","REX.W + 81 /0 id")]
        add_m64_imm32 = 53,

        /// <summary>
        /// add m64, imm8 | REX.W + 83 /0 ib | Add sign-extended imm8 to r/m64.
        /// </summary>
        [Symbol("add m64, imm8","REX.W + 83 /0 ib")]
        add_m64_imm8 = 54,

        /// <summary>
        /// add m64, r64 | REX.W + 01 /r | Add r64 to r/m64.
        /// </summary>
        [Symbol("add m64, r64","REX.W + 01 /r")]
        add_m64_r64 = 55,

        /// <summary>
        /// add m8, imm8 | 80 /0 ib | Add imm8 to r/m8.
        /// </summary>
        [Symbol("add m8, imm8","80 /0 ib")]
        add_m8_imm8 = 56,

        /// <summary>
        /// add m8, imm8 | REX + 80 /0 ib | Add sign-extended imm8 to r/m8.
        /// </summary>
        [Symbol("add m8, imm8","REX + 80 /0 ib")]
        add_m8_imm8_rex = 57,

        /// <summary>
        /// add m8, r8 | 00 /r | Add r8 to r/m8.
        /// </summary>
        [Symbol("add m8, r8","00 /r")]
        add_m8_r8 = 58,

        /// <summary>
        /// add m8, r8 | REX + 00 /r | Add r8 to r/m8.
        /// </summary>
        [Symbol("add m8, r8","REX + 00 /r")]
        add_m8_r8_rex = 59,

        /// <summary>
        /// add r16, imm16 | 81 /0 iw | Add imm16 to r/m16.
        /// </summary>
        [Symbol("add r16, imm16","81 /0 iw")]
        add_r16_imm16 = 60,

        /// <summary>
        /// add r16, imm8 | 83 /0 ib | Add sign-extended imm8 to r/m16.
        /// </summary>
        [Symbol("add r16, imm8","83 /0 ib")]
        add_r16_imm8 = 61,

        /// <summary>
        /// add r16, m16 | 03 /r | Add r/m16 to r16.
        /// </summary>
        [Symbol("add r16, m16","03 /r")]
        add_r16_m16 = 62,

        /// <summary>
        /// add r16, r16 | 01 /r | Add r16 to r/m16.
        /// </summary>
        [Symbol("add r16, r16","01 /r")]
        add_r16_r16 = 63,

        /// <summary>
        /// add r16, r16 | 03 /r | Add r/m16 to r16.
        /// </summary>
        [Symbol("add r16, r16","03 /r")]
        add_r16_r16_x03 = 64,

        /// <summary>
        /// add r32, imm32 | 81 /0 id | Add imm32 to r/m32.
        /// </summary>
        [Symbol("add r32, imm32","81 /0 id")]
        add_r32_imm32 = 65,

        /// <summary>
        /// add r32, imm8 | 83 /0 ib | Add sign-extended imm8 to r/m32.
        /// </summary>
        [Symbol("add r32, imm8","83 /0 ib")]
        add_r32_imm8 = 66,

        /// <summary>
        /// add r32, m32 | 03 /r | Add r/m32 to r32.
        /// </summary>
        [Symbol("add r32, m32","03 /r")]
        add_r32_m32 = 67,

        /// <summary>
        /// add r32, r32 | 01 /r | Add r32 to r/m32.
        /// </summary>
        [Symbol("add r32, r32","01 /r")]
        add_r32_r32 = 68,

        /// <summary>
        /// add r32, r32 | 03 /r | Add r/m32 to r32.
        /// </summary>
        [Symbol("add r32, r32","03 /r")]
        add_r32_r32_x03 = 69,

        /// <summary>
        /// add r64, imm32 | REX.W + 81 /0 id | Add imm32 sign-extended to 64-bits to r/m64.
        /// </summary>
        [Symbol("add r64, imm32","REX.W + 81 /0 id")]
        add_r64_imm32 = 70,

        /// <summary>
        /// add r64, imm8 | REX.W + 83 /0 ib | Add sign-extended imm8 to r/m64.
        /// </summary>
        [Symbol("add r64, imm8","REX.W + 83 /0 ib")]
        add_r64_imm8 = 71,

        /// <summary>
        /// add r64, m64 | REX.W + 03 /r | Add r/m64 to r64.
        /// </summary>
        [Symbol("add r64, m64","REX.W + 03 /r")]
        add_r64_m64 = 72,

        /// <summary>
        /// add r64, r64 | REX.W + 01 /r | Add r64 to r/m64.
        /// </summary>
        [Symbol("add r64, r64","REX.W + 01 /r")]
        add_r64_r64 = 73,

        /// <summary>
        /// add r64, r64 | REX.W + 03 /r | Add r/m64 to r64.
        /// </summary>
        [Symbol("add r64, r64","REX.W + 03 /r")]
        add_r64_r64_x03 = 74,

        /// <summary>
        /// add r8, imm8 | 80 /0 ib | Add imm8 to r/m8.
        /// </summary>
        [Symbol("add r8, imm8","80 /0 ib")]
        add_r8_imm8 = 75,

        /// <summary>
        /// add r8, imm8 | REX + 80 /0 ib | Add sign-extended imm8 to r/m8.
        /// </summary>
        [Symbol("add r8, imm8","REX + 80 /0 ib")]
        add_r8_imm8_rex = 76,

        /// <summary>
        /// add r8, m8 | 02 /r | Add r/m8 to r8.
        /// </summary>
        [Symbol("add r8, m8","02 /r")]
        add_r8_m8 = 77,

        /// <summary>
        /// add r8, m8 | REX + 02 /r | Add r/m8 to r8.
        /// </summary>
        [Symbol("add r8, m8","REX + 02 /r")]
        add_r8_m8_rex = 78,

        /// <summary>
        /// add r8, r8 | 00 /r | Add r8 to r/m8.
        /// </summary>
        [Symbol("add r8, r8","00 /r")]
        add_r8_r8 = 79,

        /// <summary>
        /// add r8, r8 | REX + 00 /r | Add r8 to r/m8.
        /// </summary>
        [Symbol("add r8, r8","REX + 00 /r")]
        add_r8_r8_rex = 80,

        /// <summary>
        /// add r8, r8 | 02 /r | Add r/m8 to r8.
        /// </summary>
        [Symbol("add r8, r8","02 /r")]
        add_r8_r8_x02 = 81,

        /// <summary>
        /// add RAX, imm32 | REX.W + 05 id | Add imm32 sign-extended to 64-bits to RAX.
        /// </summary>
        [Symbol("add RAX, imm32","REX.W + 05 id")]
        add_RAX_imm32 = 82,

        /// <summary>
        /// addpd xmm, m128 | 66 0F 58 /r | Add packed double-precision floating-point values from xmm2/mem to xmm1 and store result in xmm1.
        /// </summary>
        [Symbol("addpd xmm, m128","66 0F 58 /r")]
        addpd_xmm_m128 = 83,

        /// <summary>
        /// addpd xmm, r8 | 66 0F 58 /r | Add packed double-precision floating-point values from xmm2/mem to xmm1 and store result in xmm1.
        /// </summary>
        [Symbol("addpd xmm, r8","66 0F 58 /r")]
        addpd_xmm_r8 = 84,

        /// <summary>
        /// and AL, imm8 | 24 ib | AL AND imm8.
        /// </summary>
        [Symbol("and AL, imm8","24 ib")]
        and_AL_imm8 = 85,

        /// <summary>
        /// and AX, imm16 | 25 iw | AX AND imm16.
        /// </summary>
        [Symbol("and AX, imm16","25 iw")]
        and_AX_imm16 = 86,

        /// <summary>
        /// and EAX, imm32 | 25 id | EAX AND imm32.
        /// </summary>
        [Symbol("and EAX, imm32","25 id")]
        and_EAX_imm32 = 87,

        /// <summary>
        /// and m16, imm16 | 81 /4 iw | r/m16 AND imm16.
        /// </summary>
        [Symbol("and m16, imm16","81 /4 iw")]
        and_m16_imm16 = 88,

        /// <summary>
        /// and m16, imm8 | 83 /4 ib | r/m16 AND imm8 (sign-extended).
        /// </summary>
        [Symbol("and m16, imm8","83 /4 ib")]
        and_m16_imm8 = 89,

        /// <summary>
        /// and m16, r16 | 21 /r | r/m16 AND r16.
        /// </summary>
        [Symbol("and m16, r16","21 /r")]
        and_m16_r16 = 90,

        /// <summary>
        /// and m32, imm32 | 81 /4 id | r/m32 AND imm32.
        /// </summary>
        [Symbol("and m32, imm32","81 /4 id")]
        and_m32_imm32 = 91,

        /// <summary>
        /// and m32, imm8 | 83 /4 ib | r/m32 AND imm8 (sign-extended).
        /// </summary>
        [Symbol("and m32, imm8","83 /4 ib")]
        and_m32_imm8 = 92,

        /// <summary>
        /// and m32, r32 | 21 /r | r/m32 AND r32.
        /// </summary>
        [Symbol("and m32, r32","21 /r")]
        and_m32_r32 = 93,

        /// <summary>
        /// and m64, imm32 | REX.W + 81 /4 id | r/m64 AND imm32 sign extended to 64-bits.
        /// </summary>
        [Symbol("and m64, imm32","REX.W + 81 /4 id")]
        and_m64_imm32 = 94,

        /// <summary>
        /// and m64, imm8 | REX.W + 83 /4 ib | r/m64 AND imm8 (sign-extended).
        /// </summary>
        [Symbol("and m64, imm8","REX.W + 83 /4 ib")]
        and_m64_imm8 = 95,

        /// <summary>
        /// and m64, r64 | REX.W + 21 /r | r/m64 AND r32.
        /// </summary>
        [Symbol("and m64, r64","REX.W + 21 /r")]
        and_m64_r64 = 96,

        /// <summary>
        /// and m8, imm8 | 80 /4 ib | r/m8 AND imm8.
        /// </summary>
        [Symbol("and m8, imm8","80 /4 ib")]
        and_m8_imm8 = 97,

        /// <summary>
        /// and m8, imm8 | REX + 80 /4 ib | r/m8 AND imm8.
        /// </summary>
        [Symbol("and m8, imm8","REX + 80 /4 ib")]
        and_m8_imm8_rex = 98,

        /// <summary>
        /// and m8, r8 | 20 /r | r/m8 AND r8.
        /// </summary>
        [Symbol("and m8, r8","20 /r")]
        and_m8_r8 = 99,

        /// <summary>
        /// and m8, r8 | REX + 20 /r | r/m64 AND r8 (sign-extended).
        /// </summary>
        [Symbol("and m8, r8","REX + 20 /r")]
        and_m8_r8_rex = 100,

        /// <summary>
        /// and r16, imm16 | 81 /4 iw | r/m16 AND imm16.
        /// </summary>
        [Symbol("and r16, imm16","81 /4 iw")]
        and_r16_imm16 = 101,

        /// <summary>
        /// and r16, imm8 | 83 /4 ib | r/m16 AND imm8 (sign-extended).
        /// </summary>
        [Symbol("and r16, imm8","83 /4 ib")]
        and_r16_imm8 = 102,

        /// <summary>
        /// and r16, m16 | 23 /r | r16 AND r/m16.
        /// </summary>
        [Symbol("and r16, m16","23 /r")]
        and_r16_m16 = 103,

        /// <summary>
        /// and r16, r16 | 21 /r | r/m16 AND r16.
        /// </summary>
        [Symbol("and r16, r16","21 /r")]
        and_r16_r16 = 104,

        /// <summary>
        /// and r16, r16 | 23 /r | r16 AND r/m16.
        /// </summary>
        [Symbol("and r16, r16","23 /r")]
        and_r16_r16_x23 = 105,

        /// <summary>
        /// and r32, imm32 | 81 /4 id | r/m32 AND imm32.
        /// </summary>
        [Symbol("and r32, imm32","81 /4 id")]
        and_r32_imm32 = 106,

        /// <summary>
        /// and r32, imm8 | 83 /4 ib | r/m32 AND imm8 (sign-extended).
        /// </summary>
        [Symbol("and r32, imm8","83 /4 ib")]
        and_r32_imm8 = 107,

        /// <summary>
        /// and r32, m32 | 23 /r | r32 AND r/m32.
        /// </summary>
        [Symbol("and r32, m32","23 /r")]
        and_r32_m32 = 108,

        /// <summary>
        /// and r32, r32 | 21 /r | r/m32 AND r32.
        /// </summary>
        [Symbol("and r32, r32","21 /r")]
        and_r32_r32 = 109,

        /// <summary>
        /// and r32, r32 | 23 /r | r32 AND r/m32.
        /// </summary>
        [Symbol("and r32, r32","23 /r")]
        and_r32_r32_x23 = 110,

        /// <summary>
        /// and r64, imm32 | REX.W + 81 /4 id | r/m64 AND imm32 sign extended to 64-bits.
        /// </summary>
        [Symbol("and r64, imm32","REX.W + 81 /4 id")]
        and_r64_imm32 = 111,

        /// <summary>
        /// and r64, imm8 | REX.W + 83 /4 ib | r/m64 AND imm8 (sign-extended).
        /// </summary>
        [Symbol("and r64, imm8","REX.W + 83 /4 ib")]
        and_r64_imm8 = 112,

        /// <summary>
        /// and r64, m64 | REX.W + 23 /r | r64 AND r/m64.
        /// </summary>
        [Symbol("and r64, m64","REX.W + 23 /r")]
        and_r64_m64 = 113,

        /// <summary>
        /// and r64, r64 | REX.W + 21 /r | r/m64 AND r32.
        /// </summary>
        [Symbol("and r64, r64","REX.W + 21 /r")]
        and_r64_r64 = 114,

        /// <summary>
        /// and r64, r64 | REX.W + 23 /r | r64 AND r/m64.
        /// </summary>
        [Symbol("and r64, r64","REX.W + 23 /r")]
        and_r64_r64_x23 = 115,

        /// <summary>
        /// and r8, imm8 | 80 /4 ib | r/m8 AND imm8.
        /// </summary>
        [Symbol("and r8, imm8","80 /4 ib")]
        and_r8_imm8 = 116,

        /// <summary>
        /// and r8, imm8 | REX + 80 /4 ib | r/m8 AND imm8.
        /// </summary>
        [Symbol("and r8, imm8","REX + 80 /4 ib")]
        and_r8_imm8_rex = 117,

        /// <summary>
        /// and r8, m8 | REX + 22 /r | r/m64 AND r8 (sign-extended).
        /// </summary>
        [Symbol("and r8, m8","REX + 22 /r")]
        and_r8_m8 = 118,

        /// <summary>
        /// and r8, m8 | 22 /r | r8 AND r/m8.
        /// </summary>
        [Symbol("and r8, m8","22 /r")]
        and_r8_m8_x22 = 119,

        /// <summary>
        /// and r8, r8 | 20 /r | r/m8 AND r8.
        /// </summary>
        [Symbol("and r8, r8","20 /r")]
        and_r8_r8 = 120,

        /// <summary>
        /// and r8, r8 | REX + 20 /r | r/m64 AND r8 (sign-extended).
        /// </summary>
        [Symbol("and r8, r8","REX + 20 /r")]
        and_r8_r8_rex = 121,

        /// <summary>
        /// and r8, r8 | 22 /r | r8 AND r/m8.
        /// </summary>
        [Symbol("and r8, r8","22 /r")]
        and_r8_r8_x22 = 122,

        /// <summary>
        /// and RAX, imm32 | REX.W + 25 id | RAX AND imm32 sign-extended to 64-bits.
        /// </summary>
        [Symbol("and RAX, imm32","REX.W + 25 id")]
        and_RAX_imm32 = 123,

        /// <summary>
        /// andn r32, r32, m32 | VEX.LZ.0F38.W0 F2 /r | Bitwise AND of inverted r32b with r/m32, store result in r32a.
        /// </summary>
        [Symbol("andn r32, r32, m32","VEX.LZ.0F38.W0 F2 /r")]
        andn_r32_r32_m32 = 124,

        /// <summary>
        /// andn r32, r32, r32 | VEX.LZ.0F38.W0 F2 /r | Bitwise AND of inverted r32b with r/m32, store result in r32a.
        /// </summary>
        [Symbol("andn r32, r32, r32","VEX.LZ.0F38.W0 F2 /r")]
        andn_r32_r32_r32 = 125,

        /// <summary>
        /// andn r64, r64, m64 | VEX.LZ.0F38.W1 F2 /r | Bitwise AND of inverted r64b with r/m64, store result in r64a.
        /// </summary>
        [Symbol("andn r64, r64, m64","VEX.LZ.0F38.W1 F2 /r")]
        andn_r64_r64_m64 = 126,

        /// <summary>
        /// andn r64, r64, r64 | VEX.LZ.0F38.W1 F2 /r | Bitwise AND of inverted r64b with r/m64, store result in r64a.
        /// </summary>
        [Symbol("andn r64, r64, r64","VEX.LZ.0F38.W1 F2 /r")]
        andn_r64_r64_r64 = 127,

        /// <summary>
        /// bextr r32, m32, r32 | VEX.LZ.0F38.W0 F7 /r | Contiguous bitwise extract from r/m32 using r32b as control; store result in r32a.
        /// </summary>
        [Symbol("bextr r32, m32, r32","VEX.LZ.0F38.W0 F7 /r")]
        bextr_r32_m32_r32 = 128,

        /// <summary>
        /// bextr r32, r32, r32 | VEX.LZ.0F38.W0 F7 /r | Contiguous bitwise extract from r/m32 using r32b as control; store result in r32a.
        /// </summary>
        [Symbol("bextr r32, r32, r32","VEX.LZ.0F38.W0 F7 /r")]
        bextr_r32_r32_r32 = 129,

        /// <summary>
        /// bextr r64, m64, r64 | VEX.LZ.0F38.W1 F7 /r | Contiguous bitwise extract from r/m64 using r64b as control; store result in r64a
        /// </summary>
        [Symbol("bextr r64, m64, r64","VEX.LZ.0F38.W1 F7 /r")]
        bextr_r64_m64_r64 = 130,

        /// <summary>
        /// bextr r64, r64, r64 | VEX.LZ.0F38.W1 F7 /r | Contiguous bitwise extract from r/m64 using r64b as control; store result in r64a
        /// </summary>
        [Symbol("bextr r64, r64, r64","VEX.LZ.0F38.W1 F7 /r")]
        bextr_r64_r64_r64 = 131,

        /// <summary>
        /// blsi r32, m32 | VEX.LZ.0F38.W0 F3 /3 | Extract lowest set bit from r/m32 and set that bit in r32.
        /// </summary>
        [Symbol("blsi r32, m32","VEX.LZ.0F38.W0 F3 /3")]
        blsi_r32_m32 = 132,

        /// <summary>
        /// blsi r32, r32 | VEX.LZ.0F38.W0 F3 /3 | Extract lowest set bit from r/m32 and set that bit in r32.
        /// </summary>
        [Symbol("blsi r32, r32","VEX.LZ.0F38.W0 F3 /3")]
        blsi_r32_r32 = 133,

        /// <summary>
        /// blsi r64, m64 | VEX.LZ.0F38.W1 F3 /3 | Extract lowest set bit from r/m64, and set that bit in r64.
        /// </summary>
        [Symbol("blsi r64, m64","VEX.LZ.0F38.W1 F3 /3")]
        blsi_r64_m64 = 134,

        /// <summary>
        /// blsi r64, r64 | VEX.LZ.0F38.W1 F3 /3 | Extract lowest set bit from r/m64, and set that bit in r64.
        /// </summary>
        [Symbol("blsi r64, r64","VEX.LZ.0F38.W1 F3 /3")]
        blsi_r64_r64 = 135,

        /// <summary>
        /// blsmsk r32, m32 | VEX.LZ.0F38.W0 F3 /2 | Set all lower bits in r32 to “1” starting from bit 0 to lowest set bit in r/m32.
        /// </summary>
        [Symbol("blsmsk r32, m32","VEX.LZ.0F38.W0 F3 /2")]
        blsmsk_r32_m32 = 136,

        /// <summary>
        /// blsmsk r32, r32 | VEX.LZ.0F38.W0 F3 /2 | Set all lower bits in r32 to “1” starting from bit 0 to lowest set bit in r/m32.
        /// </summary>
        [Symbol("blsmsk r32, r32","VEX.LZ.0F38.W0 F3 /2")]
        blsmsk_r32_r32 = 137,

        /// <summary>
        /// blsmsk r64, m64 | VEX.LZ.0F38.W1 F3 /2 | Set all lower bits in r64 to “1” starting from bit 0 to lowest set bit in r/m64.
        /// </summary>
        [Symbol("blsmsk r64, m64","VEX.LZ.0F38.W1 F3 /2")]
        blsmsk_r64_m64 = 138,

        /// <summary>
        /// blsmsk r64, r64 | VEX.LZ.0F38.W1 F3 /2 | Set all lower bits in r64 to “1” starting from bit 0 to lowest set bit in r/m64.
        /// </summary>
        [Symbol("blsmsk r64, r64","VEX.LZ.0F38.W1 F3 /2")]
        blsmsk_r64_r64 = 139,

        /// <summary>
        /// blsr r32, m32 | VEX.LZ.0F38.W0 F3 /1 | Reset lowest set bit of r/m32, keep all other bits of r/m32 and write result to r32.
        /// </summary>
        [Symbol("blsr r32, m32","VEX.LZ.0F38.W0 F3 /1")]
        blsr_r32_m32 = 140,

        /// <summary>
        /// blsr r32, r32 | VEX.LZ.0F38.W0 F3 /1 | Reset lowest set bit of r/m32, keep all other bits of r/m32 and write result to r32.
        /// </summary>
        [Symbol("blsr r32, r32","VEX.LZ.0F38.W0 F3 /1")]
        blsr_r32_r32 = 141,

        /// <summary>
        /// blsr r64, m64 | VEX.LZ.0F38.W1 F3 /1 | Reset lowest set bit of r/m64, keep all other bits of r/m64 and write result to r64.
        /// </summary>
        [Symbol("blsr r64, m64","VEX.LZ.0F38.W1 F3 /1")]
        blsr_r64_m64 = 142,

        /// <summary>
        /// blsr r64, r64 | VEX.LZ.0F38.W1 F3 /1 | Reset lowest set bit of r/m64, keep all other bits of r/m64 and write result to r64.
        /// </summary>
        [Symbol("blsr r64, r64","VEX.LZ.0F38.W1 F3 /1")]
        blsr_r64_r64 = 143,

        /// <summary>
        /// bndldx BND, mib | NP 0F 1A /r | Load the bounds stored in a bound table entry (BTE) into bnd with address translation using the base of mib and conditional on the index of mib matching the pointer value in the BTE.
        /// </summary>
        [Symbol("bndldx BND, mib","NP 0F 1A /r")]
        bndldx_BND_mib = 144,

        /// <summary>
        /// bndstx mib, BND | NP 0F 1B /r | Store the bounds in bnd and the pointer value in the index register of mib to a bound table entry (BTE) with address translation using the base of mib.
        /// </summary>
        [Symbol("bndstx mib, BND","NP 0F 1B /r")]
        bndstx_mib_BND = 145,

        /// <summary>
        /// bsf r16, m16 | 0F BC /r | Bit scan forward on r/m16.
        /// </summary>
        [Symbol("bsf r16, m16","0F BC /r")]
        bsf_r16_m16 = 146,

        /// <summary>
        /// bsf r16, r16 | 0F BC /r | Bit scan forward on r/m16.
        /// </summary>
        [Symbol("bsf r16, r16","0F BC /r")]
        bsf_r16_r16 = 147,

        /// <summary>
        /// bsf r32, m32 | 0F BC /r | Bit scan forward on r/m32.
        /// </summary>
        [Symbol("bsf r32, m32","0F BC /r")]
        bsf_r32_m32 = 148,

        /// <summary>
        /// bsf r32, r32 | 0F BC /r | Bit scan forward on r/m32.
        /// </summary>
        [Symbol("bsf r32, r32","0F BC /r")]
        bsf_r32_r32 = 149,

        /// <summary>
        /// bsf r64, m64 | REX.W + 0F BC /r | Bit scan forward on r/m64.
        /// </summary>
        [Symbol("bsf r64, m64","REX.W + 0F BC /r")]
        bsf_r64_m64 = 150,

        /// <summary>
        /// bsf r64, r64 | REX.W + 0F BC /r | Bit scan forward on r/m64.
        /// </summary>
        [Symbol("bsf r64, r64","REX.W + 0F BC /r")]
        bsf_r64_r64 = 151,

        /// <summary>
        /// bsr r16, m16 | 0F BD /r | Bit scan reverse on r/m16.
        /// </summary>
        [Symbol("bsr r16, m16","0F BD /r")]
        bsr_r16_m16 = 152,

        /// <summary>
        /// bsr r16, r16 | 0F BD /r | Bit scan reverse on r/m16.
        /// </summary>
        [Symbol("bsr r16, r16","0F BD /r")]
        bsr_r16_r16 = 153,

        /// <summary>
        /// bsr r32, m32 | 0F BD /r | Bit scan reverse on r/m32.
        /// </summary>
        [Symbol("bsr r32, m32","0F BD /r")]
        bsr_r32_m32 = 154,

        /// <summary>
        /// bsr r32, r32 | 0F BD /r | Bit scan reverse on r/m32.
        /// </summary>
        [Symbol("bsr r32, r32","0F BD /r")]
        bsr_r32_r32 = 155,

        /// <summary>
        /// bsr r64, m64 | REX.W + 0F BD /r | Bit scan reverse on r/m64.
        /// </summary>
        [Symbol("bsr r64, m64","REX.W + 0F BD /r")]
        bsr_r64_m64 = 156,

        /// <summary>
        /// bsr r64, r64 | REX.W + 0F BD /r | Bit scan reverse on r/m64.
        /// </summary>
        [Symbol("bsr r64, r64","REX.W + 0F BD /r")]
        bsr_r64_r64 = 157,

        /// <summary>
        /// bswap r32 | 0F C8 +rd | Reverses the byte order of a 32-bit register.
        /// </summary>
        [Symbol("bswap r32","0F C8 +rd")]
        bswap_r32 = 158,

        /// <summary>
        /// bswap r64 | REX.W + 0F C8 +rd | Reverses the byte order of a 64-bit register.
        /// </summary>
        [Symbol("bswap r64","REX.W + 0F C8 +rd")]
        bswap_r64 = 159,

        /// <summary>
        /// bt m16, imm8 | 0F BA /4 ib | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt m16, imm8","0F BA /4 ib")]
        bt_m16_imm8 = 160,

        /// <summary>
        /// bt m16, r16 | 0F A3 /r | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt m16, r16","0F A3 /r")]
        bt_m16_r16 = 161,

        /// <summary>
        /// bt m32, imm8 | 0F BA /4 ib | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt m32, imm8","0F BA /4 ib")]
        bt_m32_imm8 = 162,

        /// <summary>
        /// bt m32, r32 | 0F A3 /r | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt m32, r32","0F A3 /r")]
        bt_m32_r32 = 163,

        /// <summary>
        /// bt m64, imm8 | REX.W + 0F BA /4 ib | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt m64, imm8","REX.W + 0F BA /4 ib")]
        bt_m64_imm8 = 164,

        /// <summary>
        /// bt m64, r64 | REX.W + 0F A3 /r | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt m64, r64","REX.W + 0F A3 /r")]
        bt_m64_r64 = 165,

        /// <summary>
        /// bt r16, imm8 | 0F BA /4 ib | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt r16, imm8","0F BA /4 ib")]
        bt_r16_imm8 = 166,

        /// <summary>
        /// bt r16, r16 | 0F A3 /r | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt r16, r16","0F A3 /r")]
        bt_r16_r16 = 167,

        /// <summary>
        /// bt r32, imm8 | 0F BA /4 ib | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt r32, imm8","0F BA /4 ib")]
        bt_r32_imm8 = 168,

        /// <summary>
        /// bt r32, r32 | 0F A3 /r | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt r32, r32","0F A3 /r")]
        bt_r32_r32 = 169,

        /// <summary>
        /// bt r64, imm8 | REX.W + 0F BA /4 ib | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt r64, imm8","REX.W + 0F BA /4 ib")]
        bt_r64_imm8 = 170,

        /// <summary>
        /// bt r64, r64 | REX.W + 0F A3 /r | Store selected bit in CF flag.
        /// </summary>
        [Symbol("bt r64, r64","REX.W + 0F A3 /r")]
        bt_r64_r64 = 171,

        /// <summary>
        /// btc m16, imm8 | 0F BA /7 ib | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc m16, imm8","0F BA /7 ib")]
        btc_m16_imm8 = 172,

        /// <summary>
        /// btc m16, r16 | 0F BB /r | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc m16, r16","0F BB /r")]
        btc_m16_r16 = 173,

        /// <summary>
        /// btc m32, imm8 | 0F BA /7 ib | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc m32, imm8","0F BA /7 ib")]
        btc_m32_imm8 = 174,

        /// <summary>
        /// btc m32, r32 | 0F BB /r | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc m32, r32","0F BB /r")]
        btc_m32_r32 = 175,

        /// <summary>
        /// btc m64, imm8 | REX.W + 0F BA /7 ib | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc m64, imm8","REX.W + 0F BA /7 ib")]
        btc_m64_imm8 = 176,

        /// <summary>
        /// btc m64, r64 | REX.W + 0F BB /r | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc m64, r64","REX.W + 0F BB /r")]
        btc_m64_r64 = 177,

        /// <summary>
        /// btc r16, imm8 | 0F BA /7 ib | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc r16, imm8","0F BA /7 ib")]
        btc_r16_imm8 = 178,

        /// <summary>
        /// btc r16, r16 | 0F BB /r | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc r16, r16","0F BB /r")]
        btc_r16_r16 = 179,

        /// <summary>
        /// btc r32, imm8 | 0F BA /7 ib | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc r32, imm8","0F BA /7 ib")]
        btc_r32_imm8 = 180,

        /// <summary>
        /// btc r32, r32 | 0F BB /r | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc r32, r32","0F BB /r")]
        btc_r32_r32 = 181,

        /// <summary>
        /// btc r64, imm8 | REX.W + 0F BA /7 ib | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc r64, imm8","REX.W + 0F BA /7 ib")]
        btc_r64_imm8 = 182,

        /// <summary>
        /// btc r64, r64 | REX.W + 0F BB /r | Store selected bit in CF flag and complement.
        /// </summary>
        [Symbol("btc r64, r64","REX.W + 0F BB /r")]
        btc_r64_r64 = 183,

        /// <summary>
        /// btr m16, imm8 | 0F BA /6 ib | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr m16, imm8","0F BA /6 ib")]
        btr_m16_imm8 = 184,

        /// <summary>
        /// btr m16, r16 | 0F B3 /r | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr m16, r16","0F B3 /r")]
        btr_m16_r16 = 185,

        /// <summary>
        /// btr m32, imm8 | 0F BA /6 ib | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr m32, imm8","0F BA /6 ib")]
        btr_m32_imm8 = 186,

        /// <summary>
        /// btr m32, r32 | 0F B3 /r | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr m32, r32","0F B3 /r")]
        btr_m32_r32 = 187,

        /// <summary>
        /// btr m64, imm8 | REX.W + 0F BA /6 ib | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr m64, imm8","REX.W + 0F BA /6 ib")]
        btr_m64_imm8 = 188,

        /// <summary>
        /// btr m64, r64 | REX.W + 0F B3 /r | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr m64, r64","REX.W + 0F B3 /r")]
        btr_m64_r64 = 189,

        /// <summary>
        /// btr r16, imm8 | 0F BA /6 ib | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr r16, imm8","0F BA /6 ib")]
        btr_r16_imm8 = 190,

        /// <summary>
        /// btr r16, r16 | 0F B3 /r | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr r16, r16","0F B3 /r")]
        btr_r16_r16 = 191,

        /// <summary>
        /// btr r32, imm8 | 0F BA /6 ib | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr r32, imm8","0F BA /6 ib")]
        btr_r32_imm8 = 192,

        /// <summary>
        /// btr r32, r32 | 0F B3 /r | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr r32, r32","0F B3 /r")]
        btr_r32_r32 = 193,

        /// <summary>
        /// btr r64, imm8 | REX.W + 0F BA /6 ib | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr r64, imm8","REX.W + 0F BA /6 ib")]
        btr_r64_imm8 = 194,

        /// <summary>
        /// btr r64, r64 | REX.W + 0F B3 /r | Store selected bit in CF flag and clear.
        /// </summary>
        [Symbol("btr r64, r64","REX.W + 0F B3 /r")]
        btr_r64_r64 = 195,

        /// <summary>
        /// bts m16, imm8 | 0F BA /5 ib | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts m16, imm8","0F BA /5 ib")]
        bts_m16_imm8 = 196,

        /// <summary>
        /// bts m16, r16 | 0F AB /r | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts m16, r16","0F AB /r")]
        bts_m16_r16 = 197,

        /// <summary>
        /// bts m32, imm8 | 0F BA /5 ib | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts m32, imm8","0F BA /5 ib")]
        bts_m32_imm8 = 198,

        /// <summary>
        /// bts m32, r32 | 0F AB /r | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts m32, r32","0F AB /r")]
        bts_m32_r32 = 199,

        /// <summary>
        /// bts m64, imm8 | REX.W + 0F BA /5 ib | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts m64, imm8","REX.W + 0F BA /5 ib")]
        bts_m64_imm8 = 200,

        /// <summary>
        /// bts m64, r64 | REX.W + 0F AB /r | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts m64, r64","REX.W + 0F AB /r")]
        bts_m64_r64 = 201,

        /// <summary>
        /// bts r16, imm8 | 0F BA /5 ib | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts r16, imm8","0F BA /5 ib")]
        bts_r16_imm8 = 202,

        /// <summary>
        /// bts r16, r16 | 0F AB /r | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts r16, r16","0F AB /r")]
        bts_r16_r16 = 203,

        /// <summary>
        /// bts r32, imm8 | 0F BA /5 ib | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts r32, imm8","0F BA /5 ib")]
        bts_r32_imm8 = 204,

        /// <summary>
        /// bts r32, r32 | 0F AB /r | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts r32, r32","0F AB /r")]
        bts_r32_r32 = 205,

        /// <summary>
        /// bts r64, imm8 | REX.W + 0F BA /5 ib | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts r64, imm8","REX.W + 0F BA /5 ib")]
        bts_r64_imm8 = 206,

        /// <summary>
        /// bts r64, r64 | REX.W + 0F AB /r | Store selected bit in CF flag and set.
        /// </summary>
        [Symbol("bts r64, r64","REX.W + 0F AB /r")]
        bts_r64_r64 = 207,

        /// <summary>
        /// bzhi r32, m32, r32 | VEX.LZ.0F38.W0 F5 /r | Zero bits in r/m32 starting with the position in r32b, write result to r32a.
        /// </summary>
        [Symbol("bzhi r32, m32, r32","VEX.LZ.0F38.W0 F5 /r")]
        bzhi_r32_m32_r32 = 208,

        /// <summary>
        /// bzhi r32, r32, r32 | VEX.LZ.0F38.W0 F5 /r | Zero bits in r/m32 starting with the position in r32b, write result to r32a.
        /// </summary>
        [Symbol("bzhi r32, r32, r32","VEX.LZ.0F38.W0 F5 /r")]
        bzhi_r32_r32_r32 = 209,

        /// <summary>
        /// bzhi r64, m64, r64 | VEX.LZ.0F38.W1 F5 /r | Zero bits in r/m64 starting with the position in r64b, write result to r64a.
        /// </summary>
        [Symbol("bzhi r64, m64, r64","VEX.LZ.0F38.W1 F5 /r")]
        bzhi_r64_m64_r64 = 210,

        /// <summary>
        /// bzhi r64, r64, r64 | VEX.LZ.0F38.W1 F5 /r | Zero bits in r/m64 starting with the position in r64b, write result to r64a.
        /// </summary>
        [Symbol("bzhi r64, r64, r64","VEX.LZ.0F38.W1 F5 /r")]
        bzhi_r64_r64_r64 = 211,

        /// <summary>
        /// call m16 | FF /2 | Call near, absolute indirect, address given in r/m16.
        /// </summary>
        [Symbol("call m16","FF /2")]
        call_m16 = 212,

        /// <summary>
        /// call m32 | FF /2 | Call near, absolute indirect, address given in r/m32.
        /// </summary>
        [Symbol("call m32","FF /2")]
        call_m32 = 213,

        /// <summary>
        /// call m64 | FF /2 | Call near, absolute indirect, address given in r/m 64.
        /// </summary>
        [Symbol("call m64","FF /2")]
        call_m64 = 214,

        /// <summary>
        /// call m16:16 | FF /3 | Call far, absolute indirect address given in m16:16. In 32-bit mode: if selector points to a gate, then RIP = 32-bit zero extended displacement taken from gate; else RIP = zero extended 16-bit offset from far pointer referenced in the instruction.
        /// </summary>
        [Symbol("call m16:16","FF /3")]
        call_mp16x16 = 215,

        /// <summary>
        /// call m16:32 | FF /3 | In 64-bit mode: If selector points to a gate, then RIP = 64-bit displacement taken from gate; else RIP = zero extended 32-bit offset from far pointer referenced in the instruction.
        /// </summary>
        [Symbol("call m16:32","FF /3")]
        call_mp16x32 = 216,

        /// <summary>
        /// call m16:64 | REX.W FF /3 | In 64-bit mode: If selector points to a gate, then RIP = 64-bit displacement taken from gate; else RIP = 64-bit offset from far pointer referenced in the instruction.
        /// </summary>
        [Symbol("call m16:64","REX.W FF /3")]
        call_mp16x64 = 217,

        /// <summary>
        /// call ptr16:16 | 9A cd | Call far, absolute, address given in operand.
        /// </summary>
        [Symbol("call ptr16:16","9A cd")]
        call_p16x16 = 218,

        /// <summary>
        /// call ptr16:32 | 9A cp | Call far, absolute, address given in operand.
        /// </summary>
        [Symbol("call ptr16:32","9A cp")]
        call_p16x32 = 219,

        /// <summary>
        /// call r16 | FF /2 | Call near, absolute indirect, address given in r/m16.
        /// </summary>
        [Symbol("call r16","FF /2")]
        call_r16 = 220,

        /// <summary>
        /// call r32 | FF /2 | Call near, absolute indirect, address given in r/m32.
        /// </summary>
        [Symbol("call r32","FF /2")]
        call_r32 = 221,

        /// <summary>
        /// call r64 | FF /2 | Call near, absolute indirect, address given in r/m 64.
        /// </summary>
        [Symbol("call r64","FF /2")]
        call_r64 = 222,

        /// <summary>
        /// call rel16 | E8 cw | Call near, relative, displacement relative to next instruction.
        /// </summary>
        [Symbol("call rel16","E8 cw")]
        call_rel16 = 223,

        /// <summary>
        /// call rel32 | E8 cd | Call near, relative, displacement relative to next instruction. 32-bit displacement sign extended to 64-bits in 64-bit mode.
        /// </summary>
        [Symbol("call rel32","E8 cd")]
        call_rel32 = 224,

        /// <summary>
        /// cbw | 98 | AX ← sign-extend of AL.
        /// </summary>
        [Symbol("cbw","98")]
        cbw = 225,

        /// <summary>
        /// cdq | 99 | EDX:EAX ← sign-extend of EAX.
        /// </summary>
        [Symbol("cdq","99")]
        cdq = 226,

        /// <summary>
        /// cdqe | REX.W + 98 | RAX ← sign-extend of EAX.
        /// </summary>
        [Symbol("cdqe","REX.W + 98")]
        cdqe = 227,

        /// <summary>
        /// clc | F8 | Clear CF flag.
        /// </summary>
        [Symbol("clc","F8")]
        clc = 228,

        /// <summary>
        /// cli | FA | Clear interrupt flag; interrupts disabled when interrupt flag cleared.
        /// </summary>
        [Symbol("cli","FA")]
        cli = 229,

        /// <summary>
        /// clts | 0F 06 | Clears TS flag in CR0.
        /// </summary>
        [Symbol("clts","0F 06")]
        clts = 230,

        /// <summary>
        /// cmc | F5 | Complement CF flag.
        /// </summary>
        [Symbol("cmc","F5")]
        cmc = 231,

        /// <summary>
        /// cmova r16, m16 | 0F 47 /r | Move if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmova r16, m16","0F 47 /r")]
        cmova_r16_m16 = 232,

        /// <summary>
        /// cmova r16, r16 | 0F 47 /r | Move if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmova r16, r16","0F 47 /r")]
        cmova_r16_r16 = 233,

        /// <summary>
        /// cmova r32, m32 | 0F 47 /r | Move if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmova r32, m32","0F 47 /r")]
        cmova_r32_m32 = 234,

        /// <summary>
        /// cmova r32, r32 | 0F 47 /r | Move if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmova r32, r32","0F 47 /r")]
        cmova_r32_r32 = 235,

        /// <summary>
        /// cmova r64, m64 | REX.W + 0F 47 /r | Move if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmova r64, m64","REX.W + 0F 47 /r")]
        cmova_r64_m64 = 236,

        /// <summary>
        /// cmova r64, r64 | REX.W + 0F 47 /r | Move if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmova r64, r64","REX.W + 0F 47 /r")]
        cmova_r64_r64 = 237,

        /// <summary>
        /// cmovae r16, m16 | 0F 43 /r | Move if above or equal (CF=0).
        /// </summary>
        [Symbol("cmovae r16, m16","0F 43 /r")]
        cmovae_r16_m16 = 238,

        /// <summary>
        /// cmovae r16, r16 | 0F 43 /r | Move if above or equal (CF=0).
        /// </summary>
        [Symbol("cmovae r16, r16","0F 43 /r")]
        cmovae_r16_r16 = 239,

        /// <summary>
        /// cmovae r32, m32 | 0F 43 /r | Move if above or equal (CF=0).
        /// </summary>
        [Symbol("cmovae r32, m32","0F 43 /r")]
        cmovae_r32_m32 = 240,

        /// <summary>
        /// cmovae r32, r32 | 0F 43 /r | Move if above or equal (CF=0).
        /// </summary>
        [Symbol("cmovae r32, r32","0F 43 /r")]
        cmovae_r32_r32 = 241,

        /// <summary>
        /// cmovae r64, m64 | REX.W + 0F 43 /r | Move if above or equal (CF=0).
        /// </summary>
        [Symbol("cmovae r64, m64","REX.W + 0F 43 /r")]
        cmovae_r64_m64 = 242,

        /// <summary>
        /// cmovae r64, r64 | REX.W + 0F 43 /r | Move if above or equal (CF=0).
        /// </summary>
        [Symbol("cmovae r64, r64","REX.W + 0F 43 /r")]
        cmovae_r64_r64 = 243,

        /// <summary>
        /// cmovb r16, m16 | 0F 42 /r | Move if below (CF=1).
        /// </summary>
        [Symbol("cmovb r16, m16","0F 42 /r")]
        cmovb_r16_m16 = 244,

        /// <summary>
        /// cmovb r16, r16 | 0F 42 /r | Move if below (CF=1).
        /// </summary>
        [Symbol("cmovb r16, r16","0F 42 /r")]
        cmovb_r16_r16 = 245,

        /// <summary>
        /// cmovb r32, m32 | 0F 42 /r | Move if below (CF=1).
        /// </summary>
        [Symbol("cmovb r32, m32","0F 42 /r")]
        cmovb_r32_m32 = 246,

        /// <summary>
        /// cmovb r32, r32 | 0F 42 /r | Move if below (CF=1).
        /// </summary>
        [Symbol("cmovb r32, r32","0F 42 /r")]
        cmovb_r32_r32 = 247,

        /// <summary>
        /// cmovb r64, m64 | REX.W + 0F 42 /r | Move if below (CF=1).
        /// </summary>
        [Symbol("cmovb r64, m64","REX.W + 0F 42 /r")]
        cmovb_r64_m64 = 248,

        /// <summary>
        /// cmovb r64, r64 | REX.W + 0F 42 /r | Move if below (CF=1).
        /// </summary>
        [Symbol("cmovb r64, r64","REX.W + 0F 42 /r")]
        cmovb_r64_r64 = 249,

        /// <summary>
        /// cmovbe r16, m16 | 0F 46 /r | Move if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovbe r16, m16","0F 46 /r")]
        cmovbe_r16_m16 = 250,

        /// <summary>
        /// cmovbe r16, r16 | 0F 46 /r | Move if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovbe r16, r16","0F 46 /r")]
        cmovbe_r16_r16 = 251,

        /// <summary>
        /// cmovbe r32, m32 | 0F 46 /r | Move if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovbe r32, m32","0F 46 /r")]
        cmovbe_r32_m32 = 252,

        /// <summary>
        /// cmovbe r32, r32 | 0F 46 /r | Move if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovbe r32, r32","0F 46 /r")]
        cmovbe_r32_r32 = 253,

        /// <summary>
        /// cmovbe r64, m64 | REX.W + 0F 46 /r | Move if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovbe r64, m64","REX.W + 0F 46 /r")]
        cmovbe_r64_m64 = 254,

        /// <summary>
        /// cmovbe r64, r64 | REX.W + 0F 46 /r | Move if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovbe r64, r64","REX.W + 0F 46 /r")]
        cmovbe_r64_r64 = 255,

        /// <summary>
        /// cmovc r16, m16 | 0F 42 /r | Move if carry (CF=1).
        /// </summary>
        [Symbol("cmovc r16, m16","0F 42 /r")]
        cmovc_r16_m16 = 256,

        /// <summary>
        /// cmovc r16, r16 | 0F 42 /r | Move if carry (CF=1).
        /// </summary>
        [Symbol("cmovc r16, r16","0F 42 /r")]
        cmovc_r16_r16 = 257,

        /// <summary>
        /// cmovc r32, m32 | 0F 42 /r | Move if carry (CF=1).
        /// </summary>
        [Symbol("cmovc r32, m32","0F 42 /r")]
        cmovc_r32_m32 = 258,

        /// <summary>
        /// cmovc r32, r32 | 0F 42 /r | Move if carry (CF=1).
        /// </summary>
        [Symbol("cmovc r32, r32","0F 42 /r")]
        cmovc_r32_r32 = 259,

        /// <summary>
        /// cmovc r64, m64 | REX.W + 0F 42 /r | Move if carry (CF=1).
        /// </summary>
        [Symbol("cmovc r64, m64","REX.W + 0F 42 /r")]
        cmovc_r64_m64 = 260,

        /// <summary>
        /// cmovc r64, r64 | REX.W + 0F 42 /r | Move if carry (CF=1).
        /// </summary>
        [Symbol("cmovc r64, r64","REX.W + 0F 42 /r")]
        cmovc_r64_r64 = 261,

        /// <summary>
        /// cmove r16, m16 | 0F 44 /r | Move if equal (ZF=1).
        /// </summary>
        [Symbol("cmove r16, m16","0F 44 /r")]
        cmove_r16_m16 = 262,

        /// <summary>
        /// cmove r16, r16 | 0F 44 /r | Move if equal (ZF=1).
        /// </summary>
        [Symbol("cmove r16, r16","0F 44 /r")]
        cmove_r16_r16 = 263,

        /// <summary>
        /// cmove r32, m32 | 0F 44 /r | Move if equal (ZF=1).
        /// </summary>
        [Symbol("cmove r32, m32","0F 44 /r")]
        cmove_r32_m32 = 264,

        /// <summary>
        /// cmove r32, r32 | 0F 44 /r | Move if equal (ZF=1).
        /// </summary>
        [Symbol("cmove r32, r32","0F 44 /r")]
        cmove_r32_r32 = 265,

        /// <summary>
        /// cmove r64, m64 | REX.W + 0F 44 /r | Move if equal (ZF=1).
        /// </summary>
        [Symbol("cmove r64, m64","REX.W + 0F 44 /r")]
        cmove_r64_m64 = 266,

        /// <summary>
        /// cmove r64, r64 | REX.W + 0F 44 /r | Move if equal (ZF=1).
        /// </summary>
        [Symbol("cmove r64, r64","REX.W + 0F 44 /r")]
        cmove_r64_r64 = 267,

        /// <summary>
        /// cmovg r16, m16 | 0F 4F /r | Move if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovg r16, m16","0F 4F /r")]
        cmovg_r16_m16 = 268,

        /// <summary>
        /// cmovg r16, r16 | 0F 4F /r | Move if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovg r16, r16","0F 4F /r")]
        cmovg_r16_r16 = 269,

        /// <summary>
        /// cmovg r32, m32 | 0F 4F /r | Move if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovg r32, m32","0F 4F /r")]
        cmovg_r32_m32 = 270,

        /// <summary>
        /// cmovg r32, r32 | 0F 4F /r | Move if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovg r32, r32","0F 4F /r")]
        cmovg_r32_r32 = 271,

        /// <summary>
        /// cmovg r64, m64 | REX.W + 0F 4F /r | Move if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovg r64, m64","REX.W + 0F 4F /r")]
        cmovg_r64_m64 = 272,

        /// <summary>
        /// cmovg r64, r64 | REX.W + 0F 4F /r | Move if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovg r64, r64","REX.W + 0F 4F /r")]
        cmovg_r64_r64 = 273,

        /// <summary>
        /// cmovge r16, m16 | 0F 4D /r | Move if greater or equal (SF=OF).
        /// </summary>
        [Symbol("cmovge r16, m16","0F 4D /r")]
        cmovge_r16_m16 = 274,

        /// <summary>
        /// cmovge r16, r16 | 0F 4D /r | Move if greater or equal (SF=OF).
        /// </summary>
        [Symbol("cmovge r16, r16","0F 4D /r")]
        cmovge_r16_r16 = 275,

        /// <summary>
        /// cmovge r32, m32 | 0F 4D /r | Move if greater or equal (SF=OF).
        /// </summary>
        [Symbol("cmovge r32, m32","0F 4D /r")]
        cmovge_r32_m32 = 276,

        /// <summary>
        /// cmovge r32, r32 | 0F 4D /r | Move if greater or equal (SF=OF).
        /// </summary>
        [Symbol("cmovge r32, r32","0F 4D /r")]
        cmovge_r32_r32 = 277,

        /// <summary>
        /// cmovge r64, m64 | REX.W + 0F 4D /r | Move if greater or equal (SF=OF).
        /// </summary>
        [Symbol("cmovge r64, m64","REX.W + 0F 4D /r")]
        cmovge_r64_m64 = 278,

        /// <summary>
        /// cmovge r64, r64 | REX.W + 0F 4D /r | Move if greater or equal (SF=OF).
        /// </summary>
        [Symbol("cmovge r64, r64","REX.W + 0F 4D /r")]
        cmovge_r64_r64 = 279,

        /// <summary>
        /// cmovl r16, m16 | 0F 4C /r | Move if less (SF!= OF).
        /// </summary>
        [Symbol("cmovl r16, m16","0F 4C /r")]
        cmovl_r16_m16 = 280,

        /// <summary>
        /// cmovl r16, r16 | 0F 4C /r | Move if less (SF!= OF).
        /// </summary>
        [Symbol("cmovl r16, r16","0F 4C /r")]
        cmovl_r16_r16 = 281,

        /// <summary>
        /// cmovl r32, m32 | 0F 4C /r | Move if less (SF!= OF).
        /// </summary>
        [Symbol("cmovl r32, m32","0F 4C /r")]
        cmovl_r32_m32 = 282,

        /// <summary>
        /// cmovl r32, r32 | 0F 4C /r | Move if less (SF!= OF).
        /// </summary>
        [Symbol("cmovl r32, r32","0F 4C /r")]
        cmovl_r32_r32 = 283,

        /// <summary>
        /// cmovl r64, m64 | REX.W + 0F 4C /r | Move if less (SF!= OF).
        /// </summary>
        [Symbol("cmovl r64, m64","REX.W + 0F 4C /r")]
        cmovl_r64_m64 = 284,

        /// <summary>
        /// cmovl r64, r64 | REX.W + 0F 4C /r | Move if less (SF!= OF).
        /// </summary>
        [Symbol("cmovl r64, r64","REX.W + 0F 4C /r")]
        cmovl_r64_r64 = 285,

        /// <summary>
        /// cmovle r16, m16 | 0F 4E /r | Move if less or equal (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovle r16, m16","0F 4E /r")]
        cmovle_r16_m16 = 286,

        /// <summary>
        /// cmovle r16, r16 | 0F 4E /r | Move if less or equal (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovle r16, r16","0F 4E /r")]
        cmovle_r16_r16 = 287,

        /// <summary>
        /// cmovle r32, m32 | 0F 4E /r | Move if less or equal (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovle r32, m32","0F 4E /r")]
        cmovle_r32_m32 = 288,

        /// <summary>
        /// cmovle r32, r32 | 0F 4E /r | Move if less or equal (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovle r32, r32","0F 4E /r")]
        cmovle_r32_r32 = 289,

        /// <summary>
        /// cmovle r64, m64 | REX.W + 0F 4E /r | Move if less or equal (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovle r64, m64","REX.W + 0F 4E /r")]
        cmovle_r64_m64 = 290,

        /// <summary>
        /// cmovle r64, r64 | REX.W + 0F 4E /r | Move if less or equal (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovle r64, r64","REX.W + 0F 4E /r")]
        cmovle_r64_r64 = 291,

        /// <summary>
        /// cmovna r16, m16 | 0F 46 /r | Move if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovna r16, m16","0F 46 /r")]
        cmovna_r16_m16 = 292,

        /// <summary>
        /// cmovna r16, r16 | 0F 46 /r | Move if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovna r16, r16","0F 46 /r")]
        cmovna_r16_r16 = 293,

        /// <summary>
        /// cmovna r32, m32 | 0F 46 /r | Move if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovna r32, m32","0F 46 /r")]
        cmovna_r32_m32 = 294,

        /// <summary>
        /// cmovna r32, r32 | 0F 46 /r | Move if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovna r32, r32","0F 46 /r")]
        cmovna_r32_r32 = 295,

        /// <summary>
        /// cmovna r64, m64 | REX.W + 0F 46 /r | Move if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovna r64, m64","REX.W + 0F 46 /r")]
        cmovna_r64_m64 = 296,

        /// <summary>
        /// cmovna r64, r64 | REX.W + 0F 46 /r | Move if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("cmovna r64, r64","REX.W + 0F 46 /r")]
        cmovna_r64_r64 = 297,

        /// <summary>
        /// cmovnae r16, m16 | 0F 42 /r | Move if not above or equal (CF=1).
        /// </summary>
        [Symbol("cmovnae r16, m16","0F 42 /r")]
        cmovnae_r16_m16 = 298,

        /// <summary>
        /// cmovnae r16, r16 | 0F 42 /r | Move if not above or equal (CF=1).
        /// </summary>
        [Symbol("cmovnae r16, r16","0F 42 /r")]
        cmovnae_r16_r16 = 299,

        /// <summary>
        /// cmovnae r32, m32 | 0F 42 /r | Move if not above or equal (CF=1).
        /// </summary>
        [Symbol("cmovnae r32, m32","0F 42 /r")]
        cmovnae_r32_m32 = 300,

        /// <summary>
        /// cmovnae r32, r32 | 0F 42 /r | Move if not above or equal (CF=1).
        /// </summary>
        [Symbol("cmovnae r32, r32","0F 42 /r")]
        cmovnae_r32_r32 = 301,

        /// <summary>
        /// cmovnae r64, m64 | REX.W + 0F 42 /r | Move if not above or equal (CF=1).
        /// </summary>
        [Symbol("cmovnae r64, m64","REX.W + 0F 42 /r")]
        cmovnae_r64_m64 = 302,

        /// <summary>
        /// cmovnae r64, r64 | REX.W + 0F 42 /r | Move if not above or equal (CF=1).
        /// </summary>
        [Symbol("cmovnae r64, r64","REX.W + 0F 42 /r")]
        cmovnae_r64_r64 = 303,

        /// <summary>
        /// cmovnb r16, m16 | 0F 43 /r | Move if not below (CF=0).
        /// </summary>
        [Symbol("cmovnb r16, m16","0F 43 /r")]
        cmovnb_r16_m16 = 304,

        /// <summary>
        /// cmovnb r16, r16 | 0F 43 /r | Move if not below (CF=0).
        /// </summary>
        [Symbol("cmovnb r16, r16","0F 43 /r")]
        cmovnb_r16_r16 = 305,

        /// <summary>
        /// cmovnb r32, m32 | 0F 43 /r | Move if not below (CF=0).
        /// </summary>
        [Symbol("cmovnb r32, m32","0F 43 /r")]
        cmovnb_r32_m32 = 306,

        /// <summary>
        /// cmovnb r32, r32 | 0F 43 /r | Move if not below (CF=0).
        /// </summary>
        [Symbol("cmovnb r32, r32","0F 43 /r")]
        cmovnb_r32_r32 = 307,

        /// <summary>
        /// cmovnb r64, m64 | REX.W + 0F 43 /r | Move if not below (CF=0).
        /// </summary>
        [Symbol("cmovnb r64, m64","REX.W + 0F 43 /r")]
        cmovnb_r64_m64 = 308,

        /// <summary>
        /// cmovnb r64, r64 | REX.W + 0F 43 /r | Move if not below (CF=0).
        /// </summary>
        [Symbol("cmovnb r64, r64","REX.W + 0F 43 /r")]
        cmovnb_r64_r64 = 309,

        /// <summary>
        /// cmovnbe r16, m16 | 0F 47 /r | Move if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmovnbe r16, m16","0F 47 /r")]
        cmovnbe_r16_m16 = 310,

        /// <summary>
        /// cmovnbe r16, r16 | 0F 47 /r | Move if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmovnbe r16, r16","0F 47 /r")]
        cmovnbe_r16_r16 = 311,

        /// <summary>
        /// cmovnbe r32, m32 | 0F 47 /r | Move if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmovnbe r32, m32","0F 47 /r")]
        cmovnbe_r32_m32 = 312,

        /// <summary>
        /// cmovnbe r32, r32 | 0F 47 /r | Move if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmovnbe r32, r32","0F 47 /r")]
        cmovnbe_r32_r32 = 313,

        /// <summary>
        /// cmovnbe r64, m64 | REX.W + 0F 47 /r | Move if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmovnbe r64, m64","REX.W + 0F 47 /r")]
        cmovnbe_r64_m64 = 314,

        /// <summary>
        /// cmovnbe r64, r64 | REX.W + 0F 47 /r | Move if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("cmovnbe r64, r64","REX.W + 0F 47 /r")]
        cmovnbe_r64_r64 = 315,

        /// <summary>
        /// cmovnc r16, m16 | 0F 43 /r | Move if not carry (CF=0).
        /// </summary>
        [Symbol("cmovnc r16, m16","0F 43 /r")]
        cmovnc_r16_m16 = 316,

        /// <summary>
        /// cmovnc r16, r16 | 0F 43 /r | Move if not carry (CF=0).
        /// </summary>
        [Symbol("cmovnc r16, r16","0F 43 /r")]
        cmovnc_r16_r16 = 317,

        /// <summary>
        /// cmovnc r32, m32 | 0F 43 /r | Move if not carry (CF=0).
        /// </summary>
        [Symbol("cmovnc r32, m32","0F 43 /r")]
        cmovnc_r32_m32 = 318,

        /// <summary>
        /// cmovnc r32, r32 | 0F 43 /r | Move if not carry (CF=0).
        /// </summary>
        [Symbol("cmovnc r32, r32","0F 43 /r")]
        cmovnc_r32_r32 = 319,

        /// <summary>
        /// cmovnc r64, m64 | REX.W + 0F 43 /r | Move if not carry (CF=0).
        /// </summary>
        [Symbol("cmovnc r64, m64","REX.W + 0F 43 /r")]
        cmovnc_r64_m64 = 320,

        /// <summary>
        /// cmovnc r64, r64 | REX.W + 0F 43 /r | Move if not carry (CF=0).
        /// </summary>
        [Symbol("cmovnc r64, r64","REX.W + 0F 43 /r")]
        cmovnc_r64_r64 = 321,

        /// <summary>
        /// cmovne r16, m16 | 0F 45 /r | Move if not equal (ZF=0).
        /// </summary>
        [Symbol("cmovne r16, m16","0F 45 /r")]
        cmovne_r16_m16 = 322,

        /// <summary>
        /// cmovne r16, r16 | 0F 45 /r | Move if not equal (ZF=0).
        /// </summary>
        [Symbol("cmovne r16, r16","0F 45 /r")]
        cmovne_r16_r16 = 323,

        /// <summary>
        /// cmovne r32, m32 | 0F 45 /r | Move if not equal (ZF=0).
        /// </summary>
        [Symbol("cmovne r32, m32","0F 45 /r")]
        cmovne_r32_m32 = 324,

        /// <summary>
        /// cmovne r32, r32 | 0F 45 /r | Move if not equal (ZF=0).
        /// </summary>
        [Symbol("cmovne r32, r32","0F 45 /r")]
        cmovne_r32_r32 = 325,

        /// <summary>
        /// cmovne r64, m64 | REX.W + 0F 45 /r | Move if not equal (ZF=0).
        /// </summary>
        [Symbol("cmovne r64, m64","REX.W + 0F 45 /r")]
        cmovne_r64_m64 = 326,

        /// <summary>
        /// cmovne r64, r64 | REX.W + 0F 45 /r | Move if not equal (ZF=0).
        /// </summary>
        [Symbol("cmovne r64, r64","REX.W + 0F 45 /r")]
        cmovne_r64_r64 = 327,

        /// <summary>
        /// cmovng r16, m16 | 0F 4E /r | Move if not greater (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovng r16, m16","0F 4E /r")]
        cmovng_r16_m16 = 328,

        /// <summary>
        /// cmovng r16, r16 | 0F 4E /r | Move if not greater (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovng r16, r16","0F 4E /r")]
        cmovng_r16_r16 = 329,

        /// <summary>
        /// cmovng r32, m32 | 0F 4E /r | Move if not greater (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovng r32, m32","0F 4E /r")]
        cmovng_r32_m32 = 330,

        /// <summary>
        /// cmovng r32, r32 | 0F 4E /r | Move if not greater (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovng r32, r32","0F 4E /r")]
        cmovng_r32_r32 = 331,

        /// <summary>
        /// cmovng r64, m64 | REX.W + 0F 4E /r | Move if not greater (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovng r64, m64","REX.W + 0F 4E /r")]
        cmovng_r64_m64 = 332,

        /// <summary>
        /// cmovng r64, r64 | REX.W + 0F 4E /r | Move if not greater (ZF=1 or SF!= OF).
        /// </summary>
        [Symbol("cmovng r64, r64","REX.W + 0F 4E /r")]
        cmovng_r64_r64 = 333,

        /// <summary>
        /// cmovnge r16, m16 | 0F 4C /r | Move if not greater or equal (SF!= OF).
        /// </summary>
        [Symbol("cmovnge r16, m16","0F 4C /r")]
        cmovnge_r16_m16 = 334,

        /// <summary>
        /// cmovnge r16, r16 | 0F 4C /r | Move if not greater or equal (SF!= OF).
        /// </summary>
        [Symbol("cmovnge r16, r16","0F 4C /r")]
        cmovnge_r16_r16 = 335,

        /// <summary>
        /// cmovnge r32, m32 | 0F 4C /r | Move if not greater or equal (SF!= OF).
        /// </summary>
        [Symbol("cmovnge r32, m32","0F 4C /r")]
        cmovnge_r32_m32 = 336,

        /// <summary>
        /// cmovnge r32, r32 | 0F 4C /r | Move if not greater or equal (SF!= OF).
        /// </summary>
        [Symbol("cmovnge r32, r32","0F 4C /r")]
        cmovnge_r32_r32 = 337,

        /// <summary>
        /// cmovnge r64, m64 | REX.W + 0F 4C /r | Move if not greater or equal (SF!= OF).
        /// </summary>
        [Symbol("cmovnge r64, m64","REX.W + 0F 4C /r")]
        cmovnge_r64_m64 = 338,

        /// <summary>
        /// cmovnge r64, r64 | REX.W + 0F 4C /r | Move if not greater or equal (SF!= OF).
        /// </summary>
        [Symbol("cmovnge r64, r64","REX.W + 0F 4C /r")]
        cmovnge_r64_r64 = 339,

        /// <summary>
        /// cmovnl r16, m16 | 0F 4D /r | Move if not less (SF=OF).
        /// </summary>
        [Symbol("cmovnl r16, m16","0F 4D /r")]
        cmovnl_r16_m16 = 340,

        /// <summary>
        /// cmovnl r16, r16 | 0F 4D /r | Move if not less (SF=OF).
        /// </summary>
        [Symbol("cmovnl r16, r16","0F 4D /r")]
        cmovnl_r16_r16 = 341,

        /// <summary>
        /// cmovnl r32, m32 | 0F 4D /r | Move if not less (SF=OF).
        /// </summary>
        [Symbol("cmovnl r32, m32","0F 4D /r")]
        cmovnl_r32_m32 = 342,

        /// <summary>
        /// cmovnl r32, r32 | 0F 4D /r | Move if not less (SF=OF).
        /// </summary>
        [Symbol("cmovnl r32, r32","0F 4D /r")]
        cmovnl_r32_r32 = 343,

        /// <summary>
        /// cmovnl r64, m64 | REX.W + 0F 4D /r | Move if not less (SF=OF).
        /// </summary>
        [Symbol("cmovnl r64, m64","REX.W + 0F 4D /r")]
        cmovnl_r64_m64 = 344,

        /// <summary>
        /// cmovnl r64, r64 | REX.W + 0F 4D /r | Move if not less (SF=OF).
        /// </summary>
        [Symbol("cmovnl r64, r64","REX.W + 0F 4D /r")]
        cmovnl_r64_r64 = 345,

        /// <summary>
        /// cmovnle r16, m16 | 0F 4F /r | Move if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovnle r16, m16","0F 4F /r")]
        cmovnle_r16_m16 = 346,

        /// <summary>
        /// cmovnle r16, r16 | 0F 4F /r | Move if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovnle r16, r16","0F 4F /r")]
        cmovnle_r16_r16 = 347,

        /// <summary>
        /// cmovnle r32, m32 | 0F 4F /r | Move if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovnle r32, m32","0F 4F /r")]
        cmovnle_r32_m32 = 348,

        /// <summary>
        /// cmovnle r32, r32 | 0F 4F /r | Move if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovnle r32, r32","0F 4F /r")]
        cmovnle_r32_r32 = 349,

        /// <summary>
        /// cmovnle r64, m64 | REX.W + 0F 4F /r | Move if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovnle r64, m64","REX.W + 0F 4F /r")]
        cmovnle_r64_m64 = 350,

        /// <summary>
        /// cmovnle r64, r64 | REX.W + 0F 4F /r | Move if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("cmovnle r64, r64","REX.W + 0F 4F /r")]
        cmovnle_r64_r64 = 351,

        /// <summary>
        /// cmovno r16, m16 | 0F 41 /r | Move if not overflow (OF=0).
        /// </summary>
        [Symbol("cmovno r16, m16","0F 41 /r")]
        cmovno_r16_m16 = 352,

        /// <summary>
        /// cmovno r16, r16 | 0F 41 /r | Move if not overflow (OF=0).
        /// </summary>
        [Symbol("cmovno r16, r16","0F 41 /r")]
        cmovno_r16_r16 = 353,

        /// <summary>
        /// cmovno r32, m32 | 0F 41 /r | Move if not overflow (OF=0).
        /// </summary>
        [Symbol("cmovno r32, m32","0F 41 /r")]
        cmovno_r32_m32 = 354,

        /// <summary>
        /// cmovno r32, r32 | 0F 41 /r | Move if not overflow (OF=0).
        /// </summary>
        [Symbol("cmovno r32, r32","0F 41 /r")]
        cmovno_r32_r32 = 355,

        /// <summary>
        /// cmovno r64, m64 | REX.W + 0F 41 /r | Move if not overflow (OF=0).
        /// </summary>
        [Symbol("cmovno r64, m64","REX.W + 0F 41 /r")]
        cmovno_r64_m64 = 356,

        /// <summary>
        /// cmovno r64, r64 | REX.W + 0F 41 /r | Move if not overflow (OF=0).
        /// </summary>
        [Symbol("cmovno r64, r64","REX.W + 0F 41 /r")]
        cmovno_r64_r64 = 357,

        /// <summary>
        /// cmovnp r16, m16 | 0F 4B /r | Move if not parity (PF=0).
        /// </summary>
        [Symbol("cmovnp r16, m16","0F 4B /r")]
        cmovnp_r16_m16 = 358,

        /// <summary>
        /// cmovnp r16, r16 | 0F 4B /r | Move if not parity (PF=0).
        /// </summary>
        [Symbol("cmovnp r16, r16","0F 4B /r")]
        cmovnp_r16_r16 = 359,

        /// <summary>
        /// cmovnp r32, m32 | 0F 4B /r | Move if not parity (PF=0).
        /// </summary>
        [Symbol("cmovnp r32, m32","0F 4B /r")]
        cmovnp_r32_m32 = 360,

        /// <summary>
        /// cmovnp r32, r32 | 0F 4B /r | Move if not parity (PF=0).
        /// </summary>
        [Symbol("cmovnp r32, r32","0F 4B /r")]
        cmovnp_r32_r32 = 361,

        /// <summary>
        /// cmovnp r64, m64 | REX.W + 0F 4B /r | Move if not parity (PF=0).
        /// </summary>
        [Symbol("cmovnp r64, m64","REX.W + 0F 4B /r")]
        cmovnp_r64_m64 = 362,

        /// <summary>
        /// cmovnp r64, r64 | REX.W + 0F 4B /r | Move if not parity (PF=0).
        /// </summary>
        [Symbol("cmovnp r64, r64","REX.W + 0F 4B /r")]
        cmovnp_r64_r64 = 363,

        /// <summary>
        /// cmovns r16, m16 | 0F 49 /r | Move if not sign (SF=0).
        /// </summary>
        [Symbol("cmovns r16, m16","0F 49 /r")]
        cmovns_r16_m16 = 364,

        /// <summary>
        /// cmovns r16, r16 | 0F 49 /r | Move if not sign (SF=0).
        /// </summary>
        [Symbol("cmovns r16, r16","0F 49 /r")]
        cmovns_r16_r16 = 365,

        /// <summary>
        /// cmovns r32, m32 | 0F 49 /r | Move if not sign (SF=0).
        /// </summary>
        [Symbol("cmovns r32, m32","0F 49 /r")]
        cmovns_r32_m32 = 366,

        /// <summary>
        /// cmovns r32, r32 | 0F 49 /r | Move if not sign (SF=0).
        /// </summary>
        [Symbol("cmovns r32, r32","0F 49 /r")]
        cmovns_r32_r32 = 367,

        /// <summary>
        /// cmovns r64, m64 | REX.W + 0F 49 /r | Move if not sign (SF=0).
        /// </summary>
        [Symbol("cmovns r64, m64","REX.W + 0F 49 /r")]
        cmovns_r64_m64 = 368,

        /// <summary>
        /// cmovns r64, r64 | REX.W + 0F 49 /r | Move if not sign (SF=0).
        /// </summary>
        [Symbol("cmovns r64, r64","REX.W + 0F 49 /r")]
        cmovns_r64_r64 = 369,

        /// <summary>
        /// cmovnz r16, m16 | 0F 45 /r | Move if not zero (ZF=0).
        /// </summary>
        [Symbol("cmovnz r16, m16","0F 45 /r")]
        cmovnz_r16_m16 = 370,

        /// <summary>
        /// cmovnz r16, r16 | 0F 45 /r | Move if not zero (ZF=0).
        /// </summary>
        [Symbol("cmovnz r16, r16","0F 45 /r")]
        cmovnz_r16_r16 = 371,

        /// <summary>
        /// cmovnz r32, m32 | 0F 45 /r | Move if not zero (ZF=0).
        /// </summary>
        [Symbol("cmovnz r32, m32","0F 45 /r")]
        cmovnz_r32_m32 = 372,

        /// <summary>
        /// cmovnz r32, r32 | 0F 45 /r | Move if not zero (ZF=0).
        /// </summary>
        [Symbol("cmovnz r32, r32","0F 45 /r")]
        cmovnz_r32_r32 = 373,

        /// <summary>
        /// cmovnz r64, m64 | REX.W + 0F 45 /r | Move if not zero (ZF=0).
        /// </summary>
        [Symbol("cmovnz r64, m64","REX.W + 0F 45 /r")]
        cmovnz_r64_m64 = 374,

        /// <summary>
        /// cmovnz r64, r64 | REX.W + 0F 45 /r | Move if not zero (ZF=0).
        /// </summary>
        [Symbol("cmovnz r64, r64","REX.W + 0F 45 /r")]
        cmovnz_r64_r64 = 375,

        /// <summary>
        /// cmovo r16, m16 | 0F 40 /r | Move if overflow (OF=1).
        /// </summary>
        [Symbol("cmovo r16, m16","0F 40 /r")]
        cmovo_r16_m16 = 376,

        /// <summary>
        /// cmovo r16, r16 | 0F 40 /r | Move if overflow (OF=1).
        /// </summary>
        [Symbol("cmovo r16, r16","0F 40 /r")]
        cmovo_r16_r16 = 377,

        /// <summary>
        /// cmovo r32, m32 | 0F 40 /r | Move if overflow (OF=1).
        /// </summary>
        [Symbol("cmovo r32, m32","0F 40 /r")]
        cmovo_r32_m32 = 378,

        /// <summary>
        /// cmovo r32, r32 | 0F 40 /r | Move if overflow (OF=1).
        /// </summary>
        [Symbol("cmovo r32, r32","0F 40 /r")]
        cmovo_r32_r32 = 379,

        /// <summary>
        /// cmovo r64, m64 | REX.W + 0F 40 /r | Move if overflow (OF=1).
        /// </summary>
        [Symbol("cmovo r64, m64","REX.W + 0F 40 /r")]
        cmovo_r64_m64 = 380,

        /// <summary>
        /// cmovo r64, r64 | REX.W + 0F 40 /r | Move if overflow (OF=1).
        /// </summary>
        [Symbol("cmovo r64, r64","REX.W + 0F 40 /r")]
        cmovo_r64_r64 = 381,

        /// <summary>
        /// cmovp r16, m16 | 0F 4A /r | Move if parity (PF=1).
        /// </summary>
        [Symbol("cmovp r16, m16","0F 4A /r")]
        cmovp_r16_m16 = 382,

        /// <summary>
        /// cmovp r16, r16 | 0F 4A /r | Move if parity (PF=1).
        /// </summary>
        [Symbol("cmovp r16, r16","0F 4A /r")]
        cmovp_r16_r16 = 383,

        /// <summary>
        /// cmovp r32, m32 | 0F 4A /r | Move if parity (PF=1).
        /// </summary>
        [Symbol("cmovp r32, m32","0F 4A /r")]
        cmovp_r32_m32 = 384,

        /// <summary>
        /// cmovp r32, r32 | 0F 4A /r | Move if parity (PF=1).
        /// </summary>
        [Symbol("cmovp r32, r32","0F 4A /r")]
        cmovp_r32_r32 = 385,

        /// <summary>
        /// cmovp r64, m64 | REX.W + 0F 4A /r | Move if parity (PF=1).
        /// </summary>
        [Symbol("cmovp r64, m64","REX.W + 0F 4A /r")]
        cmovp_r64_m64 = 386,

        /// <summary>
        /// cmovp r64, r64 | REX.W + 0F 4A /r | Move if parity (PF=1).
        /// </summary>
        [Symbol("cmovp r64, r64","REX.W + 0F 4A /r")]
        cmovp_r64_r64 = 387,

        /// <summary>
        /// cmovpe r16, m16 | 0F 4A /r | Move if parity even (PF=1).
        /// </summary>
        [Symbol("cmovpe r16, m16","0F 4A /r")]
        cmovpe_r16_m16 = 388,

        /// <summary>
        /// cmovpe r16, r16 | 0F 4A /r | Move if parity even (PF=1).
        /// </summary>
        [Symbol("cmovpe r16, r16","0F 4A /r")]
        cmovpe_r16_r16 = 389,

        /// <summary>
        /// cmovpe r32, m32 | 0F 4A /r | Move if parity even (PF=1).
        /// </summary>
        [Symbol("cmovpe r32, m32","0F 4A /r")]
        cmovpe_r32_m32 = 390,

        /// <summary>
        /// cmovpe r32, r32 | 0F 4A /r | Move if parity even (PF=1).
        /// </summary>
        [Symbol("cmovpe r32, r32","0F 4A /r")]
        cmovpe_r32_r32 = 391,

        /// <summary>
        /// cmovpe r64, m64 | REX.W + 0F 4A /r | Move if parity even (PF=1).
        /// </summary>
        [Symbol("cmovpe r64, m64","REX.W + 0F 4A /r")]
        cmovpe_r64_m64 = 392,

        /// <summary>
        /// cmovpe r64, r64 | REX.W + 0F 4A /r | Move if parity even (PF=1).
        /// </summary>
        [Symbol("cmovpe r64, r64","REX.W + 0F 4A /r")]
        cmovpe_r64_r64 = 393,

        /// <summary>
        /// cmovpo r16, m16 | 0F 4B /r | Move if parity odd (PF=0).
        /// </summary>
        [Symbol("cmovpo r16, m16","0F 4B /r")]
        cmovpo_r16_m16 = 394,

        /// <summary>
        /// cmovpo r16, r16 | 0F 4B /r | Move if parity odd (PF=0).
        /// </summary>
        [Symbol("cmovpo r16, r16","0F 4B /r")]
        cmovpo_r16_r16 = 395,

        /// <summary>
        /// cmovpo r32, m32 | 0F 4B /r | Move if parity odd (PF=0).
        /// </summary>
        [Symbol("cmovpo r32, m32","0F 4B /r")]
        cmovpo_r32_m32 = 396,

        /// <summary>
        /// cmovpo r32, r32 | 0F 4B /r | Move if parity odd (PF=0).
        /// </summary>
        [Symbol("cmovpo r32, r32","0F 4B /r")]
        cmovpo_r32_r32 = 397,

        /// <summary>
        /// cmovpo r64, m64 | REX.W + 0F 4B /r | Move if parity odd (PF=0).
        /// </summary>
        [Symbol("cmovpo r64, m64","REX.W + 0F 4B /r")]
        cmovpo_r64_m64 = 398,

        /// <summary>
        /// cmovpo r64, r64 | REX.W + 0F 4B /r | Move if parity odd (PF=0).
        /// </summary>
        [Symbol("cmovpo r64, r64","REX.W + 0F 4B /r")]
        cmovpo_r64_r64 = 399,

        /// <summary>
        /// cmovs r16, m16 | 0F 48 /r | Move if sign (SF=1).
        /// </summary>
        [Symbol("cmovs r16, m16","0F 48 /r")]
        cmovs_r16_m16 = 400,

        /// <summary>
        /// cmovs r16, r16 | 0F 48 /r | Move if sign (SF=1).
        /// </summary>
        [Symbol("cmovs r16, r16","0F 48 /r")]
        cmovs_r16_r16 = 401,

        /// <summary>
        /// cmovs r32, m32 | 0F 48 /r | Move if sign (SF=1).
        /// </summary>
        [Symbol("cmovs r32, m32","0F 48 /r")]
        cmovs_r32_m32 = 402,

        /// <summary>
        /// cmovs r32, r32 | 0F 48 /r | Move if sign (SF=1).
        /// </summary>
        [Symbol("cmovs r32, r32","0F 48 /r")]
        cmovs_r32_r32 = 403,

        /// <summary>
        /// cmovs r64, m64 | REX.W + 0F 48 /r | Move if sign (SF=1).
        /// </summary>
        [Symbol("cmovs r64, m64","REX.W + 0F 48 /r")]
        cmovs_r64_m64 = 404,

        /// <summary>
        /// cmovs r64, r64 | REX.W + 0F 48 /r | Move if sign (SF=1).
        /// </summary>
        [Symbol("cmovs r64, r64","REX.W + 0F 48 /r")]
        cmovs_r64_r64 = 405,

        /// <summary>
        /// cmovz r16, m16 | 0F 44 /r | Move if zero (ZF=1).
        /// </summary>
        [Symbol("cmovz r16, m16","0F 44 /r")]
        cmovz_r16_m16 = 406,

        /// <summary>
        /// cmovz r16, r16 | 0F 44 /r | Move if zero (ZF=1).
        /// </summary>
        [Symbol("cmovz r16, r16","0F 44 /r")]
        cmovz_r16_r16 = 407,

        /// <summary>
        /// cmovz r32, m32 | 0F 44 /r | Move if zero (ZF=1).
        /// </summary>
        [Symbol("cmovz r32, m32","0F 44 /r")]
        cmovz_r32_m32 = 408,

        /// <summary>
        /// cmovz r32, r32 | 0F 44 /r | Move if zero (ZF=1).
        /// </summary>
        [Symbol("cmovz r32, r32","0F 44 /r")]
        cmovz_r32_r32 = 409,

        /// <summary>
        /// cmovz r64, m64 | REX.W + 0F 44 /r | Move if zero (ZF=1).
        /// </summary>
        [Symbol("cmovz r64, m64","REX.W + 0F 44 /r")]
        cmovz_r64_m64 = 410,

        /// <summary>
        /// cmovz r64, r64 | REX.W + 0F 44 /r | Move if zero (ZF=1).
        /// </summary>
        [Symbol("cmovz r64, r64","REX.W + 0F 44 /r")]
        cmovz_r64_r64 = 411,

        /// <summary>
        /// cmp AL, imm8 | 3C ib | Compare imm8 with AL.
        /// </summary>
        [Symbol("cmp AL, imm8","3C ib")]
        cmp_AL_imm8 = 412,

        /// <summary>
        /// cmp AX, imm16 | 3D iw | Compare imm16 with AX.
        /// </summary>
        [Symbol("cmp AX, imm16","3D iw")]
        cmp_AX_imm16 = 413,

        /// <summary>
        /// cmp EAX, imm32 | 3D id | Compare imm32 with EAX.
        /// </summary>
        [Symbol("cmp EAX, imm32","3D id")]
        cmp_EAX_imm32 = 414,

        /// <summary>
        /// cmp m16, imm16 | 81 /7 iw | Compare imm16 with r/m16.
        /// </summary>
        [Symbol("cmp m16, imm16","81 /7 iw")]
        cmp_m16_imm16 = 415,

        /// <summary>
        /// cmp m16, imm8 | 83 /7 ib | Compare imm8 with r/m16.
        /// </summary>
        [Symbol("cmp m16, imm8","83 /7 ib")]
        cmp_m16_imm8 = 416,

        /// <summary>
        /// cmp m16, r16 | 39 /r | Compare r16 with r/m16.
        /// </summary>
        [Symbol("cmp m16, r16","39 /r")]
        cmp_m16_r16 = 417,

        /// <summary>
        /// cmp m32, imm32 | 81 /7 id | Compare imm32 with r/m32.
        /// </summary>
        [Symbol("cmp m32, imm32","81 /7 id")]
        cmp_m32_imm32 = 418,

        /// <summary>
        /// cmp m32, imm8 | 83 /7 ib | Compare imm8 with r/m32.
        /// </summary>
        [Symbol("cmp m32, imm8","83 /7 ib")]
        cmp_m32_imm8 = 419,

        /// <summary>
        /// cmp m32, r32 | 39 /r | Compare r32 with r/m32.
        /// </summary>
        [Symbol("cmp m32, r32","39 /r")]
        cmp_m32_r32 = 420,

        /// <summary>
        /// cmp m64, imm32 | REX.W + 81 /7 id | Compare imm32 sign-extended to 64-bits with r/m64.
        /// </summary>
        [Symbol("cmp m64, imm32","REX.W + 81 /7 id")]
        cmp_m64_imm32 = 421,

        /// <summary>
        /// cmp m64, imm8 | REX.W + 83 /7 ib | Compare imm8 with r/m64.
        /// </summary>
        [Symbol("cmp m64, imm8","REX.W + 83 /7 ib")]
        cmp_m64_imm8 = 422,

        /// <summary>
        /// cmp m64, r64 | REX.W + 39 /r | Compare r64 with r/m64.
        /// </summary>
        [Symbol("cmp m64, r64","REX.W + 39 /r")]
        cmp_m64_r64 = 423,

        /// <summary>
        /// cmp m8, imm8 | REX + 80 /7 ib | Compare imm8 with r/m8.
        /// </summary>
        [Symbol("cmp m8, imm8","REX + 80 /7 ib")]
        cmp_m8_imm8 = 424,

        /// <summary>
        /// cmp m8, imm8 | 80 /7 ib | Compare imm8 with r/m8.
        /// </summary>
        [Symbol("cmp m8, imm8","80 /7 ib")]
        cmp_m8_imm8_x80 = 425,

        /// <summary>
        /// cmp m8, r8 | 38 /r | Compare r8 with r/m8.
        /// </summary>
        [Symbol("cmp m8, r8","38 /r")]
        cmp_m8_r8 = 426,

        /// <summary>
        /// cmp m8, r8 | REX + 38 /r | Compare r8 with r/m8.
        /// </summary>
        [Symbol("cmp m8, r8","REX + 38 /r")]
        cmp_m8_r8_rex = 427,

        /// <summary>
        /// cmp r16, imm16 | 81 /7 iw | Compare imm16 with r/m16.
        /// </summary>
        [Symbol("cmp r16, imm16","81 /7 iw")]
        cmp_r16_imm16 = 428,

        /// <summary>
        /// cmp r16, imm8 | 83 /7 ib | Compare imm8 with r/m16.
        /// </summary>
        [Symbol("cmp r16, imm8","83 /7 ib")]
        cmp_r16_imm8 = 429,

        /// <summary>
        /// cmp r16, m16 | 3B /r | Compare r/m16 with r16.
        /// </summary>
        [Symbol("cmp r16, m16","3B /r")]
        cmp_r16_m16 = 430,

        /// <summary>
        /// cmp r16, r16 | 39 /r | Compare r16 with r/m16.
        /// </summary>
        [Symbol("cmp r16, r16","39 /r")]
        cmp_r16_r16 = 431,

        /// <summary>
        /// cmp r16, r16 | 3B /r | Compare r/m16 with r16.
        /// </summary>
        [Symbol("cmp r16, r16","3B /r")]
        cmp_r16_r16_x3B = 432,

        /// <summary>
        /// cmp r32, imm32 | 81 /7 id | Compare imm32 with r/m32.
        /// </summary>
        [Symbol("cmp r32, imm32","81 /7 id")]
        cmp_r32_imm32 = 433,

        /// <summary>
        /// cmp r32, imm8 | 83 /7 ib | Compare imm8 with r/m32.
        /// </summary>
        [Symbol("cmp r32, imm8","83 /7 ib")]
        cmp_r32_imm8 = 434,

        /// <summary>
        /// cmp r32, m32 | 3B /r | Compare r/m32 with r32.
        /// </summary>
        [Symbol("cmp r32, m32","3B /r")]
        cmp_r32_m32 = 435,

        /// <summary>
        /// cmp r32, r32 | 39 /r | Compare r32 with r/m32.
        /// </summary>
        [Symbol("cmp r32, r32","39 /r")]
        cmp_r32_r32 = 436,

        /// <summary>
        /// cmp r32, r32 | 3B /r | Compare r/m32 with r32.
        /// </summary>
        [Symbol("cmp r32, r32","3B /r")]
        cmp_r32_r32_x3B = 437,

        /// <summary>
        /// cmp r64, imm32 | REX.W + 81 /7 id | Compare imm32 sign-extended to 64-bits with r/m64.
        /// </summary>
        [Symbol("cmp r64, imm32","REX.W + 81 /7 id")]
        cmp_r64_imm32 = 438,

        /// <summary>
        /// cmp r64, imm8 | REX.W + 83 /7 ib | Compare imm8 with r/m64.
        /// </summary>
        [Symbol("cmp r64, imm8","REX.W + 83 /7 ib")]
        cmp_r64_imm8 = 439,

        /// <summary>
        /// cmp r64, m64 | REX.W + 3B /r | Compare r/m64 with r64.
        /// </summary>
        [Symbol("cmp r64, m64","REX.W + 3B /r")]
        cmp_r64_m64 = 440,

        /// <summary>
        /// cmp r64, r64 | REX.W + 39 /r | Compare r64 with r/m64.
        /// </summary>
        [Symbol("cmp r64, r64","REX.W + 39 /r")]
        cmp_r64_r64 = 441,

        /// <summary>
        /// cmp r64, r64 | REX.W + 3B /r | Compare r/m64 with r64.
        /// </summary>
        [Symbol("cmp r64, r64","REX.W + 3B /r")]
        cmp_r64_r64_x3B = 442,

        /// <summary>
        /// cmp r8, imm8 | REX + 80 /7 ib | Compare imm8 with r/m8.
        /// </summary>
        [Symbol("cmp r8, imm8","REX + 80 /7 ib")]
        cmp_r8_imm8 = 443,

        /// <summary>
        /// cmp r8, imm8 | 80 /7 ib | Compare imm8 with r/m8.
        /// </summary>
        [Symbol("cmp r8, imm8","80 /7 ib")]
        cmp_r8_imm8_x80 = 444,

        /// <summary>
        /// cmp r8, m8 | 3A /r | Compare r/m8 with r8.
        /// </summary>
        [Symbol("cmp r8, m8","3A /r")]
        cmp_r8_m8 = 445,

        /// <summary>
        /// cmp r8, m8 | REX + 3A /r | Compare r/m8 with r8.
        /// </summary>
        [Symbol("cmp r8, m8","REX + 3A /r")]
        cmp_r8_m8_rex = 446,

        /// <summary>
        /// cmp r8, r8 | 38 /r | Compare r8 with r/m8.
        /// </summary>
        [Symbol("cmp r8, r8","38 /r")]
        cmp_r8_r8 = 447,

        /// <summary>
        /// cmp r8, r8 | REX + 38 /r | Compare r8 with r/m8.
        /// </summary>
        [Symbol("cmp r8, r8","REX + 38 /r")]
        cmp_r8_r8_rex = 448,

        /// <summary>
        /// cmp r8, r8 | 3A /r | Compare r/m8 with r8.
        /// </summary>
        [Symbol("cmp r8, r8","3A /r")]
        cmp_r8_r8_x3A = 449,

        /// <summary>
        /// cmp RAX, imm32 | REX.W + 3D id | Compare imm32 sign-extended to 64-bits with RAX.
        /// </summary>
        [Symbol("cmp RAX, imm32","REX.W + 3D id")]
        cmp_RAX_imm32 = 450,

        /// <summary>
        /// cmpps xmm, m128, imm8 | NP 0F C2 /r ib | Compare packed single-precision floating-point values in xmm2/m128 and xmm1 using bits 2:0 of imm8 as a comparison predicate.
        /// </summary>
        [Symbol("cmpps xmm, m128, imm8","NP 0F C2 /r ib")]
        cmpps_xmm_m128_imm8 = 451,

        /// <summary>
        /// cmpps xmm, r8, imm8 | NP 0F C2 /r ib | Compare packed single-precision floating-point values in xmm2/m128 and xmm1 using bits 2:0 of imm8 as a comparison predicate.
        /// </summary>
        [Symbol("cmpps xmm, r8, imm8","NP 0F C2 /r ib")]
        cmpps_xmm_r8_imm8 = 452,

        /// <summary>
        /// cmps m16, m16 | A7 | For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R&#124;E)SI with word at address (R/E)DI. The status flags are set accordingly.
        /// </summary>
        [Symbol("cmps m16, m16","A7")]
        cmps_m16_m16 = 453,

        /// <summary>
        /// cmps m32, m32 | A7 | For legacy mode, compare dword at address DS:(E)SI at dword at address ES:(E)DI; For 64-bit mode compare dword at address (R&#124;E)SI at dword at address (R/E)DI. The status flags are set accordingly.
        /// </summary>
        [Symbol("cmps m32, m32","A7")]
        cmps_m32_m32 = 454,

        /// <summary>
        /// cmps m64, m64 | REX.W + A7 | Compares quadword at address (R/E)SI with quadword at address (R/E)DI and sets the status flags accordingly.
        /// </summary>
        [Symbol("cmps m64, m64","REX.W + A7")]
        cmps_m64_m64 = 455,

        /// <summary>
        /// cmps m8, m8 | A6 | For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R&#124;E)SI to byte at address (R/E)DI. The status flags are set accordingly.
        /// </summary>
        [Symbol("cmps m8, m8","A6")]
        cmps_m8_m8 = 456,

        /// <summary>
        /// cmpsb | A6 | For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R&#124;E)SI with byte at address (R/ E)DI. The status flags are set accordingly.
        /// </summary>
        [Symbol("cmpsb","A6")]
        cmpsb = 457,

        /// <summary>
        /// cmpsd | A7 | For legacy mode, compare dword at address DS:(E)SI with dword at address ES:(E)DI; For 64-bit mode compare dword at address (R&#124;E)SI with dword at address (R/E)DI. The status flags are set accordingly.
        /// </summary>
        [Symbol("cmpsd","A7")]
        cmpsd = 458,

        /// <summary>
        /// cmpsq | REX.W + A7 | Compares quadword at address (R/E)SI with quadword at address (R/E)DI and sets the status flags accordingly.
        /// </summary>
        [Symbol("cmpsq","REX.W + A7")]
        cmpsq = 459,

        /// <summary>
        /// cmpss xmm, m32, imm8 | F3 0F C2 /r ib | Compare low single-precision floating-point value in xmm2/m32 and xmm1 using bits 2:0 of imm8 as comparison predicate.
        /// </summary>
        [Symbol("cmpss xmm, m32, imm8","F3 0F C2 /r ib")]
        cmpss_xmm_m32_imm8 = 460,

        /// <summary>
        /// cmpss xmm, r8, imm8 | F3 0F C2 /r ib | Compare low single-precision floating-point value in xmm2/m32 and xmm1 using bits 2:0 of imm8 as comparison predicate.
        /// </summary>
        [Symbol("cmpss xmm, r8, imm8","F3 0F C2 /r ib")]
        cmpss_xmm_r8_imm8 = 461,

        /// <summary>
        /// cmpsw | A7 | For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R&#124;E)SI with word at address (R/E)DI. The status flags are set accordingly.
        /// </summary>
        [Symbol("cmpsw","A7")]
        cmpsw = 462,

        /// <summary>
        /// cmpxchg m16, r16 | 0F B1 /r | Compare AX with r/m16. If equal, ZF is set and r16 is loaded into r/m16. Else, clear ZF and load r/m16 into AX.
        /// </summary>
        [Symbol("cmpxchg m16, r16","0F B1 /r")]
        cmpxchg_m16_r16 = 463,

        /// <summary>
        /// cmpxchg m32, r32 | 0F B1 /r | Compare EAX with r/m32. If equal, ZF is set and r32 is loaded into r/m32. Else, clear ZF and load r/m32 into EAX.
        /// </summary>
        [Symbol("cmpxchg m32, r32","0F B1 /r")]
        cmpxchg_m32_r32 = 464,

        /// <summary>
        /// cmpxchg m64, r64 | REX.W + 0F B1 /r | Compare RAX with r/m64. If equal, ZF is set and r64 is loaded into r/m64. Else, clear ZF and load r/m64 into RAX.
        /// </summary>
        [Symbol("cmpxchg m64, r64","REX.W + 0F B1 /r")]
        cmpxchg_m64_r64 = 465,

        /// <summary>
        /// cmpxchg m8, r8 | 0F B0 /r | Compare AL with r/m8. If equal, ZF is set and r8 is loaded into r/m8. Else, clear ZF and load r/m8 into AL.
        /// </summary>
        [Symbol("cmpxchg m8, r8","0F B0 /r")]
        cmpxchg_m8_r8 = 466,

        /// <summary>
        /// cmpxchg m8, r8 | REX + 0F B0 /r | Compare AL with r/m8. If equal, ZF is set and r8 is loaded into r/m8. Else, clear ZF and load r/m8 into AL.
        /// </summary>
        [Symbol("cmpxchg m8, r8","REX + 0F B0 /r")]
        cmpxchg_m8_r8_rex = 467,

        /// <summary>
        /// cmpxchg r16, r16 | 0F B1 /r | Compare AX with r/m16. If equal, ZF is set and r16 is loaded into r/m16. Else, clear ZF and load r/m16 into AX.
        /// </summary>
        [Symbol("cmpxchg r16, r16","0F B1 /r")]
        cmpxchg_r16_r16 = 468,

        /// <summary>
        /// cmpxchg r32, r32 | 0F B1 /r | Compare EAX with r/m32. If equal, ZF is set and r32 is loaded into r/m32. Else, clear ZF and load r/m32 into EAX.
        /// </summary>
        [Symbol("cmpxchg r32, r32","0F B1 /r")]
        cmpxchg_r32_r32 = 469,

        /// <summary>
        /// cmpxchg r64, r64 | REX.W + 0F B1 /r | Compare RAX with r/m64. If equal, ZF is set and r64 is loaded into r/m64. Else, clear ZF and load r/m64 into RAX.
        /// </summary>
        [Symbol("cmpxchg r64, r64","REX.W + 0F B1 /r")]
        cmpxchg_r64_r64 = 470,

        /// <summary>
        /// cmpxchg r8, r8 | 0F B0 /r | Compare AL with r/m8. If equal, ZF is set and r8 is loaded into r/m8. Else, clear ZF and load r/m8 into AL.
        /// </summary>
        [Symbol("cmpxchg r8, r8","0F B0 /r")]
        cmpxchg_r8_r8 = 471,

        /// <summary>
        /// cmpxchg r8, r8 | REX + 0F B0 /r | Compare AL with r/m8. If equal, ZF is set and r8 is loaded into r/m8. Else, clear ZF and load r/m8 into AL.
        /// </summary>
        [Symbol("cmpxchg r8, r8","REX + 0F B0 /r")]
        cmpxchg_r8_r8_rex = 472,

        /// <summary>
        /// cmpxchg16b m128 | REX.W + 0F C7 /1 | Compare RDX:RAX with m128. If equal, set ZF and load RCX:RBX into m128. Else, clear ZF and load m128 into RDX:RAX.
        /// </summary>
        [Symbol("cmpxchg16b m128","REX.W + 0F C7 /1")]
        cmpxchg16b_m128 = 473,

        /// <summary>
        /// cmpxchg8b m64 | 0F C7 /1 | Compare EDX:EAX with m64. If equal, set ZF and load ECX:EBX into m64. Else, clear ZF and load m64 into EDX:EAX.
        /// </summary>
        [Symbol("cmpxchg8b m64","0F C7 /1")]
        cmpxchg8b_m64 = 474,

        /// <summary>
        /// cqo | REX.W + 99 | RDX:RAX:= sign-extend of RAX.
        /// </summary>
        [Symbol("cqo","REX.W + 99")]
        cqo = 475,

        /// <summary>
        /// crc32 r32, m16 | F2 0F 38 F1 /r | Accumulate CRC32 on r/m16.
        /// </summary>
        [Symbol("crc32 r32, m16","F2 0F 38 F1 /r")]
        crc32_r32_m16 = 476,

        /// <summary>
        /// crc32 r32, m32 | F2 0F 38 F1 /r | Accumulate CRC32 on r/m32.
        /// </summary>
        [Symbol("crc32 r32, m32","F2 0F 38 F1 /r")]
        crc32_r32_m32 = 477,

        /// <summary>
        /// crc32 r32, m8 | F2 REX 0F 38 F0 /r | Accumulate CRC32 on r/m8.
        /// </summary>
        [Symbol("crc32 r32, m8","F2 REX 0F 38 F0 /r")]
        crc32_r32_m8 = 478,

        /// <summary>
        /// crc32 r32, m8 | F2 0F 38 F0 /r | Accumulate CRC32 on r/m8.
        /// </summary>
        [Symbol("crc32 r32, m8","F2 0F 38 F0 /r")]
        crc32_r32_m8_x0F = 479,

        /// <summary>
        /// crc32 r32, r16 | F2 0F 38 F1 /r | Accumulate CRC32 on r/m16.
        /// </summary>
        [Symbol("crc32 r32, r16","F2 0F 38 F1 /r")]
        crc32_r32_r16 = 480,

        /// <summary>
        /// crc32 r32, r32 | F2 0F 38 F1 /r | Accumulate CRC32 on r/m32.
        /// </summary>
        [Symbol("crc32 r32, r32","F2 0F 38 F1 /r")]
        crc32_r32_r32 = 481,

        /// <summary>
        /// crc32 r32, r8 | F2 REX 0F 38 F0 /r | Accumulate CRC32 on r/m8.
        /// </summary>
        [Symbol("crc32 r32, r8","F2 REX 0F 38 F0 /r")]
        crc32_r32_r8 = 482,

        /// <summary>
        /// crc32 r32, r8 | F2 0F 38 F0 /r | Accumulate CRC32 on r/m8.
        /// </summary>
        [Symbol("crc32 r32, r8","F2 0F 38 F0 /r")]
        crc32_r32_r8_x0F = 483,

        /// <summary>
        /// crc32 r64, m64 | F2 REX.W 0F 38 F1 /r | Accumulate CRC32 on r/m64.
        /// </summary>
        [Symbol("crc32 r64, m64","F2 REX.W 0F 38 F1 /r")]
        crc32_r64_m64 = 484,

        /// <summary>
        /// crc32 r64, m8 | F2 REX.W 0F 38 F0 /r | Accumulate CRC32 on r/m8.
        /// </summary>
        [Symbol("crc32 r64, m8","F2 REX.W 0F 38 F0 /r")]
        crc32_r64_m8 = 485,

        /// <summary>
        /// crc32 r64, r64 | F2 REX.W 0F 38 F1 /r | Accumulate CRC32 on r/m64.
        /// </summary>
        [Symbol("crc32 r64, r64","F2 REX.W 0F 38 F1 /r")]
        crc32_r64_r64 = 486,

        /// <summary>
        /// crc32 r64, r8 | F2 REX.W 0F 38 F0 /r | Accumulate CRC32 on r/m8.
        /// </summary>
        [Symbol("crc32 r64, r8","F2 REX.W 0F 38 F0 /r")]
        crc32_r64_r8 = 487,

        /// <summary>
        /// cwd | 99 | DX:AX ← sign-extend of AX.
        /// </summary>
        [Symbol("cwd","99")]
        cwd = 488,

        /// <summary>
        /// cwde | 98 | EAX ← sign-extend of AX.
        /// </summary>
        [Symbol("cwde","98")]
        cwde = 489,

        /// <summary>
        /// dec m16 | FF /1 | Decrement r/m16 by 1.
        /// </summary>
        [Symbol("dec m16","FF /1")]
        dec_m16 = 490,

        /// <summary>
        /// dec m32 | FF /1 | Decrement r/m32 by 1.
        /// </summary>
        [Symbol("dec m32","FF /1")]
        dec_m32 = 491,

        /// <summary>
        /// dec m64 | REX.W + FF /1 | Decrement r/m64 by 1.
        /// </summary>
        [Symbol("dec m64","REX.W + FF /1")]
        dec_m64 = 492,

        /// <summary>
        /// dec m8 | FE /1 | Decrement r/m8 by 1.
        /// </summary>
        [Symbol("dec m8","FE /1")]
        dec_m8 = 493,

        /// <summary>
        /// dec m8 | REX + FE /1 | Decrement r/m8 by 1.
        /// </summary>
        [Symbol("dec m8","REX + FE /1")]
        dec_m8_rex = 494,

        /// <summary>
        /// dec r16 | FF /1 | Decrement r/m16 by 1.
        /// </summary>
        [Symbol("dec r16","FF /1")]
        dec_r16 = 495,

        /// <summary>
        /// dec r16 | 48 +rw | Decrement r16 by 1.
        /// </summary>
        [Symbol("dec r16","48 +rw")]
        dec_r16_rex = 496,

        /// <summary>
        /// dec r32 | FF /1 | Decrement r/m32 by 1.
        /// </summary>
        [Symbol("dec r32","FF /1")]
        dec_r32 = 497,

        /// <summary>
        /// dec r32 | 48 +rd | Decrement r32 by 1.
        /// </summary>
        [Symbol("dec r32","48 +rd")]
        dec_r32_rex = 498,

        /// <summary>
        /// dec r64 | REX.W + FF /1 | Decrement r/m64 by 1.
        /// </summary>
        [Symbol("dec r64","REX.W + FF /1")]
        dec_r64 = 499,

        /// <summary>
        /// dec r8 | FE /1 | Decrement r/m8 by 1.
        /// </summary>
        [Symbol("dec r8","FE /1")]
        dec_r8 = 500,

        /// <summary>
        /// dec r8 | REX + FE /1 | Decrement r/m8 by 1.
        /// </summary>
        [Symbol("dec r8","REX + FE /1")]
        dec_r8_rex = 501,

        /// <summary>
        /// div m16 | F7 /6 | Unsigned divide DX:AX by r/m16, with result stored in AX := Quotient, DX := Remainder.
        /// </summary>
        [Symbol("div m16","F7 /6")]
        div_m16 = 502,

        /// <summary>
        /// div m32 | F7 /6 | Unsigned divide EDX:EAX by r/m32, with result stored in EAX := Quotient, EDX := Remainder.
        /// </summary>
        [Symbol("div m32","F7 /6")]
        div_m32 = 503,

        /// <summary>
        /// div m64 | REX.W + F7 /6 | Unsigned divide RDX:RAX by r/m64, with result stored in RAX := Quotient, RDX := Remainder.
        /// </summary>
        [Symbol("div m64","REX.W + F7 /6")]
        div_m64 = 504,

        /// <summary>
        /// div m8 | REX + F6 /6 | Unsigned divide AX by r/m8, with result stored in AL := Quotient, AH := Remainder.
        /// </summary>
        [Symbol("div m8","REX + F6 /6")]
        div_m8 = 505,

        /// <summary>
        /// div m8 | F6 /6 | Unsigned divide AX by r/m8, with result stored in AL := Quotient, AH := Remainder.
        /// </summary>
        [Symbol("div m8","F6 /6")]
        div_m8_xF6 = 506,

        /// <summary>
        /// div r16 | F7 /6 | Unsigned divide DX:AX by r/m16, with result stored in AX := Quotient, DX := Remainder.
        /// </summary>
        [Symbol("div r16","F7 /6")]
        div_r16 = 507,

        /// <summary>
        /// div r32 | F7 /6 | Unsigned divide EDX:EAX by r/m32, with result stored in EAX := Quotient, EDX := Remainder.
        /// </summary>
        [Symbol("div r32","F7 /6")]
        div_r32 = 508,

        /// <summary>
        /// div r64 | REX.W + F7 /6 | Unsigned divide RDX:RAX by r/m64, with result stored in RAX := Quotient, RDX := Remainder.
        /// </summary>
        [Symbol("div r64","REX.W + F7 /6")]
        div_r64 = 509,

        /// <summary>
        /// div r8 | REX + F6 /6 | Unsigned divide AX by r/m8, with result stored in AL := Quotient, AH := Remainder.
        /// </summary>
        [Symbol("div r8","REX + F6 /6")]
        div_r8 = 510,

        /// <summary>
        /// div r8 | F6 /6 | Unsigned divide AX by r/m8, with result stored in AL := Quotient, AH := Remainder.
        /// </summary>
        [Symbol("div r8","F6 /6")]
        div_r8_xF6 = 511,

        /// <summary>
        /// enter imm16, imm8 | C8 iw ib | Create a stack frame with nested pointers for a procedure.
        /// </summary>
        [Symbol("enter imm16, imm8","C8 iw ib")]
        enter_imm16_imm8 = 512,

        /// <summary>
        /// enter imm16, 0 | C8 iw 00 | Create a stack frame for a procedure.
        /// </summary>
        [Symbol("enter imm16, 0","C8 iw 00")]
        enter_imm16_n0 = 513,

        /// <summary>
        /// enter imm16, 1 | C8 iw 01 | Create a stack frame with a nested pointer for a procedure.
        /// </summary>
        [Symbol("enter imm16, 1","C8 iw 01")]
        enter_imm16_n1 = 514,

        /// <summary>
        /// hlt | F4 | Halt
        /// </summary>
        [Symbol("hlt","F4")]
        hlt = 515,

        /// <summary>
        /// idiv m16 | F7 /7 | Signed divide DX:AX by r/m16, with result stored in AX ← Quotient, DX ← Remainder.
        /// </summary>
        [Symbol("idiv m16","F7 /7")]
        idiv_m16 = 516,

        /// <summary>
        /// idiv m32 | F7 /7 | Signed divide EDX:EAX by r/m32, with result stored in EAX ← Quotient, EDX ← Remainder.
        /// </summary>
        [Symbol("idiv m32","F7 /7")]
        idiv_m32 = 517,

        /// <summary>
        /// idiv m64 | REX.W + F7 /7 | Signed divide RDX:RAX by r/m64, with result stored in RAX ← Quotient, RDX ← Remainder.
        /// </summary>
        [Symbol("idiv m64","REX.W + F7 /7")]
        idiv_m64 = 518,

        /// <summary>
        /// idiv m8 | REX + F6 /7 | Signed divide AX by r/m 8, with result stored in AL ← Quotient, AH ← Remainder.
        /// </summary>
        [Symbol("idiv m8","REX + F6 /7")]
        idiv_m8 = 519,

        /// <summary>
        /// idiv m8 | F6 /7 | Signed divide AX by r/m 8, with result stored in: AL ← Quotient, AH ← Remainder.
        /// </summary>
        [Symbol("idiv m8","F6 /7")]
        idiv_m8_xF6 = 520,

        /// <summary>
        /// idiv r16 | F7 /7 | Signed divide DX:AX by r/m16, with result stored in AX ← Quotient, DX ← Remainder.
        /// </summary>
        [Symbol("idiv r16","F7 /7")]
        idiv_r16 = 521,

        /// <summary>
        /// idiv r32 | F7 /7 | Signed divide EDX:EAX by r/m32, with result stored in EAX ← Quotient, EDX ← Remainder.
        /// </summary>
        [Symbol("idiv r32","F7 /7")]
        idiv_r32 = 522,

        /// <summary>
        /// idiv r64 | REX.W + F7 /7 | Signed divide RDX:RAX by r/m64, with result stored in RAX ← Quotient, RDX ← Remainder.
        /// </summary>
        [Symbol("idiv r64","REX.W + F7 /7")]
        idiv_r64 = 523,

        /// <summary>
        /// idiv r8 | REX + F6 /7 | Signed divide AX by r/m 8, with result stored in AL ← Quotient, AH ← Remainder.
        /// </summary>
        [Symbol("idiv r8","REX + F6 /7")]
        idiv_r8 = 524,

        /// <summary>
        /// idiv r8 | F6 /7 | Signed divide AX by r/m 8, with result stored in: AL ← Quotient, AH ← Remainder.
        /// </summary>
        [Symbol("idiv r8","F6 /7")]
        idiv_r8_xF6 = 525,

        /// <summary>
        /// imul m16 | F7 /5 | DX:AX := AX ∗ r/m word.
        /// </summary>
        [Symbol("imul m16","F7 /5")]
        imul_m16 = 526,

        /// <summary>
        /// imul m32 | F7 /5 | EDX:EAX := EAX ∗ r/m 32.
        /// </summary>
        [Symbol("imul m32","F7 /5")]
        imul_m32 = 527,

        /// <summary>
        /// imul m64 | REX.W + F7 /5 | RDX:RAX := RAX ∗ r/m 64.
        /// </summary>
        [Symbol("imul m64","REX.W + F7 /5")]
        imul_m64 = 528,

        /// <summary>
        /// imul m8 | F6 /5 | AX:= AL ∗ r/m byte.
        /// </summary>
        [Symbol("imul m8","F6 /5")]
        imul_m8 = 529,

        /// <summary>
        /// imul r16 | F7 /5 | DX:AX := AX ∗ r/m word.
        /// </summary>
        [Symbol("imul r16","F7 /5")]
        imul_r16 = 530,

        /// <summary>
        /// imul r16, m16 | 0F AF /r | word register := word register ∗ r/m 16.
        /// </summary>
        [Symbol("imul r16, m16","0F AF /r")]
        imul_r16_m16 = 531,

        /// <summary>
        /// imul r16, m16, imm16 | 69 /r iw | word register := r/m16 ∗ immediate word.
        /// </summary>
        [Symbol("imul r16, m16, imm16","69 /r iw")]
        imul_r16_m16_imm16 = 532,

        /// <summary>
        /// imul r16, m16, imm8 | 6B /r ib | word register := r/m16 ∗ sign-extended immediate byte.
        /// </summary>
        [Symbol("imul r16, m16, imm8","6B /r ib")]
        imul_r16_m16_imm8 = 533,

        /// <summary>
        /// imul r16, r16 | 0F AF /r | word register := word register ∗ r/m 16.
        /// </summary>
        [Symbol("imul r16, r16","0F AF /r")]
        imul_r16_r16 = 534,

        /// <summary>
        /// imul r16, r16, imm16 | 69 /r iw | word register := r/m16 ∗ immediate word.
        /// </summary>
        [Symbol("imul r16, r16, imm16","69 /r iw")]
        imul_r16_r16_imm16 = 535,

        /// <summary>
        /// imul r16, r16, imm8 | 6B /r ib | word register := r/m16 ∗ sign-extended immediate byte.
        /// </summary>
        [Symbol("imul r16, r16, imm8","6B /r ib")]
        imul_r16_r16_imm8 = 536,

        /// <summary>
        /// imul r32 | F7 /5 | EDX:EAX := EAX ∗ r/m 32.
        /// </summary>
        [Symbol("imul r32","F7 /5")]
        imul_r32 = 537,

        /// <summary>
        /// imul r32, m32 | 0F AF /r | doubleword register := doubleword register ∗ r/m32.
        /// </summary>
        [Symbol("imul r32, m32","0F AF /r")]
        imul_r32_m32 = 538,

        /// <summary>
        /// imul r32, m32, imm32 | 69 /r id | doubleword register := r/m32 ∗ immediate doubleword.
        /// </summary>
        [Symbol("imul r32, m32, imm32","69 /r id")]
        imul_r32_m32_imm32 = 539,

        /// <summary>
        /// imul r32, m32, imm8 | 6B /r ib | doubleword register := r/m32 ∗ sign-extended immediate byte.
        /// </summary>
        [Symbol("imul r32, m32, imm8","6B /r ib")]
        imul_r32_m32_imm8 = 540,

        /// <summary>
        /// imul r32, r32 | 0F AF /r | doubleword register := doubleword register ∗ r/m32.
        /// </summary>
        [Symbol("imul r32, r32","0F AF /r")]
        imul_r32_r32 = 541,

        /// <summary>
        /// imul r32, r32, imm32 | 69 /r id | doubleword register := r/m32 ∗ immediate doubleword.
        /// </summary>
        [Symbol("imul r32, r32, imm32","69 /r id")]
        imul_r32_r32_imm32 = 542,

        /// <summary>
        /// imul r32, r32, imm8 | 6B /r ib | doubleword register := r/m32 ∗ sign-extended immediate byte.
        /// </summary>
        [Symbol("imul r32, r32, imm8","6B /r ib")]
        imul_r32_r32_imm8 = 543,

        /// <summary>
        /// imul r64 | REX.W + F7 /5 | RDX:RAX := RAX ∗ r/m 64.
        /// </summary>
        [Symbol("imul r64","REX.W + F7 /5")]
        imul_r64 = 544,

        /// <summary>
        /// imul r64, m64 | REX.W + 0F AF /r | Quadword register := Quadword register ∗ r/m64.
        /// </summary>
        [Symbol("imul r64, m64","REX.W + 0F AF /r")]
        imul_r64_m64 = 545,

        /// <summary>
        /// imul r64, m64, imm32 | REX.W + 69 /r id | Quadword register := r/m64 ∗ immediate doubleword.
        /// </summary>
        [Symbol("imul r64, m64, imm32","REX.W + 69 /r id")]
        imul_r64_m64_imm32 = 546,

        /// <summary>
        /// imul r64, m64, imm8 | REX.W + 6B /r ib | Quadword register := r/m64 ∗ sign-extended immediate byte.
        /// </summary>
        [Symbol("imul r64, m64, imm8","REX.W + 6B /r ib")]
        imul_r64_m64_imm8 = 547,

        /// <summary>
        /// imul r64, r64 | REX.W + 0F AF /r | Quadword register := Quadword register ∗ r/m64.
        /// </summary>
        [Symbol("imul r64, r64","REX.W + 0F AF /r")]
        imul_r64_r64 = 548,

        /// <summary>
        /// imul r64, r64, imm32 | REX.W + 69 /r id | Quadword register := r/m64 ∗ immediate doubleword.
        /// </summary>
        [Symbol("imul r64, r64, imm32","REX.W + 69 /r id")]
        imul_r64_r64_imm32 = 549,

        /// <summary>
        /// imul r64, r64, imm8 | REX.W + 6B /r ib | Quadword register := r/m64 ∗ sign-extended immediate byte.
        /// </summary>
        [Symbol("imul r64, r64, imm8","REX.W + 6B /r ib")]
        imul_r64_r64_imm8 = 550,

        /// <summary>
        /// imul r8 | F6 /5 | AX:= AL ∗ r/m byte.
        /// </summary>
        [Symbol("imul r8","F6 /5")]
        imul_r8 = 551,

        /// <summary>
        /// in AL, DX | EC | Input byte from I/O port in DX into AL.
        /// </summary>
        [Symbol("in AL, DX","EC")]
        in_AL_DX = 552,

        /// <summary>
        /// in AL, imm8 | E4 ib | Input byte from imm8 I/O port address into AL.
        /// </summary>
        [Symbol("in AL, imm8","E4 ib")]
        in_AL_imm8 = 553,

        /// <summary>
        /// in AX, DX | ED | Input word from I/O port in DX into AX.
        /// </summary>
        [Symbol("in AX, DX","ED")]
        in_AX_DX = 554,

        /// <summary>
        /// in AX, imm8 | E5 ib | Input word from imm8 I/O port address into AX.
        /// </summary>
        [Symbol("in AX, imm8","E5 ib")]
        in_AX_imm8 = 555,

        /// <summary>
        /// in EAX, DX | ED | Input doubleword from I/O port in DX into EAX.
        /// </summary>
        [Symbol("in EAX, DX","ED")]
        in_EAX_DX = 556,

        /// <summary>
        /// in EAX, imm8 | E5 ib | Input dword from imm8 I/O port address into EAX.
        /// </summary>
        [Symbol("in EAX, imm8","E5 ib")]
        in_EAX_imm8 = 557,

        /// <summary>
        /// inc m16 | FF /0 | Increment r/m word by 1.
        /// </summary>
        [Symbol("inc m16","FF /0")]
        inc_m16 = 558,

        /// <summary>
        /// inc m32 | FF /0 | Increment r/m doubleword by 1.
        /// </summary>
        [Symbol("inc m32","FF /0")]
        inc_m32 = 559,

        /// <summary>
        /// inc m64 | REX.W + FF /0 | Increment r/m quadword by 1.
        /// </summary>
        [Symbol("inc m64","REX.W + FF /0")]
        inc_m64 = 560,

        /// <summary>
        /// inc m8 | REX + FE /0 | Increment r/m byte by 1.
        /// </summary>
        [Symbol("inc m8","REX + FE /0")]
        inc_m8 = 561,

        /// <summary>
        /// inc m8 | FE /0 | Increment r/m byte by 1.
        /// </summary>
        [Symbol("inc m8","FE /0")]
        inc_m8_xFE = 562,

        /// <summary>
        /// inc r16 | FF /0 | Increment r/m word by 1.
        /// </summary>
        [Symbol("inc r16","FF /0")]
        inc_r16 = 563,

        /// <summary>
        /// inc r16 | 40 +rw | Increment word register by 1.
        /// </summary>
        [Symbol("inc r16","40 +rw")]
        inc_r16_rex = 564,

        /// <summary>
        /// inc r32 | FF /0 | Increment r/m doubleword by 1.
        /// </summary>
        [Symbol("inc r32","FF /0")]
        inc_r32 = 565,

        /// <summary>
        /// inc r32 | 40 +rd | Increment doubleword register by 1.
        /// </summary>
        [Symbol("inc r32","40 +rd")]
        inc_r32_rex = 566,

        /// <summary>
        /// inc r64 | REX.W + FF /0 | Increment r/m quadword by 1.
        /// </summary>
        [Symbol("inc r64","REX.W + FF /0")]
        inc_r64 = 567,

        /// <summary>
        /// inc r8 | REX + FE /0 | Increment r/m byte by 1.
        /// </summary>
        [Symbol("inc r8","REX + FE /0")]
        inc_r8 = 568,

        /// <summary>
        /// inc r8 | FE /0 | Increment r/m byte by 1.
        /// </summary>
        [Symbol("inc r8","FE /0")]
        inc_r8_xFE = 569,

        /// <summary>
        /// ins m16, DX | 6D | Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI. 1
        /// </summary>
        [Symbol("ins m16, DX","6D")]
        ins_m16_DX = 570,

        /// <summary>
        /// ins m32, DX | 6D | Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI. 1
        /// </summary>
        [Symbol("ins m32, DX","6D")]
        ins_m32_DX = 571,

        /// <summary>
        /// ins m8, DX | 6C | Input byte from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.
        /// </summary>
        [Symbol("ins m8, DX","6C")]
        ins_m8_DX = 572,

        /// <summary>
        /// insb | 6C | Input byte from I/O port specified in DX into memory location specified with ES:(E)DI or RDI. 1
        /// </summary>
        [Symbol("insb","6C")]
        insb = 573,

        /// <summary>
        /// insd | 6D | Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI. 1
        /// </summary>
        [Symbol("insd","6D")]
        insd = 574,

        /// <summary>
        /// insw | 6D | Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI. 1
        /// </summary>
        [Symbol("insw","6D")]
        insw = 575,

        /// <summary>
        /// int imm8 | CD ib | Generate software interrupt with vector specified by immediate byte.
        /// </summary>
        [Symbol("int imm8","CD ib")]
        int_imm8 = 576,

        /// <summary>
        /// int1 | F1 | Generate debug trap.
        /// </summary>
        [Symbol("int1","F1")]
        int1 = 577,

        /// <summary>
        /// int3 | CC | Generate breakpoint trap.
        /// </summary>
        [Symbol("int3","CC")]
        int3 = 578,

        /// <summary>
        /// into | CE | Generate overflow trap if overflow flag is 1.
        /// </summary>
        [Symbol("into","CE")]
        into = 579,

        /// <summary>
        /// ja rel16 | 0F 87 cw | Jump near if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("ja rel16","0F 87 cw")]
        ja_rel16 = 580,

        /// <summary>
        /// ja rel32 | 0F 87 cd | Jump near if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("ja rel32","0F 87 cd")]
        ja_rel32 = 581,

        /// <summary>
        /// ja rel8 | 77 cb | Jump short if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("ja rel8","77 cb")]
        ja_rel8 = 582,

        /// <summary>
        /// jae rel16 | 0F 83 cw | Jump near if above or equal (CF=0).
        /// </summary>
        [Symbol("jae rel16","0F 83 cw")]
        jae_rel16 = 583,

        /// <summary>
        /// jae rel32 | 0F 83 cd | Jump near if above or equal (CF=0).
        /// </summary>
        [Symbol("jae rel32","0F 83 cd")]
        jae_rel32 = 584,

        /// <summary>
        /// jae rel8 | 73 cb | Jump short if above or equal (CF=0).
        /// </summary>
        [Symbol("jae rel8","73 cb")]
        jae_rel8 = 585,

        /// <summary>
        /// jb rel16 | 0F 82 cw | Jump near if below (CF=1).
        /// </summary>
        [Symbol("jb rel16","0F 82 cw")]
        jb_rel16 = 586,

        /// <summary>
        /// jb rel32 | 0F 82 cd | Jump near if below (CF=1).
        /// </summary>
        [Symbol("jb rel32","0F 82 cd")]
        jb_rel32 = 587,

        /// <summary>
        /// jb rel8 | 72 cb | Jump short if below (CF=1).
        /// </summary>
        [Symbol("jb rel8","72 cb")]
        jb_rel8 = 588,

        /// <summary>
        /// jbe rel16 | 0F 86 cw | Jump near if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("jbe rel16","0F 86 cw")]
        jbe_rel16 = 589,

        /// <summary>
        /// jbe rel32 | 0F 86 cd | Jump near if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("jbe rel32","0F 86 cd")]
        jbe_rel32 = 590,

        /// <summary>
        /// jbe rel8 | 76 cb | Jump short if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("jbe rel8","76 cb")]
        jbe_rel8 = 591,

        /// <summary>
        /// jc rel16 | 0F 82 cw | Jump near if carry (CF=1).
        /// </summary>
        [Symbol("jc rel16","0F 82 cw")]
        jc_rel16 = 592,

        /// <summary>
        /// jc rel32 | 0F 82 cd | Jump near if carry (CF=1).
        /// </summary>
        [Symbol("jc rel32","0F 82 cd")]
        jc_rel32 = 593,

        /// <summary>
        /// jc rel8 | 72 cb | Jump short if carry (CF=1).
        /// </summary>
        [Symbol("jc rel8","72 cb")]
        jc_rel8 = 594,

        /// <summary>
        /// jcxz rel8 | E3 cb | Jump short if CX register is 0.
        /// </summary>
        [Symbol("jcxz rel8","E3 cb")]
        jcxz_rel8 = 595,

        /// <summary>
        /// je rel16 | 0F 84 cw | Jump near if equal (ZF=1).
        /// </summary>
        [Symbol("je rel16","0F 84 cw")]
        je_rel16 = 596,

        /// <summary>
        /// je rel32 | 0F 84 cd | Jump near if equal (ZF=1).
        /// </summary>
        [Symbol("je rel32","0F 84 cd")]
        je_rel32 = 597,

        /// <summary>
        /// je rel8 | 74 cb | Jump short if equal (ZF=1).
        /// </summary>
        [Symbol("je rel8","74 cb")]
        je_rel8 = 598,

        /// <summary>
        /// jecxz rel8 | E3 cb | Jump short if ECX register is 0.
        /// </summary>
        [Symbol("jecxz rel8","E3 cb")]
        jecxz_rel8 = 599,

        /// <summary>
        /// jg rel16 | 0F 8F cw | Jump near if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("jg rel16","0F 8F cw")]
        jg_rel16 = 600,

        /// <summary>
        /// jg rel32 | 0F 8F cd | Jump near if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("jg rel32","0F 8F cd")]
        jg_rel32 = 601,

        /// <summary>
        /// jg rel8 | 7F cb | Jump short if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("jg rel8","7F cb")]
        jg_rel8 = 602,

        /// <summary>
        /// jge rel16 | 0F 8D cw | Jump near if greater or equal (SF=OF).
        /// </summary>
        [Symbol("jge rel16","0F 8D cw")]
        jge_rel16 = 603,

        /// <summary>
        /// jge rel32 | 0F 8D cd | Jump near if greater or equal (SF=OF).
        /// </summary>
        [Symbol("jge rel32","0F 8D cd")]
        jge_rel32 = 604,

        /// <summary>
        /// jge rel8 | 7D cb | Jump short if greater or equal (SF=OF).
        /// </summary>
        [Symbol("jge rel8","7D cb")]
        jge_rel8 = 605,

        /// <summary>
        /// jl rel16 | 0F 8C cw | Jump near if less (SF != OF).
        /// </summary>
        [Symbol("jl rel16","0F 8C cw")]
        jl_rel16 = 606,

        /// <summary>
        /// jl rel32 | 0F 8C cd | Jump near if less (SF != OF).
        /// </summary>
        [Symbol("jl rel32","0F 8C cd")]
        jl_rel32 = 607,

        /// <summary>
        /// jl rel8 | 7C cb | Jump short if less (SF != OF).
        /// </summary>
        [Symbol("jl rel8","7C cb")]
        jl_rel8 = 608,

        /// <summary>
        /// jle rel16 | 0F 8E cw | Jump near if less or equal (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("jle rel16","0F 8E cw")]
        jle_rel16 = 609,

        /// <summary>
        /// jle rel32 | 0F 8E cd | Jump near if less or equal (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("jle rel32","0F 8E cd")]
        jle_rel32 = 610,

        /// <summary>
        /// jle rel8 | 7E cb | Jump short if less or equal (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("jle rel8","7E cb")]
        jle_rel8 = 611,

        /// <summary>
        /// jmp m16 | FF /4 | Jump near, absolute indirect, address = zero-extended r/m16. Not supported in 64-bit mode.
        /// </summary>
        [Symbol("jmp m16","FF /4")]
        jmp_m16 = 612,

        /// <summary>
        /// jmp m32 | FF /4 | Jump near, absolute indirect, address given in r/m32. Not supported in 64-bit mode.
        /// </summary>
        [Symbol("jmp m32","FF /4")]
        jmp_m32 = 613,

        /// <summary>
        /// jmp m64 | FF /4 | Jump near, absolute indirect, RIP = 64-Bit offset from register or memory
        /// </summary>
        [Symbol("jmp m64","FF /4")]
        jmp_m64 = 614,

        /// <summary>
        /// jmp m16:16 | FF /5 | Jump far, absolute indirect, address given in m16:16
        /// </summary>
        [Symbol("jmp m16:16","FF /5")]
        jmp_mp16x16 = 615,

        /// <summary>
        /// jmp m16:32 | FF /5 | Jump far, absolute indirect, address given in m16:32.
        /// </summary>
        [Symbol("jmp m16:32","FF /5")]
        jmp_mp16x32 = 616,

        /// <summary>
        /// jmp m16:64 | REX.W FF /5 | Jump far, absolute indirect, address given in m16:64.
        /// </summary>
        [Symbol("jmp m16:64","REX.W FF /5")]
        jmp_mp16x64 = 617,

        /// <summary>
        /// jmp ptr16:16 | EA cd | Jump far, absolute, address given in operand
        /// </summary>
        [Symbol("jmp ptr16:16","EA cd")]
        jmp_p16x16 = 618,

        /// <summary>
        /// jmp ptr16:32 | EA cp | Jump far, absolute, address given in operand
        /// </summary>
        [Symbol("jmp ptr16:32","EA cp")]
        jmp_p16x32 = 619,

        /// <summary>
        /// jmp r16 | FF /4 | Jump near, absolute indirect, address = zero-extended r/m16. Not supported in 64-bit mode.
        /// </summary>
        [Symbol("jmp r16","FF /4")]
        jmp_r16 = 620,

        /// <summary>
        /// jmp r32 | FF /4 | Jump near, absolute indirect, address given in r/m32. Not supported in 64-bit mode.
        /// </summary>
        [Symbol("jmp r32","FF /4")]
        jmp_r32 = 621,

        /// <summary>
        /// jmp r64 | FF /4 | Jump near, absolute indirect, RIP = 64-Bit offset from register or memory
        /// </summary>
        [Symbol("jmp r64","FF /4")]
        jmp_r64 = 622,

        /// <summary>
        /// jmp rel16 | E9 cw | Jump near, relative, displacement relative to next instruction. Not supported in 64-bit mode.
        /// </summary>
        [Symbol("jmp rel16","E9 cw")]
        jmp_rel16 = 623,

        /// <summary>
        /// jmp rel32 | E9 cd | Jump near, relative, RIP = RIP + 32-bit displacement sign extended to 64-bits
        /// </summary>
        [Symbol("jmp rel32","E9 cd")]
        jmp_rel32 = 624,

        /// <summary>
        /// jmp rel8 | EB cb | Jump short, RIP = RIP + 8-bit displacement sign extended to 64-bits
        /// </summary>
        [Symbol("jmp rel8","EB cb")]
        jmp_rel8 = 625,

        /// <summary>
        /// jna rel16 | 0F 86 cw | Jump near if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("jna rel16","0F 86 cw")]
        jna_rel16 = 626,

        /// <summary>
        /// jna rel32 | 0F 86 cd | Jump near if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("jna rel32","0F 86 cd")]
        jna_rel32 = 627,

        /// <summary>
        /// jna rel8 | 76 cb | Jump short if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("jna rel8","76 cb")]
        jna_rel8 = 628,

        /// <summary>
        /// jnae rel16 | 0F 82 cw | Jump near if not above or equal (CF=1).
        /// </summary>
        [Symbol("jnae rel16","0F 82 cw")]
        jnae_rel16 = 629,

        /// <summary>
        /// jnae rel32 | 0F 82 cd | Jump near if not above or equal (CF=1).
        /// </summary>
        [Symbol("jnae rel32","0F 82 cd")]
        jnae_rel32 = 630,

        /// <summary>
        /// jnae rel8 | 72 cb | Jump short if not above or equal (CF=1).
        /// </summary>
        [Symbol("jnae rel8","72 cb")]
        jnae_rel8 = 631,

        /// <summary>
        /// jnb rel16 | 0F 83 cw | Jump near if not below (CF=0).
        /// </summary>
        [Symbol("jnb rel16","0F 83 cw")]
        jnb_rel16 = 632,

        /// <summary>
        /// jnb rel32 | 0F 83 cd | Jump near if not below (CF=0).
        /// </summary>
        [Symbol("jnb rel32","0F 83 cd")]
        jnb_rel32 = 633,

        /// <summary>
        /// jnb rel8 | 73 cb | Jump short if not below (CF=0).
        /// </summary>
        [Symbol("jnb rel8","73 cb")]
        jnb_rel8 = 634,

        /// <summary>
        /// jnbe rel16 | 0F 87 cw | Jump near if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("jnbe rel16","0F 87 cw")]
        jnbe_rel16 = 635,

        /// <summary>
        /// jnbe rel32 | 0F 87 cd | Jump near if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("jnbe rel32","0F 87 cd")]
        jnbe_rel32 = 636,

        /// <summary>
        /// jnbe rel8 | 77 cb | Jump short if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("jnbe rel8","77 cb")]
        jnbe_rel8 = 637,

        /// <summary>
        /// jnc rel16 | 0F 83 cw | Jump near if not carry (CF=0).
        /// </summary>
        [Symbol("jnc rel16","0F 83 cw")]
        jnc_rel16 = 638,

        /// <summary>
        /// jnc rel32 | 0F 83 cd | Jump near if not carry (CF=0).
        /// </summary>
        [Symbol("jnc rel32","0F 83 cd")]
        jnc_rel32 = 639,

        /// <summary>
        /// jnc rel8 | 73 cb | Jump short if not carry (CF=0).
        /// </summary>
        [Symbol("jnc rel8","73 cb")]
        jnc_rel8 = 640,

        /// <summary>
        /// jne rel16 | 0F 85 cw | Jump near if not equal (ZF=0).
        /// </summary>
        [Symbol("jne rel16","0F 85 cw")]
        jne_rel16 = 641,

        /// <summary>
        /// jne rel32 | 0F 85 cd | Jump near if not equal (ZF=0).
        /// </summary>
        [Symbol("jne rel32","0F 85 cd")]
        jne_rel32 = 642,

        /// <summary>
        /// jne rel8 | 75 cb | Jump short if not equal (ZF=0).
        /// </summary>
        [Symbol("jne rel8","75 cb")]
        jne_rel8 = 643,

        /// <summary>
        /// jng rel16 | 0F 8E cw | Jump near if not greater (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("jng rel16","0F 8E cw")]
        jng_rel16 = 644,

        /// <summary>
        /// jng rel32 | 0F 8E cd | Jump near if not greater (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("jng rel32","0F 8E cd")]
        jng_rel32 = 645,

        /// <summary>
        /// jng rel8 | 7E cb | Jump short if not greater (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("jng rel8","7E cb")]
        jng_rel8 = 646,

        /// <summary>
        /// jnge rel16 | 0F 8C cw | Jump near if not greater or equal (SF != OF).
        /// </summary>
        [Symbol("jnge rel16","0F 8C cw")]
        jnge_rel16 = 647,

        /// <summary>
        /// jnge rel32 | 0F 8C cd | Jump near if not greater or equal (SF != OF).
        /// </summary>
        [Symbol("jnge rel32","0F 8C cd")]
        jnge_rel32 = 648,

        /// <summary>
        /// jnge rel8 | 7C cb | Jump short if not greater or equal (SF != OF).
        /// </summary>
        [Symbol("jnge rel8","7C cb")]
        jnge_rel8 = 649,

        /// <summary>
        /// jnl rel16 | 0F 8D cw | Jump near if not less (SF=OF).
        /// </summary>
        [Symbol("jnl rel16","0F 8D cw")]
        jnl_rel16 = 650,

        /// <summary>
        /// jnl rel32 | 0F 8D cd | Jump near if not less (SF=OF).
        /// </summary>
        [Symbol("jnl rel32","0F 8D cd")]
        jnl_rel32 = 651,

        /// <summary>
        /// jnl rel8 | 7D cb | Jump short if not less (SF=OF).
        /// </summary>
        [Symbol("jnl rel8","7D cb")]
        jnl_rel8 = 652,

        /// <summary>
        /// jnle rel16 | 0F 8F cw | Jump near if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("jnle rel16","0F 8F cw")]
        jnle_rel16 = 653,

        /// <summary>
        /// jnle rel32 | 0F 8F cd | Jump near if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("jnle rel32","0F 8F cd")]
        jnle_rel32 = 654,

        /// <summary>
        /// jnle rel8 | 7F cb | Jump short if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("jnle rel8","7F cb")]
        jnle_rel8 = 655,

        /// <summary>
        /// jno rel16 | 0F 81 cw | Jump near if not overflow (OF=0).
        /// </summary>
        [Symbol("jno rel16","0F 81 cw")]
        jno_rel16 = 656,

        /// <summary>
        /// jno rel32 | 0F 81 cd | Jump near if not overflow (OF=0).
        /// </summary>
        [Symbol("jno rel32","0F 81 cd")]
        jno_rel32 = 657,

        /// <summary>
        /// jno rel8 | 71 cb | Jump short if not overflow (OF=0).
        /// </summary>
        [Symbol("jno rel8","71 cb")]
        jno_rel8 = 658,

        /// <summary>
        /// jnp rel16 | 0F 8B cw | Jump near if not parity (PF=0).
        /// </summary>
        [Symbol("jnp rel16","0F 8B cw")]
        jnp_rel16 = 659,

        /// <summary>
        /// jnp rel32 | 0F 8B cd | Jump near if not parity (PF=0).
        /// </summary>
        [Symbol("jnp rel32","0F 8B cd")]
        jnp_rel32 = 660,

        /// <summary>
        /// jnp rel8 | 7B cb | Jump short if not parity (PF=0).
        /// </summary>
        [Symbol("jnp rel8","7B cb")]
        jnp_rel8 = 661,

        /// <summary>
        /// jns rel16 | 0F 89 cw | Jump near if not sign (SF=0).
        /// </summary>
        [Symbol("jns rel16","0F 89 cw")]
        jns_rel16 = 662,

        /// <summary>
        /// jns rel32 | 0F 89 cd | Jump near if not sign (SF=0).
        /// </summary>
        [Symbol("jns rel32","0F 89 cd")]
        jns_rel32 = 663,

        /// <summary>
        /// jns rel8 | 79 cb | Jump short if not sign (SF=0).
        /// </summary>
        [Symbol("jns rel8","79 cb")]
        jns_rel8 = 664,

        /// <summary>
        /// jnz rel16 | 0F 85 cw | Jump near if not zero (ZF=0).
        /// </summary>
        [Symbol("jnz rel16","0F 85 cw")]
        jnz_rel16 = 665,

        /// <summary>
        /// jnz rel32 | 0F 85 cd | Jump near if not zero (ZF=0).
        /// </summary>
        [Symbol("jnz rel32","0F 85 cd")]
        jnz_rel32 = 666,

        /// <summary>
        /// jnz rel8 | 75 cb | Jump short if not zero (ZF=0).
        /// </summary>
        [Symbol("jnz rel8","75 cb")]
        jnz_rel8 = 667,

        /// <summary>
        /// jo rel16 | 0F 80 cw | Jump near if overflow (OF=1).
        /// </summary>
        [Symbol("jo rel16","0F 80 cw")]
        jo_rel16 = 668,

        /// <summary>
        /// jo rel32 | 0F 80 cd | Jump near if overflow (OF=1).
        /// </summary>
        [Symbol("jo rel32","0F 80 cd")]
        jo_rel32 = 669,

        /// <summary>
        /// jo rel8 | 70 cb | Jump short if overflow (OF=1).
        /// </summary>
        [Symbol("jo rel8","70 cb")]
        jo_rel8 = 670,

        /// <summary>
        /// jp rel16 | 0F 8A cw | Jump near if parity (PF=1).
        /// </summary>
        [Symbol("jp rel16","0F 8A cw")]
        jp_rel16 = 671,

        /// <summary>
        /// jp rel32 | 0F 8A cd | Jump near if parity (PF=1).
        /// </summary>
        [Symbol("jp rel32","0F 8A cd")]
        jp_rel32 = 672,

        /// <summary>
        /// jp rel8 | 7A cb | Jump short if parity (PF=1).
        /// </summary>
        [Symbol("jp rel8","7A cb")]
        jp_rel8 = 673,

        /// <summary>
        /// jpe rel16 | 0F 8A cw | Jump near if parity even (PF=1).
        /// </summary>
        [Symbol("jpe rel16","0F 8A cw")]
        jpe_rel16 = 674,

        /// <summary>
        /// jpe rel32 | 0F 8A cd | Jump near if parity even (PF=1).
        /// </summary>
        [Symbol("jpe rel32","0F 8A cd")]
        jpe_rel32 = 675,

        /// <summary>
        /// jpe rel8 | 7A cb | Jump short if parity even (PF=1).
        /// </summary>
        [Symbol("jpe rel8","7A cb")]
        jpe_rel8 = 676,

        /// <summary>
        /// jpo rel16 | 0F 8B cw | Jump near if parity odd (PF=0).
        /// </summary>
        [Symbol("jpo rel16","0F 8B cw")]
        jpo_rel16 = 677,

        /// <summary>
        /// jpo rel32 | 0F 8B cd | Jump near if parity odd (PF=0).
        /// </summary>
        [Symbol("jpo rel32","0F 8B cd")]
        jpo_rel32 = 678,

        /// <summary>
        /// jpo rel8 | 7B cb | Jump short if parity odd (PF=0).
        /// </summary>
        [Symbol("jpo rel8","7B cb")]
        jpo_rel8 = 679,

        /// <summary>
        /// jrcxz rel8 | E3 cb | Jump short if RCX register is 0.
        /// </summary>
        [Symbol("jrcxz rel8","E3 cb")]
        jrcxz_rel8 = 680,

        /// <summary>
        /// js rel16 | 0F 88 cw | Jump near if sign (SF=1).
        /// </summary>
        [Symbol("js rel16","0F 88 cw")]
        js_rel16 = 681,

        /// <summary>
        /// js rel32 | 0F 88 cd | Jump near if sign (SF=1).
        /// </summary>
        [Symbol("js rel32","0F 88 cd")]
        js_rel32 = 682,

        /// <summary>
        /// js rel8 | 78 cb | Jump short if sign (SF=1).
        /// </summary>
        [Symbol("js rel8","78 cb")]
        js_rel8 = 683,

        /// <summary>
        /// jz rel16 | 0F 84 cw | Jump near if 0 (ZF=1).
        /// </summary>
        [Symbol("jz rel16","0F 84 cw")]
        jz_rel16 = 684,

        /// <summary>
        /// jz rel32 | 0F 84 cd | Jump near if 0 (ZF=1).
        /// </summary>
        [Symbol("jz rel32","0F 84 cd")]
        jz_rel32 = 685,

        /// <summary>
        /// jz rel8 | 74 cb | Jump short if zero (ZF = 1).
        /// </summary>
        [Symbol("jz rel8","74 cb")]
        jz_rel8 = 686,

        /// <summary>
        /// kaddb k, k, k | VEX.L1.66.0F.W0 4A /r | Add 8 bits masks in k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kaddb k, k, k","VEX.L1.66.0F.W0 4A /r")]
        kaddb_k_k_k = 687,

        /// <summary>
        /// kaddd k, k, k | VEX.L1.66.0F.W1 4A /r | Add 32 bits masks in k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kaddd k, k, k","VEX.L1.66.0F.W1 4A /r")]
        kaddd_k_k_k = 688,

        /// <summary>
        /// kaddq k, k, k | VEX.L1.0F.W1 4A /r | Add 64 bits masks in k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kaddq k, k, k","VEX.L1.0F.W1 4A /r")]
        kaddq_k_k_k = 689,

        /// <summary>
        /// kaddw k, k, k | VEX.L1.0F.W0 4A /r | Add 16 bits masks in k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kaddw k, k, k","VEX.L1.0F.W0 4A /r")]
        kaddw_k_k_k = 690,

        /// <summary>
        /// kandb k, k, k | VEX.L1.66.0F.W0 41 /r | Bitwise AND 8 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kandb k, k, k","VEX.L1.66.0F.W0 41 /r")]
        kandb_k_k_k = 691,

        /// <summary>
        /// kandd k, k, k | VEX.L1.66.0F.W1 41 /r | Bitwise AND 32 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kandd k, k, k","VEX.L1.66.0F.W1 41 /r")]
        kandd_k_k_k = 692,

        /// <summary>
        /// kandnb k, k, k | VEX.L1.66.0F.W0 42 /r | Bitwise AND NOT 8 bits masks k1 and k2 and place result in k1.
        /// </summary>
        [Symbol("kandnb k, k, k","VEX.L1.66.0F.W0 42 /r")]
        kandnb_k_k_k = 693,

        /// <summary>
        /// kandnd k, k, k | VEX.L1.66.0F.W1 42 /r | Bitwise AND NOT 32 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kandnd k, k, k","VEX.L1.66.0F.W1 42 /r")]
        kandnd_k_k_k = 694,

        /// <summary>
        /// kandnq k, k, k | VEX.L1.0F.W1 42 /r | Bitwise AND NOT 64 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kandnq k, k, k","VEX.L1.0F.W1 42 /r")]
        kandnq_k_k_k = 695,

        /// <summary>
        /// kandnw k, k, k | VEX.L1.0F.W0 42 /r | Bitwise AND NOT 16 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kandnw k, k, k","VEX.L1.0F.W0 42 /r")]
        kandnw_k_k_k = 696,

        /// <summary>
        /// kandq k, k, k | VEX.L1.0F.W1 41 /r | Bitwise AND 64 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kandq k, k, k","VEX.L1.0F.W1 41 /r")]
        kandq_k_k_k = 697,

        /// <summary>
        /// kandw k, k, k | VEX.L1.0F.W0 41 /r | Bitwise AND 16 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kandw k, k, k","VEX.L1.0F.W0 41 /r")]
        kandw_k_k_k = 698,

        /// <summary>
        /// kmovb k, m8 | VEX.L0.66.0F.W0 90 /r | Move 8 bits mask from k2/m8 and store the result in k1.
        /// </summary>
        [Symbol("kmovb k, m8","VEX.L0.66.0F.W0 90 /r")]
        kmovb_k_m8 = 699,

        /// <summary>
        /// kmovb k, r32 | VEX.L0.66.0F.W0 90 /r | Move 8 bits mask from k2/m8 and store the result in k1.
        /// </summary>
        [Symbol("kmovb k, r32","VEX.L0.66.0F.W0 90 /r")]
        kmovb_k_r32 = 700,

        /// <summary>
        /// kmovb k, r32 | VEX.L0.66.0F.W0 92 /r | Move 8 bits mask from r32 to k1.
        /// </summary>
        [Symbol("kmovb k, r32","VEX.L0.66.0F.W0 92 /r")]
        kmovb_k_r32_vex = 701,

        /// <summary>
        /// kmovb m8, k | VEX.L0.66.0F.W0 91 /r | Move 8 bits mask from k1 and store the result in m8.
        /// </summary>
        [Symbol("kmovb m8, k","VEX.L0.66.0F.W0 91 /r")]
        kmovb_m8_k = 702,

        /// <summary>
        /// kmovb r32, k | VEX.L0.66.0F.W0 93 /r | Move 8 bits mask from k1 to r32.
        /// </summary>
        [Symbol("kmovb r32, k","VEX.L0.66.0F.W0 93 /r")]
        kmovb_r32_k = 703,

        /// <summary>
        /// kmovd k, m32 | VEX.L0.66.0F.W1 90 /r | Move 32 bits mask from k2/m32 and store the result in k1.
        /// </summary>
        [Symbol("kmovd k, m32","VEX.L0.66.0F.W1 90 /r")]
        kmovd_k_m32 = 704,

        /// <summary>
        /// kmovd k, r32 | VEX.L0.66.0F.W1 90 /r | Move 32 bits mask from k2/m32 and store the result in k1.
        /// </summary>
        [Symbol("kmovd k, r32","VEX.L0.66.0F.W1 90 /r")]
        kmovd_k_r32 = 705,

        /// <summary>
        /// kmovd k, r32 | VEX.L0.F2.0F.W0 92 /r | Move 32 bits mask from r32 to k1.
        /// </summary>
        [Symbol("kmovd k, r32","VEX.L0.F2.0F.W0 92 /r")]
        kmovd_k_r32_vex = 706,

        /// <summary>
        /// kmovd m32, k | VEX.L0.66.0F.W1 91 /r | Move 32 bits mask from k1 and store the result in m32.
        /// </summary>
        [Symbol("kmovd m32, k","VEX.L0.66.0F.W1 91 /r")]
        kmovd_m32_k = 707,

        /// <summary>
        /// kmovd r32, k | VEX.L0.F2.0F.W0 93 /r | Move 32 bits mask from k1 to r32.
        /// </summary>
        [Symbol("kmovd r32, k","VEX.L0.F2.0F.W0 93 /r")]
        kmovd_r32_k = 708,

        /// <summary>
        /// kmovq k, m64 | VEX.L0.0F.W1 90 /r | Move 64 bits mask from k2/m64 and store the result in k1.
        /// </summary>
        [Symbol("kmovq k, m64","VEX.L0.0F.W1 90 /r")]
        kmovq_k_m64 = 709,

        /// <summary>
        /// kmovq k, r32 | VEX.L0.0F.W1 90 /r | Move 64 bits mask from k2/m64 and store the result in k1.
        /// </summary>
        [Symbol("kmovq k, r32","VEX.L0.0F.W1 90 /r")]
        kmovq_k_r32 = 710,

        /// <summary>
        /// kmovq k, r64 | VEX.L0.F2.0F.W1 92 /r | Move 64 bits mask from r64 to k1.
        /// </summary>
        [Symbol("kmovq k, r64","VEX.L0.F2.0F.W1 92 /r")]
        kmovq_k_r64 = 711,

        /// <summary>
        /// kmovq m64, k | VEX.L0.0F.W1 91 /r | Move 64 bits mask from k1 and store the result in m64.
        /// </summary>
        [Symbol("kmovq m64, k","VEX.L0.0F.W1 91 /r")]
        kmovq_m64_k = 712,

        /// <summary>
        /// kmovq r64, k | VEX.L0.F2.0F.W1 93 /r | Move 64 bits mask from k1 to r64.
        /// </summary>
        [Symbol("kmovq r64, k","VEX.L0.F2.0F.W1 93 /r")]
        kmovq_r64_k = 713,

        /// <summary>
        /// kmovw k, m16 | VEX.L0.0F.W0 90 /r | Move 16 bits mask from k2/m16 and store the result in k1.
        /// </summary>
        [Symbol("kmovw k, m16","VEX.L0.0F.W0 90 /r")]
        kmovw_k_m16 = 714,

        /// <summary>
        /// kmovw k, r32 | VEX.L0.0F.W0 90 /r | Move 16 bits mask from k2/m16 and store the result in k1.
        /// </summary>
        [Symbol("kmovw k, r32","VEX.L0.0F.W0 90 /r")]
        kmovw_k_r32 = 715,

        /// <summary>
        /// kmovw k, r32 | VEX.L0.0F.W0 92 /r | Move 16 bits mask from r32 to k1.
        /// </summary>
        [Symbol("kmovw k, r32","VEX.L0.0F.W0 92 /r")]
        kmovw_k_r32_vex = 716,

        /// <summary>
        /// kmovw m16, k | VEX.L0.0F.W0 91 /r | Move 16 bits mask from k1 and store the result in m16.
        /// </summary>
        [Symbol("kmovw m16, k","VEX.L0.0F.W0 91 /r")]
        kmovw_m16_k = 717,

        /// <summary>
        /// kmovw r32, k | VEX.L0.0F.W0 93 /r | Move 16 bits mask from k1 to r32.
        /// </summary>
        [Symbol("kmovw r32, k","VEX.L0.0F.W0 93 /r")]
        kmovw_r32_k = 718,

        /// <summary>
        /// knotb k, k | VEX.L0.66.0F.W0 44 /r | Bitwise NOT of 8 bits mask k2.
        /// </summary>
        [Symbol("knotb k, k","VEX.L0.66.0F.W0 44 /r")]
        knotb_k_k = 719,

        /// <summary>
        /// knotd k, k | VEX.L0.66.0F.W1 44 /r | Bitwise NOT of 32 bits mask k2.
        /// </summary>
        [Symbol("knotd k, k","VEX.L0.66.0F.W1 44 /r")]
        knotd_k_k = 720,

        /// <summary>
        /// knotq k, k | VEX.L0.0F.W1 44 /r | Bitwise NOT of 64 bits mask k2.
        /// </summary>
        [Symbol("knotq k, k","VEX.L0.0F.W1 44 /r")]
        knotq_k_k = 721,

        /// <summary>
        /// knotw k, k | VEX.L0.0F.W0 44 /r | Bitwise NOT of 16 bits mask k2.
        /// </summary>
        [Symbol("knotw k, k","VEX.L0.0F.W0 44 /r")]
        knotw_k_k = 722,

        /// <summary>
        /// korb k, k, k | VEX.L1.66.0F.W0 45 /r | Bitwise OR 8 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("korb k, k, k","VEX.L1.66.0F.W0 45 /r")]
        korb_k_k_k = 723,

        /// <summary>
        /// kord k, k, k | VEX.L1.66.0F.W1 45 /r | Bitwise OR 32 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kord k, k, k","VEX.L1.66.0F.W1 45 /r")]
        kord_k_k_k = 724,

        /// <summary>
        /// korq k, k, k | VEX.L1.0F.W1 45 /r | Bitwise OR 64 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("korq k, k, k","VEX.L1.0F.W1 45 /r")]
        korq_k_k_k = 725,

        /// <summary>
        /// kortestb k, k | VEX.L0.66.0F.W0 98 /r | Bitwise OR 8 bits masks k1 and k2 and update ZF and CF accordingly.
        /// </summary>
        [Symbol("kortestb k, k","VEX.L0.66.0F.W0 98 /r")]
        kortestb_k_k = 726,

        /// <summary>
        /// kortestd k, k | VEX.L0.66.0F.W1 98 /r | Bitwise OR 32 bits masks k1 and k2 and update ZF and CF accordingly.
        /// </summary>
        [Symbol("kortestd k, k","VEX.L0.66.0F.W1 98 /r")]
        kortestd_k_k = 727,

        /// <summary>
        /// kortestq k, k | VEX.L0.0F.W1 98 /r | Bitwise OR 64 bits masks k1 and k2 and update ZF and CF accordingly.
        /// </summary>
        [Symbol("kortestq k, k","VEX.L0.0F.W1 98 /r")]
        kortestq_k_k = 728,

        /// <summary>
        /// kortestw k, k | VEX.L0.0F.W0 98 /r | Bitwise OR 16 bits masks k1 and k2 and update ZF and CF accordingly.
        /// </summary>
        [Symbol("kortestw k, k","VEX.L0.0F.W0 98 /r")]
        kortestw_k_k = 729,

        /// <summary>
        /// korw k, k, k | VEX.L1.0F.W0 45 /r | Bitwise OR 16 bits masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("korw k, k, k","VEX.L1.0F.W0 45 /r")]
        korw_k_k_k = 730,

        /// <summary>
        /// kshiftlb k, k, imm8 | VEX.L0.66.0F3A.W0 32 /r | Shift left 8 bits in k2 by immediate and write result in k1.
        /// </summary>
        [Symbol("kshiftlb k, k, imm8","VEX.L0.66.0F3A.W0 32 /r")]
        kshiftlb_k_k_imm8 = 731,

        /// <summary>
        /// kshiftld k, k, imm8 | VEX.L0.66.0F3A.W0 33 /r | Shift left 32 bits in k2 by immediate and write result in k1.
        /// </summary>
        [Symbol("kshiftld k, k, imm8","VEX.L0.66.0F3A.W0 33 /r")]
        kshiftld_k_k_imm8 = 732,

        /// <summary>
        /// kshiftlq k, k, imm8 | VEX.L0.66.0F3A.W1 33 /r | Shift left 64 bits in k2 by immediate and write result in k1.
        /// </summary>
        [Symbol("kshiftlq k, k, imm8","VEX.L0.66.0F3A.W1 33 /r")]
        kshiftlq_k_k_imm8 = 733,

        /// <summary>
        /// kshiftlw k, k, imm8 | VEX.L0.66.0F3A.W1 32 /r | Shift left 16 bits in k2 by immediate and write result in k1.
        /// </summary>
        [Symbol("kshiftlw k, k, imm8","VEX.L0.66.0F3A.W1 32 /r")]
        kshiftlw_k_k_imm8 = 734,

        /// <summary>
        /// kshiftrb k, k, imm8 | VEX.L0.66.0F3A.W0 30 /r | Shift right 8 bits in k2 by immediate and write result in k1.
        /// </summary>
        [Symbol("kshiftrb k, k, imm8","VEX.L0.66.0F3A.W0 30 /r")]
        kshiftrb_k_k_imm8 = 735,

        /// <summary>
        /// kshiftrd k, k, imm8 | VEX.L0.66.0F3A.W0 31 /r | Shift right 32 bits in k2 by immediate and write result in k1.
        /// </summary>
        [Symbol("kshiftrd k, k, imm8","VEX.L0.66.0F3A.W0 31 /r")]
        kshiftrd_k_k_imm8 = 736,

        /// <summary>
        /// kshiftrq k, k, imm8 | VEX.L0.66.0F3A.W1 31 /r | Shift right 64 bits in k2 by immediate and write result in k1.
        /// </summary>
        [Symbol("kshiftrq k, k, imm8","VEX.L0.66.0F3A.W1 31 /r")]
        kshiftrq_k_k_imm8 = 737,

        /// <summary>
        /// kshiftrw k, k, imm8 | VEX.L0.66.0F3A.W1 30 /r | Shift right 16 bits in k2 by immediate and write result in k1.
        /// </summary>
        [Symbol("kshiftrw k, k, imm8","VEX.L0.66.0F3A.W1 30 /r")]
        kshiftrw_k_k_imm8 = 738,

        /// <summary>
        /// ktestb k, k | VEX.L0.66.0F.W0 99 /r | Set ZF and CF depending on sign bit AND and ANDN of 8 bits mask register sources.
        /// </summary>
        [Symbol("ktestb k, k","VEX.L0.66.0F.W0 99 /r")]
        ktestb_k_k = 739,

        /// <summary>
        /// ktestd k, k | VEX.L0.66.0F.W1 99 /r | Set ZF and CF depending on sign bit AND and ANDN of 32 bits mask register sources.
        /// </summary>
        [Symbol("ktestd k, k","VEX.L0.66.0F.W1 99 /r")]
        ktestd_k_k = 740,

        /// <summary>
        /// ktestq k, k | VEX.L0.0F.W1 99 /r | Set ZF and CF depending on sign bit AND and ANDN of 64 bits mask register sources.
        /// </summary>
        [Symbol("ktestq k, k","VEX.L0.0F.W1 99 /r")]
        ktestq_k_k = 741,

        /// <summary>
        /// ktestw k, k | VEX.L0.0F.W0 99 /r | Set ZF and CF depending on sign bit AND and ANDN of 16 bits mask register sources.
        /// </summary>
        [Symbol("ktestw k, k","VEX.L0.0F.W0 99 /r")]
        ktestw_k_k = 742,

        /// <summary>
        /// kunpckbw k, k, k | VEX.L1.66.0F.W0 4B /r | Unpack 8-bit masks in k2 and k3 and write word result in k1.
        /// </summary>
        [Symbol("kunpckbw k, k, k","VEX.L1.66.0F.W0 4B /r")]
        kunpckbw_k_k_k = 743,

        /// <summary>
        /// kunpckdq k, k, k | VEX.L1.0F.W1 4B /r | Unpack 32-bit masks in k2 and k3 and write quadword result in k1.
        /// </summary>
        [Symbol("kunpckdq k, k, k","VEX.L1.0F.W1 4B /r")]
        kunpckdq_k_k_k = 744,

        /// <summary>
        /// kunpckwd k, k, k | VEX.L1.0F.W0 4B /r | Unpack 16-bit masks in k2 and k3 and write doubleword result in k1.
        /// </summary>
        [Symbol("kunpckwd k, k, k","VEX.L1.0F.W0 4B /r")]
        kunpckwd_k_k_k = 745,

        /// <summary>
        /// kxnorb k, k, k | VEX.L1.66.0F.W0 46 /r | Bitwise XNOR 8-bit masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kxnorb k, k, k","VEX.L1.66.0F.W0 46 /r")]
        kxnorb_k_k_k = 746,

        /// <summary>
        /// kxnord k, k, k | VEX.L1.66.0F.W1 46 /r | Bitwise XNOR 32-bit masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kxnord k, k, k","VEX.L1.66.0F.W1 46 /r")]
        kxnord_k_k_k = 747,

        /// <summary>
        /// kxnorq k, k, k | VEX.L1.0F.W1 46 /r | Bitwise XNOR 64-bit masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kxnorq k, k, k","VEX.L1.0F.W1 46 /r")]
        kxnorq_k_k_k = 748,

        /// <summary>
        /// kxnorw k, k, k | VEX.L1.0F.W0 46 /r | Bitwise XNOR 16-bit masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kxnorw k, k, k","VEX.L1.0F.W0 46 /r")]
        kxnorw_k_k_k = 749,

        /// <summary>
        /// kxorb k, k, k | VEX.L1.66.0F.W0 47 /r | Bitwise XOR 8-bit masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kxorb k, k, k","VEX.L1.66.0F.W0 47 /r")]
        kxorb_k_k_k = 750,

        /// <summary>
        /// kxord k, k, k | VEX.L1.66.0F.W1 47 /r | Bitwise XOR 32-bit masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kxord k, k, k","VEX.L1.66.0F.W1 47 /r")]
        kxord_k_k_k = 751,

        /// <summary>
        /// kxorq k, k, k | VEX.L1.0F.W1 47 /r | Bitwise XOR 64-bit masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kxorq k, k, k","VEX.L1.0F.W1 47 /r")]
        kxorq_k_k_k = 752,

        /// <summary>
        /// kxorw k, k, k | VEX.L1.0F.W0 47 /r | Bitwise XOR 16-bit masks k2 and k3 and place result in k1.
        /// </summary>
        [Symbol("kxorw k, k, k","VEX.L1.0F.W0 47 /r")]
        kxorw_k_k_k = 753,

        /// <summary>
        /// lddqu xmm, mem | F2 0F F0 /r | Load unaligned data from mem and return double quadword in xmm1.
        /// </summary>
        [Symbol("lddqu xmm, mem","F2 0F F0 /r")]
        lddqu_xmm_mem = 754,

        /// <summary>
        /// lds r16, m16:16 | C5 /r | Load DS:r16 with far pointer from memory.
        /// </summary>
        [Symbol("lds r16, m16:16","C5 /r")]
        lds_r16_mp16x16 = 755,

        /// <summary>
        /// lds r32, m16:32 | C5 /r | Load DS:r32 with far pointer from memory.
        /// </summary>
        [Symbol("lds r32, m16:32","C5 /r")]
        lds_r32_mp16x32 = 756,

        /// <summary>
        /// lea r16, m | 8D /r | Store effective address for m in register r16.
        /// </summary>
        [Symbol("lea r16, m","8D /r")]
        lea_r16_m = 757,

        /// <summary>
        /// lea r32, m | 8D /r | Store effective address for m in register r32.
        /// </summary>
        [Symbol("lea r32, m","8D /r")]
        lea_r32_m = 758,

        /// <summary>
        /// lea r64, m | REX.W + 8D /r | Store effective address for m in register r64.
        /// </summary>
        [Symbol("lea r64, m","REX.W + 8D /r")]
        lea_r64_m = 759,

        /// <summary>
        /// leave | C9 | Set SP to BP, then pop BP.
        /// </summary>
        [Symbol("leave","C9")]
        leave = 760,

        /// <summary>
        /// les r16, m16:16 | C4 /r | Load ES:r16 with far pointer from memory.
        /// </summary>
        [Symbol("les r16, m16:16","C4 /r")]
        les_r16_mp16x16 = 761,

        /// <summary>
        /// les r32, m16:32 | C4 /r | Load ES:r32 with far pointer from memory.
        /// </summary>
        [Symbol("les r32, m16:32","C4 /r")]
        les_r32_mp16x32 = 762,

        /// <summary>
        /// lfs r16, m16:16 | 0F B4 /r | Load FS:r16 with far pointer from memory.
        /// </summary>
        [Symbol("lfs r16, m16:16","0F B4 /r")]
        lfs_r16_mp16x16 = 763,

        /// <summary>
        /// lfs r32, m16:32 | 0F B4 /r | Load FS:r32 with far pointer from memory.
        /// </summary>
        [Symbol("lfs r32, m16:32","0F B4 /r")]
        lfs_r32_mp16x32 = 764,

        /// <summary>
        /// lfs r64, m16:64 | REX + 0F B4 /r | Load FS:r64 with far pointer from memory.
        /// </summary>
        [Symbol("lfs r64, m16:64","REX + 0F B4 /r")]
        lfs_r64_mp16x64 = 765,

        /// <summary>
        /// lgdt m16&32 | 0F 01 /2 | Load m into GDTR.
        /// </summary>
        [Symbol("lgdt m16&32","0F 01 /2")]
        lgdt_m16x32 = 766,

        /// <summary>
        /// lgdt m16&64 | 0F 01 /2 | Load m into GDTR.
        /// </summary>
        [Symbol("lgdt m16&64","0F 01 /2")]
        lgdt_m16x64 = 767,

        /// <summary>
        /// lgs r16, m16:16 | 0F B5 /r | Load GS:r16 with far pointer from memory.
        /// </summary>
        [Symbol("lgs r16, m16:16","0F B5 /r")]
        lgs_r16_mp16x16 = 768,

        /// <summary>
        /// lgs r32, m16:32 | 0F B5 /r | Load GS:r32 with far pointer from memory.
        /// </summary>
        [Symbol("lgs r32, m16:32","0F B5 /r")]
        lgs_r32_mp16x32 = 769,

        /// <summary>
        /// lgs r64, m16:64 | REX + 0F B5 /r | Load GS:r64 with far pointer from memory.
        /// </summary>
        [Symbol("lgs r64, m16:64","REX + 0F B5 /r")]
        lgs_r64_mp16x64 = 770,

        /// <summary>
        /// lidt m16&32 | 0F 01 /3 | Load m into IDTR.
        /// </summary>
        [Symbol("lidt m16&32","0F 01 /3")]
        lidt_m16x32 = 771,

        /// <summary>
        /// lidt m16&64 | 0F 01 /3 | Load m into IDTR.
        /// </summary>
        [Symbol("lidt m16&64","0F 01 /3")]
        lidt_m16x64 = 772,

        /// <summary>
        /// lldt m16 | 0F 00 /2 | Load segment selector r/m 16 into LDTR.
        /// </summary>
        [Symbol("lldt m16","0F 00 /2")]
        lldt_m16 = 773,

        /// <summary>
        /// lldt r16 | 0F 00 /2 | Load segment selector r/m 16 into LDTR.
        /// </summary>
        [Symbol("lldt r16","0F 00 /2")]
        lldt_r16 = 774,

        /// <summary>
        /// lmsw m16 | 0F 01 /6 | Loads r/m 16 in machine status word of CR0.
        /// </summary>
        [Symbol("lmsw m16","0F 01 /6")]
        lmsw_m16 = 775,

        /// <summary>
        /// lmsw r16 | 0F 01 /6 | Loads r/m 16 in machine status word of CR0.
        /// </summary>
        [Symbol("lmsw r16","0F 01 /6")]
        lmsw_r16 = 776,

        /// <summary>
        /// lock | F0 | Asserts LOCK# signal for duration of the accompanying instruction.
        /// </summary>
        [Symbol("lock","F0")]
        @lock = 777,

        /// <summary>
        /// lods m16 | AD | For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.
        /// </summary>
        [Symbol("lods m16","AD")]
        lods_m16 = 778,

        /// <summary>
        /// lods m32 | AD | For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.
        /// </summary>
        [Symbol("lods m32","AD")]
        lods_m32 = 779,

        /// <summary>
        /// lods m64 | REX.W + AD | Load qword at address (R)SI into RAX.
        /// </summary>
        [Symbol("lods m64","REX.W + AD")]
        lods_m64 = 780,

        /// <summary>
        /// lods m8 | AC | For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.
        /// </summary>
        [Symbol("lods m8","AC")]
        lods_m8 = 781,

        /// <summary>
        /// lodsb | AC | For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.
        /// </summary>
        [Symbol("lodsb","AC")]
        lodsb = 782,

        /// <summary>
        /// lodsd | AD | For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.
        /// </summary>
        [Symbol("lodsd","AD")]
        lodsd = 783,

        /// <summary>
        /// lodsq | REX.W + AD | Load qword at address (R)SI into RAX.
        /// </summary>
        [Symbol("lodsq","REX.W + AD")]
        lodsq = 784,

        /// <summary>
        /// lodsw | AD | For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.
        /// </summary>
        [Symbol("lodsw","AD")]
        lodsw = 785,

        /// <summary>
        /// loop rel8 | E2 cb | Decrement count; jump short if count  != 0.
        /// </summary>
        [Symbol("loop rel8","E2 cb")]
        loop_rel8 = 786,

        /// <summary>
        /// loope rel8 | E1 cb | Decrement count; jump short if count  != 0 and ZF = 1.
        /// </summary>
        [Symbol("loope rel8","E1 cb")]
        loope_rel8 = 787,

        /// <summary>
        /// loopne rel8 | E0 cb | Decrement count; jump short if count  != 0 and ZF = 0.
        /// </summary>
        [Symbol("loopne rel8","E0 cb")]
        loopne_rel8 = 788,

        /// <summary>
        /// lsl r16, m16 | 0F 03 /r | Load: r16 := segment limit, selector r16/m16.
        /// </summary>
        [Symbol("lsl r16, m16","0F 03 /r")]
        lsl_r16_m16 = 789,

        /// <summary>
        /// lsl r16, r16 | 0F 03 /r | Load: r16 := segment limit, selector r16/m16.
        /// </summary>
        [Symbol("lsl r16, r16","0F 03 /r")]
        lsl_r16_r16 = 790,

        /// <summary>
        /// lsl r32, m16 | 0F 03 /r | Load: r32 := segment limit, selector r32/m16.
        /// </summary>
        [Symbol("lsl r32, m16","0F 03 /r")]
        lsl_r32_m16 = 791,

        /// <summary>
        /// lsl r32, r32 | 0F 03 /r | Load: r32 := segment limit, selector r32/m16.
        /// </summary>
        [Symbol("lsl r32, r32","0F 03 /r")]
        lsl_r32_r32 = 792,

        /// <summary>
        /// lsl r64, m16 | REX.W + 0F 03 /r | Load: r64 := segment limit, selector r32/m16
        /// </summary>
        [Symbol("lsl r64, m16","REX.W + 0F 03 /r")]
        lsl_r64_m16 = 793,

        /// <summary>
        /// lsl r64, r32 | REX.W + 0F 03 /r | Load: r64 := segment limit, selector r32/m16
        /// </summary>
        [Symbol("lsl r64, r32","REX.W + 0F 03 /r")]
        lsl_r64_r32 = 794,

        /// <summary>
        /// lss r16, m16:16 | 0F B2 /r | Load SS:r16 with far pointer from memory.
        /// </summary>
        [Symbol("lss r16, m16:16","0F B2 /r")]
        lss_r16_mp16x16 = 795,

        /// <summary>
        /// lss r32, m16:32 | 0F B2 /r | Load SS:r32 with far pointer from memory.
        /// </summary>
        [Symbol("lss r32, m16:32","0F B2 /r")]
        lss_r32_mp16x32 = 796,

        /// <summary>
        /// lss r64, m16:64 | REX + 0F B2 /r | Load SS:r64 with far pointer from memory.
        /// </summary>
        [Symbol("lss r64, m16:64","REX + 0F B2 /r")]
        lss_r64_mp16x64 = 797,

        /// <summary>
        /// maskmovdqu xmm, xmm | 66 0F F7 /r | Selectively write bytes from xmm1 to memory location using the byte mask in xmm2. The default memory location is specified by DS:DI/EDI/RDI.
        /// </summary>
        [Symbol("maskmovdqu xmm, xmm","66 0F F7 /r")]
        maskmovdqu_xmm_xmm = 798,

        /// <summary>
        /// maskmovq mm, mm | NP 0F F7 /r | Selectively write bytes from mm1 to memory location using the byte mask in mm2. The default memory location is specified by DS:DI/EDI/RDI.
        /// </summary>
        [Symbol("maskmovq mm, mm","NP 0F F7 /r")]
        maskmovq_mm_mm = 799,

        /// <summary>
        /// mov AL, moffs8 | REX.W + A0 | Move byte at ( offset ) to AL.
        /// </summary>
        [Symbol("mov AL, moffs8","REX.W + A0")]
        mov_AL_moffs8 = 800,

        /// <summary>
        /// mov AL, moffs8 | A0 | Move byte at ( seg:offset ) to AL.
        /// </summary>
        [Symbol("mov AL, moffs8","A0")]
        mov_AL_moffs8_xA0 = 801,

        /// <summary>
        /// mov AX, moffs16 | A1 | Move word at ( seg:offset ) to AX.
        /// </summary>
        [Symbol("mov AX, moffs16","A1")]
        mov_AX_moffs16 = 802,

        /// <summary>
        /// mov CR, r32 | 0F 22 /r | Move r32 to control register.
        /// </summary>
        [Symbol("mov CR, r32","0F 22 /r")]
        mov_CR_r32 = 803,

        /// <summary>
        /// mov CR, r64 | 0F 22 /r | Move r64 to extended control register.
        /// </summary>
        [Symbol("mov CR, r64","0F 22 /r")]
        mov_CR_r64 = 804,

        /// <summary>
        /// mov CR8, r64 | REX.R + 0F 22 /0 | Move r64 to extended CR8. 1
        /// </summary>
        [Symbol("mov CR8, r64","REX.R + 0F 22 /0")]
        mov_CR8_r64 = 805,

        /// <summary>
        /// mov DR, r32 | 0F 23 /r | Move r32 to debug register.
        /// </summary>
        [Symbol("mov DR, r32","0F 23 /r")]
        mov_DR_r32 = 806,

        /// <summary>
        /// mov DR, r64 | 0F 23 /r | Move r64 to extended debug register.
        /// </summary>
        [Symbol("mov DR, r64","0F 23 /r")]
        mov_DR_r64 = 807,

        /// <summary>
        /// mov EAX, moffs32 | A1 | Move doubleword at ( seg:offset ) to EAX.
        /// </summary>
        [Symbol("mov EAX, moffs32","A1")]
        mov_EAX_moffs32 = 808,

        /// <summary>
        /// mov m16, imm16 | C7 /0 iw | Move imm16 to r/m16.
        /// </summary>
        [Symbol("mov m16, imm16","C7 /0 iw")]
        mov_m16_imm16 = 809,

        /// <summary>
        /// mov m16, r16 | 89 /r | Move r16 to r/m16.
        /// </summary>
        [Symbol("mov m16, r16","89 /r")]
        mov_m16_r16 = 810,

        /// <summary>
        /// mov m16, Sreg | 8C /r | Move segment register to r/m16.
        /// </summary>
        [Symbol("mov m16, Sreg","8C /r")]
        mov_m16_Sreg = 811,

        /// <summary>
        /// mov m16, Sreg | REX.W + 8C /r | Move zero extended 16-bit segment register to r16/r32/r64/m16.
        /// </summary>
        [Symbol("mov m16, Sreg","REX.W + 8C /r")]
        mov_m16_Sreg_rex = 812,

        /// <summary>
        /// mov m32, imm32 | C7 /0 id | Move imm32 to r/m32.
        /// </summary>
        [Symbol("mov m32, imm32","C7 /0 id")]
        mov_m32_imm32 = 813,

        /// <summary>
        /// mov m32, r32 | 89 /r | Move r32 to r/m32.
        /// </summary>
        [Symbol("mov m32, r32","89 /r")]
        mov_m32_r32 = 814,

        /// <summary>
        /// mov m32, Sreg | REX.W + 8C /r | Move zero extended 16-bit segment register to r16/r32/r64/m16.
        /// </summary>
        [Symbol("mov m32, Sreg","REX.W + 8C /r")]
        mov_m32_Sreg = 815,

        /// <summary>
        /// mov m64, imm32 | REX.W + C7 /0 id | Move imm32 sign extended to 64-bits to r/m64.
        /// </summary>
        [Symbol("mov m64, imm32","REX.W + C7 /0 id")]
        mov_m64_imm32 = 816,

        /// <summary>
        /// mov m64, r64 | REX.W + 89 /r | Move r64 to r/m64.
        /// </summary>
        [Symbol("mov m64, r64","REX.W + 89 /r")]
        mov_m64_r64 = 817,

        /// <summary>
        /// mov m8, imm8 | C6 /0 ib | Move imm8 to r/m8.
        /// </summary>
        [Symbol("mov m8, imm8","C6 /0 ib")]
        mov_m8_imm8 = 818,

        /// <summary>
        /// mov m8, imm8 | REX + C6 /0 ib | Move imm8 to r/m8.
        /// </summary>
        [Symbol("mov m8, imm8","REX + C6 /0 ib")]
        mov_m8_imm8_rex = 819,

        /// <summary>
        /// mov m8, r8 | 88 /r | Move r8 to r/m8.
        /// </summary>
        [Symbol("mov m8, r8","88 /r")]
        mov_m8_r8 = 820,

        /// <summary>
        /// mov m8, r8 | REX + 88 /r | Move r8 to r/m8.
        /// </summary>
        [Symbol("mov m8, r8","REX + 88 /r")]
        mov_m8_r8_rex = 821,

        /// <summary>
        /// mov moffs16, AX | A3 | Move AX to ( seg:offset ).
        /// </summary>
        [Symbol("mov moffs16, AX","A3")]
        mov_moffs16_AX = 822,

        /// <summary>
        /// mov moffs32, EAX | A3 | Move EAX to ( seg:offset ).
        /// </summary>
        [Symbol("mov moffs32, EAX","A3")]
        mov_moffs32_EAX = 823,

        /// <summary>
        /// mov moffs64, RAX | REX.W + A3 | Move RAX to ( offset ).
        /// </summary>
        [Symbol("mov moffs64, RAX","REX.W + A3")]
        mov_moffs64_RAX = 824,

        /// <summary>
        /// mov moffs8, AL | REX.W + A2 | Move AL to ( offset ).
        /// </summary>
        [Symbol("mov moffs8, AL","REX.W + A2")]
        mov_moffs8_AL = 825,

        /// <summary>
        /// mov moffs8, AL | A2 | Move AL to ( seg:offset ).
        /// </summary>
        [Symbol("mov moffs8, AL","A2")]
        mov_moffs8_AL_xA2 = 826,

        /// <summary>
        /// mov r16, imm16 | C7 /0 iw | Move imm16 to r/m16.
        /// </summary>
        [Symbol("mov r16, imm16","C7 /0 iw")]
        mov_r16_imm16 = 827,

        /// <summary>
        /// mov r16, imm16 | B8 +rw iw | Move imm16 to r16.
        /// </summary>
        [Symbol("mov r16, imm16","B8 +rw iw")]
        mov_r16_imm16_rex = 828,

        /// <summary>
        /// mov r16, m16 | 8B /r | Move r/m16 to r16.
        /// </summary>
        [Symbol("mov r16, m16","8B /r")]
        mov_r16_m16 = 829,

        /// <summary>
        /// mov r16, r16 | 89 /r | Move r16 to r/m16.
        /// </summary>
        [Symbol("mov r16, r16","89 /r")]
        mov_r16_r16 = 830,

        /// <summary>
        /// mov r16, r16 | 8B /r | Move r/m16 to r16.
        /// </summary>
        [Symbol("mov r16, r16","8B /r")]
        mov_r16_r16_x8B = 831,

        /// <summary>
        /// mov r16, Sreg | 8C /r | Move segment register to r/m16.
        /// </summary>
        [Symbol("mov r16, Sreg","8C /r")]
        mov_r16_Sreg = 832,

        /// <summary>
        /// mov r16, Sreg | REX.W + 8C /r | Move zero extended 16-bit segment register to r16/r32/r64/m16.
        /// </summary>
        [Symbol("mov r16, Sreg","REX.W + 8C /r")]
        mov_r16_Sreg_rex = 833,

        /// <summary>
        /// mov r32, CR | 0F 20 /r | Move control register to r32.
        /// </summary>
        [Symbol("mov r32, CR","0F 20 /r")]
        mov_r32_CR = 834,

        /// <summary>
        /// mov r32, DR | 0F 21 /r | Move debug register to r32.
        /// </summary>
        [Symbol("mov r32, DR","0F 21 /r")]
        mov_r32_DR = 835,

        /// <summary>
        /// mov r32, imm32 | C7 /0 id | Move imm32 to r/m32.
        /// </summary>
        [Symbol("mov r32, imm32","C7 /0 id")]
        mov_r32_imm32 = 836,

        /// <summary>
        /// mov r32, imm32 | B8 +rd id | Move imm32 to r32.
        /// </summary>
        [Symbol("mov r32, imm32","B8 +rd id")]
        mov_r32_imm32_rex = 837,

        /// <summary>
        /// mov r32, m32 | 8B /r | Move r/m32 to r32.
        /// </summary>
        [Symbol("mov r32, m32","8B /r")]
        mov_r32_m32 = 838,

        /// <summary>
        /// mov r32, r32 | 89 /r | Move r32 to r/m32.
        /// </summary>
        [Symbol("mov r32, r32","89 /r")]
        mov_r32_r32 = 839,

        /// <summary>
        /// mov r32, r32 | 8B /r | Move r/m32 to r32.
        /// </summary>
        [Symbol("mov r32, r32","8B /r")]
        mov_r32_r32_x8B = 840,

        /// <summary>
        /// mov r64, CR | 0F 20 /r | Move extended control register to r64.
        /// </summary>
        [Symbol("mov r64, CR","0F 20 /r")]
        mov_r64_CR = 841,

        /// <summary>
        /// mov r64, CR8 | REX.R + 0F 20 /0 | Move extended CR8 to r64. 1
        /// </summary>
        [Symbol("mov r64, CR8","REX.R + 0F 20 /0")]
        mov_r64_CR8 = 842,

        /// <summary>
        /// mov r64, DR | 0F 21 /r | Move extended debug register to r64.
        /// </summary>
        [Symbol("mov r64, DR","0F 21 /r")]
        mov_r64_DR = 843,

        /// <summary>
        /// mov r64, imm32 | REX.W + C7 /0 id | Move imm32 sign extended to 64-bits to r/m64.
        /// </summary>
        [Symbol("mov r64, imm32","REX.W + C7 /0 id")]
        mov_r64_imm32 = 844,

        /// <summary>
        /// mov r64, imm64 | REX.W + B8 +rd io | Move imm64 to r64.
        /// </summary>
        [Symbol("mov r64, imm64","REX.W + B8 +rd io")]
        mov_r64_imm64 = 845,

        /// <summary>
        /// mov r64, m64 | REX.W + 8B /r | Move r/m64 to r64.
        /// </summary>
        [Symbol("mov r64, m64","REX.W + 8B /r")]
        mov_r64_m64 = 846,

        /// <summary>
        /// mov r64, r64 | REX.W + 89 /r | Move r64 to r/m64.
        /// </summary>
        [Symbol("mov r64, r64","REX.W + 89 /r")]
        mov_r64_r64 = 847,

        /// <summary>
        /// mov r64, r64 | REX.W + 8B /r | Move r/m64 to r64.
        /// </summary>
        [Symbol("mov r64, r64","REX.W + 8B /r")]
        mov_r64_r64_x8B = 848,

        /// <summary>
        /// mov r64, Sreg | REX.W + 8C /r | Move zero extended 16-bit segment register to r64/m16.
        /// </summary>
        [Symbol("mov r64, Sreg","REX.W + 8C /r")]
        mov_r64_Sreg = 849,

        /// <summary>
        /// mov r8, imm8 | C6 /0 ib | Move imm8 to r/m8.
        /// </summary>
        [Symbol("mov r8, imm8","C6 /0 ib")]
        mov_r8_imm8 = 850,

        /// <summary>
        /// mov r8, imm8 | REX + C6 /0 ib | Move imm8 to r/m8.
        /// </summary>
        [Symbol("mov r8, imm8","REX + C6 /0 ib")]
        mov_r8_imm8_rex = 851,

        /// <summary>
        /// mov r8, m8 | 8A /r | Move r/m8 to r8.
        /// </summary>
        [Symbol("mov r8, m8","8A /r")]
        mov_r8_m8 = 852,

        /// <summary>
        /// mov r8, m8 | REX + 8A /r | Move r/m8 to r8.
        /// </summary>
        [Symbol("mov r8, m8","REX + 8A /r")]
        mov_r8_m8_rex = 853,

        /// <summary>
        /// mov r8, r8 | 88 /r | Move r8 to r/m8.
        /// </summary>
        [Symbol("mov r8, r8","88 /r")]
        mov_r8_r8 = 854,

        /// <summary>
        /// mov r8, r8 | REX + 88 /r | Move r8 to r/m8.
        /// </summary>
        [Symbol("mov r8, r8","REX + 88 /r")]
        mov_r8_r8_rex = 855,

        /// <summary>
        /// mov r8, r8 | 8A /r | Move r/m8 to r8.
        /// </summary>
        [Symbol("mov r8, r8","8A /r")]
        mov_r8_r8_x8A = 856,

        /// <summary>
        /// mov RAX, moffs64 | REX.W + A1 | Move quadword at ( offset ) to RAX.
        /// </summary>
        [Symbol("mov RAX, moffs64","REX.W + A1")]
        mov_RAX_moffs64 = 857,

        /// <summary>
        /// mov Sreg, m16 | 8E /r | Move r/m16 to segment register.
        /// </summary>
        [Symbol("mov Sreg, m16","8E /r")]
        mov_Sreg_m16 = 858,

        /// <summary>
        /// mov Sreg, m64 | REX.W + 8E /r | Move lower 16 bits of r/m64 to segment register.
        /// </summary>
        [Symbol("mov Sreg, m64","REX.W + 8E /r")]
        mov_Sreg_m64 = 859,

        /// <summary>
        /// mov Sreg, r16 | 8E /r | Move r/m16 to segment register.
        /// </summary>
        [Symbol("mov Sreg, r16","8E /r")]
        mov_Sreg_r16 = 860,

        /// <summary>
        /// mov Sreg, r64 | REX.W + 8E /r | Move lower 16 bits of r/m64 to segment register.
        /// </summary>
        [Symbol("mov Sreg, r64","REX.W + 8E /r")]
        mov_Sreg_r64 = 861,

        /// <summary>
        /// movapd m128, xmm | 66 0F 29 /r | Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("movapd m128, xmm","66 0F 29 /r")]
        movapd_m128_xmm = 862,

        /// <summary>
        /// movapd r8, xmm | 66 0F 29 /r | Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("movapd r8, xmm","66 0F 29 /r")]
        movapd_r8_xmm = 863,

        /// <summary>
        /// movapd xmm, m128 | 66 0F 28 /r | Move aligned packed double-precision floating-point values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("movapd xmm, m128","66 0F 28 /r")]
        movapd_xmm_m128 = 864,

        /// <summary>
        /// movapd xmm, r8 | 66 0F 28 /r | Move aligned packed double-precision floating-point values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("movapd xmm, r8","66 0F 28 /r")]
        movapd_xmm_r8 = 865,

        /// <summary>
        /// movaps m128, xmm | NP 0F 29 /r | Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("movaps m128, xmm","NP 0F 29 /r")]
        movaps_m128_xmm = 866,

        /// <summary>
        /// movaps r8, xmm | NP 0F 29 /r | Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("movaps r8, xmm","NP 0F 29 /r")]
        movaps_r8_xmm = 867,

        /// <summary>
        /// movaps xmm, m128 | NP 0F 28 /r | Move aligned packed single-precision floating-point values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("movaps xmm, m128","NP 0F 28 /r")]
        movaps_xmm_m128 = 868,

        /// <summary>
        /// movaps xmm, r8 | NP 0F 28 /r | Move aligned packed single-precision floating-point values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("movaps xmm, r8","NP 0F 28 /r")]
        movaps_xmm_r8 = 869,

        /// <summary>
        /// movd m32, mm | NP 0F 7E /r | Move doubleword from mm to r/m32.
        /// </summary>
        [Symbol("movd m32, mm","NP 0F 7E /r")]
        movd_m32_mm = 870,

        /// <summary>
        /// movd m32, xmm | 66 0F 7E /r | Move doubleword from xmm register to r/m32.
        /// </summary>
        [Symbol("movd m32, xmm","66 0F 7E /r")]
        movd_m32_xmm = 871,

        /// <summary>
        /// movd mm, m32 | NP 0F 6E /r | Move doubleword from r/m32 to mm.
        /// </summary>
        [Symbol("movd mm, m32","NP 0F 6E /r")]
        movd_mm_m32 = 872,

        /// <summary>
        /// movd mm, r32 | NP 0F 6E /r | Move doubleword from r/m32 to mm.
        /// </summary>
        [Symbol("movd mm, r32","NP 0F 6E /r")]
        movd_mm_r32 = 873,

        /// <summary>
        /// movd r32, mm | NP 0F 7E /r | Move doubleword from mm to r/m32.
        /// </summary>
        [Symbol("movd r32, mm","NP 0F 7E /r")]
        movd_r32_mm = 874,

        /// <summary>
        /// movd r32, xmm | 66 0F 7E /r | Move doubleword from xmm register to r/m32.
        /// </summary>
        [Symbol("movd r32, xmm","66 0F 7E /r")]
        movd_r32_xmm = 875,

        /// <summary>
        /// movd xmm, m32 | 66 0F 6E /r | Move doubleword from r/m32 to xmm.
        /// </summary>
        [Symbol("movd xmm, m32","66 0F 6E /r")]
        movd_xmm_m32 = 876,

        /// <summary>
        /// movd xmm, r32 | 66 0F 6E /r | Move doubleword from r/m32 to xmm.
        /// </summary>
        [Symbol("movd xmm, r32","66 0F 6E /r")]
        movd_xmm_r32 = 877,

        /// <summary>
        /// movdir64b m32, m512 | 66 0F 38 F8 /r | Move 64-bytes as direct-store with guaranteed 64-byte write atomicity from the source memory operand address to destination memory address specified as offset to ES segment in the register operand.
        /// </summary>
        [Symbol("movdir64b m32, m512","66 0F 38 F8 /r")]
        movdir64b_m32_m512 = 878,

        /// <summary>
        /// movdir64b m64, m512 | 66 0F 38 F8 /r | Move 64-bytes as direct-store with guaranteed 64-byte write atomicity from the source memory operand address to destination memory address specified as offset to ES segment in the register operand.
        /// </summary>
        [Symbol("movdir64b m64, m512","66 0F 38 F8 /r")]
        movdir64b_m64_m512 = 879,

        /// <summary>
        /// movdir64b r16, m512 | 66 0F 38 F8 /r | Move 64-bytes as direct-store with guaranteed 64-byte write atomicity from the source memory operand address to destination memory address specified as offset to ES segment in the register operand.
        /// </summary>
        [Symbol("movdir64b r16, m512","66 0F 38 F8 /r")]
        movdir64b_r16_m512 = 880,

        /// <summary>
        /// movdqa m128, xmm | 66 0F 7F /r | Move aligned packed integer values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("movdqa m128, xmm","66 0F 7F /r")]
        movdqa_m128_xmm = 881,

        /// <summary>
        /// movdqa r8, xmm | 66 0F 7F /r | Move aligned packed integer values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("movdqa r8, xmm","66 0F 7F /r")]
        movdqa_r8_xmm = 882,

        /// <summary>
        /// movdqa xmm, m128 | 66 0F 6F /r | Move aligned packed integer values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("movdqa xmm, m128","66 0F 6F /r")]
        movdqa_xmm_m128 = 883,

        /// <summary>
        /// movdqa xmm, r8 | 66 0F 6F /r | Move aligned packed integer values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("movdqa xmm, r8","66 0F 6F /r")]
        movdqa_xmm_r8 = 884,

        /// <summary>
        /// movdqu m128, xmm | F3 0F 7F /r | Move unaligned packed integer values from xmm1 to xmm2/m128.
        /// </summary>
        [Symbol("movdqu m128, xmm","F3 0F 7F /r")]
        movdqu_m128_xmm = 885,

        /// <summary>
        /// movdqu r8, xmm | F3 0F 7F /r | Move unaligned packed integer values from xmm1 to xmm2/m128.
        /// </summary>
        [Symbol("movdqu r8, xmm","F3 0F 7F /r")]
        movdqu_r8_xmm = 886,

        /// <summary>
        /// movdqu xmm, m128 | F3 0F 6F /r | Move unaligned packed integer values from xmm2/m128 to xmm1.
        /// </summary>
        [Symbol("movdqu xmm, m128","F3 0F 6F /r")]
        movdqu_xmm_m128 = 887,

        /// <summary>
        /// movdqu xmm, r8 | F3 0F 6F /r | Move unaligned packed integer values from xmm2/m128 to xmm1.
        /// </summary>
        [Symbol("movdqu xmm, r8","F3 0F 6F /r")]
        movdqu_xmm_r8 = 888,

        /// <summary>
        /// movq m64, mm | NP 0F 7F /r | Move quadword from mm to mm/m64.
        /// </summary>
        [Symbol("movq m64, mm","NP 0F 7F /r")]
        movq_m64_mm = 889,

        /// <summary>
        /// movq m64, mm | NP REX.W + 0F 7E /r | Move quadword from mm to r/m64.
        /// </summary>
        [Symbol("movq m64, mm","NP REX.W + 0F 7E /r")]
        movq_m64_mm_rex = 890,

        /// <summary>
        /// movq m64, xmm | 66 REX.W 0F 7E /r | Move quadword from xmm register to r/m64.
        /// </summary>
        [Symbol("movq m64, xmm","66 REX.W 0F 7E /r")]
        movq_m64_xmm = 891,

        /// <summary>
        /// movq m64, xmm | 66 0F D6 /r | Move quadword from xmm1 to xmm2/mem64.
        /// </summary>
        [Symbol("movq m64, xmm","66 0F D6 /r")]
        movq_m64_xmm_x0F = 892,

        /// <summary>
        /// movq mm, m64 | NP 0F 6F /r | Move quadword from mm/m64 to mm.
        /// </summary>
        [Symbol("movq mm, m64","NP 0F 6F /r")]
        movq_mm_m64 = 893,

        /// <summary>
        /// movq mm, m64 | NP REX.W + 0F 6E /r | Move quadword from r/m64 to mm.
        /// </summary>
        [Symbol("movq mm, m64","NP REX.W + 0F 6E /r")]
        movq_mm_m64_rex = 894,

        /// <summary>
        /// movq mm, r64 | NP REX.W + 0F 6E /r | Move quadword from r/m64 to mm.
        /// </summary>
        [Symbol("movq mm, r64","NP REX.W + 0F 6E /r")]
        movq_mm_r64 = 895,

        /// <summary>
        /// movq mm, r8 | NP 0F 6F /r | Move quadword from mm/m64 to mm.
        /// </summary>
        [Symbol("movq mm, r8","NP 0F 6F /r")]
        movq_mm_r8 = 896,

        /// <summary>
        /// movq r64, mm | NP REX.W + 0F 7E /r | Move quadword from mm to r/m64.
        /// </summary>
        [Symbol("movq r64, mm","NP REX.W + 0F 7E /r")]
        movq_r64_mm = 897,

        /// <summary>
        /// movq r64, xmm | 66 REX.W 0F 7E /r | Move quadword from xmm register to r/m64.
        /// </summary>
        [Symbol("movq r64, xmm","66 REX.W 0F 7E /r")]
        movq_r64_xmm = 898,

        /// <summary>
        /// movq r8, mm | NP 0F 7F /r | Move quadword from mm to mm/m64.
        /// </summary>
        [Symbol("movq r8, mm","NP 0F 7F /r")]
        movq_r8_mm = 899,

        /// <summary>
        /// movq r8, xmm | 66 0F D6 /r | Move quadword from xmm1 to xmm2/mem64.
        /// </summary>
        [Symbol("movq r8, xmm","66 0F D6 /r")]
        movq_r8_xmm = 900,

        /// <summary>
        /// movq xmm, m64 | 66 REX.W 0F 6E /r | Move quadword from r/m64 to xmm.
        /// </summary>
        [Symbol("movq xmm, m64","66 REX.W 0F 6E /r")]
        movq_xmm_m64 = 901,

        /// <summary>
        /// movq xmm, m64 | F3 0F 7E /r | Move quadword from xmm2/mem64 to xmm1.
        /// </summary>
        [Symbol("movq xmm, m64","F3 0F 7E /r")]
        movq_xmm_m64_xF3 = 902,

        /// <summary>
        /// movq xmm, r64 | 66 REX.W 0F 6E /r | Move quadword from r/m64 to xmm.
        /// </summary>
        [Symbol("movq xmm, r64","66 REX.W 0F 6E /r")]
        movq_xmm_r64 = 903,

        /// <summary>
        /// movq xmm, r8 | F3 0F 7E /r | Move quadword from xmm2/mem64 to xmm1.
        /// </summary>
        [Symbol("movq xmm, r8","F3 0F 7E /r")]
        movq_xmm_r8 = 904,

        /// <summary>
        /// movs m16, m16 | A5 | For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R&#124;E)SI to (R/E)DI
        /// </summary>
        [Symbol("movs m16, m16","A5")]
        movs_m16_m16 = 905,

        /// <summary>
        /// movs m32, m32 | A5 | For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R&#124;E)SI to (R/E)DI
        /// </summary>
        [Symbol("movs m32, m32","A5")]
        movs_m32_m32 = 906,

        /// <summary>
        /// movs m64, m64 | REX.W + A5 | Move qword from address (R/E)SI to (R/E)DI
        /// </summary>
        [Symbol("movs m64, m64","REX.W + A5")]
        movs_m64_m64 = 907,

        /// <summary>
        /// movs m8, m8 | A4 | For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R&#124;E)SI to (R/E)DI.
        /// </summary>
        [Symbol("movs m8, m8","A4")]
        movs_m8_m8 = 908,

        /// <summary>
        /// movsb | A4 | For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R/E)SI to (R/E)DI.
        /// </summary>
        [Symbol("movsb","A4")]
        movsb = 909,

        /// <summary>
        /// movsd | A5 | For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R/E)SI to (R/E)DI.
        /// </summary>
        [Symbol("movsd","A5")]
        movsd = 910,

        /// <summary>
        /// movsq | REX.W + A5 | Move qword from address (R/E)SI to (R/E)DI.
        /// </summary>
        [Symbol("movsq","REX.W + A5")]
        movsq = 911,

        /// <summary>
        /// movsw | A5 | For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R/E)SI to (R/E)DI.
        /// </summary>
        [Symbol("movsw","A5")]
        movsw = 912,

        /// <summary>
        /// movsx r16, m8 | 0F BE /r | Move byte to word with sign-extension.
        /// </summary>
        [Symbol("movsx r16, m8","0F BE /r")]
        movsx_r16_m8 = 913,

        /// <summary>
        /// movsx r16, r8 | 0F BE /r | Move byte to word with sign-extension.
        /// </summary>
        [Symbol("movsx r16, r8","0F BE /r")]
        movsx_r16_r8 = 914,

        /// <summary>
        /// movsx r32, m16 | 0F BF /r | Move word to doubleword, with sign-extension.
        /// </summary>
        [Symbol("movsx r32, m16","0F BF /r")]
        movsx_r32_m16 = 915,

        /// <summary>
        /// movsx r32, m8 | 0F BE /r | Move byte to doubleword with sign-extension.
        /// </summary>
        [Symbol("movsx r32, m8","0F BE /r")]
        movsx_r32_m8 = 916,

        /// <summary>
        /// movsx r32, r16 | 0F BF /r | Move word to doubleword, with sign-extension.
        /// </summary>
        [Symbol("movsx r32, r16","0F BF /r")]
        movsx_r32_r16 = 917,

        /// <summary>
        /// movsx r32, r8 | 0F BE /r | Move byte to doubleword with sign-extension.
        /// </summary>
        [Symbol("movsx r32, r8","0F BE /r")]
        movsx_r32_r8 = 918,

        /// <summary>
        /// movsx r64, m16 | REX.W + 0F BF /r | Move word to quadword with sign-extension.
        /// </summary>
        [Symbol("movsx r64, m16","REX.W + 0F BF /r")]
        movsx_r64_m16 = 919,

        /// <summary>
        /// movsx r64, m8 | REX.W + 0F BE /r | Move byte to quadword with sign-extension.
        /// </summary>
        [Symbol("movsx r64, m8","REX.W + 0F BE /r")]
        movsx_r64_m8 = 920,

        /// <summary>
        /// movsx r64, r16 | REX.W + 0F BF /r | Move word to quadword with sign-extension.
        /// </summary>
        [Symbol("movsx r64, r16","REX.W + 0F BF /r")]
        movsx_r64_r16 = 921,

        /// <summary>
        /// movsx r64, r8 | REX.W + 0F BE /r | Move byte to quadword with sign-extension.
        /// </summary>
        [Symbol("movsx r64, r8","REX.W + 0F BE /r")]
        movsx_r64_r8 = 922,

        /// <summary>
        /// movsxd r16, m16 | 63 /r | Move word to word with sign-extension.
        /// </summary>
        [Symbol("movsxd r16, m16","63 /r")]
        movsxd_r16_m16 = 923,

        /// <summary>
        /// movsxd r16, r16 | 63 /r | Move word to word with sign-extension.
        /// </summary>
        [Symbol("movsxd r16, r16","63 /r")]
        movsxd_r16_r16 = 924,

        /// <summary>
        /// movsxd r32, m32 | 63 /r | Move doubleword to doubleword with sign-extension.
        /// </summary>
        [Symbol("movsxd r32, m32","63 /r")]
        movsxd_r32_m32 = 925,

        /// <summary>
        /// movsxd r32, r32 | 63 /r | Move doubleword to doubleword with sign-extension.
        /// </summary>
        [Symbol("movsxd r32, r32","63 /r")]
        movsxd_r32_r32 = 926,

        /// <summary>
        /// movsxd r64, m32 | REX.W + 63 /r | Move doubleword to quadword with sign-extension.
        /// </summary>
        [Symbol("movsxd r64, m32","REX.W + 63 /r")]
        movsxd_r64_m32 = 927,

        /// <summary>
        /// movsxd r64, r32 | REX.W + 63 /r | Move doubleword to quadword with sign-extension.
        /// </summary>
        [Symbol("movsxd r64, r32","REX.W + 63 /r")]
        movsxd_r64_r32 = 928,

        /// <summary>
        /// movupd m128, xmm | 66 0F 11 /r | Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("movupd m128, xmm","66 0F 11 /r")]
        movupd_m128_xmm = 929,

        /// <summary>
        /// movupd r8, xmm | 66 0F 11 /r | Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("movupd r8, xmm","66 0F 11 /r")]
        movupd_r8_xmm = 930,

        /// <summary>
        /// movupd xmm, m128 | 66 0F 10 /r | Move unaligned packed double-precision floating-point from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("movupd xmm, m128","66 0F 10 /r")]
        movupd_xmm_m128 = 931,

        /// <summary>
        /// movupd xmm, r8 | 66 0F 10 /r | Move unaligned packed double-precision floating-point from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("movupd xmm, r8","66 0F 10 /r")]
        movupd_xmm_r8 = 932,

        /// <summary>
        /// movzx r16, m8 | 0F B6 /r | Move byte to word with zero-extension.
        /// </summary>
        [Symbol("movzx r16, m8","0F B6 /r")]
        movzx_r16_m8 = 933,

        /// <summary>
        /// movzx r16, r8 | 0F B6 /r | Move byte to word with zero-extension.
        /// </summary>
        [Symbol("movzx r16, r8","0F B6 /r")]
        movzx_r16_r8 = 934,

        /// <summary>
        /// movzx r32, m16 | 0F B7 /r | Move word to doubleword, zero-extension.
        /// </summary>
        [Symbol("movzx r32, m16","0F B7 /r")]
        movzx_r32_m16 = 935,

        /// <summary>
        /// movzx r32, m8 | 0F B6 /r | Move byte to doubleword, zero-extension.
        /// </summary>
        [Symbol("movzx r32, m8","0F B6 /r")]
        movzx_r32_m8 = 936,

        /// <summary>
        /// movzx r32, r16 | 0F B7 /r | Move word to doubleword, zero-extension.
        /// </summary>
        [Symbol("movzx r32, r16","0F B7 /r")]
        movzx_r32_r16 = 937,

        /// <summary>
        /// movzx r32, r8 | 0F B6 /r | Move byte to doubleword, zero-extension.
        /// </summary>
        [Symbol("movzx r32, r8","0F B6 /r")]
        movzx_r32_r8 = 938,

        /// <summary>
        /// movzx r64, m16 | REX.W + 0F B7 /r | Move word to quadword, zero-extension.
        /// </summary>
        [Symbol("movzx r64, m16","REX.W + 0F B7 /r")]
        movzx_r64_m16 = 939,

        /// <summary>
        /// movzx r64, m8 | REX.W + 0F B6 /r | Move byte to quadword, zero-extension.
        /// </summary>
        [Symbol("movzx r64, m8","REX.W + 0F B6 /r")]
        movzx_r64_m8 = 940,

        /// <summary>
        /// movzx r64, r16 | REX.W + 0F B7 /r | Move word to quadword, zero-extension.
        /// </summary>
        [Symbol("movzx r64, r16","REX.W + 0F B7 /r")]
        movzx_r64_r16 = 941,

        /// <summary>
        /// movzx r64, r8 | REX.W + 0F B6 /r | Move byte to quadword, zero-extension.
        /// </summary>
        [Symbol("movzx r64, r8","REX.W + 0F B6 /r")]
        movzx_r64_r8 = 942,

        /// <summary>
        /// mpsadbw xmm, m128, imm8 | 66 0F 3A 42 /r ib | Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm1 and xmm2/m128 and writes the results in xmm1. Starting offsets within xmm1 and xmm2/m128 are determined by imm8.
        /// </summary>
        [Symbol("mpsadbw xmm, m128, imm8","66 0F 3A 42 /r ib")]
        mpsadbw_xmm_m128_imm8 = 943,

        /// <summary>
        /// mpsadbw xmm, r8, imm8 | 66 0F 3A 42 /r ib | Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm1 and xmm2/m128 and writes the results in xmm1. Starting offsets within xmm1 and xmm2/m128 are determined by imm8.
        /// </summary>
        [Symbol("mpsadbw xmm, r8, imm8","66 0F 3A 42 /r ib")]
        mpsadbw_xmm_r8_imm8 = 944,

        /// <summary>
        /// mul m16 | F7 /4 | Unsigned multiply (DX:AX := AX ∗ r/m16 ).
        /// </summary>
        [Symbol("mul m16","F7 /4")]
        mul_m16 = 945,

        /// <summary>
        /// mul m32 | F7 /4 | Unsigned multiply (EDX:EAX := EAX ∗ r/m32 ).
        /// </summary>
        [Symbol("mul m32","F7 /4")]
        mul_m32 = 946,

        /// <summary>
        /// mul m64 | REX.W + F7 /4 | Unsigned multiply (RDX:RAX := RAX ∗ r/m64).
        /// </summary>
        [Symbol("mul m64","REX.W + F7 /4")]
        mul_m64 = 947,

        /// <summary>
        /// mul m8 | F6 /4 | Unsigned multiply (AX := AL ∗ r/m8 ).
        /// </summary>
        [Symbol("mul m8","F6 /4")]
        mul_m8 = 948,

        /// <summary>
        /// mul m8 | REX + F6 /4 | Unsigned multiply (AX := AL ∗ r/m8 ).
        /// </summary>
        [Symbol("mul m8","REX + F6 /4")]
        mul_m8_rex = 949,

        /// <summary>
        /// mul r16 | F7 /4 | Unsigned multiply (DX:AX := AX ∗ r/m16 ).
        /// </summary>
        [Symbol("mul r16","F7 /4")]
        mul_r16 = 950,

        /// <summary>
        /// mul r32 | F7 /4 | Unsigned multiply (EDX:EAX := EAX ∗ r/m32 ).
        /// </summary>
        [Symbol("mul r32","F7 /4")]
        mul_r32 = 951,

        /// <summary>
        /// mul r64 | REX.W + F7 /4 | Unsigned multiply (RDX:RAX := RAX ∗ r/m64).
        /// </summary>
        [Symbol("mul r64","REX.W + F7 /4")]
        mul_r64 = 952,

        /// <summary>
        /// mul r8 | F6 /4 | Unsigned multiply (AX := AL ∗ r/m8 ).
        /// </summary>
        [Symbol("mul r8","F6 /4")]
        mul_r8 = 953,

        /// <summary>
        /// mul r8 | REX + F6 /4 | Unsigned multiply (AX := AL ∗ r/m8 ).
        /// </summary>
        [Symbol("mul r8","REX + F6 /4")]
        mul_r8_rex = 954,

        /// <summary>
        /// neg m16 | F7 /3 | Two's complement negate r/m16.
        /// </summary>
        [Symbol("neg m16","F7 /3")]
        neg_m16 = 955,

        /// <summary>
        /// neg m32 | F7 /3 | Two's complement negate r/m32.
        /// </summary>
        [Symbol("neg m32","F7 /3")]
        neg_m32 = 956,

        /// <summary>
        /// neg m64 | REX.W + F7 /3 | Two's complement negate r/m64.
        /// </summary>
        [Symbol("neg m64","REX.W + F7 /3")]
        neg_m64 = 957,

        /// <summary>
        /// neg m8 | REX + F6 /3 | Two's complement negate r/m8.
        /// </summary>
        [Symbol("neg m8","REX + F6 /3")]
        neg_m8 = 958,

        /// <summary>
        /// neg m8 | F6 /3 | Two's complement negate r/m8.
        /// </summary>
        [Symbol("neg m8","F6 /3")]
        neg_m8_xF6 = 959,

        /// <summary>
        /// neg r16 | F7 /3 | Two's complement negate r/m16.
        /// </summary>
        [Symbol("neg r16","F7 /3")]
        neg_r16 = 960,

        /// <summary>
        /// neg r32 | F7 /3 | Two's complement negate r/m32.
        /// </summary>
        [Symbol("neg r32","F7 /3")]
        neg_r32 = 961,

        /// <summary>
        /// neg r64 | REX.W + F7 /3 | Two's complement negate r/m64.
        /// </summary>
        [Symbol("neg r64","REX.W + F7 /3")]
        neg_r64 = 962,

        /// <summary>
        /// neg r8 | REX + F6 /3 | Two's complement negate r/m8.
        /// </summary>
        [Symbol("neg r8","REX + F6 /3")]
        neg_r8 = 963,

        /// <summary>
        /// neg r8 | F6 /3 | Two's complement negate r/m8.
        /// </summary>
        [Symbol("neg r8","F6 /3")]
        neg_r8_xF6 = 964,

        /// <summary>
        /// not m16 | F7 /2 | Reverse each bit of r/m16.
        /// </summary>
        [Symbol("not m16","F7 /2")]
        not_m16 = 965,

        /// <summary>
        /// not m32 | F7 /2 | Reverse each bit of r/m32.
        /// </summary>
        [Symbol("not m32","F7 /2")]
        not_m32 = 966,

        /// <summary>
        /// not m64 | REX.W + F7 /2 | Reverse each bit of r/m64.
        /// </summary>
        [Symbol("not m64","REX.W + F7 /2")]
        not_m64 = 967,

        /// <summary>
        /// not m8 | F6 /2 | Reverse each bit of r/m8.
        /// </summary>
        [Symbol("not m8","F6 /2")]
        not_m8 = 968,

        /// <summary>
        /// not m8 | REX + F6 /2 | Reverse each bit of r/m8.
        /// </summary>
        [Symbol("not m8","REX + F6 /2")]
        not_m8_rex = 969,

        /// <summary>
        /// not r16 | F7 /2 | Reverse each bit of r/m16.
        /// </summary>
        [Symbol("not r16","F7 /2")]
        not_r16 = 970,

        /// <summary>
        /// not r32 | F7 /2 | Reverse each bit of r/m32.
        /// </summary>
        [Symbol("not r32","F7 /2")]
        not_r32 = 971,

        /// <summary>
        /// not r64 | REX.W + F7 /2 | Reverse each bit of r/m64.
        /// </summary>
        [Symbol("not r64","REX.W + F7 /2")]
        not_r64 = 972,

        /// <summary>
        /// not r8 | F6 /2 | Reverse each bit of r/m8.
        /// </summary>
        [Symbol("not r8","F6 /2")]
        not_r8 = 973,

        /// <summary>
        /// not r8 | REX + F6 /2 | Reverse each bit of r/m8.
        /// </summary>
        [Symbol("not r8","REX + F6 /2")]
        not_r8_rex = 974,

        /// <summary>
        /// or AL, imm8 | 0C ib | AL OR imm8.
        /// </summary>
        [Symbol("or AL, imm8","0C ib")]
        or_AL_imm8 = 975,

        /// <summary>
        /// or AX, imm16 | 0D iw | AX OR imm16.
        /// </summary>
        [Symbol("or AX, imm16","0D iw")]
        or_AX_imm16 = 976,

        /// <summary>
        /// or EAX, imm32 | 0D id | EAX OR imm32.
        /// </summary>
        [Symbol("or EAX, imm32","0D id")]
        or_EAX_imm32 = 977,

        /// <summary>
        /// or m16, imm16 | 81 /1 iw | r/m16 OR imm16.
        /// </summary>
        [Symbol("or m16, imm16","81 /1 iw")]
        or_m16_imm16 = 978,

        /// <summary>
        /// or m16, imm8 | 83 /1 ib | r/m16 OR imm8 (sign-extended).
        /// </summary>
        [Symbol("or m16, imm8","83 /1 ib")]
        or_m16_imm8 = 979,

        /// <summary>
        /// or m16, r16 | 09 /r | r/m16 OR r16.
        /// </summary>
        [Symbol("or m16, r16","09 /r")]
        or_m16_r16 = 980,

        /// <summary>
        /// or m32, imm32 | 81 /1 id | r/m32 OR imm32.
        /// </summary>
        [Symbol("or m32, imm32","81 /1 id")]
        or_m32_imm32 = 981,

        /// <summary>
        /// or m32, imm8 | 83 /1 ib | r/m32 OR imm8 (sign-extended).
        /// </summary>
        [Symbol("or m32, imm8","83 /1 ib")]
        or_m32_imm8 = 982,

        /// <summary>
        /// or m32, r32 | 09 /r | r/m32 OR r32.
        /// </summary>
        [Symbol("or m32, r32","09 /r")]
        or_m32_r32 = 983,

        /// <summary>
        /// or m64, imm32 | REX.W + 81 /1 id | r/m64 OR imm32 (sign-extended).
        /// </summary>
        [Symbol("or m64, imm32","REX.W + 81 /1 id")]
        or_m64_imm32 = 984,

        /// <summary>
        /// or m64, imm8 | REX.W + 83 /1 ib | r/m64 OR imm8 (sign-extended).
        /// </summary>
        [Symbol("or m64, imm8","REX.W + 83 /1 ib")]
        or_m64_imm8 = 985,

        /// <summary>
        /// or m64, r64 | REX.W + 09 /r | r/m64 OR r64.
        /// </summary>
        [Symbol("or m64, r64","REX.W + 09 /r")]
        or_m64_r64 = 986,

        /// <summary>
        /// or m8, imm8 | REX + 80 /1 ib | r/m8 OR imm8.
        /// </summary>
        [Symbol("or m8, imm8","REX + 80 /1 ib")]
        or_m8_imm8 = 987,

        /// <summary>
        /// or m8, imm8 | 80 /1 ib | r/m8 OR imm8.
        /// </summary>
        [Symbol("or m8, imm8","80 /1 ib")]
        or_m8_imm8_x80 = 988,

        /// <summary>
        /// or m8, r8 | 08 /r | r/m8 OR r8.
        /// </summary>
        [Symbol("or m8, r8","08 /r")]
        or_m8_r8 = 989,

        /// <summary>
        /// or m8, r8 | REX + 08 /r | r/m8 OR r8.
        /// </summary>
        [Symbol("or m8, r8","REX + 08 /r")]
        or_m8_r8_rex = 990,

        /// <summary>
        /// or r16, imm16 | 81 /1 iw | r/m16 OR imm16.
        /// </summary>
        [Symbol("or r16, imm16","81 /1 iw")]
        or_r16_imm16 = 991,

        /// <summary>
        /// or r16, imm8 | 83 /1 ib | r/m16 OR imm8 (sign-extended).
        /// </summary>
        [Symbol("or r16, imm8","83 /1 ib")]
        or_r16_imm8 = 992,

        /// <summary>
        /// or r16, m16 | 0B /r | r16 OR r/m16.
        /// </summary>
        [Symbol("or r16, m16","0B /r")]
        or_r16_m16 = 993,

        /// <summary>
        /// or r16, r16 | 09 /r | r/m16 OR r16.
        /// </summary>
        [Symbol("or r16, r16","09 /r")]
        or_r16_r16 = 994,

        /// <summary>
        /// or r16, r16 | 0B /r | r16 OR r/m16.
        /// </summary>
        [Symbol("or r16, r16","0B /r")]
        or_r16_r16_x0B = 995,

        /// <summary>
        /// or r32, imm32 | 81 /1 id | r/m32 OR imm32.
        /// </summary>
        [Symbol("or r32, imm32","81 /1 id")]
        or_r32_imm32 = 996,

        /// <summary>
        /// or r32, imm8 | 83 /1 ib | r/m32 OR imm8 (sign-extended).
        /// </summary>
        [Symbol("or r32, imm8","83 /1 ib")]
        or_r32_imm8 = 997,

        /// <summary>
        /// or r32, m32 | 0B /r | r32 OR r/m32.
        /// </summary>
        [Symbol("or r32, m32","0B /r")]
        or_r32_m32 = 998,

        /// <summary>
        /// or r32, r32 | 09 /r | r/m32 OR r32.
        /// </summary>
        [Symbol("or r32, r32","09 /r")]
        or_r32_r32 = 999,

        /// <summary>
        /// or r32, r32 | 0B /r | r32 OR r/m32.
        /// </summary>
        [Symbol("or r32, r32","0B /r")]
        or_r32_r32_x0B = 1000,

        /// <summary>
        /// or r64, imm32 | REX.W + 81 /1 id | r/m64 OR imm32 (sign-extended).
        /// </summary>
        [Symbol("or r64, imm32","REX.W + 81 /1 id")]
        or_r64_imm32 = 1001,

        /// <summary>
        /// or r64, imm8 | REX.W + 83 /1 ib | r/m64 OR imm8 (sign-extended).
        /// </summary>
        [Symbol("or r64, imm8","REX.W + 83 /1 ib")]
        or_r64_imm8 = 1002,

        /// <summary>
        /// or r64, m64 | REX.W + 0B /r | r64 OR r/m64.
        /// </summary>
        [Symbol("or r64, m64","REX.W + 0B /r")]
        or_r64_m64 = 1003,

        /// <summary>
        /// or r64, r64 | REX.W + 09 /r | r/m64 OR r64.
        /// </summary>
        [Symbol("or r64, r64","REX.W + 09 /r")]
        or_r64_r64 = 1004,

        /// <summary>
        /// or r64, r64 | REX.W + 0B /r | r64 OR r/m64.
        /// </summary>
        [Symbol("or r64, r64","REX.W + 0B /r")]
        or_r64_r64_x0B = 1005,

        /// <summary>
        /// or r8, imm8 | REX + 80 /1 ib | r/m8 OR imm8.
        /// </summary>
        [Symbol("or r8, imm8","REX + 80 /1 ib")]
        or_r8_imm8 = 1006,

        /// <summary>
        /// or r8, imm8 | 80 /1 ib | r/m8 OR imm8.
        /// </summary>
        [Symbol("or r8, imm8","80 /1 ib")]
        or_r8_imm8_x80 = 1007,

        /// <summary>
        /// or r8, m8 | 0A /r | r8 OR r/m8.
        /// </summary>
        [Symbol("or r8, m8","0A /r")]
        or_r8_m8 = 1008,

        /// <summary>
        /// or r8, m8 | REX + 0A /r | r8 OR r/m8.
        /// </summary>
        [Symbol("or r8, m8","REX + 0A /r")]
        or_r8_m8_rex = 1009,

        /// <summary>
        /// or r8, r8 | 08 /r | r/m8 OR r8.
        /// </summary>
        [Symbol("or r8, r8","08 /r")]
        or_r8_r8 = 1010,

        /// <summary>
        /// or r8, r8 | REX + 08 /r | r/m8 OR r8.
        /// </summary>
        [Symbol("or r8, r8","REX + 08 /r")]
        or_r8_r8_rex = 1011,

        /// <summary>
        /// or r8, r8 | 0A /r | r8 OR r/m8.
        /// </summary>
        [Symbol("or r8, r8","0A /r")]
        or_r8_r8_x0A = 1012,

        /// <summary>
        /// or RAX, imm32 | REX.W + 0D id | RAX OR imm32 (sign-extended).
        /// </summary>
        [Symbol("or RAX, imm32","REX.W + 0D id")]
        or_RAX_imm32 = 1013,

        /// <summary>
        /// out DX, AL | EE | Output byte in AL to I/O port address in DX.
        /// </summary>
        [Symbol("out DX, AL","EE")]
        out_DX_AL = 1014,

        /// <summary>
        /// out DX, AX | EF | Output word in AX to I/O port address in DX.
        /// </summary>
        [Symbol("out DX, AX","EF")]
        out_DX_AX = 1015,

        /// <summary>
        /// out DX, EAX | EF | Output doubleword in EAX to I/O port address in DX.
        /// </summary>
        [Symbol("out DX, EAX","EF")]
        out_DX_EAX = 1016,

        /// <summary>
        /// out imm8, AL | E6 ib | Output byte in AL to I/O port address imm8.
        /// </summary>
        [Symbol("out imm8, AL","E6 ib")]
        out_imm8_AL = 1017,

        /// <summary>
        /// out imm8, AX | E7 ib | Output word in AX to I/O port address imm8.
        /// </summary>
        [Symbol("out imm8, AX","E7 ib")]
        out_imm8_AX = 1018,

        /// <summary>
        /// out imm8, EAX | E7 ib | Output doubleword in EAX to I/O port address imm8.
        /// </summary>
        [Symbol("out imm8, EAX","E7 ib")]
        out_imm8_EAX = 1019,

        /// <summary>
        /// outs DX, m16 | 6F | Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
        /// </summary>
        [Symbol("outs DX, m16","6F")]
        outs_DX_m16 = 1020,

        /// <summary>
        /// outs DX, m32 | 6F | Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
        /// </summary>
        [Symbol("outs DX, m32","6F")]
        outs_DX_m32 = 1021,

        /// <summary>
        /// outs DX, m8 | 6E | Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
        /// </summary>
        [Symbol("outs DX, m8","6E")]
        outs_DX_m8 = 1022,

        /// <summary>
        /// outsb | 6E | Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
        /// </summary>
        [Symbol("outsb","6E")]
        outsb = 1023,

        /// <summary>
        /// outsd | 6F | Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
        /// </summary>
        [Symbol("outsd","6F")]
        outsd = 1024,

        /// <summary>
        /// outsw | 6F | Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX.
        /// </summary>
        [Symbol("outsw","6F")]
        outsw = 1025,

        /// <summary>
        /// pabsb mm, m64 | NP 0F 38 1C /r 1 | Compute the absolute value of bytes in mm2/m64 and store UNSIGNED result in mm1.
        /// </summary>
        [Symbol("pabsb mm, m64","NP 0F 38 1C /r 1")]
        pabsb_mm_m64 = 1026,

        /// <summary>
        /// pabsb mm, r8 | NP 0F 38 1C /r 1 | Compute the absolute value of bytes in mm2/m64 and store UNSIGNED result in mm1.
        /// </summary>
        [Symbol("pabsb mm, r8","NP 0F 38 1C /r 1")]
        pabsb_mm_r8 = 1027,

        /// <summary>
        /// pabsb xmm, m128 | 66 0F 38 1C /r | Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("pabsb xmm, m128","66 0F 38 1C /r")]
        pabsb_xmm_m128 = 1028,

        /// <summary>
        /// pabsb xmm, r8 | 66 0F 38 1C /r | Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("pabsb xmm, r8","66 0F 38 1C /r")]
        pabsb_xmm_r8 = 1029,

        /// <summary>
        /// pabsd mm, m64 | NP 0F 38 1E /r 1 | Compute the absolute value of 32-bit integers in mm2/m64 and store UNSIGNED result in mm1.
        /// </summary>
        [Symbol("pabsd mm, m64","NP 0F 38 1E /r 1")]
        pabsd_mm_m64 = 1030,

        /// <summary>
        /// pabsd mm, r8 | NP 0F 38 1E /r 1 | Compute the absolute value of 32-bit integers in mm2/m64 and store UNSIGNED result in mm1.
        /// </summary>
        [Symbol("pabsd mm, r8","NP 0F 38 1E /r 1")]
        pabsd_mm_r8 = 1031,

        /// <summary>
        /// pabsd xmm, m128 | 66 0F 38 1E /r | Compute the absolute value of 32-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("pabsd xmm, m128","66 0F 38 1E /r")]
        pabsd_xmm_m128 = 1032,

        /// <summary>
        /// pabsd xmm, r8 | 66 0F 38 1E /r | Compute the absolute value of 32-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("pabsd xmm, r8","66 0F 38 1E /r")]
        pabsd_xmm_r8 = 1033,

        /// <summary>
        /// pabsw mm, m64 | NP 0F 38 1D /r 1 | Compute the absolute value of 16-bit integers in mm2/m64 and store UNSIGNED result in mm1.
        /// </summary>
        [Symbol("pabsw mm, m64","NP 0F 38 1D /r 1")]
        pabsw_mm_m64 = 1034,

        /// <summary>
        /// pabsw mm, r8 | NP 0F 38 1D /r 1 | Compute the absolute value of 16-bit integers in mm2/m64 and store UNSIGNED result in mm1.
        /// </summary>
        [Symbol("pabsw mm, r8","NP 0F 38 1D /r 1")]
        pabsw_mm_r8 = 1035,

        /// <summary>
        /// pabsw xmm, m128 | 66 0F 38 1D /r | Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("pabsw xmm, m128","66 0F 38 1D /r")]
        pabsw_xmm_m128 = 1036,

        /// <summary>
        /// pabsw xmm, r8 | 66 0F 38 1D /r | Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("pabsw xmm, r8","66 0F 38 1D /r")]
        pabsw_xmm_r8 = 1037,

        /// <summary>
        /// packssdw mm, m64 | NP 0F 6B /r 1 | Converts 2 packed signed doubleword integers from mm1 and from mm2/m64 into 4 packed signed word integers in mm1 using signed saturation.
        /// </summary>
        [Symbol("packssdw mm, m64","NP 0F 6B /r 1")]
        packssdw_mm_m64 = 1038,

        /// <summary>
        /// packssdw mm, r8 | NP 0F 6B /r 1 | Converts 2 packed signed doubleword integers from mm1 and from mm2/m64 into 4 packed signed word integers in mm1 using signed saturation.
        /// </summary>
        [Symbol("packssdw mm, r8","NP 0F 6B /r 1")]
        packssdw_mm_r8 = 1039,

        /// <summary>
        /// packssdw xmm, m128 | 66 0F 6B /r | Converts 4 packed signed doubleword integers from xmm1 and from xxm2/m128 into 8 packed signed word integers in xxm1 using signed saturation.
        /// </summary>
        [Symbol("packssdw xmm, m128","66 0F 6B /r")]
        packssdw_xmm_m128 = 1040,

        /// <summary>
        /// packssdw xmm, r8 | 66 0F 6B /r | Converts 4 packed signed doubleword integers from xmm1 and from xxm2/m128 into 8 packed signed word integers in xxm1 using signed saturation.
        /// </summary>
        [Symbol("packssdw xmm, r8","66 0F 6B /r")]
        packssdw_xmm_r8 = 1041,

        /// <summary>
        /// packsswb mm, m64 | NP 0F 63 /r 1 | Converts 4 packed signed word integers from mm1 and from mm2/m64 into 8 packed signed byte integers in mm1 using signed saturation.
        /// </summary>
        [Symbol("packsswb mm, m64","NP 0F 63 /r 1")]
        packsswb_mm_m64 = 1042,

        /// <summary>
        /// packsswb mm, r8 | NP 0F 63 /r 1 | Converts 4 packed signed word integers from mm1 and from mm2/m64 into 8 packed signed byte integers in mm1 using signed saturation.
        /// </summary>
        [Symbol("packsswb mm, r8","NP 0F 63 /r 1")]
        packsswb_mm_r8 = 1043,

        /// <summary>
        /// packsswb xmm, m128 | 66 0F 63 /r | Converts 8 packed signed word integers from xmm1 and from xxm2/m128 into 16 packed signed byte integers in xxm1 using signed saturation.
        /// </summary>
        [Symbol("packsswb xmm, m128","66 0F 63 /r")]
        packsswb_xmm_m128 = 1044,

        /// <summary>
        /// packsswb xmm, r8 | 66 0F 63 /r | Converts 8 packed signed word integers from xmm1 and from xxm2/m128 into 16 packed signed byte integers in xxm1 using signed saturation.
        /// </summary>
        [Symbol("packsswb xmm, r8","66 0F 63 /r")]
        packsswb_xmm_r8 = 1045,

        /// <summary>
        /// packusdw xmm, m128 | 66 0F 38 2B /r | Convert 4 packed signed doubleword integers from xmm1 and 4 packed signed doubleword integers from xmm2/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation.
        /// </summary>
        [Symbol("packusdw xmm, m128","66 0F 38 2B /r")]
        packusdw_xmm_m128 = 1046,

        /// <summary>
        /// packusdw xmm, r8 | 66 0F 38 2B /r | Convert 4 packed signed doubleword integers from xmm1 and 4 packed signed doubleword integers from xmm2/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation.
        /// </summary>
        [Symbol("packusdw xmm, r8","66 0F 38 2B /r")]
        packusdw_xmm_r8 = 1047,

        /// <summary>
        /// packuswb mm, m64 | NP 0F 67 /r | Converts 4 signed word integers from mm and 4 signed word integers from mm/m64 into 8 unsigned byte integers in mm using unsigned saturation.
        /// </summary>
        [Symbol("packuswb mm, m64","NP 0F 67 /r")]
        packuswb_mm_m64 = 1048,

        /// <summary>
        /// packuswb mm, r8 | NP 0F 67 /r | Converts 4 signed word integers from mm and 4 signed word integers from mm/m64 into 8 unsigned byte integers in mm using unsigned saturation.
        /// </summary>
        [Symbol("packuswb mm, r8","NP 0F 67 /r")]
        packuswb_mm_r8 = 1049,

        /// <summary>
        /// packuswb xmm, m128 | 66 0F 67 /r | Converts 8 signed word integers from xmm1 and 8 signed word integers from xmm2/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation.
        /// </summary>
        [Symbol("packuswb xmm, m128","66 0F 67 /r")]
        packuswb_xmm_m128 = 1050,

        /// <summary>
        /// packuswb xmm, r8 | 66 0F 67 /r | Converts 8 signed word integers from xmm1 and 8 signed word integers from xmm2/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation.
        /// </summary>
        [Symbol("packuswb xmm, r8","66 0F 67 /r")]
        packuswb_xmm_r8 = 1051,

        /// <summary>
        /// paddb mm, m64 | NP 0F FC /r 1 | Add packed byte integers from mm/m64 and mm.
        /// </summary>
        [Symbol("paddb mm, m64","NP 0F FC /r 1")]
        paddb_mm_m64 = 1052,

        /// <summary>
        /// paddb mm, r8 | NP 0F FC /r 1 | Add packed byte integers from mm/m64 and mm.
        /// </summary>
        [Symbol("paddb mm, r8","NP 0F FC /r 1")]
        paddb_mm_r8 = 1053,

        /// <summary>
        /// paddb xmm, m128 | 66 0F FC /r | Add packed byte integers from xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("paddb xmm, m128","66 0F FC /r")]
        paddb_xmm_m128 = 1054,

        /// <summary>
        /// paddb xmm, r8 | 66 0F FC /r | Add packed byte integers from xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("paddb xmm, r8","66 0F FC /r")]
        paddb_xmm_r8 = 1055,

        /// <summary>
        /// paddd mm, m64 | NP 0F FE /r 1 | Add packed doubleword integers from mm/m64 and mm.
        /// </summary>
        [Symbol("paddd mm, m64","NP 0F FE /r 1")]
        paddd_mm_m64 = 1056,

        /// <summary>
        /// paddd mm, r8 | NP 0F FE /r 1 | Add packed doubleword integers from mm/m64 and mm.
        /// </summary>
        [Symbol("paddd mm, r8","NP 0F FE /r 1")]
        paddd_mm_r8 = 1057,

        /// <summary>
        /// paddd xmm, m128 | 66 0F FE /r | Add packed doubleword integers from xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("paddd xmm, m128","66 0F FE /r")]
        paddd_xmm_m128 = 1058,

        /// <summary>
        /// paddd xmm, r8 | 66 0F FE /r | Add packed doubleword integers from xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("paddd xmm, r8","66 0F FE /r")]
        paddd_xmm_r8 = 1059,

        /// <summary>
        /// paddq mm, m64 | NP 0F D4 /r 1 | Add packed quadword integers from mm/m64 and mm.
        /// </summary>
        [Symbol("paddq mm, m64","NP 0F D4 /r 1")]
        paddq_mm_m64 = 1060,

        /// <summary>
        /// paddq mm, r8 | NP 0F D4 /r 1 | Add packed quadword integers from mm/m64 and mm.
        /// </summary>
        [Symbol("paddq mm, r8","NP 0F D4 /r 1")]
        paddq_mm_r8 = 1061,

        /// <summary>
        /// paddq xmm, m128 | 66 0F D4 /r | Add packed quadword integers from xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("paddq xmm, m128","66 0F D4 /r")]
        paddq_xmm_m128 = 1062,

        /// <summary>
        /// paddq xmm, r8 | 66 0F D4 /r | Add packed quadword integers from xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("paddq xmm, r8","66 0F D4 /r")]
        paddq_xmm_r8 = 1063,

        /// <summary>
        /// paddsb mm, m64 | NP 0F EC /r 1 | Add packed signed byte integers from mm/m64 and mm and saturate the results.
        /// </summary>
        [Symbol("paddsb mm, m64","NP 0F EC /r 1")]
        paddsb_mm_m64 = 1064,

        /// <summary>
        /// paddsb mm, r8 | NP 0F EC /r 1 | Add packed signed byte integers from mm/m64 and mm and saturate the results.
        /// </summary>
        [Symbol("paddsb mm, r8","NP 0F EC /r 1")]
        paddsb_mm_r8 = 1065,

        /// <summary>
        /// paddsb xmm, m128 | 66 0F EC /r | Add packed signed byte integers from xmm2/m128 and xmm1 saturate the results.
        /// </summary>
        [Symbol("paddsb xmm, m128","66 0F EC /r")]
        paddsb_xmm_m128 = 1066,

        /// <summary>
        /// paddsb xmm, r8 | 66 0F EC /r | Add packed signed byte integers from xmm2/m128 and xmm1 saturate the results.
        /// </summary>
        [Symbol("paddsb xmm, r8","66 0F EC /r")]
        paddsb_xmm_r8 = 1067,

        /// <summary>
        /// paddsw mm, m64 | NP 0F ED /r 1 | Add packed signed word integers from mm/m64 and mm and saturate the results.
        /// </summary>
        [Symbol("paddsw mm, m64","NP 0F ED /r 1")]
        paddsw_mm_m64 = 1068,

        /// <summary>
        /// paddsw mm, r8 | NP 0F ED /r 1 | Add packed signed word integers from mm/m64 and mm and saturate the results.
        /// </summary>
        [Symbol("paddsw mm, r8","NP 0F ED /r 1")]
        paddsw_mm_r8 = 1069,

        /// <summary>
        /// paddsw xmm, m128 | 66 0F ED /r | Add packed signed word integers from xmm2/m128 and xmm1 and saturate the results.
        /// </summary>
        [Symbol("paddsw xmm, m128","66 0F ED /r")]
        paddsw_xmm_m128 = 1070,

        /// <summary>
        /// paddsw xmm, r8 | 66 0F ED /r | Add packed signed word integers from xmm2/m128 and xmm1 and saturate the results.
        /// </summary>
        [Symbol("paddsw xmm, r8","66 0F ED /r")]
        paddsw_xmm_r8 = 1071,

        /// <summary>
        /// paddusb mm, m64 | NP 0F DC /r 1 | Add packed unsigned byte integers from mm/m64 and mm and saturate the results.
        /// </summary>
        [Symbol("paddusb mm, m64","NP 0F DC /r 1")]
        paddusb_mm_m64 = 1072,

        /// <summary>
        /// paddusb mm, r8 | NP 0F DC /r 1 | Add packed unsigned byte integers from mm/m64 and mm and saturate the results.
        /// </summary>
        [Symbol("paddusb mm, r8","NP 0F DC /r 1")]
        paddusb_mm_r8 = 1073,

        /// <summary>
        /// paddusb xmm, m128 | 66 0F DC /r | Add packed unsigned byte integers from xmm2/m128 and xmm1 saturate the results.
        /// </summary>
        [Symbol("paddusb xmm, m128","66 0F DC /r")]
        paddusb_xmm_m128 = 1074,

        /// <summary>
        /// paddusb xmm, r8 | 66 0F DC /r | Add packed unsigned byte integers from xmm2/m128 and xmm1 saturate the results.
        /// </summary>
        [Symbol("paddusb xmm, r8","66 0F DC /r")]
        paddusb_xmm_r8 = 1075,

        /// <summary>
        /// paddusw mm, m64 | NP 0F DD /r 1 | Add packed unsigned word integers from mm/m64 and mm and saturate the results.
        /// </summary>
        [Symbol("paddusw mm, m64","NP 0F DD /r 1")]
        paddusw_mm_m64 = 1076,

        /// <summary>
        /// paddusw mm, r8 | NP 0F DD /r 1 | Add packed unsigned word integers from mm/m64 and mm and saturate the results.
        /// </summary>
        [Symbol("paddusw mm, r8","NP 0F DD /r 1")]
        paddusw_mm_r8 = 1077,

        /// <summary>
        /// paddusw xmm, m128 | 66 0F DD /r | Add packed unsigned word integers from xmm2/m128 to xmm1 and saturate the results.
        /// </summary>
        [Symbol("paddusw xmm, m128","66 0F DD /r")]
        paddusw_xmm_m128 = 1078,

        /// <summary>
        /// paddusw xmm, r8 | 66 0F DD /r | Add packed unsigned word integers from xmm2/m128 to xmm1 and saturate the results.
        /// </summary>
        [Symbol("paddusw xmm, r8","66 0F DD /r")]
        paddusw_xmm_r8 = 1079,

        /// <summary>
        /// paddw mm, m64 | NP 0F FD /r 1 | Add packed word integers from mm/m64 and mm.
        /// </summary>
        [Symbol("paddw mm, m64","NP 0F FD /r 1")]
        paddw_mm_m64 = 1080,

        /// <summary>
        /// paddw mm, r8 | NP 0F FD /r 1 | Add packed word integers from mm/m64 and mm.
        /// </summary>
        [Symbol("paddw mm, r8","NP 0F FD /r 1")]
        paddw_mm_r8 = 1081,

        /// <summary>
        /// paddw xmm, m128 | 66 0F FD /r | Add packed word integers from xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("paddw xmm, m128","66 0F FD /r")]
        paddw_xmm_m128 = 1082,

        /// <summary>
        /// paddw xmm, r8 | 66 0F FD /r | Add packed word integers from xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("paddw xmm, r8","66 0F FD /r")]
        paddw_xmm_r8 = 1083,

        /// <summary>
        /// pand mm, m64 | NP 0F DB /r 1 | Bitwise AND mm/m64 and mm.
        /// </summary>
        [Symbol("pand mm, m64","NP 0F DB /r 1")]
        pand_mm_m64 = 1084,

        /// <summary>
        /// pand mm, r8 | NP 0F DB /r 1 | Bitwise AND mm/m64 and mm.
        /// </summary>
        [Symbol("pand mm, r8","NP 0F DB /r 1")]
        pand_mm_r8 = 1085,

        /// <summary>
        /// pand xmm, m128 | 66 0F DB /r | Bitwise AND of xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("pand xmm, m128","66 0F DB /r")]
        pand_xmm_m128 = 1086,

        /// <summary>
        /// pand xmm, r8 | 66 0F DB /r | Bitwise AND of xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("pand xmm, r8","66 0F DB /r")]
        pand_xmm_r8 = 1087,

        /// <summary>
        /// pandn mm, m64 | NP 0F DF /r 1 | Bitwise AND NOT of mm/m64 and mm.
        /// </summary>
        [Symbol("pandn mm, m64","NP 0F DF /r 1")]
        pandn_mm_m64 = 1088,

        /// <summary>
        /// pandn mm, r8 | NP 0F DF /r 1 | Bitwise AND NOT of mm/m64 and mm.
        /// </summary>
        [Symbol("pandn mm, r8","NP 0F DF /r 1")]
        pandn_mm_r8 = 1089,

        /// <summary>
        /// pandn xmm, m128 | 66 0F DF /r | Bitwise AND NOT of xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("pandn xmm, m128","66 0F DF /r")]
        pandn_xmm_m128 = 1090,

        /// <summary>
        /// pandn xmm, r8 | 66 0F DF /r | Bitwise AND NOT of xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("pandn xmm, r8","66 0F DF /r")]
        pandn_xmm_r8 = 1091,

        /// <summary>
        /// pavgb mm, m64 | NP 0F E0 /r 1 | Average packed unsigned byte integers from mm2/m64 and mm1 with rounding.
        /// </summary>
        [Symbol("pavgb mm, m64","NP 0F E0 /r 1")]
        pavgb_mm_m64 = 1092,

        /// <summary>
        /// pavgb mm, r8 | NP 0F E0 /r 1 | Average packed unsigned byte integers from mm2/m64 and mm1 with rounding.
        /// </summary>
        [Symbol("pavgb mm, r8","NP 0F E0 /r 1")]
        pavgb_mm_r8 = 1093,

        /// <summary>
        /// pavgb xmm, m128 | 66 0F E0 /r | Average packed unsigned byte integers from xmm2/m128 and xmm1 with rounding.
        /// </summary>
        [Symbol("pavgb xmm, m128","66 0F E0 /r")]
        pavgb_xmm_m128 = 1094,

        /// <summary>
        /// pavgb xmm, r8 | 66 0F E0 /r | Average packed unsigned byte integers from xmm2/m128 and xmm1 with rounding.
        /// </summary>
        [Symbol("pavgb xmm, r8","66 0F E0 /r")]
        pavgb_xmm_r8 = 1095,

        /// <summary>
        /// pavgw mm, m64 | NP 0F E3 /r 1 | Average packed unsigned word integers from mm2/m64 and mm1 with rounding.
        /// </summary>
        [Symbol("pavgw mm, m64","NP 0F E3 /r 1")]
        pavgw_mm_m64 = 1096,

        /// <summary>
        /// pavgw mm, r8 | NP 0F E3 /r 1 | Average packed unsigned word integers from mm2/m64 and mm1 with rounding.
        /// </summary>
        [Symbol("pavgw mm, r8","NP 0F E3 /r 1")]
        pavgw_mm_r8 = 1097,

        /// <summary>
        /// pavgw xmm, m128 | 66 0F E3 /r | Average packed unsigned word integers from xmm2/m128 and xmm1 with rounding.
        /// </summary>
        [Symbol("pavgw xmm, m128","66 0F E3 /r")]
        pavgw_xmm_m128 = 1098,

        /// <summary>
        /// pavgw xmm, r8 | 66 0F E3 /r | Average packed unsigned word integers from xmm2/m128 and xmm1 with rounding.
        /// </summary>
        [Symbol("pavgw xmm, r8","66 0F E3 /r")]
        pavgw_xmm_r8 = 1099,

        /// <summary>
        /// pcmpeqb mm, m64 | NP 0F 74 /r 1 | Compare packed bytes in mm/m64 and mm for equality.
        /// </summary>
        [Symbol("pcmpeqb mm, m64","NP 0F 74 /r 1")]
        pcmpeqb_mm_m64 = 1100,

        /// <summary>
        /// pcmpeqb mm, r8 | NP 0F 74 /r 1 | Compare packed bytes in mm/m64 and mm for equality.
        /// </summary>
        [Symbol("pcmpeqb mm, r8","NP 0F 74 /r 1")]
        pcmpeqb_mm_r8 = 1101,

        /// <summary>
        /// pcmpeqb xmm, m128 | 66 0F 74 /r | Compare packed bytes in xmm2/m128 and xmm1 for equality.
        /// </summary>
        [Symbol("pcmpeqb xmm, m128","66 0F 74 /r")]
        pcmpeqb_xmm_m128 = 1102,

        /// <summary>
        /// pcmpeqb xmm, r8 | 66 0F 74 /r | Compare packed bytes in xmm2/m128 and xmm1 for equality.
        /// </summary>
        [Symbol("pcmpeqb xmm, r8","66 0F 74 /r")]
        pcmpeqb_xmm_r8 = 1103,

        /// <summary>
        /// pcmpeqd mm, m64 | NP 0F 76 /r 1 | Compare packed doublewords in mm/m64 and mm for equality.
        /// </summary>
        [Symbol("pcmpeqd mm, m64","NP 0F 76 /r 1")]
        pcmpeqd_mm_m64 = 1104,

        /// <summary>
        /// pcmpeqd mm, r8 | NP 0F 76 /r 1 | Compare packed doublewords in mm/m64 and mm for equality.
        /// </summary>
        [Symbol("pcmpeqd mm, r8","NP 0F 76 /r 1")]
        pcmpeqd_mm_r8 = 1105,

        /// <summary>
        /// pcmpeqd xmm, m128 | 66 0F 76 /r | Compare packed doublewords in xmm2/m128 and xmm1 for equality.
        /// </summary>
        [Symbol("pcmpeqd xmm, m128","66 0F 76 /r")]
        pcmpeqd_xmm_m128 = 1106,

        /// <summary>
        /// pcmpeqd xmm, r8 | 66 0F 76 /r | Compare packed doublewords in xmm2/m128 and xmm1 for equality.
        /// </summary>
        [Symbol("pcmpeqd xmm, r8","66 0F 76 /r")]
        pcmpeqd_xmm_r8 = 1107,

        /// <summary>
        /// pcmpeqq xmm, m128 | 66 0F 38 29 /r | Compare packed qwords in xmm2/m128 and xmm1 for equality.
        /// </summary>
        [Symbol("pcmpeqq xmm, m128","66 0F 38 29 /r")]
        pcmpeqq_xmm_m128 = 1108,

        /// <summary>
        /// pcmpeqq xmm, r8 | 66 0F 38 29 /r | Compare packed qwords in xmm2/m128 and xmm1 for equality.
        /// </summary>
        [Symbol("pcmpeqq xmm, r8","66 0F 38 29 /r")]
        pcmpeqq_xmm_r8 = 1109,

        /// <summary>
        /// pcmpeqw mm, m64 | NP 0F 75 /r 1 | Compare packed words in mm/m64 and mm for equality.
        /// </summary>
        [Symbol("pcmpeqw mm, m64","NP 0F 75 /r 1")]
        pcmpeqw_mm_m64 = 1110,

        /// <summary>
        /// pcmpeqw mm, r8 | NP 0F 75 /r 1 | Compare packed words in mm/m64 and mm for equality.
        /// </summary>
        [Symbol("pcmpeqw mm, r8","NP 0F 75 /r 1")]
        pcmpeqw_mm_r8 = 1111,

        /// <summary>
        /// pcmpeqw xmm, m128 | 66 0F 75 /r | Compare packed words in xmm2/m128 and xmm1 for equality.
        /// </summary>
        [Symbol("pcmpeqw xmm, m128","66 0F 75 /r")]
        pcmpeqw_xmm_m128 = 1112,

        /// <summary>
        /// pcmpeqw xmm, r8 | 66 0F 75 /r | Compare packed words in xmm2/m128 and xmm1 for equality.
        /// </summary>
        [Symbol("pcmpeqw xmm, r8","66 0F 75 /r")]
        pcmpeqw_xmm_r8 = 1113,

        /// <summary>
        /// pcmpgtb mm, m64 | NP 0F 64 /r | Compare packed signed byte integers in mm and mm/m64 for greater than.
        /// </summary>
        [Symbol("pcmpgtb mm, m64","NP 0F 64 /r")]
        pcmpgtb_mm_m64 = 1114,

        /// <summary>
        /// pcmpgtb mm, r8 | NP 0F 64 /r | Compare packed signed byte integers in mm and mm/m64 for greater than.
        /// </summary>
        [Symbol("pcmpgtb mm, r8","NP 0F 64 /r")]
        pcmpgtb_mm_r8 = 1115,

        /// <summary>
        /// pcmpgtb xmm, m128 | 66 0F 64 /r | Compare packed signed byte integers in xmm1 and xmm2/m128 for greater than.
        /// </summary>
        [Symbol("pcmpgtb xmm, m128","66 0F 64 /r")]
        pcmpgtb_xmm_m128 = 1116,

        /// <summary>
        /// pcmpgtb xmm, r8 | 66 0F 64 /r | Compare packed signed byte integers in xmm1 and xmm2/m128 for greater than.
        /// </summary>
        [Symbol("pcmpgtb xmm, r8","66 0F 64 /r")]
        pcmpgtb_xmm_r8 = 1117,

        /// <summary>
        /// pcmpgtd mm, m64 | NP 0F 66 /r | Compare packed signed doubleword integers in mm and mm/m64 for greater than.
        /// </summary>
        [Symbol("pcmpgtd mm, m64","NP 0F 66 /r")]
        pcmpgtd_mm_m64 = 1118,

        /// <summary>
        /// pcmpgtd mm, r8 | NP 0F 66 /r | Compare packed signed doubleword integers in mm and mm/m64 for greater than.
        /// </summary>
        [Symbol("pcmpgtd mm, r8","NP 0F 66 /r")]
        pcmpgtd_mm_r8 = 1119,

        /// <summary>
        /// pcmpgtd xmm, m128 | 66 0F 66 /r | Compare packed signed doubleword integers in xmm1 and xmm2/m128 for greater than.
        /// </summary>
        [Symbol("pcmpgtd xmm, m128","66 0F 66 /r")]
        pcmpgtd_xmm_m128 = 1120,

        /// <summary>
        /// pcmpgtd xmm, r8 | 66 0F 66 /r | Compare packed signed doubleword integers in xmm1 and xmm2/m128 for greater than.
        /// </summary>
        [Symbol("pcmpgtd xmm, r8","66 0F 66 /r")]
        pcmpgtd_xmm_r8 = 1121,

        /// <summary>
        /// pcmpgtq xmm, m128 | 66 0F 38 37 /r | Compare packed signed qwords in xmm2/m128 and xmm1 for greater than.
        /// </summary>
        [Symbol("pcmpgtq xmm, m128","66 0F 38 37 /r")]
        pcmpgtq_xmm_m128 = 1122,

        /// <summary>
        /// pcmpgtq xmm, r8 | 66 0F 38 37 /r | Compare packed signed qwords in xmm2/m128 and xmm1 for greater than.
        /// </summary>
        [Symbol("pcmpgtq xmm, r8","66 0F 38 37 /r")]
        pcmpgtq_xmm_r8 = 1123,

        /// <summary>
        /// pcmpgtw mm, m64 | NP 0F 65 /r | Compare packed signed word integers in mm and mm/m64 for greater than.
        /// </summary>
        [Symbol("pcmpgtw mm, m64","NP 0F 65 /r")]
        pcmpgtw_mm_m64 = 1124,

        /// <summary>
        /// pcmpgtw mm, r8 | NP 0F 65 /r | Compare packed signed word integers in mm and mm/m64 for greater than.
        /// </summary>
        [Symbol("pcmpgtw mm, r8","NP 0F 65 /r")]
        pcmpgtw_mm_r8 = 1125,

        /// <summary>
        /// pcmpgtw xmm, m128 | 66 0F 65 /r | Compare packed signed word integers in xmm1 and xmm2/m128 for greater than.
        /// </summary>
        [Symbol("pcmpgtw xmm, m128","66 0F 65 /r")]
        pcmpgtw_xmm_m128 = 1126,

        /// <summary>
        /// pcmpgtw xmm, r8 | 66 0F 65 /r | Compare packed signed word integers in xmm1 and xmm2/m128 for greater than.
        /// </summary>
        [Symbol("pcmpgtw xmm, r8","66 0F 65 /r")]
        pcmpgtw_xmm_r8 = 1127,

        /// <summary>
        /// pdep r32, r32, m32 | VEX.LZ.F2.0F38.W0 F5 /r | Parallel deposit of bits from r32b using mask in r/m32 , result is written to r32a.
        /// </summary>
        [Symbol("pdep r32, r32, m32","VEX.LZ.F2.0F38.W0 F5 /r")]
        pdep_r32_r32_m32 = 1128,

        /// <summary>
        /// pdep r32, r32, r32 | VEX.LZ.F2.0F38.W0 F5 /r | Parallel deposit of bits from r32b using mask in r/m32 , result is written to r32a.
        /// </summary>
        [Symbol("pdep r32, r32, r32","VEX.LZ.F2.0F38.W0 F5 /r")]
        pdep_r32_r32_r32 = 1129,

        /// <summary>
        /// pdep r64, r64, m64 | VEX.LZ.F2.0F38.W1 F5 /r | Parallel deposit of bits from r64b using mask in r/m64 , result is written to r64a.
        /// </summary>
        [Symbol("pdep r64, r64, m64","VEX.LZ.F2.0F38.W1 F5 /r")]
        pdep_r64_r64_m64 = 1130,

        /// <summary>
        /// pdep r64, r64, r64 | VEX.LZ.F2.0F38.W1 F5 /r | Parallel deposit of bits from r64b using mask in r/m64 , result is written to r64a.
        /// </summary>
        [Symbol("pdep r64, r64, r64","VEX.LZ.F2.0F38.W1 F5 /r")]
        pdep_r64_r64_r64 = 1131,

        /// <summary>
        /// pextrb m8, xmm, imm8 | 66 0F 3A 14 /r ib | Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r32 or r64 are zeroed.
        /// </summary>
        [Symbol("pextrb m8, xmm, imm8","66 0F 3A 14 /r ib")]
        pextrb_m8_xmm_imm8 = 1132,

        /// <summary>
        /// pextrb r8, xmm, imm8 | 66 0F 3A 14 /r ib | Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r32 or r64 are zeroed.
        /// </summary>
        [Symbol("pextrb r8, xmm, imm8","66 0F 3A 14 /r ib")]
        pextrb_r8_xmm_imm8 = 1133,

        /// <summary>
        /// pextrd m32, xmm, imm8 | 66 0F 3A 16 /r ib | Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r/m32.
        /// </summary>
        [Symbol("pextrd m32, xmm, imm8","66 0F 3A 16 /r ib")]
        pextrd_m32_xmm_imm8 = 1134,

        /// <summary>
        /// pextrd r32, xmm, imm8 | 66 0F 3A 16 /r ib | Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r/m32.
        /// </summary>
        [Symbol("pextrd r32, xmm, imm8","66 0F 3A 16 /r ib")]
        pextrd_r32_xmm_imm8 = 1135,

        /// <summary>
        /// pextrq m64, xmm, imm8 | 66 REX.W 0F 3A 16 /r ib | Extract a qword integer value from xmm2 at the source qword offset specified by imm8 into r/m64.
        /// </summary>
        [Symbol("pextrq m64, xmm, imm8","66 REX.W 0F 3A 16 /r ib")]
        pextrq_m64_xmm_imm8 = 1136,

        /// <summary>
        /// pextrq r64, xmm, imm8 | 66 REX.W 0F 3A 16 /r ib | Extract a qword integer value from xmm2 at the source qword offset specified by imm8 into r/m64.
        /// </summary>
        [Symbol("pextrq r64, xmm, imm8","66 REX.W 0F 3A 16 /r ib")]
        pextrq_r64_xmm_imm8 = 1137,

        /// <summary>
        /// pextrw m16, xmm, imm8 | 66 0F 3A 15 /r ib | Extract the word specified by imm8 from xmm and copy it to lowest 16 bits of reg or m16. Zero-extend the result in the destination, r32 or r64.
        /// </summary>
        [Symbol("pextrw m16, xmm, imm8","66 0F 3A 15 /r ib")]
        pextrw_m16_xmm_imm8 = 1138,

        /// <summary>
        /// pextrw r16, xmm, imm8 | 66 0F 3A 15 /r ib | Extract the word specified by imm8 from xmm and copy it to lowest 16 bits of reg or m16. Zero-extend the result in the destination, r32 or r64.
        /// </summary>
        [Symbol("pextrw r16, xmm, imm8","66 0F 3A 15 /r ib")]
        pextrw_r16_xmm_imm8 = 1139,

        /// <summary>
        /// pextrw reg, mm, imm8 | NP 0F C5 /r ib 1 | Extract the word specified by imm8 from mm and move it to reg, bits 15-0. The upper bits of r32 or r64 is zeroed.
        /// </summary>
        [Symbol("pextrw reg, mm, imm8","NP 0F C5 /r ib 1")]
        pextrw_reg_mm_imm8 = 1140,

        /// <summary>
        /// pextrw reg, xmm, imm8 | 66 0F C5 /r ib | Extract the word specified by imm8 from xmm and move it to reg, bits 15-0. The upper bits of r32 or r64 is zeroed.
        /// </summary>
        [Symbol("pextrw reg, xmm, imm8","66 0F C5 /r ib")]
        pextrw_reg_xmm_imm8 = 1141,

        /// <summary>
        /// phaddd mm, m64 | NP 0F 38 02 /r | Add 32-bit integers horizontally, pack to mm1.
        /// </summary>
        [Symbol("phaddd mm, m64","NP 0F 38 02 /r")]
        phaddd_mm_m64 = 1142,

        /// <summary>
        /// phaddd mm, r8 | NP 0F 38 02 /r | Add 32-bit integers horizontally, pack to mm1.
        /// </summary>
        [Symbol("phaddd mm, r8","NP 0F 38 02 /r")]
        phaddd_mm_r8 = 1143,

        /// <summary>
        /// phaddd xmm, m128 | 66 0F 38 02 /r | Add 32-bit integers horizontally, pack to xmm1.
        /// </summary>
        [Symbol("phaddd xmm, m128","66 0F 38 02 /r")]
        phaddd_xmm_m128 = 1144,

        /// <summary>
        /// phaddd xmm, r8 | 66 0F 38 02 /r | Add 32-bit integers horizontally, pack to xmm1.
        /// </summary>
        [Symbol("phaddd xmm, r8","66 0F 38 02 /r")]
        phaddd_xmm_r8 = 1145,

        /// <summary>
        /// phaddsw mm, m64 | NP 0F 38 03 /r 1 | Add 16-bit signed integers horizontally, pack saturated integers to mm1.
        /// </summary>
        [Symbol("phaddsw mm, m64","NP 0F 38 03 /r 1")]
        phaddsw_mm_m64 = 1146,

        /// <summary>
        /// phaddsw mm, r8 | NP 0F 38 03 /r 1 | Add 16-bit signed integers horizontally, pack saturated integers to mm1.
        /// </summary>
        [Symbol("phaddsw mm, r8","NP 0F 38 03 /r 1")]
        phaddsw_mm_r8 = 1147,

        /// <summary>
        /// phaddsw xmm, m128 | 66 0F 38 03 /r | Add 16-bit signed integers horizontally, pack saturated integers to xmm1.
        /// </summary>
        [Symbol("phaddsw xmm, m128","66 0F 38 03 /r")]
        phaddsw_xmm_m128 = 1148,

        /// <summary>
        /// phaddsw xmm, r8 | 66 0F 38 03 /r | Add 16-bit signed integers horizontally, pack saturated integers to xmm1.
        /// </summary>
        [Symbol("phaddsw xmm, r8","66 0F 38 03 /r")]
        phaddsw_xmm_r8 = 1149,

        /// <summary>
        /// phaddw mm, m64 | NP 0F 38 01 /r 1 | Add 16-bit integers horizontally, pack to mm1.
        /// </summary>
        [Symbol("phaddw mm, m64","NP 0F 38 01 /r 1")]
        phaddw_mm_m64 = 1150,

        /// <summary>
        /// phaddw mm, r8 | NP 0F 38 01 /r 1 | Add 16-bit integers horizontally, pack to mm1.
        /// </summary>
        [Symbol("phaddw mm, r8","NP 0F 38 01 /r 1")]
        phaddw_mm_r8 = 1151,

        /// <summary>
        /// phaddw xmm, m128 | 66 0F 38 01 /r | Add 16-bit integers horizontally, pack to xmm1.
        /// </summary>
        [Symbol("phaddw xmm, m128","66 0F 38 01 /r")]
        phaddw_xmm_m128 = 1152,

        /// <summary>
        /// phaddw xmm, r8 | 66 0F 38 01 /r | Add 16-bit integers horizontally, pack to xmm1.
        /// </summary>
        [Symbol("phaddw xmm, r8","66 0F 38 01 /r")]
        phaddw_xmm_r8 = 1153,

        /// <summary>
        /// pinsrb xmm, m8, imm8 | 66 0F 3A 20 /r ib | Insert a byte integer value from r32/m8 into xmm1 at the destination element in xmm1 specified by imm8.
        /// </summary>
        [Symbol("pinsrb xmm, m8, imm8","66 0F 3A 20 /r ib")]
        pinsrb_xmm_m8_imm8 = 1154,

        /// <summary>
        /// pinsrb xmm, r32, imm8 | 66 0F 3A 20 /r ib | Insert a byte integer value from r32/m8 into xmm1 at the destination element in xmm1 specified by imm8.
        /// </summary>
        [Symbol("pinsrb xmm, r32, imm8","66 0F 3A 20 /r ib")]
        pinsrb_xmm_r32_imm8 = 1155,

        /// <summary>
        /// pinsrd xmm, m32, imm8 | 66 0F 3A 22 /r ib | Insert a dword integer value from r/m32 into the xmm1 at the destination element specified by imm8.
        /// </summary>
        [Symbol("pinsrd xmm, m32, imm8","66 0F 3A 22 /r ib")]
        pinsrd_xmm_m32_imm8 = 1156,

        /// <summary>
        /// pinsrd xmm, r32, imm8 | 66 0F 3A 22 /r ib | Insert a dword integer value from r/m32 into the xmm1 at the destination element specified by imm8.
        /// </summary>
        [Symbol("pinsrd xmm, r32, imm8","66 0F 3A 22 /r ib")]
        pinsrd_xmm_r32_imm8 = 1157,

        /// <summary>
        /// pinsrq xmm, m64, imm8 | 66 REX.W 0F 3A 22 /r ib | Insert a qword integer value from r/m64 i nto the xmm1 at the destination element specified by imm8.
        /// </summary>
        [Symbol("pinsrq xmm, m64, imm8","66 REX.W 0F 3A 22 /r ib")]
        pinsrq_xmm_m64_imm8 = 1158,

        /// <summary>
        /// pinsrq xmm, r64, imm8 | 66 REX.W 0F 3A 22 /r ib | Insert a qword integer value from r/m64 i nto the xmm1 at the destination element specified by imm8.
        /// </summary>
        [Symbol("pinsrq xmm, r64, imm8","66 REX.W 0F 3A 22 /r ib")]
        pinsrq_xmm_r64_imm8 = 1159,

        /// <summary>
        /// pinsrw mm, m16, imm8 | NP 0F C4 /r ib 1 | Insert the low word from r32 or from m16 into mm at the word position specified by imm8.
        /// </summary>
        [Symbol("pinsrw mm, m16, imm8","NP 0F C4 /r ib 1")]
        pinsrw_mm_m16_imm8 = 1160,

        /// <summary>
        /// pinsrw mm, r32, imm8 | NP 0F C4 /r ib 1 | Insert the low word from r32 or from m16 into mm at the word position specified by imm8.
        /// </summary>
        [Symbol("pinsrw mm, r32, imm8","NP 0F C4 /r ib 1")]
        pinsrw_mm_r32_imm8 = 1161,

        /// <summary>
        /// pinsrw xmm, m16, imm8 | 66 0F C4 /r ib | Move the low word of r32 or from m16 into xmm at the word position specified by imm8.
        /// </summary>
        [Symbol("pinsrw xmm, m16, imm8","66 0F C4 /r ib")]
        pinsrw_xmm_m16_imm8 = 1162,

        /// <summary>
        /// pinsrw xmm, r32, imm8 | 66 0F C4 /r ib | Move the low word of r32 or from m16 into xmm at the word position specified by imm8.
        /// </summary>
        [Symbol("pinsrw xmm, r32, imm8","66 0F C4 /r ib")]
        pinsrw_xmm_r32_imm8 = 1163,

        /// <summary>
        /// pmaxsb xmm, m128 | 66 0F 38 3C /r | Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("pmaxsb xmm, m128","66 0F 38 3C /r")]
        pmaxsb_xmm_m128 = 1164,

        /// <summary>
        /// pmaxsb xmm, r8 | 66 0F 38 3C /r | Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("pmaxsb xmm, r8","66 0F 38 3C /r")]
        pmaxsb_xmm_r8 = 1165,

        /// <summary>
        /// pmaxsd xmm, m128 | 66 0F 38 3D /r | Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("pmaxsd xmm, m128","66 0F 38 3D /r")]
        pmaxsd_xmm_m128 = 1166,

        /// <summary>
        /// pmaxsd xmm, r8 | 66 0F 38 3D /r | Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("pmaxsd xmm, r8","66 0F 38 3D /r")]
        pmaxsd_xmm_r8 = 1167,

        /// <summary>
        /// pmaxsw mm, m64 | NP 0F EE /r | Compare signed word integers in mm2/m64 and mm1 and return maximum values.
        /// </summary>
        [Symbol("pmaxsw mm, m64","NP 0F EE /r")]
        pmaxsw_mm_m64 = 1168,

        /// <summary>
        /// pmaxsw mm, r8 | NP 0F EE /r | Compare signed word integers in mm2/m64 and mm1 and return maximum values.
        /// </summary>
        [Symbol("pmaxsw mm, r8","NP 0F EE /r")]
        pmaxsw_mm_r8 = 1169,

        /// <summary>
        /// pmaxsw xmm, m128 | 66 0F EE /r | Compare packed signed word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.
        /// </summary>
        [Symbol("pmaxsw xmm, m128","66 0F EE /r")]
        pmaxsw_xmm_m128 = 1170,

        /// <summary>
        /// pmaxsw xmm, r8 | 66 0F EE /r | Compare packed signed word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.
        /// </summary>
        [Symbol("pmaxsw xmm, r8","66 0F EE /r")]
        pmaxsw_xmm_r8 = 1171,

        /// <summary>
        /// pmaxub mm, m64 | NP 0F DE /r 1 | Compare unsigned byte integers in mm2/m64 and mm1 and returns maximum values.
        /// </summary>
        [Symbol("pmaxub mm, m64","NP 0F DE /r 1")]
        pmaxub_mm_m64 = 1172,

        /// <summary>
        /// pmaxub mm, r8 | NP 0F DE /r 1 | Compare unsigned byte integers in mm2/m64 and mm1 and returns maximum values.
        /// </summary>
        [Symbol("pmaxub mm, r8","NP 0F DE /r 1")]
        pmaxub_mm_r8 = 1173,

        /// <summary>
        /// pmaxub xmm, m128 | 66 0F DE /r | Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("pmaxub xmm, m128","66 0F DE /r")]
        pmaxub_xmm_m128 = 1174,

        /// <summary>
        /// pmaxub xmm, r8 | 66 0F DE /r | Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("pmaxub xmm, r8","66 0F DE /r")]
        pmaxub_xmm_r8 = 1175,

        /// <summary>
        /// pmaxuw xmm, m128 | 66 0F 38 3E /r | Compare packed unsigned word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.
        /// </summary>
        [Symbol("pmaxuw xmm, m128","66 0F 38 3E /r")]
        pmaxuw_xmm_m128 = 1176,

        /// <summary>
        /// pmaxuw xmm, r8 | 66 0F 38 3E /r | Compare packed unsigned word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.
        /// </summary>
        [Symbol("pmaxuw xmm, r8","66 0F 38 3E /r")]
        pmaxuw_xmm_r8 = 1177,

        /// <summary>
        /// pminsb xmm, m128 | 66 0F 38 38 /r | Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("pminsb xmm, m128","66 0F 38 38 /r")]
        pminsb_xmm_m128 = 1178,

        /// <summary>
        /// pminsb xmm, r8 | 66 0F 38 38 /r | Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("pminsb xmm, r8","66 0F 38 38 /r")]
        pminsb_xmm_r8 = 1179,

        /// <summary>
        /// pminsw mm, m64 | NP 0F EA /r 1 | Compare signed word integers in mm2/m64 and mm1 and return minimum values.
        /// </summary>
        [Symbol("pminsw mm, m64","NP 0F EA /r 1")]
        pminsw_mm_m64 = 1180,

        /// <summary>
        /// pminsw mm, r8 | NP 0F EA /r 1 | Compare signed word integers in mm2/m64 and mm1 and return minimum values.
        /// </summary>
        [Symbol("pminsw mm, r8","NP 0F EA /r 1")]
        pminsw_mm_r8 = 1181,

        /// <summary>
        /// pminsw xmm, m128 | 66 0F EA /r | Compare packed signed word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("pminsw xmm, m128","66 0F EA /r")]
        pminsw_xmm_m128 = 1182,

        /// <summary>
        /// pminsw xmm, r8 | 66 0F EA /r | Compare packed signed word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("pminsw xmm, r8","66 0F EA /r")]
        pminsw_xmm_r8 = 1183,

        /// <summary>
        /// pminub mm, m64 | NP 0F DA /r 1 | Compare unsigned byte integers in mm2/m64 and mm1 and returns minimum values.
        /// </summary>
        [Symbol("pminub mm, m64","NP 0F DA /r 1")]
        pminub_mm_m64 = 1184,

        /// <summary>
        /// pminub mm, r8 | NP 0F DA /r 1 | Compare unsigned byte integers in mm2/m64 and mm1 and returns minimum values.
        /// </summary>
        [Symbol("pminub mm, r8","NP 0F DA /r 1")]
        pminub_mm_r8 = 1185,

        /// <summary>
        /// pminub xmm, m128 | 66 0F DA /r | Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("pminub xmm, m128","66 0F DA /r")]
        pminub_xmm_m128 = 1186,

        /// <summary>
        /// pminub xmm, r8 | 66 0F DA /r | Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("pminub xmm, r8","66 0F DA /r")]
        pminub_xmm_r8 = 1187,

        /// <summary>
        /// pminuw xmm, m128 | 66 0F 38 3A /r | Compare packed unsigned word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("pminuw xmm, m128","66 0F 38 3A /r")]
        pminuw_xmm_m128 = 1188,

        /// <summary>
        /// pminuw xmm, r8 | 66 0F 38 3A /r | Compare packed unsigned word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("pminuw xmm, r8","66 0F 38 3A /r")]
        pminuw_xmm_r8 = 1189,

        /// <summary>
        /// pmovmskb reg, mm | NP 0F D7 /r 1 | Move a byte mask of mm to reg. The upper bits of r32 or r64 are zeroed
        /// </summary>
        [Symbol("pmovmskb reg, mm","NP 0F D7 /r 1")]
        pmovmskb_reg_mm = 1190,

        /// <summary>
        /// pmovmskb reg, xmm | 66 0F D7 /r | Move a byte mask of xmm to reg. The upper bits of r32 or r64 are zeroed
        /// </summary>
        [Symbol("pmovmskb reg, xmm","66 0F D7 /r")]
        pmovmskb_reg_xmm = 1191,

        /// <summary>
        /// pmovsxbd xmm, m32 | 66 0F 38 21 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxbd xmm, m32","66 0F 38 21 /r")]
        pmovsxbd_xmm_m32 = 1192,

        /// <summary>
        /// pmovsxbd xmm, r8 | 66 0F 38 21 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxbd xmm, r8","66 0F 38 21 /r")]
        pmovsxbd_xmm_r8 = 1193,

        /// <summary>
        /// pmovsxbq xmm, m16 | 66 0F 38 22 /r | Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxbq xmm, m16","66 0F 38 22 /r")]
        pmovsxbq_xmm_m16 = 1194,

        /// <summary>
        /// pmovsxbq xmm, r8 | 66 0F 38 22 /r | Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxbq xmm, r8","66 0F 38 22 /r")]
        pmovsxbq_xmm_r8 = 1195,

        /// <summary>
        /// pmovsxbw xmm, m64 | 66 0F 38 20 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxbw xmm, m64","66 0F 38 20 /r")]
        pmovsxbw_xmm_m64 = 1196,

        /// <summary>
        /// pmovsxbw xmm, r8 | 66 0F 38 20 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxbw xmm, r8","66 0F 38 20 /r")]
        pmovsxbw_xmm_r8 = 1197,

        /// <summary>
        /// pmovsxdq xmm, m64 | 66 0F 38 25 /r | Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxdq xmm, m64","66 0F 38 25 /r")]
        pmovsxdq_xmm_m64 = 1198,

        /// <summary>
        /// pmovsxdq xmm, r8 | 66 0F 38 25 /r | Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxdq xmm, r8","66 0F 38 25 /r")]
        pmovsxdq_xmm_r8 = 1199,

        /// <summary>
        /// pmovsxwd xmm, m64 | 66 0F 38 23 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxwd xmm, m64","66 0F 38 23 /r")]
        pmovsxwd_xmm_m64 = 1200,

        /// <summary>
        /// pmovsxwd xmm, r8 | 66 0F 38 23 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxwd xmm, r8","66 0F 38 23 /r")]
        pmovsxwd_xmm_r8 = 1201,

        /// <summary>
        /// pmovsxwq xmm, m32 | 66 0F 38 24 /r | Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxwq xmm, m32","66 0F 38 24 /r")]
        pmovsxwq_xmm_m32 = 1202,

        /// <summary>
        /// pmovsxwq xmm, r8 | 66 0F 38 24 /r | Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovsxwq xmm, r8","66 0F 38 24 /r")]
        pmovsxwq_xmm_r8 = 1203,

        /// <summary>
        /// pmovzxbd xmm, m32 | 66 0F 38 31 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxbd xmm, m32","66 0F 38 31 /r")]
        pmovzxbd_xmm_m32 = 1204,

        /// <summary>
        /// pmovzxbd xmm, r8 | 66 0F 38 31 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxbd xmm, r8","66 0F 38 31 /r")]
        pmovzxbd_xmm_r8 = 1205,

        /// <summary>
        /// pmovzxbq xmm, m16 | 66 0F 38 32 /r | Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxbq xmm, m16","66 0F 38 32 /r")]
        pmovzxbq_xmm_m16 = 1206,

        /// <summary>
        /// pmovzxbq xmm, r8 | 66 0F 38 32 /r | Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxbq xmm, r8","66 0F 38 32 /r")]
        pmovzxbq_xmm_r8 = 1207,

        /// <summary>
        /// pmovzxbw xmm, m64 | 66 0F 38 30 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxbw xmm, m64","66 0F 38 30 /r")]
        pmovzxbw_xmm_m64 = 1208,

        /// <summary>
        /// pmovzxbw xmm, r8 | 66 0F 38 30 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxbw xmm, r8","66 0F 38 30 /r")]
        pmovzxbw_xmm_r8 = 1209,

        /// <summary>
        /// pmovzxdq xmm, m64 | 66 0F 38 35 /r | Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxdq xmm, m64","66 0F 38 35 /r")]
        pmovzxdq_xmm_m64 = 1210,

        /// <summary>
        /// pmovzxdq xmm, r8 | 66 0F 38 35 /r | Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxdq xmm, r8","66 0F 38 35 /r")]
        pmovzxdq_xmm_r8 = 1211,

        /// <summary>
        /// pmovzxwd xmm, m64 | 66 0F 38 33 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxwd xmm, m64","66 0F 38 33 /r")]
        pmovzxwd_xmm_m64 = 1212,

        /// <summary>
        /// pmovzxwd xmm, r8 | 66 0F 38 33 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxwd xmm, r8","66 0F 38 33 /r")]
        pmovzxwd_xmm_r8 = 1213,

        /// <summary>
        /// pmovzxwq xmm, m32 | 66 0F 38 34 /r | Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxwq xmm, m32","66 0F 38 34 /r")]
        pmovzxwq_xmm_m32 = 1214,

        /// <summary>
        /// pmovzxwq xmm, r8 | 66 0F 38 34 /r | Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("pmovzxwq xmm, r8","66 0F 38 34 /r")]
        pmovzxwq_xmm_r8 = 1215,

        /// <summary>
        /// pmulhuw mm, m64 | NP 0F E4 /r 1 | Multiply the packed unsigned word integers in mm1 register and mm2/m64 , and store the high 16 bits of the results in mm1.
        /// </summary>
        [Symbol("pmulhuw mm, m64","NP 0F E4 /r 1")]
        pmulhuw_mm_m64 = 1216,

        /// <summary>
        /// pmulhuw mm, r8 | NP 0F E4 /r 1 | Multiply the packed unsigned word integers in mm1 register and mm2/m64 , and store the high 16 bits of the results in mm1.
        /// </summary>
        [Symbol("pmulhuw mm, r8","NP 0F E4 /r 1")]
        pmulhuw_mm_r8 = 1217,

        /// <summary>
        /// pmulhuw xmm, m128 | 66 0F E4 /r | Multiply the packed unsigned word integers in xmm1 and xmm2/m128 , and store the high 16 bits of the results in xmm1.
        /// </summary>
        [Symbol("pmulhuw xmm, m128","66 0F E4 /r")]
        pmulhuw_xmm_m128 = 1218,

        /// <summary>
        /// pmulhuw xmm, r8 | 66 0F E4 /r | Multiply the packed unsigned word integers in xmm1 and xmm2/m128 , and store the high 16 bits of the results in xmm1.
        /// </summary>
        [Symbol("pmulhuw xmm, r8","66 0F E4 /r")]
        pmulhuw_xmm_r8 = 1219,

        /// <summary>
        /// pmullw mm, m64 | NP 0F D5 /r 1 | Multiply the packed signed word integers in mm1 register and mm2/m64 , and store the low 16 bits of the results in mm1.
        /// </summary>
        [Symbol("pmullw mm, m64","NP 0F D5 /r 1")]
        pmullw_mm_m64 = 1220,

        /// <summary>
        /// pmullw mm, r8 | NP 0F D5 /r 1 | Multiply the packed signed word integers in mm1 register and mm2/m64 , and store the low 16 bits of the results in mm1.
        /// </summary>
        [Symbol("pmullw mm, r8","NP 0F D5 /r 1")]
        pmullw_mm_r8 = 1221,

        /// <summary>
        /// pmullw xmm, m128 | 66 0F D5 /r | Multiply the packed signed word integers in xmm1 and xmm2/m128 , and store the low 16 bits of the results in xmm1.
        /// </summary>
        [Symbol("pmullw xmm, m128","66 0F D5 /r")]
        pmullw_xmm_m128 = 1222,

        /// <summary>
        /// pmullw xmm, r8 | 66 0F D5 /r | Multiply the packed signed word integers in xmm1 and xmm2/m128 , and store the low 16 bits of the results in xmm1.
        /// </summary>
        [Symbol("pmullw xmm, r8","66 0F D5 /r")]
        pmullw_xmm_r8 = 1223,

        /// <summary>
        /// pop DS | 1F | Pop top of stack into DS; increment stack pointer.
        /// </summary>
        [Symbol("pop DS","1F")]
        pop_DS = 1224,

        /// <summary>
        /// pop ES | 07 | Pop top of stack into ES; increment stack pointer.
        /// </summary>
        [Symbol("pop ES","07")]
        pop_ES = 1225,

        /// <summary>
        /// pop FS | 0F A1 | Pop top of stack into FS; increment stack pointer by 32 bits.
        /// </summary>
        [Symbol("pop FS","0F A1")]
        pop_FS = 1226,

        /// <summary>
        /// pop GS | 0F A9 | Pop top of stack into GS; increment stack pointer by 64 bits.
        /// </summary>
        [Symbol("pop GS","0F A9")]
        pop_GS = 1227,

        /// <summary>
        /// pop m16 | 8F /0 | Pop top of stack into m16 ; increment stack pointer.
        /// </summary>
        [Symbol("pop m16","8F /0")]
        pop_m16 = 1228,

        /// <summary>
        /// pop m32 | 8F /0 | Pop top of stack into m32 ; increment stack pointer.
        /// </summary>
        [Symbol("pop m32","8F /0")]
        pop_m32 = 1229,

        /// <summary>
        /// pop m64 | 8F /0 | Pop top of stack into m64 ; increment stack pointer. Cannot encode 32-bit operand size.
        /// </summary>
        [Symbol("pop m64","8F /0")]
        pop_m64 = 1230,

        /// <summary>
        /// pop r16 | 8F /0 | Pop top of stack into m16 ; increment stack pointer.
        /// </summary>
        [Symbol("pop r16","8F /0")]
        pop_r16 = 1231,

        /// <summary>
        /// pop r16 | 58 +rw | Pop top of stack into r16 ; increment stack pointer.
        /// </summary>
        [Symbol("pop r16","58 +rw")]
        pop_r16_rex = 1232,

        /// <summary>
        /// pop r32 | 8F /0 | Pop top of stack into m32 ; increment stack pointer.
        /// </summary>
        [Symbol("pop r32","8F /0")]
        pop_r32 = 1233,

        /// <summary>
        /// pop r32 | 58 +rd | Pop top of stack into r32 ; increment stack pointer.
        /// </summary>
        [Symbol("pop r32","58 +rd")]
        pop_r32_rex = 1234,

        /// <summary>
        /// pop r64 | 8F /0 | Pop top of stack into m64 ; increment stack pointer. Cannot encode 32-bit operand size.
        /// </summary>
        [Symbol("pop r64","8F /0")]
        pop_r64 = 1235,

        /// <summary>
        /// pop r64 | 58 +rd | Pop top of stack into r64 ; increment stack pointer. Cannot encode 32-bit operand size.
        /// </summary>
        [Symbol("pop r64","58 +rd")]
        pop_r64_rex = 1236,

        /// <summary>
        /// pop SS | 17 | Pop top of stack into SS; increment stack pointer.
        /// </summary>
        [Symbol("pop SS","17")]
        pop_SS = 1237,

        /// <summary>
        /// popf | 9D | Pop top of stack into lower 16 bits of EFLAGS.
        /// </summary>
        [Symbol("popf","9D")]
        popf = 1238,

        /// <summary>
        /// popfd | 9D | Pop top of stack into EFLAGS.
        /// </summary>
        [Symbol("popfd","9D")]
        popfd = 1239,

        /// <summary>
        /// popfq | 9D | Pop top of stack and zero-extend into RFLAGS.
        /// </summary>
        [Symbol("popfq","9D")]
        popfq = 1240,

        /// <summary>
        /// por mm, m64 | NP 0F EB /r 1 | Bitwise OR of mm/m64 and mm.
        /// </summary>
        [Symbol("por mm, m64","NP 0F EB /r 1")]
        por_mm_m64 = 1241,

        /// <summary>
        /// por mm, r8 | NP 0F EB /r 1 | Bitwise OR of mm/m64 and mm.
        /// </summary>
        [Symbol("por mm, r8","NP 0F EB /r 1")]
        por_mm_r8 = 1242,

        /// <summary>
        /// por xmm, m128 | 66 0F EB /r | Bitwise OR of xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("por xmm, m128","66 0F EB /r")]
        por_xmm_m128 = 1243,

        /// <summary>
        /// por xmm, r8 | 66 0F EB /r | Bitwise OR of xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("por xmm, r8","66 0F EB /r")]
        por_xmm_r8 = 1244,

        /// <summary>
        /// prefetchnta m8 | 0F 18 /0 | Move data from m8 closer to the processor using NTA hint.
        /// </summary>
        [Symbol("prefetchnta m8","0F 18 /0")]
        prefetchnta_m8 = 1245,

        /// <summary>
        /// prefetcht0 m8 | 0F 18 /1 | Move data from m8 closer to the processor using T0 hint.
        /// </summary>
        [Symbol("prefetcht0 m8","0F 18 /1")]
        prefetcht0_m8 = 1246,

        /// <summary>
        /// prefetcht1 m8 | 0F 18 /2 | Move data from m8 closer to the processor using T1 hint.
        /// </summary>
        [Symbol("prefetcht1 m8","0F 18 /2")]
        prefetcht1_m8 = 1247,

        /// <summary>
        /// prefetcht2 m8 | 0F 18 /3 | Move data from m8 closer to the processor using T2 hint.
        /// </summary>
        [Symbol("prefetcht2 m8","0F 18 /3")]
        prefetcht2_m8 = 1248,

        /// <summary>
        /// pshufb mm, m64 | NP 0F 38 00 /r 1 | Shuffle bytes in mm1 according to contents of mm2/m64.
        /// </summary>
        [Symbol("pshufb mm, m64","NP 0F 38 00 /r 1")]
        pshufb_mm_m64 = 1249,

        /// <summary>
        /// pshufb mm, r8 | NP 0F 38 00 /r 1 | Shuffle bytes in mm1 according to contents of mm2/m64.
        /// </summary>
        [Symbol("pshufb mm, r8","NP 0F 38 00 /r 1")]
        pshufb_mm_r8 = 1250,

        /// <summary>
        /// pshufb xmm, m128 | 66 0F 38 00 /r | Shuffle bytes in xmm1 according to contents of xmm2/m128.
        /// </summary>
        [Symbol("pshufb xmm, m128","66 0F 38 00 /r")]
        pshufb_xmm_m128 = 1251,

        /// <summary>
        /// pshufb xmm, r8 | 66 0F 38 00 /r | Shuffle bytes in xmm1 according to contents of xmm2/m128.
        /// </summary>
        [Symbol("pshufb xmm, r8","66 0F 38 00 /r")]
        pshufb_xmm_r8 = 1252,

        /// <summary>
        /// pshufd xmm, m128, imm8 | 66 0F 70 /r ib | Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
        /// </summary>
        [Symbol("pshufd xmm, m128, imm8","66 0F 70 /r ib")]
        pshufd_xmm_m128_imm8 = 1253,

        /// <summary>
        /// pshufd xmm, r8, imm8 | 66 0F 70 /r ib | Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
        /// </summary>
        [Symbol("pshufd xmm, r8, imm8","66 0F 70 /r ib")]
        pshufd_xmm_r8_imm8 = 1254,

        /// <summary>
        /// pshuflw xmm, m128, imm8 | F2 0F 70 /r ib | Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
        /// </summary>
        [Symbol("pshuflw xmm, m128, imm8","F2 0F 70 /r ib")]
        pshuflw_xmm_m128_imm8 = 1255,

        /// <summary>
        /// pshuflw xmm, r8, imm8 | F2 0F 70 /r ib | Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
        /// </summary>
        [Symbol("pshuflw xmm, r8, imm8","F2 0F 70 /r ib")]
        pshuflw_xmm_r8_imm8 = 1256,

        /// <summary>
        /// pshufw mm, m64, imm8 | NP 0F 70 /r ib | Shuffle the words in mm2/m64 based on the encoding in imm8 and store the result in mm1.
        /// </summary>
        [Symbol("pshufw mm, m64, imm8","NP 0F 70 /r ib")]
        pshufw_mm_m64_imm8 = 1257,

        /// <summary>
        /// pshufw mm, r8, imm8 | NP 0F 70 /r ib | Shuffle the words in mm2/m64 based on the encoding in imm8 and store the result in mm1.
        /// </summary>
        [Symbol("pshufw mm, r8, imm8","NP 0F 70 /r ib")]
        pshufw_mm_r8_imm8 = 1258,

        /// <summary>
        /// psignb mm, m64 | NP 0F 38 08 /r 1 | Negate/zero/preserve packed byte integers in mm1 depending on the corresponding sign in mm2/m64.
        /// </summary>
        [Symbol("psignb mm, m64","NP 0F 38 08 /r 1")]
        psignb_mm_m64 = 1259,

        /// <summary>
        /// psignb mm, r8 | NP 0F 38 08 /r 1 | Negate/zero/preserve packed byte integers in mm1 depending on the corresponding sign in mm2/m64.
        /// </summary>
        [Symbol("psignb mm, r8","NP 0F 38 08 /r 1")]
        psignb_mm_r8 = 1260,

        /// <summary>
        /// psignb xmm, m128 | 66 0F 38 08 /r | Negate/zero/preserve packed byte integers in xmm1 depending on the corresponding sign in xmm2/m128.
        /// </summary>
        [Symbol("psignb xmm, m128","66 0F 38 08 /r")]
        psignb_xmm_m128 = 1261,

        /// <summary>
        /// psignb xmm, r8 | 66 0F 38 08 /r | Negate/zero/preserve packed byte integers in xmm1 depending on the corresponding sign in xmm2/m128.
        /// </summary>
        [Symbol("psignb xmm, r8","66 0F 38 08 /r")]
        psignb_xmm_r8 = 1262,

        /// <summary>
        /// psignd mm, m64 | NP 0F 38 0A /r 1 | Negate/zero/preserve packed doubleword integers in mm1 depending on the corresponding sign in mm2/m128.
        /// </summary>
        [Symbol("psignd mm, m64","NP 0F 38 0A /r 1")]
        psignd_mm_m64 = 1263,

        /// <summary>
        /// psignd mm, r8 | NP 0F 38 0A /r 1 | Negate/zero/preserve packed doubleword integers in mm1 depending on the corresponding sign in mm2/m128.
        /// </summary>
        [Symbol("psignd mm, r8","NP 0F 38 0A /r 1")]
        psignd_mm_r8 = 1264,

        /// <summary>
        /// psignd xmm, m128 | 66 0F 38 0A /r | Negate/zero/preserve packed doubleword integers in xmm1 depending on the corresponding sign in xmm2/m128.
        /// </summary>
        [Symbol("psignd xmm, m128","66 0F 38 0A /r")]
        psignd_xmm_m128 = 1265,

        /// <summary>
        /// psignd xmm, r8 | 66 0F 38 0A /r | Negate/zero/preserve packed doubleword integers in xmm1 depending on the corresponding sign in xmm2/m128.
        /// </summary>
        [Symbol("psignd xmm, r8","66 0F 38 0A /r")]
        psignd_xmm_r8 = 1266,

        /// <summary>
        /// psignw mm, m64 | NP 0F 38 09 /r 1 | Negate/zero/preserve packed word integers in mm1 depending on the corresponding sign in mm2/m128.
        /// </summary>
        [Symbol("psignw mm, m64","NP 0F 38 09 /r 1")]
        psignw_mm_m64 = 1267,

        /// <summary>
        /// psignw mm, r8 | NP 0F 38 09 /r 1 | Negate/zero/preserve packed word integers in mm1 depending on the corresponding sign in mm2/m128.
        /// </summary>
        [Symbol("psignw mm, r8","NP 0F 38 09 /r 1")]
        psignw_mm_r8 = 1268,

        /// <summary>
        /// psignw xmm, m128 | 66 0F 38 09 /r | Negate/zero/preserve packed word integers in xmm1 depending on the corresponding sign in xmm2/m128.
        /// </summary>
        [Symbol("psignw xmm, m128","66 0F 38 09 /r")]
        psignw_xmm_m128 = 1269,

        /// <summary>
        /// psignw xmm, r8 | 66 0F 38 09 /r | Negate/zero/preserve packed word integers in xmm1 depending on the corresponding sign in xmm2/m128.
        /// </summary>
        [Symbol("psignw xmm, r8","66 0F 38 09 /r")]
        psignw_xmm_r8 = 1270,

        /// <summary>
        /// pslld mm, imm8 | NP 0F 72 /6 ib | Shift doublewords in mm left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("pslld mm, imm8","NP 0F 72 /6 ib")]
        pslld_mm_imm8 = 1271,

        /// <summary>
        /// pslld mm, m64 | NP 0F F2 /r | Shift doublewords in mm left by mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("pslld mm, m64","NP 0F F2 /r")]
        pslld_mm_m64 = 1272,

        /// <summary>
        /// pslld mm, r8 | NP 0F F2 /r | Shift doublewords in mm left by mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("pslld mm, r8","NP 0F F2 /r")]
        pslld_mm_r8 = 1273,

        /// <summary>
        /// pslld xmm, imm8 | 66 0F 72 /6 ib | Shift doublewords in xmm1 left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("pslld xmm, imm8","66 0F 72 /6 ib")]
        pslld_xmm_imm8 = 1274,

        /// <summary>
        /// pslld xmm, m128 | 66 0F F2 /r | Shift doublewords in xmm1 left by xmm2/m128 while shifting in 0s.
        /// </summary>
        [Symbol("pslld xmm, m128","66 0F F2 /r")]
        pslld_xmm_m128 = 1275,

        /// <summary>
        /// pslld xmm, r8 | 66 0F F2 /r | Shift doublewords in xmm1 left by xmm2/m128 while shifting in 0s.
        /// </summary>
        [Symbol("pslld xmm, r8","66 0F F2 /r")]
        pslld_xmm_r8 = 1276,

        /// <summary>
        /// pslldq xmm, imm8 | 66 0F 73 /7 ib | Shift xmm1 left by imm8 bytes while shifting in 0s.
        /// </summary>
        [Symbol("pslldq xmm, imm8","66 0F 73 /7 ib")]
        pslldq_xmm_imm8 = 1277,

        /// <summary>
        /// psllq mm, imm8 | NP 0F 73 /6 ib | Shift quadword in mm left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("psllq mm, imm8","NP 0F 73 /6 ib")]
        psllq_mm_imm8 = 1278,

        /// <summary>
        /// psllq mm, m64 | NP 0F F3 /r | Shift quadword in mm left by mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("psllq mm, m64","NP 0F F3 /r")]
        psllq_mm_m64 = 1279,

        /// <summary>
        /// psllq mm, r8 | NP 0F F3 /r | Shift quadword in mm left by mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("psllq mm, r8","NP 0F F3 /r")]
        psllq_mm_r8 = 1280,

        /// <summary>
        /// psllq xmm, imm8 | 66 0F 73 /6 ib | Shift quadwords in xmm1 left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("psllq xmm, imm8","66 0F 73 /6 ib")]
        psllq_xmm_imm8 = 1281,

        /// <summary>
        /// psllq xmm, m128 | 66 0F F3 /r | Shift quadwords in xmm1 left by xmm2/m128 while shifting in 0s.
        /// </summary>
        [Symbol("psllq xmm, m128","66 0F F3 /r")]
        psllq_xmm_m128 = 1282,

        /// <summary>
        /// psllq xmm, r8 | 66 0F F3 /r | Shift quadwords in xmm1 left by xmm2/m128 while shifting in 0s.
        /// </summary>
        [Symbol("psllq xmm, r8","66 0F F3 /r")]
        psllq_xmm_r8 = 1283,

        /// <summary>
        /// psllw mm, imm8 | NP 0F 71 /6 ib | Shift words in mm left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("psllw mm, imm8","NP 0F 71 /6 ib")]
        psllw_mm_imm8 = 1284,

        /// <summary>
        /// psllw mm, m64 | NP 0F F1 /r | Shift words in mm left mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("psllw mm, m64","NP 0F F1 /r")]
        psllw_mm_m64 = 1285,

        /// <summary>
        /// psllw mm, r8 | NP 0F F1 /r | Shift words in mm left mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("psllw mm, r8","NP 0F F1 /r")]
        psllw_mm_r8 = 1286,

        /// <summary>
        /// psllw xmm, imm8 | 66 0F 71 /6 ib | Shift words in xmm1 left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("psllw xmm, imm8","66 0F 71 /6 ib")]
        psllw_xmm_imm8 = 1287,

        /// <summary>
        /// psllw xmm, m128 | 66 0F F1 /r | Shift words in xmm1 left by xmm2/m128 while shifting in 0s.
        /// </summary>
        [Symbol("psllw xmm, m128","66 0F F1 /r")]
        psllw_xmm_m128 = 1288,

        /// <summary>
        /// psllw xmm, r8 | 66 0F F1 /r | Shift words in xmm1 left by xmm2/m128 while shifting in 0s.
        /// </summary>
        [Symbol("psllw xmm, r8","66 0F F1 /r")]
        psllw_xmm_r8 = 1289,

        /// <summary>
        /// psrad mm, imm8 | NP 0F 72 /4 ib 1 | Shift doublewords in mm right by imm8 while shifting in sign bits.
        /// </summary>
        [Symbol("psrad mm, imm8","NP 0F 72 /4 ib 1")]
        psrad_mm_imm8 = 1290,

        /// <summary>
        /// psrad mm, m64 | NP 0F E2 /r 1 | Shift doublewords in mm right by mm/m64 while shifting in sign bits.
        /// </summary>
        [Symbol("psrad mm, m64","NP 0F E2 /r 1")]
        psrad_mm_m64 = 1291,

        /// <summary>
        /// psrad mm, r8 | NP 0F E2 /r 1 | Shift doublewords in mm right by mm/m64 while shifting in sign bits.
        /// </summary>
        [Symbol("psrad mm, r8","NP 0F E2 /r 1")]
        psrad_mm_r8 = 1292,

        /// <summary>
        /// psrad xmm, imm8 | 66 0F 72 /4 ib | Shift doublewords in xmm1 right by imm8 while shifting in sign bits.
        /// </summary>
        [Symbol("psrad xmm, imm8","66 0F 72 /4 ib")]
        psrad_xmm_imm8 = 1293,

        /// <summary>
        /// psrad xmm, m128 | 66 0F E2 /r | Shift doubleword in xmm1 right by xmm2 /m128 while shifting in sign bits.
        /// </summary>
        [Symbol("psrad xmm, m128","66 0F E2 /r")]
        psrad_xmm_m128 = 1294,

        /// <summary>
        /// psrad xmm, r8 | 66 0F E2 /r | Shift doubleword in xmm1 right by xmm2 /m128 while shifting in sign bits.
        /// </summary>
        [Symbol("psrad xmm, r8","66 0F E2 /r")]
        psrad_xmm_r8 = 1295,

        /// <summary>
        /// psraw mm, imm8 | NP 0F 71 /4 ib 1 | Shift words in mm right by imm8 while shifting in sign bits
        /// </summary>
        [Symbol("psraw mm, imm8","NP 0F 71 /4 ib 1")]
        psraw_mm_imm8 = 1296,

        /// <summary>
        /// psraw mm, m64 | NP 0F E1 /r 1 | Shift words in mm right by mm/m64 while shifting in sign bits.
        /// </summary>
        [Symbol("psraw mm, m64","NP 0F E1 /r 1")]
        psraw_mm_m64 = 1297,

        /// <summary>
        /// psraw mm, r8 | NP 0F E1 /r 1 | Shift words in mm right by mm/m64 while shifting in sign bits.
        /// </summary>
        [Symbol("psraw mm, r8","NP 0F E1 /r 1")]
        psraw_mm_r8 = 1298,

        /// <summary>
        /// psraw xmm, imm8 | 66 0F 71 /4 ib | Shift words in xmm1 right by imm8 while shifting in sign bits
        /// </summary>
        [Symbol("psraw xmm, imm8","66 0F 71 /4 ib")]
        psraw_xmm_imm8 = 1299,

        /// <summary>
        /// psraw xmm, m128 | 66 0F E1 /r | Shift words in xmm1 right by xmm2/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("psraw xmm, m128","66 0F E1 /r")]
        psraw_xmm_m128 = 1300,

        /// <summary>
        /// psraw xmm, r8 | 66 0F E1 /r | Shift words in xmm1 right by xmm2/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("psraw xmm, r8","66 0F E1 /r")]
        psraw_xmm_r8 = 1301,

        /// <summary>
        /// psrld mm, imm8 | NP 0F 72 /2 ib 1 | Shift doublewords in mm right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("psrld mm, imm8","NP 0F 72 /2 ib 1")]
        psrld_mm_imm8 = 1302,

        /// <summary>
        /// psrld mm, m64 | NP 0F D2 /r 1 | Shift doublewords in mm right by amount specified in mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("psrld mm, m64","NP 0F D2 /r 1")]
        psrld_mm_m64 = 1303,

        /// <summary>
        /// psrld mm, r8 | NP 0F D2 /r 1 | Shift doublewords in mm right by amount specified in mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("psrld mm, r8","NP 0F D2 /r 1")]
        psrld_mm_r8 = 1304,

        /// <summary>
        /// psrld xmm, imm8 | 66 0F 72 /2 ib | Shift doublewords in xmm1 right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("psrld xmm, imm8","66 0F 72 /2 ib")]
        psrld_xmm_imm8 = 1305,

        /// <summary>
        /// psrld xmm, m128 | 66 0F D2 /r | Shift doublewords in xmm1 right by amount specified in xmm2 /m128 while shifting in 0s.
        /// </summary>
        [Symbol("psrld xmm, m128","66 0F D2 /r")]
        psrld_xmm_m128 = 1306,

        /// <summary>
        /// psrld xmm, r8 | 66 0F D2 /r | Shift doublewords in xmm1 right by amount specified in xmm2 /m128 while shifting in 0s.
        /// </summary>
        [Symbol("psrld xmm, r8","66 0F D2 /r")]
        psrld_xmm_r8 = 1307,

        /// <summary>
        /// psrlq mm, imm8 | NP 0F 73 /2 ib 1 | Shift mm right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("psrlq mm, imm8","NP 0F 73 /2 ib 1")]
        psrlq_mm_imm8 = 1308,

        /// <summary>
        /// psrlq mm, m64 | NP 0F D3 /r 1 | Shift mm right by amount specified in mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("psrlq mm, m64","NP 0F D3 /r 1")]
        psrlq_mm_m64 = 1309,

        /// <summary>
        /// psrlq mm, r8 | NP 0F D3 /r 1 | Shift mm right by amount specified in mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("psrlq mm, r8","NP 0F D3 /r 1")]
        psrlq_mm_r8 = 1310,

        /// <summary>
        /// psrlq xmm, imm8 | 66 0F 73 /2 ib | Shift quadwords in xmm1 right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("psrlq xmm, imm8","66 0F 73 /2 ib")]
        psrlq_xmm_imm8 = 1311,

        /// <summary>
        /// psrlq xmm, m128 | 66 0F D3 /r | Shift quadwords in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.
        /// </summary>
        [Symbol("psrlq xmm, m128","66 0F D3 /r")]
        psrlq_xmm_m128 = 1312,

        /// <summary>
        /// psrlq xmm, r8 | 66 0F D3 /r | Shift quadwords in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.
        /// </summary>
        [Symbol("psrlq xmm, r8","66 0F D3 /r")]
        psrlq_xmm_r8 = 1313,

        /// <summary>
        /// psrlw mm, imm8 | NP 0F 71 /2 ib 1 | Shift words in mm right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("psrlw mm, imm8","NP 0F 71 /2 ib 1")]
        psrlw_mm_imm8 = 1314,

        /// <summary>
        /// psrlw mm, m64 | NP 0F D1 /r 1 | Shift words in mm right by amount specified in mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("psrlw mm, m64","NP 0F D1 /r 1")]
        psrlw_mm_m64 = 1315,

        /// <summary>
        /// psrlw mm, r8 | NP 0F D1 /r 1 | Shift words in mm right by amount specified in mm/m64 while shifting in 0s.
        /// </summary>
        [Symbol("psrlw mm, r8","NP 0F D1 /r 1")]
        psrlw_mm_r8 = 1316,

        /// <summary>
        /// psrlw xmm, imm8 | 66 0F 71 /2 ib | Shift words in xmm1 right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("psrlw xmm, imm8","66 0F 71 /2 ib")]
        psrlw_xmm_imm8 = 1317,

        /// <summary>
        /// psrlw xmm, m128 | 66 0F D1 /r | Shift words in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.
        /// </summary>
        [Symbol("psrlw xmm, m128","66 0F D1 /r")]
        psrlw_xmm_m128 = 1318,

        /// <summary>
        /// psrlw xmm, r8 | 66 0F D1 /r | Shift words in xmm1 right by amount specified in xmm2/m128 while shifting in 0s.
        /// </summary>
        [Symbol("psrlw xmm, r8","66 0F D1 /r")]
        psrlw_xmm_r8 = 1319,

        /// <summary>
        /// psubb mm, m64 | NP 0F F8 /r 1 | Subtract packed byte integers in mm/m64 from packed byte integers in mm.
        /// </summary>
        [Symbol("psubb mm, m64","NP 0F F8 /r 1")]
        psubb_mm_m64 = 1320,

        /// <summary>
        /// psubb mm, r8 | NP 0F F8 /r 1 | Subtract packed byte integers in mm/m64 from packed byte integers in mm.
        /// </summary>
        [Symbol("psubb mm, r8","NP 0F F8 /r 1")]
        psubb_mm_r8 = 1321,

        /// <summary>
        /// psubb xmm, m128 | 66 0F F8 /r | Subtract packed byte integers in xmm2/m128 from packed byte integers in xmm1.
        /// </summary>
        [Symbol("psubb xmm, m128","66 0F F8 /r")]
        psubb_xmm_m128 = 1322,

        /// <summary>
        /// psubb xmm, r8 | 66 0F F8 /r | Subtract packed byte integers in xmm2/m128 from packed byte integers in xmm1.
        /// </summary>
        [Symbol("psubb xmm, r8","66 0F F8 /r")]
        psubb_xmm_r8 = 1323,

        /// <summary>
        /// psubd mm, m64 | NP 0F FA /r 1 | Subtract packed doubleword integers in mm/m64 from packed doubleword integers in mm.
        /// </summary>
        [Symbol("psubd mm, m64","NP 0F FA /r 1")]
        psubd_mm_m64 = 1324,

        /// <summary>
        /// psubd mm, r8 | NP 0F FA /r 1 | Subtract packed doubleword integers in mm/m64 from packed doubleword integers in mm.
        /// </summary>
        [Symbol("psubd mm, r8","NP 0F FA /r 1")]
        psubd_mm_r8 = 1325,

        /// <summary>
        /// psubd xmm, m128 | 66 0F FA /r | Subtract packed doubleword integers in xmm2/mem128 from packed doubleword integers in xmm1.
        /// </summary>
        [Symbol("psubd xmm, m128","66 0F FA /r")]
        psubd_xmm_m128 = 1326,

        /// <summary>
        /// psubd xmm, r8 | 66 0F FA /r | Subtract packed doubleword integers in xmm2/mem128 from packed doubleword integers in xmm1.
        /// </summary>
        [Symbol("psubd xmm, r8","66 0F FA /r")]
        psubd_xmm_r8 = 1327,

        /// <summary>
        /// psubq mm, m64 | NP 0F FB /r 1 | Subtract quadword integer in mm1 from mm2 /m64.
        /// </summary>
        [Symbol("psubq mm, m64","NP 0F FB /r 1")]
        psubq_mm_m64 = 1328,

        /// <summary>
        /// psubq mm, r8 | NP 0F FB /r 1 | Subtract quadword integer in mm1 from mm2 /m64.
        /// </summary>
        [Symbol("psubq mm, r8","NP 0F FB /r 1")]
        psubq_mm_r8 = 1329,

        /// <summary>
        /// psubq xmm, m128 | 66 0F FB /r | Subtract packed quadword integers in xmm1 from xmm2 /m128.
        /// </summary>
        [Symbol("psubq xmm, m128","66 0F FB /r")]
        psubq_xmm_m128 = 1330,

        /// <summary>
        /// psubq xmm, r8 | 66 0F FB /r | Subtract packed quadword integers in xmm1 from xmm2 /m128.
        /// </summary>
        [Symbol("psubq xmm, r8","66 0F FB /r")]
        psubq_xmm_r8 = 1331,

        /// <summary>
        /// psubsb mm, m64 | NP 0F E8 /r 1 | Subtract signed packed bytes in mm/m64 from signed packed bytes in mm and saturate results.
        /// </summary>
        [Symbol("psubsb mm, m64","NP 0F E8 /r 1")]
        psubsb_mm_m64 = 1332,

        /// <summary>
        /// psubsb mm, r8 | NP 0F E8 /r 1 | Subtract signed packed bytes in mm/m64 from signed packed bytes in mm and saturate results.
        /// </summary>
        [Symbol("psubsb mm, r8","NP 0F E8 /r 1")]
        psubsb_mm_r8 = 1333,

        /// <summary>
        /// psubsb xmm, m128 | 66 0F E8 /r | Subtract packed signed byte integers in xmm2/m128 from packed signed byte integers in xmm1 and saturate results.
        /// </summary>
        [Symbol("psubsb xmm, m128","66 0F E8 /r")]
        psubsb_xmm_m128 = 1334,

        /// <summary>
        /// psubsb xmm, r8 | 66 0F E8 /r | Subtract packed signed byte integers in xmm2/m128 from packed signed byte integers in xmm1 and saturate results.
        /// </summary>
        [Symbol("psubsb xmm, r8","66 0F E8 /r")]
        psubsb_xmm_r8 = 1335,

        /// <summary>
        /// psubsw mm, m64 | NP 0F E9 /r 1 | Subtract signed packed words in mm/m64 from signed packed words in mm and saturate results.
        /// </summary>
        [Symbol("psubsw mm, m64","NP 0F E9 /r 1")]
        psubsw_mm_m64 = 1336,

        /// <summary>
        /// psubsw mm, r8 | NP 0F E9 /r 1 | Subtract signed packed words in mm/m64 from signed packed words in mm and saturate results.
        /// </summary>
        [Symbol("psubsw mm, r8","NP 0F E9 /r 1")]
        psubsw_mm_r8 = 1337,

        /// <summary>
        /// psubsw xmm, m128 | 66 0F E9 /r | Subtract packed signed word integers in xmm2/m128 from packed signed word integers in xmm1 and saturate results.
        /// </summary>
        [Symbol("psubsw xmm, m128","66 0F E9 /r")]
        psubsw_xmm_m128 = 1338,

        /// <summary>
        /// psubsw xmm, r8 | 66 0F E9 /r | Subtract packed signed word integers in xmm2/m128 from packed signed word integers in xmm1 and saturate results.
        /// </summary>
        [Symbol("psubsw xmm, r8","66 0F E9 /r")]
        psubsw_xmm_r8 = 1339,

        /// <summary>
        /// psubusb mm, m64 | NP 0F D8 /r 1 | Subtract unsigned packed bytes in mm/m64 from unsigned packed bytes in mm and saturate result.
        /// </summary>
        [Symbol("psubusb mm, m64","NP 0F D8 /r 1")]
        psubusb_mm_m64 = 1340,

        /// <summary>
        /// psubusb mm, r8 | NP 0F D8 /r 1 | Subtract unsigned packed bytes in mm/m64 from unsigned packed bytes in mm and saturate result.
        /// </summary>
        [Symbol("psubusb mm, r8","NP 0F D8 /r 1")]
        psubusb_mm_r8 = 1341,

        /// <summary>
        /// psubusb xmm, m128 | 66 0F D8 /r | Subtract packed unsigned byte integers in xmm2/m128 from packed unsigned byte integers in xmm1 and saturate result.
        /// </summary>
        [Symbol("psubusb xmm, m128","66 0F D8 /r")]
        psubusb_xmm_m128 = 1342,

        /// <summary>
        /// psubusb xmm, r8 | 66 0F D8 /r | Subtract packed unsigned byte integers in xmm2/m128 from packed unsigned byte integers in xmm1 and saturate result.
        /// </summary>
        [Symbol("psubusb xmm, r8","66 0F D8 /r")]
        psubusb_xmm_r8 = 1343,

        /// <summary>
        /// psubusw mm, m64 | NP 0F D9 /r 1 | Subtract unsigned packed words in mm/m64 from unsigned packed words in mm and saturate result.
        /// </summary>
        [Symbol("psubusw mm, m64","NP 0F D9 /r 1")]
        psubusw_mm_m64 = 1344,

        /// <summary>
        /// psubusw mm, r8 | NP 0F D9 /r 1 | Subtract unsigned packed words in mm/m64 from unsigned packed words in mm and saturate result.
        /// </summary>
        [Symbol("psubusw mm, r8","NP 0F D9 /r 1")]
        psubusw_mm_r8 = 1345,

        /// <summary>
        /// psubusw xmm, m128 | 66 0F D9 /r | Subtract packed unsigned word integers in xmm2/m128 from packed unsigned word integers in xmm1 and saturate result.
        /// </summary>
        [Symbol("psubusw xmm, m128","66 0F D9 /r")]
        psubusw_xmm_m128 = 1346,

        /// <summary>
        /// psubusw xmm, r8 | 66 0F D9 /r | Subtract packed unsigned word integers in xmm2/m128 from packed unsigned word integers in xmm1 and saturate result.
        /// </summary>
        [Symbol("psubusw xmm, r8","66 0F D9 /r")]
        psubusw_xmm_r8 = 1347,

        /// <summary>
        /// psubw mm, m64 | NP 0F F9 /r 1 | Subtract packed word integers in mm/m64 from packed word integers in mm.
        /// </summary>
        [Symbol("psubw mm, m64","NP 0F F9 /r 1")]
        psubw_mm_m64 = 1348,

        /// <summary>
        /// psubw mm, r8 | NP 0F F9 /r 1 | Subtract packed word integers in mm/m64 from packed word integers in mm.
        /// </summary>
        [Symbol("psubw mm, r8","NP 0F F9 /r 1")]
        psubw_mm_r8 = 1349,

        /// <summary>
        /// psubw xmm, m128 | 66 0F F9 /r | Subtract packed word integers in xmm2/m128 from packed word integers in xmm1.
        /// </summary>
        [Symbol("psubw xmm, m128","66 0F F9 /r")]
        psubw_xmm_m128 = 1350,

        /// <summary>
        /// psubw xmm, r8 | 66 0F F9 /r | Subtract packed word integers in xmm2/m128 from packed word integers in xmm1.
        /// </summary>
        [Symbol("psubw xmm, r8","66 0F F9 /r")]
        psubw_xmm_r8 = 1351,

        /// <summary>
        /// ptest xmm, m128 | 66 0F 38 17 /r | Set ZF if xmm2/m128 AND xmm1 result is all 0s. Set CF if xmm2/m128 AND NOT xmm1 result is all 0s.
        /// </summary>
        [Symbol("ptest xmm, m128","66 0F 38 17 /r")]
        ptest_xmm_m128 = 1352,

        /// <summary>
        /// ptest xmm, r8 | 66 0F 38 17 /r | Set ZF if xmm2/m128 AND xmm1 result is all 0s. Set CF if xmm2/m128 AND NOT xmm1 result is all 0s.
        /// </summary>
        [Symbol("ptest xmm, r8","66 0F 38 17 /r")]
        ptest_xmm_r8 = 1353,

        /// <summary>
        /// punpckhbw mm, m64 | NP 0F 68 /r | Unpack and interleave high-order bytes from mm and mm/m64 into mm.
        /// </summary>
        [Symbol("punpckhbw mm, m64","NP 0F 68 /r")]
        punpckhbw_mm_m64 = 1354,

        /// <summary>
        /// punpckhbw mm, r8 | NP 0F 68 /r | Unpack and interleave high-order bytes from mm and mm/m64 into mm.
        /// </summary>
        [Symbol("punpckhbw mm, r8","NP 0F 68 /r")]
        punpckhbw_mm_r8 = 1355,

        /// <summary>
        /// punpckhbw xmm, m128 | 66 0F 68 /r | Unpack and interleave high-order bytes from xmm1 and xmm2/m128 into xmm1.
        /// </summary>
        [Symbol("punpckhbw xmm, m128","66 0F 68 /r")]
        punpckhbw_xmm_m128 = 1356,

        /// <summary>
        /// punpckhbw xmm, r8 | 66 0F 68 /r | Unpack and interleave high-order bytes from xmm1 and xmm2/m128 into xmm1.
        /// </summary>
        [Symbol("punpckhbw xmm, r8","66 0F 68 /r")]
        punpckhbw_xmm_r8 = 1357,

        /// <summary>
        /// punpckhdq mm, m64 | NP 0F 6A /r | Unpack and interleave high-order doublewords from mm and mm/m64 into mm.
        /// </summary>
        [Symbol("punpckhdq mm, m64","NP 0F 6A /r")]
        punpckhdq_mm_m64 = 1358,

        /// <summary>
        /// punpckhdq mm, r8 | NP 0F 6A /r | Unpack and interleave high-order doublewords from mm and mm/m64 into mm.
        /// </summary>
        [Symbol("punpckhdq mm, r8","NP 0F 6A /r")]
        punpckhdq_mm_r8 = 1359,

        /// <summary>
        /// punpckhdq xmm, m128 | 66 0F 6A /r | Unpack and interleave high-order doublewords from xmm1 and xmm2/m128 into xmm1.
        /// </summary>
        [Symbol("punpckhdq xmm, m128","66 0F 6A /r")]
        punpckhdq_xmm_m128 = 1360,

        /// <summary>
        /// punpckhdq xmm, r8 | 66 0F 6A /r | Unpack and interleave high-order doublewords from xmm1 and xmm2/m128 into xmm1.
        /// </summary>
        [Symbol("punpckhdq xmm, r8","66 0F 6A /r")]
        punpckhdq_xmm_r8 = 1361,

        /// <summary>
        /// punpckhqdq xmm, m128 | 66 0F 6D /r | Unpack and interleave high-order quadwords from xmm1 and xmm2/m128 into xmm1.
        /// </summary>
        [Symbol("punpckhqdq xmm, m128","66 0F 6D /r")]
        punpckhqdq_xmm_m128 = 1362,

        /// <summary>
        /// punpckhqdq xmm, r8 | 66 0F 6D /r | Unpack and interleave high-order quadwords from xmm1 and xmm2/m128 into xmm1.
        /// </summary>
        [Symbol("punpckhqdq xmm, r8","66 0F 6D /r")]
        punpckhqdq_xmm_r8 = 1363,

        /// <summary>
        /// punpckhwd mm, m64 | NP 0F 69 /r | Unpack and interleave high-order words from mm and mm/m64 into mm.
        /// </summary>
        [Symbol("punpckhwd mm, m64","NP 0F 69 /r")]
        punpckhwd_mm_m64 = 1364,

        /// <summary>
        /// punpckhwd mm, r8 | NP 0F 69 /r | Unpack and interleave high-order words from mm and mm/m64 into mm.
        /// </summary>
        [Symbol("punpckhwd mm, r8","NP 0F 69 /r")]
        punpckhwd_mm_r8 = 1365,

        /// <summary>
        /// punpckhwd xmm, m128 | 66 0F 69 /r | Unpack and interleave high-order words from xmm1 and xmm2/m128 into xmm1.
        /// </summary>
        [Symbol("punpckhwd xmm, m128","66 0F 69 /r")]
        punpckhwd_xmm_m128 = 1366,

        /// <summary>
        /// punpckhwd xmm, r8 | 66 0F 69 /r | Unpack and interleave high-order words from xmm1 and xmm2/m128 into xmm1.
        /// </summary>
        [Symbol("punpckhwd xmm, r8","66 0F 69 /r")]
        punpckhwd_xmm_r8 = 1367,

        /// <summary>
        /// punpckldq mm, m32 | NP 0F 62 /r | Interleave low-order doublewords from mm and mm/m32 into mm.
        /// </summary>
        [Symbol("punpckldq mm, m32","NP 0F 62 /r")]
        punpckldq_mm_m32 = 1368,

        /// <summary>
        /// punpckldq mm, r8 | NP 0F 62 /r | Interleave low-order doublewords from mm and mm/m32 into mm.
        /// </summary>
        [Symbol("punpckldq mm, r8","NP 0F 62 /r")]
        punpckldq_mm_r8 = 1369,

        /// <summary>
        /// punpckldq xmm, m128 | 66 0F 62 /r | Interleave low-order doublewords from xmm1 and xmm2/m128 into xmm1.
        /// </summary>
        [Symbol("punpckldq xmm, m128","66 0F 62 /r")]
        punpckldq_xmm_m128 = 1370,

        /// <summary>
        /// punpckldq xmm, r8 | 66 0F 62 /r | Interleave low-order doublewords from xmm1 and xmm2/m128 into xmm1.
        /// </summary>
        [Symbol("punpckldq xmm, r8","66 0F 62 /r")]
        punpckldq_xmm_r8 = 1371,

        /// <summary>
        /// punpcklqdq xmm, m128 | 66 0F 6C /r | Interleave low-order quadword from xmm1 and xmm2/m128 into xmm1 register.
        /// </summary>
        [Symbol("punpcklqdq xmm, m128","66 0F 6C /r")]
        punpcklqdq_xmm_m128 = 1372,

        /// <summary>
        /// punpcklqdq xmm, r8 | 66 0F 6C /r | Interleave low-order quadword from xmm1 and xmm2/m128 into xmm1 register.
        /// </summary>
        [Symbol("punpcklqdq xmm, r8","66 0F 6C /r")]
        punpcklqdq_xmm_r8 = 1373,

        /// <summary>
        /// push CS | 0E | Push CS.
        /// </summary>
        [Symbol("push CS","0E")]
        push_CS = 1374,

        /// <summary>
        /// push DS | 1E | Push DS.
        /// </summary>
        [Symbol("push DS","1E")]
        push_DS = 1375,

        /// <summary>
        /// push ES | 06 | Push ES.
        /// </summary>
        [Symbol("push ES","06")]
        push_ES = 1376,

        /// <summary>
        /// push FS | 0F A0 | Push FS.
        /// </summary>
        [Symbol("push FS","0F A0")]
        push_FS = 1377,

        /// <summary>
        /// push GS | 0F A8 | Push GS.
        /// </summary>
        [Symbol("push GS","0F A8")]
        push_GS = 1378,

        /// <summary>
        /// push imm16 | 68 iw | Push imm16.
        /// </summary>
        [Symbol("push imm16","68 iw")]
        push_imm16 = 1379,

        /// <summary>
        /// push imm32 | 68 id | Push imm32.
        /// </summary>
        [Symbol("push imm32","68 id")]
        push_imm32 = 1380,

        /// <summary>
        /// push imm8 | 6A ib | Push imm8.
        /// </summary>
        [Symbol("push imm8","6A ib")]
        push_imm8 = 1381,

        /// <summary>
        /// push m16 | FF /6 | Push r/m16.
        /// </summary>
        [Symbol("push m16","FF /6")]
        push_m16 = 1382,

        /// <summary>
        /// push m32 | FF /6 | Push r/m32.
        /// </summary>
        [Symbol("push m32","FF /6")]
        push_m32 = 1383,

        /// <summary>
        /// push m64 | FF /6 | Push r/m64.
        /// </summary>
        [Symbol("push m64","FF /6")]
        push_m64 = 1384,

        /// <summary>
        /// push r16 | FF /6 | Push r/m16.
        /// </summary>
        [Symbol("push r16","FF /6")]
        push_r16 = 1385,

        /// <summary>
        /// push r16 | 50 +rw | Push r16.
        /// </summary>
        [Symbol("push r16","50 +rw")]
        push_r16_rex = 1386,

        /// <summary>
        /// push r32 | FF /6 | Push r/m32.
        /// </summary>
        [Symbol("push r32","FF /6")]
        push_r32 = 1387,

        /// <summary>
        /// push r32 | 50 +rd | Push r32.
        /// </summary>
        [Symbol("push r32","50 +rd")]
        push_r32_rex = 1388,

        /// <summary>
        /// push r64 | FF /6 | Push r/m64.
        /// </summary>
        [Symbol("push r64","FF /6")]
        push_r64 = 1389,

        /// <summary>
        /// push r64 | 50 +rd | Push r64.
        /// </summary>
        [Symbol("push r64","50 +rd")]
        push_r64_rex = 1390,

        /// <summary>
        /// push SS | 16 | Push SS.
        /// </summary>
        [Symbol("push SS","16")]
        push_SS = 1391,

        /// <summary>
        /// pushf | 9C | Push lower 16 bits of EFLAGS.
        /// </summary>
        [Symbol("pushf","9C")]
        pushf = 1392,

        /// <summary>
        /// pushfd | 9C | Push EFLAGS.
        /// </summary>
        [Symbol("pushfd","9C")]
        pushfd = 1393,

        /// <summary>
        /// pushfq | 9C | Push RFLAGS.
        /// </summary>
        [Symbol("pushfq","9C")]
        pushfq = 1394,

        /// <summary>
        /// pxor mm, m64 | NP 0F EF /r 1 | Bitwise XOR of mm/m64 and mm.
        /// </summary>
        [Symbol("pxor mm, m64","NP 0F EF /r 1")]
        pxor_mm_m64 = 1395,

        /// <summary>
        /// pxor mm, r8 | NP 0F EF /r 1 | Bitwise XOR of mm/m64 and mm.
        /// </summary>
        [Symbol("pxor mm, r8","NP 0F EF /r 1")]
        pxor_mm_r8 = 1396,

        /// <summary>
        /// pxor xmm, m128 | 66 0F EF /r | Bitwise XOR of xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("pxor xmm, m128","66 0F EF /r")]
        pxor_xmm_m128 = 1397,

        /// <summary>
        /// pxor xmm, r8 | 66 0F EF /r | Bitwise XOR of xmm2/m128 and xmm1.
        /// </summary>
        [Symbol("pxor xmm, r8","66 0F EF /r")]
        pxor_xmm_r8 = 1398,

        /// <summary>
        /// rcl m16, CL | D3 /2 | Rotate 17 bits (CF, r/m16) left CL times.
        /// </summary>
        [Symbol("rcl m16, CL","D3 /2")]
        rcl_m16_CL = 1399,

        /// <summary>
        /// rcl m16, imm8 | C1 /2 ib | Rotate 17 bits (CF, r/m16) left imm8 times.
        /// </summary>
        [Symbol("rcl m16, imm8","C1 /2 ib")]
        rcl_m16_imm8 = 1400,

        /// <summary>
        /// rcl m16, 1 | D1 /2 | Rotate 17 bits (CF, r/m16) left once.
        /// </summary>
        [Symbol("rcl m16, 1","D1 /2")]
        rcl_m16_n1 = 1401,

        /// <summary>
        /// rcl m32, CL | D3 /2 | Rotate 33 bits (CF, r/m32) left CL times.
        /// </summary>
        [Symbol("rcl m32, CL","D3 /2")]
        rcl_m32_CL = 1402,

        /// <summary>
        /// rcl m32, imm8 | C1 /2 ib | Rotate 33 bits (CF, r/m32) left imm8 times.
        /// </summary>
        [Symbol("rcl m32, imm8","C1 /2 ib")]
        rcl_m32_imm8 = 1403,

        /// <summary>
        /// rcl m32, 1 | D1 /2 | Rotate 33 bits (CF, r/m32) left once.
        /// </summary>
        [Symbol("rcl m32, 1","D1 /2")]
        rcl_m32_n1 = 1404,

        /// <summary>
        /// rcl m64, CL | REX.W + D3 /2 | Rotate 65 bits (CF, r/m64) left CL times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcl m64, CL","REX.W + D3 /2")]
        rcl_m64_CL = 1405,

        /// <summary>
        /// rcl m64, imm8 | REX.W + C1 /2 ib | Rotate 65 bits (CF, r/m64) left imm8 times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcl m64, imm8","REX.W + C1 /2 ib")]
        rcl_m64_imm8 = 1406,

        /// <summary>
        /// rcl m64, 1 | REX.W + D1 /2 | Rotate 65 bits (CF, r/m64) left once. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcl m64, 1","REX.W + D1 /2")]
        rcl_m64_n1 = 1407,

        /// <summary>
        /// rcl m8, CL | D2 /2 | Rotate 9 bits (CF, r/m8) left CL times.
        /// </summary>
        [Symbol("rcl m8, CL","D2 /2")]
        rcl_m8_CL = 1408,

        /// <summary>
        /// rcl m8, CL | REX + D2 /2 | Rotate 9 bits (CF, r/m8) left CL times.
        /// </summary>
        [Symbol("rcl m8, CL","REX + D2 /2")]
        rcl_m8_CL_rex = 1409,

        /// <summary>
        /// rcl m8, imm8 | C0 /2 ib | Rotate 9 bits (CF, r/m8) left imm8 times.
        /// </summary>
        [Symbol("rcl m8, imm8","C0 /2 ib")]
        rcl_m8_imm8 = 1410,

        /// <summary>
        /// rcl m8, imm8 | REX + C0 /2 ib | Rotate 9 bits (CF, r/m8) left imm8 times.
        /// </summary>
        [Symbol("rcl m8, imm8","REX + C0 /2 ib")]
        rcl_m8_imm8_rex = 1411,

        /// <summary>
        /// rcl m8, 1 | REX + D0 /2 | Rotate 9 bits (CF, r/m8) left once.
        /// </summary>
        [Symbol("rcl m8, 1","REX + D0 /2")]
        rcl_m8_n1 = 1412,

        /// <summary>
        /// rcl m8, 1 | D0 /2 | Rotate 9 bits (CF, r/m8) left once.
        /// </summary>
        [Symbol("rcl m8, 1","D0 /2")]
        rcl_m8_n1_xD0 = 1413,

        /// <summary>
        /// rcl r16, CL | D3 /2 | Rotate 17 bits (CF, r/m16) left CL times.
        /// </summary>
        [Symbol("rcl r16, CL","D3 /2")]
        rcl_r16_CL = 1414,

        /// <summary>
        /// rcl r16, imm8 | C1 /2 ib | Rotate 17 bits (CF, r/m16) left imm8 times.
        /// </summary>
        [Symbol("rcl r16, imm8","C1 /2 ib")]
        rcl_r16_imm8 = 1415,

        /// <summary>
        /// rcl r16, 1 | D1 /2 | Rotate 17 bits (CF, r/m16) left once.
        /// </summary>
        [Symbol("rcl r16, 1","D1 /2")]
        rcl_r16_n1 = 1416,

        /// <summary>
        /// rcl r32, CL | D3 /2 | Rotate 33 bits (CF, r/m32) left CL times.
        /// </summary>
        [Symbol("rcl r32, CL","D3 /2")]
        rcl_r32_CL = 1417,

        /// <summary>
        /// rcl r32, imm8 | C1 /2 ib | Rotate 33 bits (CF, r/m32) left imm8 times.
        /// </summary>
        [Symbol("rcl r32, imm8","C1 /2 ib")]
        rcl_r32_imm8 = 1418,

        /// <summary>
        /// rcl r32, 1 | D1 /2 | Rotate 33 bits (CF, r/m32) left once.
        /// </summary>
        [Symbol("rcl r32, 1","D1 /2")]
        rcl_r32_n1 = 1419,

        /// <summary>
        /// rcl r64, CL | REX.W + D3 /2 | Rotate 65 bits (CF, r/m64) left CL times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcl r64, CL","REX.W + D3 /2")]
        rcl_r64_CL = 1420,

        /// <summary>
        /// rcl r64, imm8 | REX.W + C1 /2 ib | Rotate 65 bits (CF, r/m64) left imm8 times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcl r64, imm8","REX.W + C1 /2 ib")]
        rcl_r64_imm8 = 1421,

        /// <summary>
        /// rcl r64, 1 | REX.W + D1 /2 | Rotate 65 bits (CF, r/m64) left once. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcl r64, 1","REX.W + D1 /2")]
        rcl_r64_n1 = 1422,

        /// <summary>
        /// rcl r8, CL | D2 /2 | Rotate 9 bits (CF, r/m8) left CL times.
        /// </summary>
        [Symbol("rcl r8, CL","D2 /2")]
        rcl_r8_CL = 1423,

        /// <summary>
        /// rcl r8, CL | REX + D2 /2 | Rotate 9 bits (CF, r/m8) left CL times.
        /// </summary>
        [Symbol("rcl r8, CL","REX + D2 /2")]
        rcl_r8_CL_rex = 1424,

        /// <summary>
        /// rcl r8, imm8 | C0 /2 ib | Rotate 9 bits (CF, r/m8) left imm8 times.
        /// </summary>
        [Symbol("rcl r8, imm8","C0 /2 ib")]
        rcl_r8_imm8 = 1425,

        /// <summary>
        /// rcl r8, imm8 | REX + C0 /2 ib | Rotate 9 bits (CF, r/m8) left imm8 times.
        /// </summary>
        [Symbol("rcl r8, imm8","REX + C0 /2 ib")]
        rcl_r8_imm8_rex = 1426,

        /// <summary>
        /// rcl r8, 1 | REX + D0 /2 | Rotate 9 bits (CF, r/m8) left once.
        /// </summary>
        [Symbol("rcl r8, 1","REX + D0 /2")]
        rcl_r8_n1 = 1427,

        /// <summary>
        /// rcl r8, 1 | D0 /2 | Rotate 9 bits (CF, r/m8) left once.
        /// </summary>
        [Symbol("rcl r8, 1","D0 /2")]
        rcl_r8_n1_xD0 = 1428,

        /// <summary>
        /// rcr m16, CL | D3 /3 | Rotate 17 bits (CF, r/m16) right CL times.
        /// </summary>
        [Symbol("rcr m16, CL","D3 /3")]
        rcr_m16_CL = 1429,

        /// <summary>
        /// rcr m16, imm8 | C1 /3 ib | Rotate 17 bits (CF, r/m16) right imm8 times.
        /// </summary>
        [Symbol("rcr m16, imm8","C1 /3 ib")]
        rcr_m16_imm8 = 1430,

        /// <summary>
        /// rcr m16, 1 | D1 /3 | Rotate 17 bits (CF, r/m16) right once.
        /// </summary>
        [Symbol("rcr m16, 1","D1 /3")]
        rcr_m16_n1 = 1431,

        /// <summary>
        /// rcr m32, CL | D3 /3 | Rotate 33 bits (CF, r/m32) right CL times.
        /// </summary>
        [Symbol("rcr m32, CL","D3 /3")]
        rcr_m32_CL = 1432,

        /// <summary>
        /// rcr m32, imm8 | C1 /3 ib | Rotate 33 bits (CF, r/m32) right imm8 times.
        /// </summary>
        [Symbol("rcr m32, imm8","C1 /3 ib")]
        rcr_m32_imm8 = 1433,

        /// <summary>
        /// rcr m32, 1 | D1 /3 | Rotate 33 bits (CF, r/m32) right once. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcr m32, 1","D1 /3")]
        rcr_m32_n1 = 1434,

        /// <summary>
        /// rcr m64, CL | REX.W + D3 /3 | Rotate 65 bits (CF, r/m64) right CL times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcr m64, CL","REX.W + D3 /3")]
        rcr_m64_CL = 1435,

        /// <summary>
        /// rcr m64, imm8 | REX.W + C1 /3 ib | Rotate 65 bits (CF, r/m64) right imm8 times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcr m64, imm8","REX.W + C1 /3 ib")]
        rcr_m64_imm8 = 1436,

        /// <summary>
        /// rcr m64, 1 | REX.W + D1 /3 | Rotate 65 bits (CF, r/m64) right once. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcr m64, 1","REX.W + D1 /3")]
        rcr_m64_n1 = 1437,

        /// <summary>
        /// rcr m8, CL | D2 /3 | Rotate 9 bits (CF, r/m8) right CL times.
        /// </summary>
        [Symbol("rcr m8, CL","D2 /3")]
        rcr_m8_CL = 1438,

        /// <summary>
        /// rcr m8, CL | REX + D2 /3 | Rotate 9 bits (CF, r/m8) right CL times.
        /// </summary>
        [Symbol("rcr m8, CL","REX + D2 /3")]
        rcr_m8_CL_rex = 1439,

        /// <summary>
        /// rcr m8, imm8 | C0 /3 ib | Rotate 9 bits (CF, r/m8) right imm8 times.
        /// </summary>
        [Symbol("rcr m8, imm8","C0 /3 ib")]
        rcr_m8_imm8 = 1440,

        /// <summary>
        /// rcr m8, imm8 | REX + C0 /3 ib | Rotate 9 bits (CF, r/m8) right imm8 times.
        /// </summary>
        [Symbol("rcr m8, imm8","REX + C0 /3 ib")]
        rcr_m8_imm8_rex = 1441,

        /// <summary>
        /// rcr m8, 1 | D0 /3 | Rotate 9 bits (CF, r/m8) right once.
        /// </summary>
        [Symbol("rcr m8, 1","D0 /3")]
        rcr_m8_n1 = 1442,

        /// <summary>
        /// rcr m8, 1 | REX + D0 /3 | Rotate 9 bits (CF, r/m8) right once.
        /// </summary>
        [Symbol("rcr m8, 1","REX + D0 /3")]
        rcr_m8_n1_rex = 1443,

        /// <summary>
        /// rcr r16, CL | D3 /3 | Rotate 17 bits (CF, r/m16) right CL times.
        /// </summary>
        [Symbol("rcr r16, CL","D3 /3")]
        rcr_r16_CL = 1444,

        /// <summary>
        /// rcr r16, imm8 | C1 /3 ib | Rotate 17 bits (CF, r/m16) right imm8 times.
        /// </summary>
        [Symbol("rcr r16, imm8","C1 /3 ib")]
        rcr_r16_imm8 = 1445,

        /// <summary>
        /// rcr r16, 1 | D1 /3 | Rotate 17 bits (CF, r/m16) right once.
        /// </summary>
        [Symbol("rcr r16, 1","D1 /3")]
        rcr_r16_n1 = 1446,

        /// <summary>
        /// rcr r32, CL | D3 /3 | Rotate 33 bits (CF, r/m32) right CL times.
        /// </summary>
        [Symbol("rcr r32, CL","D3 /3")]
        rcr_r32_CL = 1447,

        /// <summary>
        /// rcr r32, imm8 | C1 /3 ib | Rotate 33 bits (CF, r/m32) right imm8 times.
        /// </summary>
        [Symbol("rcr r32, imm8","C1 /3 ib")]
        rcr_r32_imm8 = 1448,

        /// <summary>
        /// rcr r32, 1 | D1 /3 | Rotate 33 bits (CF, r/m32) right once. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcr r32, 1","D1 /3")]
        rcr_r32_n1 = 1449,

        /// <summary>
        /// rcr r64, CL | REX.W + D3 /3 | Rotate 65 bits (CF, r/m64) right CL times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcr r64, CL","REX.W + D3 /3")]
        rcr_r64_CL = 1450,

        /// <summary>
        /// rcr r64, imm8 | REX.W + C1 /3 ib | Rotate 65 bits (CF, r/m64) right imm8 times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcr r64, imm8","REX.W + C1 /3 ib")]
        rcr_r64_imm8 = 1451,

        /// <summary>
        /// rcr r64, 1 | REX.W + D1 /3 | Rotate 65 bits (CF, r/m64) right once. Uses a 6 bit count.
        /// </summary>
        [Symbol("rcr r64, 1","REX.W + D1 /3")]
        rcr_r64_n1 = 1452,

        /// <summary>
        /// rcr r8, CL | D2 /3 | Rotate 9 bits (CF, r/m8) right CL times.
        /// </summary>
        [Symbol("rcr r8, CL","D2 /3")]
        rcr_r8_CL = 1453,

        /// <summary>
        /// rcr r8, CL | REX + D2 /3 | Rotate 9 bits (CF, r/m8) right CL times.
        /// </summary>
        [Symbol("rcr r8, CL","REX + D2 /3")]
        rcr_r8_CL_rex = 1454,

        /// <summary>
        /// rcr r8, imm8 | C0 /3 ib | Rotate 9 bits (CF, r/m8) right imm8 times.
        /// </summary>
        [Symbol("rcr r8, imm8","C0 /3 ib")]
        rcr_r8_imm8 = 1455,

        /// <summary>
        /// rcr r8, imm8 | REX + C0 /3 ib | Rotate 9 bits (CF, r/m8) right imm8 times.
        /// </summary>
        [Symbol("rcr r8, imm8","REX + C0 /3 ib")]
        rcr_r8_imm8_rex = 1456,

        /// <summary>
        /// rcr r8, 1 | D0 /3 | Rotate 9 bits (CF, r/m8) right once.
        /// </summary>
        [Symbol("rcr r8, 1","D0 /3")]
        rcr_r8_n1 = 1457,

        /// <summary>
        /// rcr r8, 1 | REX + D0 /3 | Rotate 9 bits (CF, r/m8) right once.
        /// </summary>
        [Symbol("rcr r8, 1","REX + D0 /3")]
        rcr_r8_n1_rex = 1458,

        /// <summary>
        /// rdfsbase r32 | F3 0F AE /0 | Load the 32-bit destination register with the FS base address.
        /// </summary>
        [Symbol("rdfsbase r32","F3 0F AE /0")]
        rdfsbase_r32 = 1459,

        /// <summary>
        /// rdfsbase r64 | F3 REX.W 0F AE /0 | Load the 64-bit destination register with the FS base address.
        /// </summary>
        [Symbol("rdfsbase r64","F3 REX.W 0F AE /0")]
        rdfsbase_r64 = 1460,

        /// <summary>
        /// rdgsbase r32 | F3 0F AE /1 | Load the 32-bit destination register with the GS base address.
        /// </summary>
        [Symbol("rdgsbase r32","F3 0F AE /1")]
        rdgsbase_r32 = 1461,

        /// <summary>
        /// rdgsbase r64 | F3 REX.W 0F AE /1 | Load the 64-bit destination register with the GS base address.
        /// </summary>
        [Symbol("rdgsbase r64","F3 REX.W 0F AE /1")]
        rdgsbase_r64 = 1462,

        /// <summary>
        /// rdtsc | 0F 31 | Read time-stamp counter into EDX:EAX.
        /// </summary>
        [Symbol("rdtsc","0F 31")]
        rdtsc = 1463,

        /// <summary>
        /// rol m16, CL | D3 /0 | Rotate 16 bits r/m16 left CL times.
        /// </summary>
        [Symbol("rol m16, CL","D3 /0")]
        rol_m16_CL = 1464,

        /// <summary>
        /// rol m16, imm8 | C1 /0 ib | Rotate 16 bits r/m16 left imm8 times.
        /// </summary>
        [Symbol("rol m16, imm8","C1 /0 ib")]
        rol_m16_imm8 = 1465,

        /// <summary>
        /// rol m16, 1 | D1 /0 | Rotate 16 bits r/m16 left once.
        /// </summary>
        [Symbol("rol m16, 1","D1 /0")]
        rol_m16_n1 = 1466,

        /// <summary>
        /// rol m32, CL | D3 /0 | Rotate 32 bits r/m32 left CL times.
        /// </summary>
        [Symbol("rol m32, CL","D3 /0")]
        rol_m32_CL = 1467,

        /// <summary>
        /// rol m32, imm8 | C1 /0 ib | Rotate 32 bits r/m32 left imm8 times.
        /// </summary>
        [Symbol("rol m32, imm8","C1 /0 ib")]
        rol_m32_imm8 = 1468,

        /// <summary>
        /// rol m32, 1 | D1 /0 | Rotate 32 bits r/m32 left once.
        /// </summary>
        [Symbol("rol m32, 1","D1 /0")]
        rol_m32_n1 = 1469,

        /// <summary>
        /// rol m64, CL | REX.W + D3 /0 | Rotate 64 bits r/m64 left CL times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rol m64, CL","REX.W + D3 /0")]
        rol_m64_CL = 1470,

        /// <summary>
        /// rol m64, imm8 | REX.W + C1 /0 ib | Rotate 64 bits r/m64 left imm8 times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rol m64, imm8","REX.W + C1 /0 ib")]
        rol_m64_imm8 = 1471,

        /// <summary>
        /// rol m64, 1 | REX.W + D1 /0 | Rotate 64 bits r/m64 left once. Uses a 6 bit count.
        /// </summary>
        [Symbol("rol m64, 1","REX.W + D1 /0")]
        rol_m64_n1 = 1472,

        /// <summary>
        /// rol m8, CL | D2 /0 | Rotate 8 bits r/m8 left CL times.
        /// </summary>
        [Symbol("rol m8, CL","D2 /0")]
        rol_m8_CL = 1473,

        /// <summary>
        /// rol m8, CL | REX + D2 /0 | Rotate 8 bits r/m8 left CL times.
        /// </summary>
        [Symbol("rol m8, CL","REX + D2 /0")]
        rol_m8_CL_rex = 1474,

        /// <summary>
        /// rol m8, imm8 | C0 /0 ib | Rotate 8 bits r/m8 left imm8 times.
        /// </summary>
        [Symbol("rol m8, imm8","C0 /0 ib")]
        rol_m8_imm8 = 1475,

        /// <summary>
        /// rol m8, imm8 | REX + C0 /0 ib | Rotate 8 bits r/m8 left imm8 times.
        /// </summary>
        [Symbol("rol m8, imm8","REX + C0 /0 ib")]
        rol_m8_imm8_rex = 1476,

        /// <summary>
        /// rol m8, 1 | D0 /0 | Rotate 8 bits r/m8 left once.
        /// </summary>
        [Symbol("rol m8, 1","D0 /0")]
        rol_m8_n1 = 1477,

        /// <summary>
        /// rol m8, 1 | REX + D0 /0 | Rotate 8 bits r/m8 left once
        /// </summary>
        [Symbol("rol m8, 1","REX + D0 /0")]
        rol_m8_n1_rex = 1478,

        /// <summary>
        /// rol r16, CL | D3 /0 | Rotate 16 bits r/m16 left CL times.
        /// </summary>
        [Symbol("rol r16, CL","D3 /0")]
        rol_r16_CL = 1479,

        /// <summary>
        /// rol r16, imm8 | C1 /0 ib | Rotate 16 bits r/m16 left imm8 times.
        /// </summary>
        [Symbol("rol r16, imm8","C1 /0 ib")]
        rol_r16_imm8 = 1480,

        /// <summary>
        /// rol r16, 1 | D1 /0 | Rotate 16 bits r/m16 left once.
        /// </summary>
        [Symbol("rol r16, 1","D1 /0")]
        rol_r16_n1 = 1481,

        /// <summary>
        /// rol r32, CL | D3 /0 | Rotate 32 bits r/m32 left CL times.
        /// </summary>
        [Symbol("rol r32, CL","D3 /0")]
        rol_r32_CL = 1482,

        /// <summary>
        /// rol r32, imm8 | C1 /0 ib | Rotate 32 bits r/m32 left imm8 times.
        /// </summary>
        [Symbol("rol r32, imm8","C1 /0 ib")]
        rol_r32_imm8 = 1483,

        /// <summary>
        /// rol r32, 1 | D1 /0 | Rotate 32 bits r/m32 left once.
        /// </summary>
        [Symbol("rol r32, 1","D1 /0")]
        rol_r32_n1 = 1484,

        /// <summary>
        /// rol r64, CL | REX.W + D3 /0 | Rotate 64 bits r/m64 left CL times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rol r64, CL","REX.W + D3 /0")]
        rol_r64_CL = 1485,

        /// <summary>
        /// rol r64, imm8 | REX.W + C1 /0 ib | Rotate 64 bits r/m64 left imm8 times. Uses a 6 bit count.
        /// </summary>
        [Symbol("rol r64, imm8","REX.W + C1 /0 ib")]
        rol_r64_imm8 = 1486,

        /// <summary>
        /// rol r64, 1 | REX.W + D1 /0 | Rotate 64 bits r/m64 left once. Uses a 6 bit count.
        /// </summary>
        [Symbol("rol r64, 1","REX.W + D1 /0")]
        rol_r64_n1 = 1487,

        /// <summary>
        /// rol r8, CL | D2 /0 | Rotate 8 bits r/m8 left CL times.
        /// </summary>
        [Symbol("rol r8, CL","D2 /0")]
        rol_r8_CL = 1488,

        /// <summary>
        /// rol r8, CL | REX + D2 /0 | Rotate 8 bits r/m8 left CL times.
        /// </summary>
        [Symbol("rol r8, CL","REX + D2 /0")]
        rol_r8_CL_rex = 1489,

        /// <summary>
        /// rol r8, imm8 | C0 /0 ib | Rotate 8 bits r/m8 left imm8 times.
        /// </summary>
        [Symbol("rol r8, imm8","C0 /0 ib")]
        rol_r8_imm8 = 1490,

        /// <summary>
        /// rol r8, imm8 | REX + C0 /0 ib | Rotate 8 bits r/m8 left imm8 times.
        /// </summary>
        [Symbol("rol r8, imm8","REX + C0 /0 ib")]
        rol_r8_imm8_rex = 1491,

        /// <summary>
        /// rol r8, 1 | D0 /0 | Rotate 8 bits r/m8 left once.
        /// </summary>
        [Symbol("rol r8, 1","D0 /0")]
        rol_r8_n1 = 1492,

        /// <summary>
        /// rol r8, 1 | REX + D0 /0 | Rotate 8 bits r/m8 left once
        /// </summary>
        [Symbol("rol r8, 1","REX + D0 /0")]
        rol_r8_n1_rex = 1493,

        /// <summary>
        /// ror m16, CL | D3 /1 | Rotate 16 bits r/m16 right CL times.
        /// </summary>
        [Symbol("ror m16, CL","D3 /1")]
        ror_m16_CL = 1494,

        /// <summary>
        /// ror m16, imm8 | C1 /1 ib | Rotate 16 bits r/m16 right imm8 times.
        /// </summary>
        [Symbol("ror m16, imm8","C1 /1 ib")]
        ror_m16_imm8 = 1495,

        /// <summary>
        /// ror m16, 1 | D1 /1 | Rotate 16 bits r/m16 right once.
        /// </summary>
        [Symbol("ror m16, 1","D1 /1")]
        ror_m16_n1 = 1496,

        /// <summary>
        /// ror m32, CL | D3 /1 | Rotate 32 bits r/m32 right CL times.
        /// </summary>
        [Symbol("ror m32, CL","D3 /1")]
        ror_m32_CL = 1497,

        /// <summary>
        /// ror m32, imm8 | C1 /1 ib | Rotate 32 bits r/m32 right imm8 times.
        /// </summary>
        [Symbol("ror m32, imm8","C1 /1 ib")]
        ror_m32_imm8 = 1498,

        /// <summary>
        /// ror m32, 1 | D1 /1 | Rotate 32 bits r/m32 right once.
        /// </summary>
        [Symbol("ror m32, 1","D1 /1")]
        ror_m32_n1 = 1499,

        /// <summary>
        /// ror m64, CL | REX.W + D3 /1 | Rotate 64 bits r/m64 right CL times. Uses a 6 bit count.
        /// </summary>
        [Symbol("ror m64, CL","REX.W + D3 /1")]
        ror_m64_CL = 1500,

        /// <summary>
        /// ror m64, imm8 | REX.W + C1 /1 ib | Rotate 64 bits r/m64 right imm8 times. Uses a 6 bit count.
        /// </summary>
        [Symbol("ror m64, imm8","REX.W + C1 /1 ib")]
        ror_m64_imm8 = 1501,

        /// <summary>
        /// ror m64, 1 | REX.W + D1 /1 | Rotate 64 bits r/m64 right once. Uses a 6 bit count.
        /// </summary>
        [Symbol("ror m64, 1","REX.W + D1 /1")]
        ror_m64_n1 = 1502,

        /// <summary>
        /// ror m8, CL | D2 /1 | Rotate 8 bits r/m8 right CL times.
        /// </summary>
        [Symbol("ror m8, CL","D2 /1")]
        ror_m8_CL = 1503,

        /// <summary>
        /// ror m8, CL | REX + D2 /1 | Rotate 8 bits r/m8 right CL times.
        /// </summary>
        [Symbol("ror m8, CL","REX + D2 /1")]
        ror_m8_CL_rex = 1504,

        /// <summary>
        /// ror m8, imm8 | C0 /1 ib | Rotate 8 bits r/m16 right imm8 times.
        /// </summary>
        [Symbol("ror m8, imm8","C0 /1 ib")]
        ror_m8_imm8 = 1505,

        /// <summary>
        /// ror m8, imm8 | REX + C0 /1 ib | Rotate 8 bits r/m16 right imm8 times.
        /// </summary>
        [Symbol("ror m8, imm8","REX + C0 /1 ib")]
        ror_m8_imm8_rex = 1506,

        /// <summary>
        /// ror m8, 1 | REX + D0 /1 | Rotate 8 bits r/m8 right once.
        /// </summary>
        [Symbol("ror m8, 1","REX + D0 /1")]
        ror_m8_n1 = 1507,

        /// <summary>
        /// ror m8, 1 | D0 /1 | Rotate 8 bits r/m8 right once.
        /// </summary>
        [Symbol("ror m8, 1","D0 /1")]
        ror_m8_n1_xD0 = 1508,

        /// <summary>
        /// ror r16, CL | D3 /1 | Rotate 16 bits r/m16 right CL times.
        /// </summary>
        [Symbol("ror r16, CL","D3 /1")]
        ror_r16_CL = 1509,

        /// <summary>
        /// ror r16, imm8 | C1 /1 ib | Rotate 16 bits r/m16 right imm8 times.
        /// </summary>
        [Symbol("ror r16, imm8","C1 /1 ib")]
        ror_r16_imm8 = 1510,

        /// <summary>
        /// ror r16, 1 | D1 /1 | Rotate 16 bits r/m16 right once.
        /// </summary>
        [Symbol("ror r16, 1","D1 /1")]
        ror_r16_n1 = 1511,

        /// <summary>
        /// ror r32, CL | D3 /1 | Rotate 32 bits r/m32 right CL times.
        /// </summary>
        [Symbol("ror r32, CL","D3 /1")]
        ror_r32_CL = 1512,

        /// <summary>
        /// ror r32, imm8 | C1 /1 ib | Rotate 32 bits r/m32 right imm8 times.
        /// </summary>
        [Symbol("ror r32, imm8","C1 /1 ib")]
        ror_r32_imm8 = 1513,

        /// <summary>
        /// ror r32, 1 | D1 /1 | Rotate 32 bits r/m32 right once.
        /// </summary>
        [Symbol("ror r32, 1","D1 /1")]
        ror_r32_n1 = 1514,

        /// <summary>
        /// ror r64, CL | REX.W + D3 /1 | Rotate 64 bits r/m64 right CL times. Uses a 6 bit count.
        /// </summary>
        [Symbol("ror r64, CL","REX.W + D3 /1")]
        ror_r64_CL = 1515,

        /// <summary>
        /// ror r64, imm8 | REX.W + C1 /1 ib | Rotate 64 bits r/m64 right imm8 times. Uses a 6 bit count.
        /// </summary>
        [Symbol("ror r64, imm8","REX.W + C1 /1 ib")]
        ror_r64_imm8 = 1516,

        /// <summary>
        /// ror r64, 1 | REX.W + D1 /1 | Rotate 64 bits r/m64 right once. Uses a 6 bit count.
        /// </summary>
        [Symbol("ror r64, 1","REX.W + D1 /1")]
        ror_r64_n1 = 1517,

        /// <summary>
        /// ror r8, CL | D2 /1 | Rotate 8 bits r/m8 right CL times.
        /// </summary>
        [Symbol("ror r8, CL","D2 /1")]
        ror_r8_CL = 1518,

        /// <summary>
        /// ror r8, CL | REX + D2 /1 | Rotate 8 bits r/m8 right CL times.
        /// </summary>
        [Symbol("ror r8, CL","REX + D2 /1")]
        ror_r8_CL_rex = 1519,

        /// <summary>
        /// ror r8, imm8 | C0 /1 ib | Rotate 8 bits r/m16 right imm8 times.
        /// </summary>
        [Symbol("ror r8, imm8","C0 /1 ib")]
        ror_r8_imm8 = 1520,

        /// <summary>
        /// ror r8, imm8 | REX + C0 /1 ib | Rotate 8 bits r/m16 right imm8 times.
        /// </summary>
        [Symbol("ror r8, imm8","REX + C0 /1 ib")]
        ror_r8_imm8_rex = 1521,

        /// <summary>
        /// ror r8, 1 | REX + D0 /1 | Rotate 8 bits r/m8 right once.
        /// </summary>
        [Symbol("ror r8, 1","REX + D0 /1")]
        ror_r8_n1 = 1522,

        /// <summary>
        /// ror r8, 1 | D0 /1 | Rotate 8 bits r/m8 right once.
        /// </summary>
        [Symbol("ror r8, 1","D0 /1")]
        ror_r8_n1_xD0 = 1523,

        /// <summary>
        /// sal m16, CL | D3 /4 | Multiply r/m16 by 2, CL times.
        /// </summary>
        [Symbol("sal m16, CL","D3 /4")]
        sal_m16_CL = 1524,

        /// <summary>
        /// sal m16, imm8 | C1 /4 ib | Multiply r/m16 by 2, imm8 times.
        /// </summary>
        [Symbol("sal m16, imm8","C1 /4 ib")]
        sal_m16_imm8 = 1525,

        /// <summary>
        /// sal m16, 1 | D1 /4 | Multiply r/m16 by 2, once.
        /// </summary>
        [Symbol("sal m16, 1","D1 /4")]
        sal_m16_n1 = 1526,

        /// <summary>
        /// sal m32, CL | D3 /4 | Multiply r/m32 by 2, CL times.
        /// </summary>
        [Symbol("sal m32, CL","D3 /4")]
        sal_m32_CL = 1527,

        /// <summary>
        /// sal m32, imm8 | C1 /4 ib | Multiply r/m32 by 2, imm8 times.
        /// </summary>
        [Symbol("sal m32, imm8","C1 /4 ib")]
        sal_m32_imm8 = 1528,

        /// <summary>
        /// sal m32, 1 | D1 /4 | Multiply r/m32 by 2, once.
        /// </summary>
        [Symbol("sal m32, 1","D1 /4")]
        sal_m32_n1 = 1529,

        /// <summary>
        /// sal m64, CL | REX.W + D3 /4 | Multiply r/m64 by 2, CL times.
        /// </summary>
        [Symbol("sal m64, CL","REX.W + D3 /4")]
        sal_m64_CL = 1530,

        /// <summary>
        /// sal m64, imm8 | REX.W + C1 /4 ib | Multiply r/m64 by 2, imm8 times.
        /// </summary>
        [Symbol("sal m64, imm8","REX.W + C1 /4 ib")]
        sal_m64_imm8 = 1531,

        /// <summary>
        /// sal m64, 1 | REX.W + D1 /4 | Multiply r/m64 by 2, once.
        /// </summary>
        [Symbol("sal m64, 1","REX.W + D1 /4")]
        sal_m64_n1 = 1532,

        /// <summary>
        /// sal m8, CL | REX + D2 /4 | Multiply r/m8 by 2, CL times.
        /// </summary>
        [Symbol("sal m8, CL","REX + D2 /4")]
        sal_m8_CL = 1533,

        /// <summary>
        /// sal m8, CL | D2 /4 | Multiply r/m8 by 2, CL times.
        /// </summary>
        [Symbol("sal m8, CL","D2 /4")]
        sal_m8_CL_xD2 = 1534,

        /// <summary>
        /// sal m8, imm8 | C0 /4 ib | Multiply r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("sal m8, imm8","C0 /4 ib")]
        sal_m8_imm8 = 1535,

        /// <summary>
        /// sal m8, imm8 | REX + C0 /4 ib | Multiply r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("sal m8, imm8","REX + C0 /4 ib")]
        sal_m8_imm8_rex = 1536,

        /// <summary>
        /// sal m8, 1 | REX + D0 /4 | Multiply r/m8 by 2, once.
        /// </summary>
        [Symbol("sal m8, 1","REX + D0 /4")]
        sal_m8_n1 = 1537,

        /// <summary>
        /// sal m8, 1 | D0 /4 | Multiply r/m8 by 2, once.
        /// </summary>
        [Symbol("sal m8, 1","D0 /4")]
        sal_m8_n1_xD0 = 1538,

        /// <summary>
        /// sal r16, CL | D3 /4 | Multiply r/m16 by 2, CL times.
        /// </summary>
        [Symbol("sal r16, CL","D3 /4")]
        sal_r16_CL = 1539,

        /// <summary>
        /// sal r16, imm8 | C1 /4 ib | Multiply r/m16 by 2, imm8 times.
        /// </summary>
        [Symbol("sal r16, imm8","C1 /4 ib")]
        sal_r16_imm8 = 1540,

        /// <summary>
        /// sal r16, 1 | D1 /4 | Multiply r/m16 by 2, once.
        /// </summary>
        [Symbol("sal r16, 1","D1 /4")]
        sal_r16_n1 = 1541,

        /// <summary>
        /// sal r32, CL | D3 /4 | Multiply r/m32 by 2, CL times.
        /// </summary>
        [Symbol("sal r32, CL","D3 /4")]
        sal_r32_CL = 1542,

        /// <summary>
        /// sal r32, imm8 | C1 /4 ib | Multiply r/m32 by 2, imm8 times.
        /// </summary>
        [Symbol("sal r32, imm8","C1 /4 ib")]
        sal_r32_imm8 = 1543,

        /// <summary>
        /// sal r32, 1 | D1 /4 | Multiply r/m32 by 2, once.
        /// </summary>
        [Symbol("sal r32, 1","D1 /4")]
        sal_r32_n1 = 1544,

        /// <summary>
        /// sal r64, CL | REX.W + D3 /4 | Multiply r/m64 by 2, CL times.
        /// </summary>
        [Symbol("sal r64, CL","REX.W + D3 /4")]
        sal_r64_CL = 1545,

        /// <summary>
        /// sal r64, imm8 | REX.W + C1 /4 ib | Multiply r/m64 by 2, imm8 times.
        /// </summary>
        [Symbol("sal r64, imm8","REX.W + C1 /4 ib")]
        sal_r64_imm8 = 1546,

        /// <summary>
        /// sal r64, 1 | REX.W + D1 /4 | Multiply r/m64 by 2, once.
        /// </summary>
        [Symbol("sal r64, 1","REX.W + D1 /4")]
        sal_r64_n1 = 1547,

        /// <summary>
        /// sal r8, CL | REX + D2 /4 | Multiply r/m8 by 2, CL times.
        /// </summary>
        [Symbol("sal r8, CL","REX + D2 /4")]
        sal_r8_CL = 1548,

        /// <summary>
        /// sal r8, CL | D2 /4 | Multiply r/m8 by 2, CL times.
        /// </summary>
        [Symbol("sal r8, CL","D2 /4")]
        sal_r8_CL_xD2 = 1549,

        /// <summary>
        /// sal r8, imm8 | C0 /4 ib | Multiply r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("sal r8, imm8","C0 /4 ib")]
        sal_r8_imm8 = 1550,

        /// <summary>
        /// sal r8, imm8 | REX + C0 /4 ib | Multiply r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("sal r8, imm8","REX + C0 /4 ib")]
        sal_r8_imm8_rex = 1551,

        /// <summary>
        /// sal r8, 1 | REX + D0 /4 | Multiply r/m8 by 2, once.
        /// </summary>
        [Symbol("sal r8, 1","REX + D0 /4")]
        sal_r8_n1 = 1552,

        /// <summary>
        /// sal r8, 1 | D0 /4 | Multiply r/m8 by 2, once.
        /// </summary>
        [Symbol("sal r8, 1","D0 /4")]
        sal_r8_n1_xD0 = 1553,

        /// <summary>
        /// sar m16, CL | D3 /7 | Signed divide r/m16 by 2, CL times.
        /// </summary>
        [Symbol("sar m16, CL","D3 /7")]
        sar_m16_CL = 1554,

        /// <summary>
        /// sar m16, imm8 | C1 /7 ib | Signed divide r/m16 by 2, imm8 times.
        /// </summary>
        [Symbol("sar m16, imm8","C1 /7 ib")]
        sar_m16_imm8 = 1555,

        /// <summary>
        /// sar m16, 1 | D1 /7 | Signed divide r/m16 by 2, once.
        /// </summary>
        [Symbol("sar m16, 1","D1 /7")]
        sar_m16_n1 = 1556,

        /// <summary>
        /// sar m32, CL | D3 /7 | Signed divide r/m32 by 2, CL times.
        /// </summary>
        [Symbol("sar m32, CL","D3 /7")]
        sar_m32_CL = 1557,

        /// <summary>
        /// sar m32, imm8 | C1 /7 ib | Signed divide r/m32 by 2, imm8 times.
        /// </summary>
        [Symbol("sar m32, imm8","C1 /7 ib")]
        sar_m32_imm8 = 1558,

        /// <summary>
        /// sar m32, 1 | D1 /7 | Signed divide r/m32 by 2, once.
        /// </summary>
        [Symbol("sar m32, 1","D1 /7")]
        sar_m32_n1 = 1559,

        /// <summary>
        /// sar m64, CL | REX.W + D3 /7 | Signed divide r/m64 by 2, CL times.
        /// </summary>
        [Symbol("sar m64, CL","REX.W + D3 /7")]
        sar_m64_CL = 1560,

        /// <summary>
        /// sar m64, imm8 | REX.W + C1 /7 ib | Signed divide r/m64 by 2, imm8 times
        /// </summary>
        [Symbol("sar m64, imm8","REX.W + C1 /7 ib")]
        sar_m64_imm8 = 1561,

        /// <summary>
        /// sar m64, 1 | REX.W + D1 /7 | Signed divide r/m64 by 2, once.
        /// </summary>
        [Symbol("sar m64, 1","REX.W + D1 /7")]
        sar_m64_n1 = 1562,

        /// <summary>
        /// sar m8, CL | D2 /7 | Signed divide r/m8 by 2, CL times.
        /// </summary>
        [Symbol("sar m8, CL","D2 /7")]
        sar_m8_CL = 1563,

        /// <summary>
        /// sar m8, CL | REX + D2 /7 | Signed divide r/m8 by 2, CL times.
        /// </summary>
        [Symbol("sar m8, CL","REX + D2 /7")]
        sar_m8_CL_rex = 1564,

        /// <summary>
        /// sar m8, imm8 | C0 /7 ib | Signed divide r/m8 by 2, imm8 time.
        /// </summary>
        [Symbol("sar m8, imm8","C0 /7 ib")]
        sar_m8_imm8 = 1565,

        /// <summary>
        /// sar m8, imm8 | REX + C0 /7 ib | Signed divide r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("sar m8, imm8","REX + C0 /7 ib")]
        sar_m8_imm8_rex = 1566,

        /// <summary>
        /// sar m8, 1 | REX + D0 /7 | Signed divide r/m8 by 2, once.
        /// </summary>
        [Symbol("sar m8, 1","REX + D0 /7")]
        sar_m8_n1 = 1567,

        /// <summary>
        /// sar m8, 1 | D0 /7 | Signed divide r/m8 by 2, once.
        /// </summary>
        [Symbol("sar m8, 1","D0 /7")]
        sar_m8_n1_xD0 = 1568,

        /// <summary>
        /// sar r16, CL | D3 /7 | Signed divide r/m16 by 2, CL times.
        /// </summary>
        [Symbol("sar r16, CL","D3 /7")]
        sar_r16_CL = 1569,

        /// <summary>
        /// sar r16, imm8 | C1 /7 ib | Signed divide r/m16 by 2, imm8 times.
        /// </summary>
        [Symbol("sar r16, imm8","C1 /7 ib")]
        sar_r16_imm8 = 1570,

        /// <summary>
        /// sar r16, 1 | D1 /7 | Signed divide r/m16 by 2, once.
        /// </summary>
        [Symbol("sar r16, 1","D1 /7")]
        sar_r16_n1 = 1571,

        /// <summary>
        /// sar r32, CL | D3 /7 | Signed divide r/m32 by 2, CL times.
        /// </summary>
        [Symbol("sar r32, CL","D3 /7")]
        sar_r32_CL = 1572,

        /// <summary>
        /// sar r32, imm8 | C1 /7 ib | Signed divide r/m32 by 2, imm8 times.
        /// </summary>
        [Symbol("sar r32, imm8","C1 /7 ib")]
        sar_r32_imm8 = 1573,

        /// <summary>
        /// sar r32, 1 | D1 /7 | Signed divide r/m32 by 2, once.
        /// </summary>
        [Symbol("sar r32, 1","D1 /7")]
        sar_r32_n1 = 1574,

        /// <summary>
        /// sar r64, CL | REX.W + D3 /7 | Signed divide r/m64 by 2, CL times.
        /// </summary>
        [Symbol("sar r64, CL","REX.W + D3 /7")]
        sar_r64_CL = 1575,

        /// <summary>
        /// sar r64, imm8 | REX.W + C1 /7 ib | Signed divide r/m64 by 2, imm8 times
        /// </summary>
        [Symbol("sar r64, imm8","REX.W + C1 /7 ib")]
        sar_r64_imm8 = 1576,

        /// <summary>
        /// sar r64, 1 | REX.W + D1 /7 | Signed divide r/m64 by 2, once.
        /// </summary>
        [Symbol("sar r64, 1","REX.W + D1 /7")]
        sar_r64_n1 = 1577,

        /// <summary>
        /// sar r8, CL | D2 /7 | Signed divide r/m8 by 2, CL times.
        /// </summary>
        [Symbol("sar r8, CL","D2 /7")]
        sar_r8_CL = 1578,

        /// <summary>
        /// sar r8, CL | REX + D2 /7 | Signed divide r/m8 by 2, CL times.
        /// </summary>
        [Symbol("sar r8, CL","REX + D2 /7")]
        sar_r8_CL_rex = 1579,

        /// <summary>
        /// sar r8, imm8 | C0 /7 ib | Signed divide r/m8 by 2, imm8 time.
        /// </summary>
        [Symbol("sar r8, imm8","C0 /7 ib")]
        sar_r8_imm8 = 1580,

        /// <summary>
        /// sar r8, imm8 | REX + C0 /7 ib | Signed divide r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("sar r8, imm8","REX + C0 /7 ib")]
        sar_r8_imm8_rex = 1581,

        /// <summary>
        /// sar r8, 1 | REX + D0 /7 | Signed divide r/m8 by 2, once.
        /// </summary>
        [Symbol("sar r8, 1","REX + D0 /7")]
        sar_r8_n1 = 1582,

        /// <summary>
        /// sar r8, 1 | D0 /7 | Signed divide r/m8 by 2, once.
        /// </summary>
        [Symbol("sar r8, 1","D0 /7")]
        sar_r8_n1_xD0 = 1583,

        /// <summary>
        /// sarx r32, m32, r32 | VEX.LZ.F3.0F38.W0 F7 /r | Shift r/m32 arithmetically right with count specified in r32b.
        /// </summary>
        [Symbol("sarx r32, m32, r32","VEX.LZ.F3.0F38.W0 F7 /r")]
        sarx_r32_m32_r32 = 1584,

        /// <summary>
        /// sarx r32, r32, r32 | VEX.LZ.F3.0F38.W0 F7 /r | Shift r/m32 arithmetically right with count specified in r32b.
        /// </summary>
        [Symbol("sarx r32, r32, r32","VEX.LZ.F3.0F38.W0 F7 /r")]
        sarx_r32_r32_r32 = 1585,

        /// <summary>
        /// sarx r64, m64, r64 | VEX.LZ.F3.0F38.W1 F7 /r | Shift r/m64 arithmetically right with count specified in r64b.
        /// </summary>
        [Symbol("sarx r64, m64, r64","VEX.LZ.F3.0F38.W1 F7 /r")]
        sarx_r64_m64_r64 = 1586,

        /// <summary>
        /// sarx r64, r64, r64 | VEX.LZ.F3.0F38.W1 F7 /r | Shift r/m64 arithmetically right with count specified in r64b.
        /// </summary>
        [Symbol("sarx r64, r64, r64","VEX.LZ.F3.0F38.W1 F7 /r")]
        sarx_r64_r64_r64 = 1587,

        /// <summary>
        /// sbb AL, imm8 | 1C ib | Subtract with borrow imm8 from AL.
        /// </summary>
        [Symbol("sbb AL, imm8","1C ib")]
        sbb_AL_imm8 = 1588,

        /// <summary>
        /// sbb AX, imm16 | 1D iw | Subtract with borrow imm16 from AX.
        /// </summary>
        [Symbol("sbb AX, imm16","1D iw")]
        sbb_AX_imm16 = 1589,

        /// <summary>
        /// sbb EAX, imm32 | 1D id | Subtract with borrow imm32 from EAX.
        /// </summary>
        [Symbol("sbb EAX, imm32","1D id")]
        sbb_EAX_imm32 = 1590,

        /// <summary>
        /// sbb m16, imm16 | 81 /3 iw | Subtract with borrow imm16 from r/m16.
        /// </summary>
        [Symbol("sbb m16, imm16","81 /3 iw")]
        sbb_m16_imm16 = 1591,

        /// <summary>
        /// sbb m16, imm8 | 83 /3 ib | Subtract with borrow sign-extended imm8 from r/m16.
        /// </summary>
        [Symbol("sbb m16, imm8","83 /3 ib")]
        sbb_m16_imm8 = 1592,

        /// <summary>
        /// sbb m16, r16 | 19 /r | Subtract with borrow r16 from r/m16.
        /// </summary>
        [Symbol("sbb m16, r16","19 /r")]
        sbb_m16_r16 = 1593,

        /// <summary>
        /// sbb m32, imm32 | 81 /3 id | Subtract with borrow imm32 from r/m32.
        /// </summary>
        [Symbol("sbb m32, imm32","81 /3 id")]
        sbb_m32_imm32 = 1594,

        /// <summary>
        /// sbb m32, imm8 | 83 /3 ib | Subtract with borrow sign-extended imm8 from r/m32.
        /// </summary>
        [Symbol("sbb m32, imm8","83 /3 ib")]
        sbb_m32_imm8 = 1595,

        /// <summary>
        /// sbb m32, r32 | 19 /r | Subtract with borrow r32 from r/m32.
        /// </summary>
        [Symbol("sbb m32, r32","19 /r")]
        sbb_m32_r32 = 1596,

        /// <summary>
        /// sbb m64, imm32 | REX.W + 81 /3 id | Subtract with borrow sign-extended imm32 to 64-bits from r/m64.
        /// </summary>
        [Symbol("sbb m64, imm32","REX.W + 81 /3 id")]
        sbb_m64_imm32 = 1597,

        /// <summary>
        /// sbb m64, imm8 | REX.W + 83 /3 ib | Subtract with borrow sign-extended imm8 from r/m64.
        /// </summary>
        [Symbol("sbb m64, imm8","REX.W + 83 /3 ib")]
        sbb_m64_imm8 = 1598,

        /// <summary>
        /// sbb m64, r64 | REX.W + 19 /r | Subtract with borrow r64 from r/m64.
        /// </summary>
        [Symbol("sbb m64, r64","REX.W + 19 /r")]
        sbb_m64_r64 = 1599,

        /// <summary>
        /// sbb m8, imm8 | 80 /3 ib | Subtract with borrow imm8 from r/m8.
        /// </summary>
        [Symbol("sbb m8, imm8","80 /3 ib")]
        sbb_m8_imm8 = 1600,

        /// <summary>
        /// sbb m8, imm8 | REX + 80 /3 ib | Subtract with borrow imm8 from r/m8.
        /// </summary>
        [Symbol("sbb m8, imm8","REX + 80 /3 ib")]
        sbb_m8_imm8_rex = 1601,

        /// <summary>
        /// sbb m8, r8 | 18 /r | Subtract with borrow r8 from r/m8.
        /// </summary>
        [Symbol("sbb m8, r8","18 /r")]
        sbb_m8_r8 = 1602,

        /// <summary>
        /// sbb m8, r8 | REX + 18 /r | Subtract with borrow r8 from r/m8.
        /// </summary>
        [Symbol("sbb m8, r8","REX + 18 /r")]
        sbb_m8_r8_rex = 1603,

        /// <summary>
        /// sbb r16, imm16 | 81 /3 iw | Subtract with borrow imm16 from r/m16.
        /// </summary>
        [Symbol("sbb r16, imm16","81 /3 iw")]
        sbb_r16_imm16 = 1604,

        /// <summary>
        /// sbb r16, imm8 | 83 /3 ib | Subtract with borrow sign-extended imm8 from r/m16.
        /// </summary>
        [Symbol("sbb r16, imm8","83 /3 ib")]
        sbb_r16_imm8 = 1605,

        /// <summary>
        /// sbb r16, m16 | 1B /r | Subtract with borrow r/m16 from r16.
        /// </summary>
        [Symbol("sbb r16, m16","1B /r")]
        sbb_r16_m16 = 1606,

        /// <summary>
        /// sbb r16, r16 | 19 /r | Subtract with borrow r16 from r/m16.
        /// </summary>
        [Symbol("sbb r16, r16","19 /r")]
        sbb_r16_r16 = 1607,

        /// <summary>
        /// sbb r16, r16 | 1B /r | Subtract with borrow r/m16 from r16.
        /// </summary>
        [Symbol("sbb r16, r16","1B /r")]
        sbb_r16_r16_x1B = 1608,

        /// <summary>
        /// sbb r32, imm32 | 81 /3 id | Subtract with borrow imm32 from r/m32.
        /// </summary>
        [Symbol("sbb r32, imm32","81 /3 id")]
        sbb_r32_imm32 = 1609,

        /// <summary>
        /// sbb r32, imm8 | 83 /3 ib | Subtract with borrow sign-extended imm8 from r/m32.
        /// </summary>
        [Symbol("sbb r32, imm8","83 /3 ib")]
        sbb_r32_imm8 = 1610,

        /// <summary>
        /// sbb r32, m32 | 1B /r | Subtract with borrow r/m32 from r32.
        /// </summary>
        [Symbol("sbb r32, m32","1B /r")]
        sbb_r32_m32 = 1611,

        /// <summary>
        /// sbb r32, r32 | 19 /r | Subtract with borrow r32 from r/m32.
        /// </summary>
        [Symbol("sbb r32, r32","19 /r")]
        sbb_r32_r32 = 1612,

        /// <summary>
        /// sbb r32, r32 | 1B /r | Subtract with borrow r/m32 from r32.
        /// </summary>
        [Symbol("sbb r32, r32","1B /r")]
        sbb_r32_r32_x1B = 1613,

        /// <summary>
        /// sbb r64, imm32 | REX.W + 81 /3 id | Subtract with borrow sign-extended imm32 to 64-bits from r/m64.
        /// </summary>
        [Symbol("sbb r64, imm32","REX.W + 81 /3 id")]
        sbb_r64_imm32 = 1614,

        /// <summary>
        /// sbb r64, imm8 | REX.W + 83 /3 ib | Subtract with borrow sign-extended imm8 from r/m64.
        /// </summary>
        [Symbol("sbb r64, imm8","REX.W + 83 /3 ib")]
        sbb_r64_imm8 = 1615,

        /// <summary>
        /// sbb r64, m64 | REX.W + 1B /r | Subtract with borrow r/m64 from r64.
        /// </summary>
        [Symbol("sbb r64, m64","REX.W + 1B /r")]
        sbb_r64_m64 = 1616,

        /// <summary>
        /// sbb r64, r64 | REX.W + 19 /r | Subtract with borrow r64 from r/m64.
        /// </summary>
        [Symbol("sbb r64, r64","REX.W + 19 /r")]
        sbb_r64_r64 = 1617,

        /// <summary>
        /// sbb r64, r64 | REX.W + 1B /r | Subtract with borrow r/m64 from r64.
        /// </summary>
        [Symbol("sbb r64, r64","REX.W + 1B /r")]
        sbb_r64_r64_x1B = 1618,

        /// <summary>
        /// sbb r8, imm8 | 80 /3 ib | Subtract with borrow imm8 from r/m8.
        /// </summary>
        [Symbol("sbb r8, imm8","80 /3 ib")]
        sbb_r8_imm8 = 1619,

        /// <summary>
        /// sbb r8, imm8 | REX + 80 /3 ib | Subtract with borrow imm8 from r/m8.
        /// </summary>
        [Symbol("sbb r8, imm8","REX + 80 /3 ib")]
        sbb_r8_imm8_rex = 1620,

        /// <summary>
        /// sbb r8, m8 | 1A /r | Subtract with borrow r/m8 from r8.
        /// </summary>
        [Symbol("sbb r8, m8","1A /r")]
        sbb_r8_m8 = 1621,

        /// <summary>
        /// sbb r8, m8 | REX + 1A /r | Subtract with borrow r/m8 from r8.
        /// </summary>
        [Symbol("sbb r8, m8","REX + 1A /r")]
        sbb_r8_m8_rex = 1622,

        /// <summary>
        /// sbb r8, r8 | 18 /r | Subtract with borrow r8 from r/m8.
        /// </summary>
        [Symbol("sbb r8, r8","18 /r")]
        sbb_r8_r8 = 1623,

        /// <summary>
        /// sbb r8, r8 | REX + 18 /r | Subtract with borrow r8 from r/m8.
        /// </summary>
        [Symbol("sbb r8, r8","REX + 18 /r")]
        sbb_r8_r8_rex = 1624,

        /// <summary>
        /// sbb r8, r8 | 1A /r | Subtract with borrow r/m8 from r8.
        /// </summary>
        [Symbol("sbb r8, r8","1A /r")]
        sbb_r8_r8_x1A = 1625,

        /// <summary>
        /// sbb RAX, imm32 | REX.W + 1D id | Subtract with borrow sign-extended imm.32 to 64-bits from RAX.
        /// </summary>
        [Symbol("sbb RAX, imm32","REX.W + 1D id")]
        sbb_RAX_imm32 = 1626,

        /// <summary>
        /// seta m8 | 0F 97 | Set byte if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("seta m8","0F 97")]
        seta_m8 = 1627,

        /// <summary>
        /// seta m8 | REX + 0F 97 | Set byte if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("seta m8","REX + 0F 97")]
        seta_m8_rex = 1628,

        /// <summary>
        /// seta r8 | 0F 97 | Set byte if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("seta r8","0F 97")]
        seta_r8 = 1629,

        /// <summary>
        /// seta r8 | REX + 0F 97 | Set byte if above (CF=0 and ZF=0).
        /// </summary>
        [Symbol("seta r8","REX + 0F 97")]
        seta_r8_rex = 1630,

        /// <summary>
        /// setae m8 | 0F 93 | Set byte if above or equal (CF=0).
        /// </summary>
        [Symbol("setae m8","0F 93")]
        setae_m8 = 1631,

        /// <summary>
        /// setae m8 | REX + 0F 93 | Set byte if above or equal (CF=0).
        /// </summary>
        [Symbol("setae m8","REX + 0F 93")]
        setae_m8_rex = 1632,

        /// <summary>
        /// setae r8 | 0F 93 | Set byte if above or equal (CF=0).
        /// </summary>
        [Symbol("setae r8","0F 93")]
        setae_r8 = 1633,

        /// <summary>
        /// setae r8 | REX + 0F 93 | Set byte if above or equal (CF=0).
        /// </summary>
        [Symbol("setae r8","REX + 0F 93")]
        setae_r8_rex = 1634,

        /// <summary>
        /// setb m8 | 0F 92 | Set byte if below (CF=1).
        /// </summary>
        [Symbol("setb m8","0F 92")]
        setb_m8 = 1635,

        /// <summary>
        /// setb m8 | REX + 0F 92 | Set byte if below (CF=1).
        /// </summary>
        [Symbol("setb m8","REX + 0F 92")]
        setb_m8_rex = 1636,

        /// <summary>
        /// setb r8 | 0F 92 | Set byte if below (CF=1).
        /// </summary>
        [Symbol("setb r8","0F 92")]
        setb_r8 = 1637,

        /// <summary>
        /// setb r8 | REX + 0F 92 | Set byte if below (CF=1).
        /// </summary>
        [Symbol("setb r8","REX + 0F 92")]
        setb_r8_rex = 1638,

        /// <summary>
        /// setbe m8 | 0F 96 | Set byte if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("setbe m8","0F 96")]
        setbe_m8 = 1639,

        /// <summary>
        /// setbe m8 | REX + 0F 96 | Set byte if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("setbe m8","REX + 0F 96")]
        setbe_m8_rex = 1640,

        /// <summary>
        /// setbe r8 | 0F 96 | Set byte if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("setbe r8","0F 96")]
        setbe_r8 = 1641,

        /// <summary>
        /// setbe r8 | REX + 0F 96 | Set byte if below or equal (CF=1 or ZF=1).
        /// </summary>
        [Symbol("setbe r8","REX + 0F 96")]
        setbe_r8_rex = 1642,

        /// <summary>
        /// setc m8 | 0F 92 | Set byte if carry (CF=1).
        /// </summary>
        [Symbol("setc m8","0F 92")]
        setc_m8 = 1643,

        /// <summary>
        /// setc m8 | REX + 0F 92 | Set byte if carry (CF=1).
        /// </summary>
        [Symbol("setc m8","REX + 0F 92")]
        setc_m8_rex = 1644,

        /// <summary>
        /// setc r8 | 0F 92 | Set byte if carry (CF=1).
        /// </summary>
        [Symbol("setc r8","0F 92")]
        setc_r8 = 1645,

        /// <summary>
        /// setc r8 | REX + 0F 92 | Set byte if carry (CF=1).
        /// </summary>
        [Symbol("setc r8","REX + 0F 92")]
        setc_r8_rex = 1646,

        /// <summary>
        /// sete m8 | 0F 94 | Set byte if equal (ZF=1).
        /// </summary>
        [Symbol("sete m8","0F 94")]
        sete_m8 = 1647,

        /// <summary>
        /// sete m8 | REX + 0F 94 | Set byte if equal (ZF=1).
        /// </summary>
        [Symbol("sete m8","REX + 0F 94")]
        sete_m8_rex = 1648,

        /// <summary>
        /// sete r8 | 0F 94 | Set byte if equal (ZF=1).
        /// </summary>
        [Symbol("sete r8","0F 94")]
        sete_r8 = 1649,

        /// <summary>
        /// sete r8 | REX + 0F 94 | Set byte if equal (ZF=1).
        /// </summary>
        [Symbol("sete r8","REX + 0F 94")]
        sete_r8_rex = 1650,

        /// <summary>
        /// setg m8 | 0F 9F | Set byte if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("setg m8","0F 9F")]
        setg_m8 = 1651,

        /// <summary>
        /// setg m8 | REX + 0F 9F | Set byte if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("setg m8","REX + 0F 9F")]
        setg_m8_rex = 1652,

        /// <summary>
        /// setg r8 | 0F 9F | Set byte if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("setg r8","0F 9F")]
        setg_r8 = 1653,

        /// <summary>
        /// setg r8 | REX + 0F 9F | Set byte if greater (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("setg r8","REX + 0F 9F")]
        setg_r8_rex = 1654,

        /// <summary>
        /// setge m8 | 0F 9D | Set byte if greater or equal (SF=OF).
        /// </summary>
        [Symbol("setge m8","0F 9D")]
        setge_m8 = 1655,

        /// <summary>
        /// setge m8 | REX + 0F 9D | Set byte if greater or equal (SF=OF).
        /// </summary>
        [Symbol("setge m8","REX + 0F 9D")]
        setge_m8_rex = 1656,

        /// <summary>
        /// setge r8 | 0F 9D | Set byte if greater or equal (SF=OF).
        /// </summary>
        [Symbol("setge r8","0F 9D")]
        setge_r8 = 1657,

        /// <summary>
        /// setge r8 | REX + 0F 9D | Set byte if greater or equal (SF=OF).
        /// </summary>
        [Symbol("setge r8","REX + 0F 9D")]
        setge_r8_rex = 1658,

        /// <summary>
        /// setl m8 | REX + 0F 9C | Set byte if less (SF != OF).
        /// </summary>
        [Symbol("setl m8","REX + 0F 9C")]
        setl_m8 = 1659,

        /// <summary>
        /// setl m8 | 0F 9C | Set byte if less (SF != OF).
        /// </summary>
        [Symbol("setl m8","0F 9C")]
        setl_m8_x0F = 1660,

        /// <summary>
        /// setl r8 | REX + 0F 9C | Set byte if less (SF != OF).
        /// </summary>
        [Symbol("setl r8","REX + 0F 9C")]
        setl_r8 = 1661,

        /// <summary>
        /// setl r8 | 0F 9C | Set byte if less (SF != OF).
        /// </summary>
        [Symbol("setl r8","0F 9C")]
        setl_r8_x0F = 1662,

        /// <summary>
        /// setle m8 | REX + 0F 9E | Set byte if less or equal (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("setle m8","REX + 0F 9E")]
        setle_m8 = 1663,

        /// <summary>
        /// setle m8 | 0F 9E | Set byte if less or equal (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("setle m8","0F 9E")]
        setle_m8_x0F = 1664,

        /// <summary>
        /// setle r8 | REX + 0F 9E | Set byte if less or equal (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("setle r8","REX + 0F 9E")]
        setle_r8 = 1665,

        /// <summary>
        /// setle r8 | 0F 9E | Set byte if less or equal (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("setle r8","0F 9E")]
        setle_r8_x0F = 1666,

        /// <summary>
        /// setna m8 | 0F 96 | Set byte if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("setna m8","0F 96")]
        setna_m8 = 1667,

        /// <summary>
        /// setna m8 | REX + 0F 96 | Set byte if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("setna m8","REX + 0F 96")]
        setna_m8_rex = 1668,

        /// <summary>
        /// setna r8 | 0F 96 | Set byte if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("setna r8","0F 96")]
        setna_r8 = 1669,

        /// <summary>
        /// setna r8 | REX + 0F 96 | Set byte if not above (CF=1 or ZF=1).
        /// </summary>
        [Symbol("setna r8","REX + 0F 96")]
        setna_r8_rex = 1670,

        /// <summary>
        /// setnae m8 | 0F 92 | Set byte if not above or equal (CF=1).
        /// </summary>
        [Symbol("setnae m8","0F 92")]
        setnae_m8 = 1671,

        /// <summary>
        /// setnae m8 | REX + 0F 92 | Set byte if not above or equal (CF=1).
        /// </summary>
        [Symbol("setnae m8","REX + 0F 92")]
        setnae_m8_rex = 1672,

        /// <summary>
        /// setnae r8 | 0F 92 | Set byte if not above or equal (CF=1).
        /// </summary>
        [Symbol("setnae r8","0F 92")]
        setnae_r8 = 1673,

        /// <summary>
        /// setnae r8 | REX + 0F 92 | Set byte if not above or equal (CF=1).
        /// </summary>
        [Symbol("setnae r8","REX + 0F 92")]
        setnae_r8_rex = 1674,

        /// <summary>
        /// setnb m8 | REX + 0F 93 | Set byte if not below (CF=0).
        /// </summary>
        [Symbol("setnb m8","REX + 0F 93")]
        setnb_m8 = 1675,

        /// <summary>
        /// setnb m8 | 0F 93 | Set byte if not below (CF=0).
        /// </summary>
        [Symbol("setnb m8","0F 93")]
        setnb_m8_x0F = 1676,

        /// <summary>
        /// setnb r8 | REX + 0F 93 | Set byte if not below (CF=0).
        /// </summary>
        [Symbol("setnb r8","REX + 0F 93")]
        setnb_r8 = 1677,

        /// <summary>
        /// setnb r8 | 0F 93 | Set byte if not below (CF=0).
        /// </summary>
        [Symbol("setnb r8","0F 93")]
        setnb_r8_x0F = 1678,

        /// <summary>
        /// setnbe m8 | REX + 0F 97 | Set byte if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("setnbe m8","REX + 0F 97")]
        setnbe_m8 = 1679,

        /// <summary>
        /// setnbe m8 | 0F 97 | Set byte if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("setnbe m8","0F 97")]
        setnbe_m8_x0F = 1680,

        /// <summary>
        /// setnbe r8 | REX + 0F 97 | Set byte if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("setnbe r8","REX + 0F 97")]
        setnbe_r8 = 1681,

        /// <summary>
        /// setnbe r8 | 0F 97 | Set byte if not below or equal (CF=0 and ZF=0).
        /// </summary>
        [Symbol("setnbe r8","0F 97")]
        setnbe_r8_x0F = 1682,

        /// <summary>
        /// setnc m8 | REX + 0F 93 | Set byte if not carry (CF=0).
        /// </summary>
        [Symbol("setnc m8","REX + 0F 93")]
        setnc_m8 = 1683,

        /// <summary>
        /// setnc m8 | 0F 93 | Set byte if not carry (CF=0).
        /// </summary>
        [Symbol("setnc m8","0F 93")]
        setnc_m8_x0F = 1684,

        /// <summary>
        /// setnc r8 | REX + 0F 93 | Set byte if not carry (CF=0).
        /// </summary>
        [Symbol("setnc r8","REX + 0F 93")]
        setnc_r8 = 1685,

        /// <summary>
        /// setnc r8 | 0F 93 | Set byte if not carry (CF=0).
        /// </summary>
        [Symbol("setnc r8","0F 93")]
        setnc_r8_x0F = 1686,

        /// <summary>
        /// setne m8 | REX + 0F 95 | Set byte if not equal (ZF=0).
        /// </summary>
        [Symbol("setne m8","REX + 0F 95")]
        setne_m8 = 1687,

        /// <summary>
        /// setne m8 | 0F 95 | Set byte if not equal (ZF=0).
        /// </summary>
        [Symbol("setne m8","0F 95")]
        setne_m8_x0F = 1688,

        /// <summary>
        /// setne r8 | REX + 0F 95 | Set byte if not equal (ZF=0).
        /// </summary>
        [Symbol("setne r8","REX + 0F 95")]
        setne_r8 = 1689,

        /// <summary>
        /// setne r8 | 0F 95 | Set byte if not equal (ZF=0).
        /// </summary>
        [Symbol("setne r8","0F 95")]
        setne_r8_x0F = 1690,

        /// <summary>
        /// setng m8 | REX + 0F 9E | Set byte if not greater (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("setng m8","REX + 0F 9E")]
        setng_m8 = 1691,

        /// <summary>
        /// setng m8 | 0F 9E | Set byte if not greater (ZF=1 or SF != OF)
        /// </summary>
        [Symbol("setng m8","0F 9E")]
        setng_m8_x0F = 1692,

        /// <summary>
        /// setng r8 | REX + 0F 9E | Set byte if not greater (ZF=1 or SF != OF).
        /// </summary>
        [Symbol("setng r8","REX + 0F 9E")]
        setng_r8 = 1693,

        /// <summary>
        /// setng r8 | 0F 9E | Set byte if not greater (ZF=1 or SF != OF)
        /// </summary>
        [Symbol("setng r8","0F 9E")]
        setng_r8_x0F = 1694,

        /// <summary>
        /// setnge m8 | REX + 0F 9C | Set byte if not greater or equal (SF != OF).
        /// </summary>
        [Symbol("setnge m8","REX + 0F 9C")]
        setnge_m8 = 1695,

        /// <summary>
        /// setnge m8 | 0F 9C | Set byte if not greater or equal (SF != OF).
        /// </summary>
        [Symbol("setnge m8","0F 9C")]
        setnge_m8_x0F = 1696,

        /// <summary>
        /// setnge r8 | REX + 0F 9C | Set byte if not greater or equal (SF != OF).
        /// </summary>
        [Symbol("setnge r8","REX + 0F 9C")]
        setnge_r8 = 1697,

        /// <summary>
        /// setnge r8 | 0F 9C | Set byte if not greater or equal (SF != OF).
        /// </summary>
        [Symbol("setnge r8","0F 9C")]
        setnge_r8_x0F = 1698,

        /// <summary>
        /// setnl m8 | REX + 0F 9D | Set byte if not less (SF=OF).
        /// </summary>
        [Symbol("setnl m8","REX + 0F 9D")]
        setnl_m8 = 1699,

        /// <summary>
        /// setnl m8 | 0F 9D | Set byte if not less (SF=OF).
        /// </summary>
        [Symbol("setnl m8","0F 9D")]
        setnl_m8_x0F = 1700,

        /// <summary>
        /// setnl r8 | REX + 0F 9D | Set byte if not less (SF=OF).
        /// </summary>
        [Symbol("setnl r8","REX + 0F 9D")]
        setnl_r8 = 1701,

        /// <summary>
        /// setnl r8 | 0F 9D | Set byte if not less (SF=OF).
        /// </summary>
        [Symbol("setnl r8","0F 9D")]
        setnl_r8_x0F = 1702,

        /// <summary>
        /// setnle m8 | 0F 9F | Set byte if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("setnle m8","0F 9F")]
        setnle_m8 = 1703,

        /// <summary>
        /// setnle m8 | REX + 0F 9F | Set byte if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("setnle m8","REX + 0F 9F")]
        setnle_m8_rex = 1704,

        /// <summary>
        /// setnle r8 | 0F 9F | Set byte if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("setnle r8","0F 9F")]
        setnle_r8 = 1705,

        /// <summary>
        /// setnle r8 | REX + 0F 9F | Set byte if not less or equal (ZF=0 and SF=OF).
        /// </summary>
        [Symbol("setnle r8","REX + 0F 9F")]
        setnle_r8_rex = 1706,

        /// <summary>
        /// setno m8 | 0F 91 | Set byte if not overflow (OF=0).
        /// </summary>
        [Symbol("setno m8","0F 91")]
        setno_m8 = 1707,

        /// <summary>
        /// setno m8 | REX + 0F 91 | Set byte if not overflow (OF=0).
        /// </summary>
        [Symbol("setno m8","REX + 0F 91")]
        setno_m8_rex = 1708,

        /// <summary>
        /// setno r8 | 0F 91 | Set byte if not overflow (OF=0).
        /// </summary>
        [Symbol("setno r8","0F 91")]
        setno_r8 = 1709,

        /// <summary>
        /// setno r8 | REX + 0F 91 | Set byte if not overflow (OF=0).
        /// </summary>
        [Symbol("setno r8","REX + 0F 91")]
        setno_r8_rex = 1710,

        /// <summary>
        /// setnp m8 | 0F 9B | Set byte if not parity (PF=0).
        /// </summary>
        [Symbol("setnp m8","0F 9B")]
        setnp_m8 = 1711,

        /// <summary>
        /// setnp m8 | REX + 0F 9B | Set byte if not parity (PF=0).
        /// </summary>
        [Symbol("setnp m8","REX + 0F 9B")]
        setnp_m8_rex = 1712,

        /// <summary>
        /// setnp r8 | 0F 9B | Set byte if not parity (PF=0).
        /// </summary>
        [Symbol("setnp r8","0F 9B")]
        setnp_r8 = 1713,

        /// <summary>
        /// setnp r8 | REX + 0F 9B | Set byte if not parity (PF=0).
        /// </summary>
        [Symbol("setnp r8","REX + 0F 9B")]
        setnp_r8_rex = 1714,

        /// <summary>
        /// setns m8 | 0F 99 | Set byte if not sign (SF=0).
        /// </summary>
        [Symbol("setns m8","0F 99")]
        setns_m8 = 1715,

        /// <summary>
        /// setns m8 | REX + 0F 99 | Set byte if not sign (SF=0).
        /// </summary>
        [Symbol("setns m8","REX + 0F 99")]
        setns_m8_rex = 1716,

        /// <summary>
        /// setns r8 | 0F 99 | Set byte if not sign (SF=0).
        /// </summary>
        [Symbol("setns r8","0F 99")]
        setns_r8 = 1717,

        /// <summary>
        /// setns r8 | REX + 0F 99 | Set byte if not sign (SF=0).
        /// </summary>
        [Symbol("setns r8","REX + 0F 99")]
        setns_r8_rex = 1718,

        /// <summary>
        /// setnz m8 | REX + 0F 95 | Set byte if not zero (ZF=0).
        /// </summary>
        [Symbol("setnz m8","REX + 0F 95")]
        setnz_m8 = 1719,

        /// <summary>
        /// setnz m8 | 0F 95 | Set byte if not zero (ZF=0).
        /// </summary>
        [Symbol("setnz m8","0F 95")]
        setnz_m8_x0F = 1720,

        /// <summary>
        /// setnz r8 | REX + 0F 95 | Set byte if not zero (ZF=0).
        /// </summary>
        [Symbol("setnz r8","REX + 0F 95")]
        setnz_r8 = 1721,

        /// <summary>
        /// setnz r8 | 0F 95 | Set byte if not zero (ZF=0).
        /// </summary>
        [Symbol("setnz r8","0F 95")]
        setnz_r8_x0F = 1722,

        /// <summary>
        /// seto m8 | REX + 0F 90 | Set byte if overflow (OF=1).
        /// </summary>
        [Symbol("seto m8","REX + 0F 90")]
        seto_m8 = 1723,

        /// <summary>
        /// seto m8 | 0F 90 | Set byte if overflow (OF=1)
        /// </summary>
        [Symbol("seto m8","0F 90")]
        seto_m8_x0F = 1724,

        /// <summary>
        /// seto r8 | REX + 0F 90 | Set byte if overflow (OF=1).
        /// </summary>
        [Symbol("seto r8","REX + 0F 90")]
        seto_r8 = 1725,

        /// <summary>
        /// seto r8 | 0F 90 | Set byte if overflow (OF=1)
        /// </summary>
        [Symbol("seto r8","0F 90")]
        seto_r8_x0F = 1726,

        /// <summary>
        /// setp m8 | REX + 0F 9A | Set byte if parity (PF=1).
        /// </summary>
        [Symbol("setp m8","REX + 0F 9A")]
        setp_m8 = 1727,

        /// <summary>
        /// setp m8 | 0F 9A | Set byte if parity (PF=1).
        /// </summary>
        [Symbol("setp m8","0F 9A")]
        setp_m8_x0F = 1728,

        /// <summary>
        /// setp r8 | REX + 0F 9A | Set byte if parity (PF=1).
        /// </summary>
        [Symbol("setp r8","REX + 0F 9A")]
        setp_r8 = 1729,

        /// <summary>
        /// setp r8 | 0F 9A | Set byte if parity (PF=1).
        /// </summary>
        [Symbol("setp r8","0F 9A")]
        setp_r8_x0F = 1730,

        /// <summary>
        /// setpe m8 | 0F 9A | Set byte if parity even (PF=1).
        /// </summary>
        [Symbol("setpe m8","0F 9A")]
        setpe_m8 = 1731,

        /// <summary>
        /// setpe m8 | REX + 0F 9A | Set byte if parity even (PF=1).
        /// </summary>
        [Symbol("setpe m8","REX + 0F 9A")]
        setpe_m8_rex = 1732,

        /// <summary>
        /// setpe r8 | 0F 9A | Set byte if parity even (PF=1).
        /// </summary>
        [Symbol("setpe r8","0F 9A")]
        setpe_r8 = 1733,

        /// <summary>
        /// setpe r8 | REX + 0F 9A | Set byte if parity even (PF=1).
        /// </summary>
        [Symbol("setpe r8","REX + 0F 9A")]
        setpe_r8_rex = 1734,

        /// <summary>
        /// setpo m8 | 0F 9B | Set byte if parity odd (PF=0).
        /// </summary>
        [Symbol("setpo m8","0F 9B")]
        setpo_m8 = 1735,

        /// <summary>
        /// setpo m8 | REX + 0F 9B | Set byte if parity odd (PF=0).
        /// </summary>
        [Symbol("setpo m8","REX + 0F 9B")]
        setpo_m8_rex = 1736,

        /// <summary>
        /// setpo r8 | 0F 9B | Set byte if parity odd (PF=0).
        /// </summary>
        [Symbol("setpo r8","0F 9B")]
        setpo_r8 = 1737,

        /// <summary>
        /// setpo r8 | REX + 0F 9B | Set byte if parity odd (PF=0).
        /// </summary>
        [Symbol("setpo r8","REX + 0F 9B")]
        setpo_r8_rex = 1738,

        /// <summary>
        /// sets m8 | 0F 98 | Set byte if sign (SF=1).
        /// </summary>
        [Symbol("sets m8","0F 98")]
        sets_m8 = 1739,

        /// <summary>
        /// sets m8 | REX + 0F 98 | Set byte if sign (SF=1).
        /// </summary>
        [Symbol("sets m8","REX + 0F 98")]
        sets_m8_rex = 1740,

        /// <summary>
        /// sets r8 | 0F 98 | Set byte if sign (SF=1).
        /// </summary>
        [Symbol("sets r8","0F 98")]
        sets_r8 = 1741,

        /// <summary>
        /// sets r8 | REX + 0F 98 | Set byte if sign (SF=1).
        /// </summary>
        [Symbol("sets r8","REX + 0F 98")]
        sets_r8_rex = 1742,

        /// <summary>
        /// setz m8 | REX + 0F 94 | Set byte if zero (ZF=1).
        /// </summary>
        [Symbol("setz m8","REX + 0F 94")]
        setz_m8 = 1743,

        /// <summary>
        /// setz m8 | 0F 94 | Set byte if zero (ZF=1).
        /// </summary>
        [Symbol("setz m8","0F 94")]
        setz_m8_x0F = 1744,

        /// <summary>
        /// setz r8 | REX + 0F 94 | Set byte if zero (ZF=1).
        /// </summary>
        [Symbol("setz r8","REX + 0F 94")]
        setz_r8 = 1745,

        /// <summary>
        /// setz r8 | 0F 94 | Set byte if zero (ZF=1).
        /// </summary>
        [Symbol("setz r8","0F 94")]
        setz_r8_x0F = 1746,

        /// <summary>
        /// shl m16, CL | D3 /4 | Multiply r/m16 by 2, CL times.
        /// </summary>
        [Symbol("shl m16, CL","D3 /4")]
        shl_m16_CL = 1747,

        /// <summary>
        /// shl m16, imm8 | C1 /4 ib | Multiply r/m16 by 2, imm8 times.
        /// </summary>
        [Symbol("shl m16, imm8","C1 /4 ib")]
        shl_m16_imm8 = 1748,

        /// <summary>
        /// shl m16, 1 | D1 /4 | Multiply r/m16 by 2, once.
        /// </summary>
        [Symbol("shl m16, 1","D1 /4")]
        shl_m16_n1 = 1749,

        /// <summary>
        /// shl m32, CL | D3 /4 | Multiply r/m32 by 2, CL times.
        /// </summary>
        [Symbol("shl m32, CL","D3 /4")]
        shl_m32_CL = 1750,

        /// <summary>
        /// shl m32, imm8 | C1 /4 ib | Multiply r/m32 by 2, imm8 times.
        /// </summary>
        [Symbol("shl m32, imm8","C1 /4 ib")]
        shl_m32_imm8 = 1751,

        /// <summary>
        /// shl m32, 1 | D1 /4 | Multiply r/m32 by 2, once.
        /// </summary>
        [Symbol("shl m32, 1","D1 /4")]
        shl_m32_n1 = 1752,

        /// <summary>
        /// shl m64, CL | REX.W + D3 /4 | Multiply r/m64 by 2, CL times.
        /// </summary>
        [Symbol("shl m64, CL","REX.W + D3 /4")]
        shl_m64_CL = 1753,

        /// <summary>
        /// shl m64, imm8 | REX.W + C1 /4 ib | Multiply r/m64 by 2, imm8 times.
        /// </summary>
        [Symbol("shl m64, imm8","REX.W + C1 /4 ib")]
        shl_m64_imm8 = 1754,

        /// <summary>
        /// shl m64, 1 | REX.W + D1 /4 | Multiply r/m64 by 2, once.
        /// </summary>
        [Symbol("shl m64, 1","REX.W + D1 /4")]
        shl_m64_n1 = 1755,

        /// <summary>
        /// shl m8, CL | D2 /4 | Multiply r/m8 by 2, CL times.
        /// </summary>
        [Symbol("shl m8, CL","D2 /4")]
        shl_m8_CL = 1756,

        /// <summary>
        /// shl m8, CL | REX + D2 /4 | Multiply r/m8 by 2, CL times.
        /// </summary>
        [Symbol("shl m8, CL","REX + D2 /4")]
        shl_m8_CL_rex = 1757,

        /// <summary>
        /// shl m8, imm8 | C0 /4 ib | Multiply r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("shl m8, imm8","C0 /4 ib")]
        shl_m8_imm8 = 1758,

        /// <summary>
        /// shl m8, imm8 | REX + C0 /4 ib | Multiply r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("shl m8, imm8","REX + C0 /4 ib")]
        shl_m8_imm8_rex = 1759,

        /// <summary>
        /// shl m8, 1 | REX + D0 /4 | Multiply r/m8 by 2, once.
        /// </summary>
        [Symbol("shl m8, 1","REX + D0 /4")]
        shl_m8_n1 = 1760,

        /// <summary>
        /// shl m8, 1 | D0 /4 | Multiply r/m8 by 2, once.
        /// </summary>
        [Symbol("shl m8, 1","D0 /4")]
        shl_m8_n1_xD0 = 1761,

        /// <summary>
        /// shl r16, CL | D3 /4 | Multiply r/m16 by 2, CL times.
        /// </summary>
        [Symbol("shl r16, CL","D3 /4")]
        shl_r16_CL = 1762,

        /// <summary>
        /// shl r16, imm8 | C1 /4 ib | Multiply r/m16 by 2, imm8 times.
        /// </summary>
        [Symbol("shl r16, imm8","C1 /4 ib")]
        shl_r16_imm8 = 1763,

        /// <summary>
        /// shl r16, 1 | D1 /4 | Multiply r/m16 by 2, once.
        /// </summary>
        [Symbol("shl r16, 1","D1 /4")]
        shl_r16_n1 = 1764,

        /// <summary>
        /// shl r32, CL | D3 /4 | Multiply r/m32 by 2, CL times.
        /// </summary>
        [Symbol("shl r32, CL","D3 /4")]
        shl_r32_CL = 1765,

        /// <summary>
        /// shl r32, imm8 | C1 /4 ib | Multiply r/m32 by 2, imm8 times.
        /// </summary>
        [Symbol("shl r32, imm8","C1 /4 ib")]
        shl_r32_imm8 = 1766,

        /// <summary>
        /// shl r32, 1 | D1 /4 | Multiply r/m32 by 2, once.
        /// </summary>
        [Symbol("shl r32, 1","D1 /4")]
        shl_r32_n1 = 1767,

        /// <summary>
        /// shl r64, CL | REX.W + D3 /4 | Multiply r/m64 by 2, CL times.
        /// </summary>
        [Symbol("shl r64, CL","REX.W + D3 /4")]
        shl_r64_CL = 1768,

        /// <summary>
        /// shl r64, imm8 | REX.W + C1 /4 ib | Multiply r/m64 by 2, imm8 times.
        /// </summary>
        [Symbol("shl r64, imm8","REX.W + C1 /4 ib")]
        shl_r64_imm8 = 1769,

        /// <summary>
        /// shl r64, 1 | REX.W + D1 /4 | Multiply r/m64 by 2, once.
        /// </summary>
        [Symbol("shl r64, 1","REX.W + D1 /4")]
        shl_r64_n1 = 1770,

        /// <summary>
        /// shl r8, CL | D2 /4 | Multiply r/m8 by 2, CL times.
        /// </summary>
        [Symbol("shl r8, CL","D2 /4")]
        shl_r8_CL = 1771,

        /// <summary>
        /// shl r8, CL | REX + D2 /4 | Multiply r/m8 by 2, CL times.
        /// </summary>
        [Symbol("shl r8, CL","REX + D2 /4")]
        shl_r8_CL_rex = 1772,

        /// <summary>
        /// shl r8, imm8 | C0 /4 ib | Multiply r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("shl r8, imm8","C0 /4 ib")]
        shl_r8_imm8 = 1773,

        /// <summary>
        /// shl r8, imm8 | REX + C0 /4 ib | Multiply r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("shl r8, imm8","REX + C0 /4 ib")]
        shl_r8_imm8_rex = 1774,

        /// <summary>
        /// shl r8, 1 | REX + D0 /4 | Multiply r/m8 by 2, once.
        /// </summary>
        [Symbol("shl r8, 1","REX + D0 /4")]
        shl_r8_n1 = 1775,

        /// <summary>
        /// shl r8, 1 | D0 /4 | Multiply r/m8 by 2, once.
        /// </summary>
        [Symbol("shl r8, 1","D0 /4")]
        shl_r8_n1_xD0 = 1776,

        /// <summary>
        /// shlx r32, m32, r32 | VEX.LZ.66.0F38.W0 F7 /r | Shift r/m32 logically left with count specified in r32b.
        /// </summary>
        [Symbol("shlx r32, m32, r32","VEX.LZ.66.0F38.W0 F7 /r")]
        shlx_r32_m32_r32 = 1777,

        /// <summary>
        /// shlx r32, r32, r32 | VEX.LZ.66.0F38.W0 F7 /r | Shift r/m32 logically left with count specified in r32b.
        /// </summary>
        [Symbol("shlx r32, r32, r32","VEX.LZ.66.0F38.W0 F7 /r")]
        shlx_r32_r32_r32 = 1778,

        /// <summary>
        /// shlx r64, m64, r64 | VEX.LZ.66.0F38.W1 F7 /r | Shift r/m64 logically left with count specified in r64b.
        /// </summary>
        [Symbol("shlx r64, m64, r64","VEX.LZ.66.0F38.W1 F7 /r")]
        shlx_r64_m64_r64 = 1779,

        /// <summary>
        /// shlx r64, r64, r64 | VEX.LZ.66.0F38.W1 F7 /r | Shift r/m64 logically left with count specified in r64b.
        /// </summary>
        [Symbol("shlx r64, r64, r64","VEX.LZ.66.0F38.W1 F7 /r")]
        shlx_r64_r64_r64 = 1780,

        /// <summary>
        /// shr m16, CL | D3 /5 | Unsigned divide r/m16 by 2, CL times
        /// </summary>
        [Symbol("shr m16, CL","D3 /5")]
        shr_m16_CL = 1781,

        /// <summary>
        /// shr m16, imm8 | C1 /5 ib | Unsigned divide r/m16 by 2, imm8 times.
        /// </summary>
        [Symbol("shr m16, imm8","C1 /5 ib")]
        shr_m16_imm8 = 1782,

        /// <summary>
        /// shr m16, 1 | D1 /5 | Unsigned divide r/m16 by 2, once.
        /// </summary>
        [Symbol("shr m16, 1","D1 /5")]
        shr_m16_n1 = 1783,

        /// <summary>
        /// shr m32, CL | D3 /5 | Unsigned divide r/m32 by 2, CL times.
        /// </summary>
        [Symbol("shr m32, CL","D3 /5")]
        shr_m32_CL = 1784,

        /// <summary>
        /// shr m32, imm8 | C1 /5 ib | Unsigned divide r/m32 by 2, imm8 times.
        /// </summary>
        [Symbol("shr m32, imm8","C1 /5 ib")]
        shr_m32_imm8 = 1785,

        /// <summary>
        /// shr m32, 1 | D1 /5 | Unsigned divide r/m32 by 2, once.
        /// </summary>
        [Symbol("shr m32, 1","D1 /5")]
        shr_m32_n1 = 1786,

        /// <summary>
        /// shr m64, CL | REX.W + D3 /5 | Unsigned divide r/m64 by 2, CL times.
        /// </summary>
        [Symbol("shr m64, CL","REX.W + D3 /5")]
        shr_m64_CL = 1787,

        /// <summary>
        /// shr m64, imm8 | REX.W + C1 /5 ib | Unsigned divide r/m64 by 2, imm8 times.
        /// </summary>
        [Symbol("shr m64, imm8","REX.W + C1 /5 ib")]
        shr_m64_imm8 = 1788,

        /// <summary>
        /// shr m64, 1 | REX.W + D1 /5 | Unsigned divide r/m64 by 2, once.
        /// </summary>
        [Symbol("shr m64, 1","REX.W + D1 /5")]
        shr_m64_n1 = 1789,

        /// <summary>
        /// shr m8, CL | REX + D2 /5 | Unsigned divide r/m8 by 2, CL times.
        /// </summary>
        [Symbol("shr m8, CL","REX + D2 /5")]
        shr_m8_CL = 1790,

        /// <summary>
        /// shr m8, CL | D2 /5 | Unsigned divide r/m8 by 2, CL times.
        /// </summary>
        [Symbol("shr m8, CL","D2 /5")]
        shr_m8_CL_xD2 = 1791,

        /// <summary>
        /// shr m8, imm8 | C0 /5 ib | Unsigned divide r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("shr m8, imm8","C0 /5 ib")]
        shr_m8_imm8 = 1792,

        /// <summary>
        /// shr m8, imm8 | REX + C0 /5 ib | Unsigned divide r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("shr m8, imm8","REX + C0 /5 ib")]
        shr_m8_imm8_rex = 1793,

        /// <summary>
        /// shr m8, 1 | REX + D0 /5 | Unsigned divide r/m8 by 2, once.
        /// </summary>
        [Symbol("shr m8, 1","REX + D0 /5")]
        shr_m8_n1 = 1794,

        /// <summary>
        /// shr m8, 1 | D0 /5 | Unsigned divide r/m8 by 2, once.
        /// </summary>
        [Symbol("shr m8, 1","D0 /5")]
        shr_m8_n1_xD0 = 1795,

        /// <summary>
        /// shr r16, CL | D3 /5 | Unsigned divide r/m16 by 2, CL times
        /// </summary>
        [Symbol("shr r16, CL","D3 /5")]
        shr_r16_CL = 1796,

        /// <summary>
        /// shr r16, imm8 | C1 /5 ib | Unsigned divide r/m16 by 2, imm8 times.
        /// </summary>
        [Symbol("shr r16, imm8","C1 /5 ib")]
        shr_r16_imm8 = 1797,

        /// <summary>
        /// shr r16, 1 | D1 /5 | Unsigned divide r/m16 by 2, once.
        /// </summary>
        [Symbol("shr r16, 1","D1 /5")]
        shr_r16_n1 = 1798,

        /// <summary>
        /// shr r32, CL | D3 /5 | Unsigned divide r/m32 by 2, CL times.
        /// </summary>
        [Symbol("shr r32, CL","D3 /5")]
        shr_r32_CL = 1799,

        /// <summary>
        /// shr r32, imm8 | C1 /5 ib | Unsigned divide r/m32 by 2, imm8 times.
        /// </summary>
        [Symbol("shr r32, imm8","C1 /5 ib")]
        shr_r32_imm8 = 1800,

        /// <summary>
        /// shr r32, 1 | D1 /5 | Unsigned divide r/m32 by 2, once.
        /// </summary>
        [Symbol("shr r32, 1","D1 /5")]
        shr_r32_n1 = 1801,

        /// <summary>
        /// shr r64, CL | REX.W + D3 /5 | Unsigned divide r/m64 by 2, CL times.
        /// </summary>
        [Symbol("shr r64, CL","REX.W + D3 /5")]
        shr_r64_CL = 1802,

        /// <summary>
        /// shr r64, imm8 | REX.W + C1 /5 ib | Unsigned divide r/m64 by 2, imm8 times.
        /// </summary>
        [Symbol("shr r64, imm8","REX.W + C1 /5 ib")]
        shr_r64_imm8 = 1803,

        /// <summary>
        /// shr r64, 1 | REX.W + D1 /5 | Unsigned divide r/m64 by 2, once.
        /// </summary>
        [Symbol("shr r64, 1","REX.W + D1 /5")]
        shr_r64_n1 = 1804,

        /// <summary>
        /// shr r8, CL | REX + D2 /5 | Unsigned divide r/m8 by 2, CL times.
        /// </summary>
        [Symbol("shr r8, CL","REX + D2 /5")]
        shr_r8_CL = 1805,

        /// <summary>
        /// shr r8, CL | D2 /5 | Unsigned divide r/m8 by 2, CL times.
        /// </summary>
        [Symbol("shr r8, CL","D2 /5")]
        shr_r8_CL_xD2 = 1806,

        /// <summary>
        /// shr r8, imm8 | C0 /5 ib | Unsigned divide r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("shr r8, imm8","C0 /5 ib")]
        shr_r8_imm8 = 1807,

        /// <summary>
        /// shr r8, imm8 | REX + C0 /5 ib | Unsigned divide r/m8 by 2, imm8 times.
        /// </summary>
        [Symbol("shr r8, imm8","REX + C0 /5 ib")]
        shr_r8_imm8_rex = 1808,

        /// <summary>
        /// shr r8, 1 | REX + D0 /5 | Unsigned divide r/m8 by 2, once.
        /// </summary>
        [Symbol("shr r8, 1","REX + D0 /5")]
        shr_r8_n1 = 1809,

        /// <summary>
        /// shr r8, 1 | D0 /5 | Unsigned divide r/m8 by 2, once.
        /// </summary>
        [Symbol("shr r8, 1","D0 /5")]
        shr_r8_n1_xD0 = 1810,

        /// <summary>
        /// shrx r32, m32, r32 | VEX.LZ.F2.0F38.W0 F7 /r | Shift r/m32 logically right with count specified in r32b.
        /// </summary>
        [Symbol("shrx r32, m32, r32","VEX.LZ.F2.0F38.W0 F7 /r")]
        shrx_r32_m32_r32 = 1811,

        /// <summary>
        /// shrx r32, r32, r32 | VEX.LZ.F2.0F38.W0 F7 /r | Shift r/m32 logically right with count specified in r32b.
        /// </summary>
        [Symbol("shrx r32, r32, r32","VEX.LZ.F2.0F38.W0 F7 /r")]
        shrx_r32_r32_r32 = 1812,

        /// <summary>
        /// shrx r64, m64, r64 | VEX.LZ.F2.0F38.W1 F7 /r | Shift r/m64 logically right with count specified in r64b.
        /// </summary>
        [Symbol("shrx r64, m64, r64","VEX.LZ.F2.0F38.W1 F7 /r")]
        shrx_r64_m64_r64 = 1813,

        /// <summary>
        /// shrx r64, r64, r64 | VEX.LZ.F2.0F38.W1 F7 /r | Shift r/m64 logically right with count specified in r64b.
        /// </summary>
        [Symbol("shrx r64, r64, r64","VEX.LZ.F2.0F38.W1 F7 /r")]
        shrx_r64_r64_r64 = 1814,

        /// <summary>
        /// sti | FB | Set interrupt flag; external, maskable interrupts enabled at the end of the next instruction.
        /// </summary>
        [Symbol("sti","FB")]
        sti = 1815,

        /// <summary>
        /// stos m16 | AB | For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.
        /// </summary>
        [Symbol("stos m16","AB")]
        stos_m16 = 1816,

        /// <summary>
        /// stos m32 | AB | For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.
        /// </summary>
        [Symbol("stos m32","AB")]
        stos_m32 = 1817,

        /// <summary>
        /// stos m64 | REX.W + AB | Store RAX at address RDI or EDI.
        /// </summary>
        [Symbol("stos m64","REX.W + AB")]
        stos_m64 = 1818,

        /// <summary>
        /// stos m8 | AA | For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.
        /// </summary>
        [Symbol("stos m8","AA")]
        stos_m8 = 1819,

        /// <summary>
        /// stosb | AA | For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.
        /// </summary>
        [Symbol("stosb","AA")]
        stosb = 1820,

        /// <summary>
        /// stosd | AB | For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.
        /// </summary>
        [Symbol("stosd","AB")]
        stosd = 1821,

        /// <summary>
        /// stosq | REX.W + AB | Store RAX at address RDI or EDI.
        /// </summary>
        [Symbol("stosq","REX.W + AB")]
        stosq = 1822,

        /// <summary>
        /// stosw | AB | For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.
        /// </summary>
        [Symbol("stosw","AB")]
        stosw = 1823,

        /// <summary>
        /// sub AL, imm8 | 2C ib | Subtract imm8 from AL.
        /// </summary>
        [Symbol("sub AL, imm8","2C ib")]
        sub_AL_imm8 = 1824,

        /// <summary>
        /// sub AX, imm16 | 2D iw | Subtract imm16 from AX.
        /// </summary>
        [Symbol("sub AX, imm16","2D iw")]
        sub_AX_imm16 = 1825,

        /// <summary>
        /// sub EAX, imm32 | 2D id | Subtract imm32 from EAX.
        /// </summary>
        [Symbol("sub EAX, imm32","2D id")]
        sub_EAX_imm32 = 1826,

        /// <summary>
        /// sub m16, imm16 | 81 /5 iw | Subtract imm16 from r/m16.
        /// </summary>
        [Symbol("sub m16, imm16","81 /5 iw")]
        sub_m16_imm16 = 1827,

        /// <summary>
        /// sub m16, imm8 | 83 /5 ib | Subtract sign-extended imm8 from r/m16.
        /// </summary>
        [Symbol("sub m16, imm8","83 /5 ib")]
        sub_m16_imm8 = 1828,

        /// <summary>
        /// sub m16, r16 | 29 /r | Subtract r16 from r/m16.
        /// </summary>
        [Symbol("sub m16, r16","29 /r")]
        sub_m16_r16 = 1829,

        /// <summary>
        /// sub m32, imm32 | 81 /5 id | Subtract imm32 from r/m32.
        /// </summary>
        [Symbol("sub m32, imm32","81 /5 id")]
        sub_m32_imm32 = 1830,

        /// <summary>
        /// sub m32, imm8 | 83 /5 ib | Subtract sign-extended imm8 from r/m32.
        /// </summary>
        [Symbol("sub m32, imm8","83 /5 ib")]
        sub_m32_imm8 = 1831,

        /// <summary>
        /// sub m32, r32 | 29 /r | Subtract r32 from r/m32.
        /// </summary>
        [Symbol("sub m32, r32","29 /r")]
        sub_m32_r32 = 1832,

        /// <summary>
        /// sub m64, imm32 | REX.W + 81 /5 id | Subtract imm32 sign-extended to 64-bits from r/m64.
        /// </summary>
        [Symbol("sub m64, imm32","REX.W + 81 /5 id")]
        sub_m64_imm32 = 1833,

        /// <summary>
        /// sub m64, imm8 | REX.W + 83 /5 ib | Subtract sign-extended imm8 from r/m64.
        /// </summary>
        [Symbol("sub m64, imm8","REX.W + 83 /5 ib")]
        sub_m64_imm8 = 1834,

        /// <summary>
        /// sub m64, r64 | REX.W + 29 /r | Subtract r64 from r/m64.
        /// </summary>
        [Symbol("sub m64, r64","REX.W + 29 /r")]
        sub_m64_r64 = 1835,

        /// <summary>
        /// sub m8, imm8 | REX + 80 /5 ib | Subtract imm8 from r/m8.
        /// </summary>
        [Symbol("sub m8, imm8","REX + 80 /5 ib")]
        sub_m8_imm8 = 1836,

        /// <summary>
        /// sub m8, imm8 | 80 /5 ib | Subtract imm8 from r/m8.
        /// </summary>
        [Symbol("sub m8, imm8","80 /5 ib")]
        sub_m8_imm8_x80 = 1837,

        /// <summary>
        /// sub m8, r8 | 28 /r | Subtract r8 from r/m8.
        /// </summary>
        [Symbol("sub m8, r8","28 /r")]
        sub_m8_r8 = 1838,

        /// <summary>
        /// sub m8, r8 | REX + 28 /r | Subtract r8 from r/m8.
        /// </summary>
        [Symbol("sub m8, r8","REX + 28 /r")]
        sub_m8_r8_rex = 1839,

        /// <summary>
        /// sub r16, imm16 | 81 /5 iw | Subtract imm16 from r/m16.
        /// </summary>
        [Symbol("sub r16, imm16","81 /5 iw")]
        sub_r16_imm16 = 1840,

        /// <summary>
        /// sub r16, imm8 | 83 /5 ib | Subtract sign-extended imm8 from r/m16.
        /// </summary>
        [Symbol("sub r16, imm8","83 /5 ib")]
        sub_r16_imm8 = 1841,

        /// <summary>
        /// sub r16, m16 | 2B /r | Subtract r/m16 from r16.
        /// </summary>
        [Symbol("sub r16, m16","2B /r")]
        sub_r16_m16 = 1842,

        /// <summary>
        /// sub r16, r16 | 29 /r | Subtract r16 from r/m16.
        /// </summary>
        [Symbol("sub r16, r16","29 /r")]
        sub_r16_r16 = 1843,

        /// <summary>
        /// sub r16, r16 | 2B /r | Subtract r/m16 from r16.
        /// </summary>
        [Symbol("sub r16, r16","2B /r")]
        sub_r16_r16_x2B = 1844,

        /// <summary>
        /// sub r32, imm32 | 81 /5 id | Subtract imm32 from r/m32.
        /// </summary>
        [Symbol("sub r32, imm32","81 /5 id")]
        sub_r32_imm32 = 1845,

        /// <summary>
        /// sub r32, imm8 | 83 /5 ib | Subtract sign-extended imm8 from r/m32.
        /// </summary>
        [Symbol("sub r32, imm8","83 /5 ib")]
        sub_r32_imm8 = 1846,

        /// <summary>
        /// sub r32, m32 | 2B /r | Subtract r/m32 from r32.
        /// </summary>
        [Symbol("sub r32, m32","2B /r")]
        sub_r32_m32 = 1847,

        /// <summary>
        /// sub r32, r32 | 29 /r | Subtract r32 from r/m32.
        /// </summary>
        [Symbol("sub r32, r32","29 /r")]
        sub_r32_r32 = 1848,

        /// <summary>
        /// sub r32, r32 | 2B /r | Subtract r/m32 from r32.
        /// </summary>
        [Symbol("sub r32, r32","2B /r")]
        sub_r32_r32_x2B = 1849,

        /// <summary>
        /// sub r64, imm32 | REX.W + 81 /5 id | Subtract imm32 sign-extended to 64-bits from r/m64.
        /// </summary>
        [Symbol("sub r64, imm32","REX.W + 81 /5 id")]
        sub_r64_imm32 = 1850,

        /// <summary>
        /// sub r64, imm8 | REX.W + 83 /5 ib | Subtract sign-extended imm8 from r/m64.
        /// </summary>
        [Symbol("sub r64, imm8","REX.W + 83 /5 ib")]
        sub_r64_imm8 = 1851,

        /// <summary>
        /// sub r64, m64 | REX.W + 2B /r | Subtract r/m64 from r64.
        /// </summary>
        [Symbol("sub r64, m64","REX.W + 2B /r")]
        sub_r64_m64 = 1852,

        /// <summary>
        /// sub r64, r64 | REX.W + 29 /r | Subtract r64 from r/m64.
        /// </summary>
        [Symbol("sub r64, r64","REX.W + 29 /r")]
        sub_r64_r64 = 1853,

        /// <summary>
        /// sub r64, r64 | REX.W + 2B /r | Subtract r/m64 from r64.
        /// </summary>
        [Symbol("sub r64, r64","REX.W + 2B /r")]
        sub_r64_r64_x2B = 1854,

        /// <summary>
        /// sub r8, imm8 | REX + 80 /5 ib | Subtract imm8 from r/m8.
        /// </summary>
        [Symbol("sub r8, imm8","REX + 80 /5 ib")]
        sub_r8_imm8 = 1855,

        /// <summary>
        /// sub r8, imm8 | 80 /5 ib | Subtract imm8 from r/m8.
        /// </summary>
        [Symbol("sub r8, imm8","80 /5 ib")]
        sub_r8_imm8_x80 = 1856,

        /// <summary>
        /// sub r8, m8 | REX + 2A /r | Subtract r/m8 from r8.
        /// </summary>
        [Symbol("sub r8, m8","REX + 2A /r")]
        sub_r8_m8 = 1857,

        /// <summary>
        /// sub r8, m8 | 2A /r | Subtract r/m8 from r8.
        /// </summary>
        [Symbol("sub r8, m8","2A /r")]
        sub_r8_m8_x2A = 1858,

        /// <summary>
        /// sub r8, r8 | 28 /r | Subtract r8 from r/m8.
        /// </summary>
        [Symbol("sub r8, r8","28 /r")]
        sub_r8_r8 = 1859,

        /// <summary>
        /// sub r8, r8 | REX + 28 /r | Subtract r8 from r/m8.
        /// </summary>
        [Symbol("sub r8, r8","REX + 28 /r")]
        sub_r8_r8_rex = 1860,

        /// <summary>
        /// sub r8, r8 | 2A /r | Subtract r/m8 from r8.
        /// </summary>
        [Symbol("sub r8, r8","2A /r")]
        sub_r8_r8_x2A = 1861,

        /// <summary>
        /// sub RAX, imm32 | REX.W + 2D id | Subtract imm32 sign-extended to 64-bits from RAX.
        /// </summary>
        [Symbol("sub RAX, imm32","REX.W + 2D id")]
        sub_RAX_imm32 = 1862,

        /// <summary>
        /// syscall | 0F 05 | Fast call to privilege level 0 system procedures.
        /// </summary>
        [Symbol("syscall","0F 05")]
        syscall = 1863,

        /// <summary>
        /// test AL, imm8 | A8 ib | AND imm8 with AL; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test AL, imm8","A8 ib")]
        test_AL_imm8 = 1864,

        /// <summary>
        /// test AX, imm16 | A9 iw | AND imm16 with AX; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test AX, imm16","A9 iw")]
        test_AX_imm16 = 1865,

        /// <summary>
        /// test EAX, imm32 | A9 id | AND imm32 with EAX; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test EAX, imm32","A9 id")]
        test_EAX_imm32 = 1866,

        /// <summary>
        /// test m16, imm16 | F7 /0 iw | AND imm16 with r/m16 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test m16, imm16","F7 /0 iw")]
        test_m16_imm16 = 1867,

        /// <summary>
        /// test m16, r16 | 85 /4 | AND r16 with r/m16 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test m16, r16","85 /4")]
        test_m16_r16 = 1868,

        /// <summary>
        /// test m32, imm32 | F7 /0 id | AND imm32 with r/m32 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test m32, imm32","F7 /0 id")]
        test_m32_imm32 = 1869,

        /// <summary>
        /// test m32, r32 | 85 /4 | AND r32 with r/m32 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test m32, r32","85 /4")]
        test_m32_r32 = 1870,

        /// <summary>
        /// test m64, imm32 | REX.W + F7 /0 id | AND imm32 sign-extended to 64-bits with r/m64 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test m64, imm32","REX.W + F7 /0 id")]
        test_m64_imm32 = 1871,

        /// <summary>
        /// test m64, r64 | REX.W + 85 /4 | AND r64 with r/m64 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test m64, r64","REX.W + 85 /4")]
        test_m64_r64 = 1872,

        /// <summary>
        /// test m8, imm8 | F6 /0 ib | AND imm8 with r/m8 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test m8, imm8","F6 /0 ib")]
        test_m8_imm8 = 1873,

        /// <summary>
        /// test m8, imm8 | REX + F6 /0 ib | AND imm8 with r/m8 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test m8, imm8","REX + F6 /0 ib")]
        test_m8_imm8_rex = 1874,

        /// <summary>
        /// test m8, r8 | REX + 84 /4 | AND r8 with r/m8 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test m8, r8","REX + 84 /4")]
        test_m8_r8 = 1875,

        /// <summary>
        /// test m8, r8 | 84 /4 | AND r8 with r/m8 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test m8, r8","84 /4")]
        test_m8_r8_x84 = 1876,

        /// <summary>
        /// test r16, imm16 | F7 /0 iw | AND imm16 with r/m16 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test r16, imm16","F7 /0 iw")]
        test_r16_imm16 = 1877,

        /// <summary>
        /// test r16, r16 | 85 /4 | AND r16 with r/m16 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test r16, r16","85 /4")]
        test_r16_r16 = 1878,

        /// <summary>
        /// test r32, imm32 | F7 /0 id | AND imm32 with r/m32 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test r32, imm32","F7 /0 id")]
        test_r32_imm32 = 1879,

        /// <summary>
        /// test r32, r32 | 85 /4 | AND r32 with r/m32 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test r32, r32","85 /4")]
        test_r32_r32 = 1880,

        /// <summary>
        /// test r64, imm32 | REX.W + F7 /0 id | AND imm32 sign-extended to 64-bits with r/m64 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test r64, imm32","REX.W + F7 /0 id")]
        test_r64_imm32 = 1881,

        /// <summary>
        /// test r64, r64 | REX.W + 85 /4 | AND r64 with r/m64 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test r64, r64","REX.W + 85 /4")]
        test_r64_r64 = 1882,

        /// <summary>
        /// test r8, imm8 | F6 /0 ib | AND imm8 with r/m8 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test r8, imm8","F6 /0 ib")]
        test_r8_imm8 = 1883,

        /// <summary>
        /// test r8, imm8 | REX + F6 /0 ib | AND imm8 with r/m8 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test r8, imm8","REX + F6 /0 ib")]
        test_r8_imm8_rex = 1884,

        /// <summary>
        /// test r8, r8 | REX + 84 /4 | AND r8 with r/m8 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test r8, r8","REX + 84 /4")]
        test_r8_r8 = 1885,

        /// <summary>
        /// test r8, r8 | 84 /4 | AND r8 with r/m8 ; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test r8, r8","84 /4")]
        test_r8_r8_x84 = 1886,

        /// <summary>
        /// test RAX, imm32 | REX.W + A9 id | AND imm32 sign-extended to 64-bits with RAX; set SF, ZF, PF according to result.
        /// </summary>
        [Symbol("test RAX, imm32","REX.W + A9 id")]
        test_RAX_imm32 = 1887,

        /// <summary>
        /// tpause r32, EDX, EAX | 66 0F AE /6 | Directs the processor to enter an implementation-dependent optimized state until the TSC reaches the value in EDX:EAX.
        /// </summary>
        [Symbol("tpause r32, EDX, EAX","66 0F AE /6")]
        tpause_r32_EDX_EAX = 1888,

        /// <summary>
        /// vaddpd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 58 /r | Add packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 58 /r")]
        vaddpd_xmm_k1z_xmm_m128 = 1889,

        /// <summary>
        /// vaddpd xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F.W1 58 /r | Add packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F.W1 58 /r")]
        vaddpd_xmm_k1z_xmm_m64bcst = 1890,

        /// <summary>
        /// vaddpd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W1 58 /r | Add packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W1 58 /r")]
        vaddpd_xmm_k1z_xmm_xmm = 1891,

        /// <summary>
        /// vaddpd xmm, xmm, m128 | EVEX.128.66.0F.W1 58 /r | Add packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd xmm, xmm, m128","EVEX.128.66.0F.W1 58 /r")]
        vaddpd_xmm_xmm_m128 = 1892,

        /// <summary>
        /// vaddpd xmm, xmm, m128 | VEX.128.66.0F.WIG 58 /r | Add packed double-precision floating-point values from xmm3/mem to xmm2 and store result in xmm1.
        /// </summary>
        [Symbol("vaddpd xmm, xmm, m128","VEX.128.66.0F.WIG 58 /r")]
        vaddpd_xmm_xmm_m128_vex = 1893,

        /// <summary>
        /// vaddpd xmm, xmm, m64bcst | EVEX.128.66.0F.W1 58 /r | Add packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd xmm, xmm, m64bcst","EVEX.128.66.0F.W1 58 /r")]
        vaddpd_xmm_xmm_m64bcst = 1894,

        /// <summary>
        /// vaddpd xmm, xmm, r8 | VEX.128.66.0F.WIG 58 /r | Add packed double-precision floating-point values from xmm3/mem to xmm2 and store result in xmm1.
        /// </summary>
        [Symbol("vaddpd xmm, xmm, r8","VEX.128.66.0F.WIG 58 /r")]
        vaddpd_xmm_xmm_r8 = 1895,

        /// <summary>
        /// vaddpd xmm, xmm, xmm | EVEX.128.66.0F.W1 58 /r | Add packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd xmm, xmm, xmm","EVEX.128.66.0F.W1 58 /r")]
        vaddpd_xmm_xmm_xmm = 1896,

        /// <summary>
        /// vaddpd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W1 58 /r | Add packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W1 58 /r")]
        vaddpd_ymm_k1z_ymm_m256 = 1897,

        /// <summary>
        /// vaddpd ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F.W1 58 /r | Add packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F.W1 58 /r")]
        vaddpd_ymm_k1z_ymm_m64bcst = 1898,

        /// <summary>
        /// vaddpd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W1 58 /r | Add packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W1 58 /r")]
        vaddpd_ymm_k1z_ymm_ymm = 1899,

        /// <summary>
        /// vaddpd ymm, ymm, m256 | EVEX.256.66.0F.W1 58 /r | Add packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd ymm, ymm, m256","EVEX.256.66.0F.W1 58 /r")]
        vaddpd_ymm_ymm_m256 = 1900,

        /// <summary>
        /// vaddpd ymm, ymm, m256 | VEX.256.66.0F.WIG 58 /r | Add packed double-precision floating-point values from ymm3/mem to ymm2 and store result in ymm1.
        /// </summary>
        [Symbol("vaddpd ymm, ymm, m256","VEX.256.66.0F.WIG 58 /r")]
        vaddpd_ymm_ymm_m256_vex = 1901,

        /// <summary>
        /// vaddpd ymm, ymm, m64bcst | EVEX.256.66.0F.W1 58 /r | Add packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd ymm, ymm, m64bcst","EVEX.256.66.0F.W1 58 /r")]
        vaddpd_ymm_ymm_m64bcst = 1902,

        /// <summary>
        /// vaddpd ymm, ymm, r16 | VEX.256.66.0F.WIG 58 /r | Add packed double-precision floating-point values from ymm3/mem to ymm2 and store result in ymm1.
        /// </summary>
        [Symbol("vaddpd ymm, ymm, r16","VEX.256.66.0F.WIG 58 /r")]
        vaddpd_ymm_ymm_r16 = 1903,

        /// <summary>
        /// vaddpd ymm, ymm, ymm | EVEX.256.66.0F.W1 58 /r | Add packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd ymm, ymm, ymm","EVEX.256.66.0F.W1 58 /r")]
        vaddpd_ymm_ymm_ymm = 1904,

        /// <summary>
        /// vaddpd zmm {k1}{z}, zmm, m512 {k1} | EVEX.512.66.0F.W1 58 /r | Add packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd zmm {k1}{z}, zmm, m512 {k1}","EVEX.512.66.0F.W1 58 /r")]
        vaddpd_zmm_k1z_zmm_m512_k1 = 1905,

        /// <summary>
        /// vaddpd zmm {k1}{z}, zmm, m64bcst {k1} | EVEX.512.66.0F.W1 58 /r | Add packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd zmm {k1}{z}, zmm, m64bcst {k1}","EVEX.512.66.0F.W1 58 /r")]
        vaddpd_zmm_k1z_zmm_m64bcst_k1 = 1906,

        /// <summary>
        /// vaddpd zmm {k1}{z}, zmm, zmm {k1} | EVEX.512.66.0F.W1 58 /r | Add packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd zmm {k1}{z}, zmm, zmm {k1}","EVEX.512.66.0F.W1 58 /r")]
        vaddpd_zmm_k1z_zmm_zmm_k1 = 1907,

        /// <summary>
        /// vaddpd zmm, zmm, m512 | EVEX.512.66.0F.W1 58 /r | Add packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd zmm, zmm, m512","EVEX.512.66.0F.W1 58 /r")]
        vaddpd_zmm_zmm_m512 = 1908,

        /// <summary>
        /// vaddpd zmm, zmm, m64bcst | EVEX.512.66.0F.W1 58 /r | Add packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd zmm, zmm, m64bcst","EVEX.512.66.0F.W1 58 /r")]
        vaddpd_zmm_zmm_m64bcst = 1909,

        /// <summary>
        /// vaddpd zmm, zmm, zmm | EVEX.512.66.0F.W1 58 /r | Add packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1.
        /// </summary>
        [Symbol("vaddpd zmm, zmm, zmm","EVEX.512.66.0F.W1 58 /r")]
        vaddpd_zmm_zmm_zmm = 1910,

        /// <summary>
        /// valignd xmm {k1}{z}, xmm, m128, imm8 | EVEX.NDS.128.66.0F3A.W0 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignd xmm {k1}{z}, xmm, m128, imm8","EVEX.NDS.128.66.0F3A.W0 03 /r ib")]
        valignd_xmm_k1z_xmm_m128_imm8 = 1911,

        /// <summary>
        /// valignd xmm {k1}{z}, xmm, m32bcst, imm8 | EVEX.NDS.128.66.0F3A.W0 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignd xmm {k1}{z}, xmm, m32bcst, imm8","EVEX.NDS.128.66.0F3A.W0 03 /r ib")]
        valignd_xmm_k1z_xmm_m32bcst_imm8 = 1912,

        /// <summary>
        /// valignd xmm {k1}{z}, xmm, xmm, imm8 | EVEX.NDS.128.66.0F3A.W0 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignd xmm {k1}{z}, xmm, xmm, imm8","EVEX.NDS.128.66.0F3A.W0 03 /r ib")]
        valignd_xmm_k1z_xmm_xmm_imm8 = 1913,

        /// <summary>
        /// valignd xmm, xmm, m128, imm8 | EVEX.NDS.128.66.0F3A.W0 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignd xmm, xmm, m128, imm8","EVEX.NDS.128.66.0F3A.W0 03 /r ib")]
        valignd_xmm_xmm_m128_imm8 = 1914,

        /// <summary>
        /// valignd xmm, xmm, m32bcst, imm8 | EVEX.NDS.128.66.0F3A.W0 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignd xmm, xmm, m32bcst, imm8","EVEX.NDS.128.66.0F3A.W0 03 /r ib")]
        valignd_xmm_xmm_m32bcst_imm8 = 1915,

        /// <summary>
        /// valignd xmm, xmm, xmm, imm8 | EVEX.NDS.128.66.0F3A.W0 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignd xmm, xmm, xmm, imm8","EVEX.NDS.128.66.0F3A.W0 03 /r ib")]
        valignd_xmm_xmm_xmm_imm8 = 1916,

        /// <summary>
        /// valignd ymm {k1}{z}, ymm, m256, imm8 | EVEX.NDS.256.66.0F3A.W0 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignd ymm {k1}{z}, ymm, m256, imm8","EVEX.NDS.256.66.0F3A.W0 03 /r ib")]
        valignd_ymm_k1z_ymm_m256_imm8 = 1917,

        /// <summary>
        /// valignd ymm {k1}{z}, ymm, m32bcst, imm8 | EVEX.NDS.256.66.0F3A.W0 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignd ymm {k1}{z}, ymm, m32bcst, imm8","EVEX.NDS.256.66.0F3A.W0 03 /r ib")]
        valignd_ymm_k1z_ymm_m32bcst_imm8 = 1918,

        /// <summary>
        /// valignd ymm {k1}{z}, ymm, ymm, imm8 | EVEX.NDS.256.66.0F3A.W0 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignd ymm {k1}{z}, ymm, ymm, imm8","EVEX.NDS.256.66.0F3A.W0 03 /r ib")]
        valignd_ymm_k1z_ymm_ymm_imm8 = 1919,

        /// <summary>
        /// valignd ymm, ymm, m256, imm8 | EVEX.NDS.256.66.0F3A.W0 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignd ymm, ymm, m256, imm8","EVEX.NDS.256.66.0F3A.W0 03 /r ib")]
        valignd_ymm_ymm_m256_imm8 = 1920,

        /// <summary>
        /// valignd ymm, ymm, m32bcst, imm8 | EVEX.NDS.256.66.0F3A.W0 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignd ymm, ymm, m32bcst, imm8","EVEX.NDS.256.66.0F3A.W0 03 /r ib")]
        valignd_ymm_ymm_m32bcst_imm8 = 1921,

        /// <summary>
        /// valignd ymm, ymm, ymm, imm8 | EVEX.NDS.256.66.0F3A.W0 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignd ymm, ymm, ymm, imm8","EVEX.NDS.256.66.0F3A.W0 03 /r ib")]
        valignd_ymm_ymm_ymm_imm8 = 1922,

        /// <summary>
        /// valignd zmm {k1}{z}, zmm, m32bcst, imm8 | EVEX.NDS.512.66.0F3A.W0 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignd zmm {k1}{z}, zmm, m32bcst, imm8","EVEX.NDS.512.66.0F3A.W0 03 /r ib")]
        valignd_zmm_k1z_zmm_m32bcst_imm8 = 1923,

        /// <summary>
        /// valignd zmm {k1}{z}, zmm, m512, imm8 | EVEX.NDS.512.66.0F3A.W0 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignd zmm {k1}{z}, zmm, m512, imm8","EVEX.NDS.512.66.0F3A.W0 03 /r ib")]
        valignd_zmm_k1z_zmm_m512_imm8 = 1924,

        /// <summary>
        /// valignd zmm {k1}{z}, zmm, zmm, imm8 | EVEX.NDS.512.66.0F3A.W0 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignd zmm {k1}{z}, zmm, zmm, imm8","EVEX.NDS.512.66.0F3A.W0 03 /r ib")]
        valignd_zmm_k1z_zmm_zmm_imm8 = 1925,

        /// <summary>
        /// valignd zmm, zmm, m32bcst, imm8 | EVEX.NDS.512.66.0F3A.W0 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignd zmm, zmm, m32bcst, imm8","EVEX.NDS.512.66.0F3A.W0 03 /r ib")]
        valignd_zmm_zmm_m32bcst_imm8 = 1926,

        /// <summary>
        /// valignd zmm, zmm, m512, imm8 | EVEX.NDS.512.66.0F3A.W0 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignd zmm, zmm, m512, imm8","EVEX.NDS.512.66.0F3A.W0 03 /r ib")]
        valignd_zmm_zmm_m512_imm8 = 1927,

        /// <summary>
        /// valignd zmm, zmm, zmm, imm8 | EVEX.NDS.512.66.0F3A.W0 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignd zmm, zmm, zmm, imm8","EVEX.NDS.512.66.0F3A.W0 03 /r ib")]
        valignd_zmm_zmm_zmm_imm8 = 1928,

        /// <summary>
        /// valignq xmm {k1}{z}, xmm, m128, imm8 | EVEX.NDS.128.66.0F3A.W1 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignq xmm {k1}{z}, xmm, m128, imm8","EVEX.NDS.128.66.0F3A.W1 03 /r ib")]
        valignq_xmm_k1z_xmm_m128_imm8 = 1929,

        /// <summary>
        /// valignq xmm {k1}{z}, xmm, m64bcst, imm8 | EVEX.NDS.128.66.0F3A.W1 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignq xmm {k1}{z}, xmm, m64bcst, imm8","EVEX.NDS.128.66.0F3A.W1 03 /r ib")]
        valignq_xmm_k1z_xmm_m64bcst_imm8 = 1930,

        /// <summary>
        /// valignq xmm {k1}{z}, xmm, xmm, imm8 | EVEX.NDS.128.66.0F3A.W1 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignq xmm {k1}{z}, xmm, xmm, imm8","EVEX.NDS.128.66.0F3A.W1 03 /r ib")]
        valignq_xmm_k1z_xmm_xmm_imm8 = 1931,

        /// <summary>
        /// valignq xmm, xmm, m128, imm8 | EVEX.NDS.128.66.0F3A.W1 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignq xmm, xmm, m128, imm8","EVEX.NDS.128.66.0F3A.W1 03 /r ib")]
        valignq_xmm_xmm_m128_imm8 = 1932,

        /// <summary>
        /// valignq xmm, xmm, m64bcst, imm8 | EVEX.NDS.128.66.0F3A.W1 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignq xmm, xmm, m64bcst, imm8","EVEX.NDS.128.66.0F3A.W1 03 /r ib")]
        valignq_xmm_xmm_m64bcst_imm8 = 1933,

        /// <summary>
        /// valignq xmm, xmm, xmm, imm8 | EVEX.NDS.128.66.0F3A.W1 03 /r ib | Shift right and merge vectors xmm2 and xmm3/m128/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.
        /// </summary>
        [Symbol("valignq xmm, xmm, xmm, imm8","EVEX.NDS.128.66.0F3A.W1 03 /r ib")]
        valignq_xmm_xmm_xmm_imm8 = 1934,

        /// <summary>
        /// valignq ymm {k1}{z}, ymm, m256, imm8 | EVEX.NDS.256.66.0F3A.W1 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignq ymm {k1}{z}, ymm, m256, imm8","EVEX.NDS.256.66.0F3A.W1 03 /r ib")]
        valignq_ymm_k1z_ymm_m256_imm8 = 1935,

        /// <summary>
        /// valignq ymm {k1}{z}, ymm, m64bcst, imm8 | EVEX.NDS.256.66.0F3A.W1 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignq ymm {k1}{z}, ymm, m64bcst, imm8","EVEX.NDS.256.66.0F3A.W1 03 /r ib")]
        valignq_ymm_k1z_ymm_m64bcst_imm8 = 1936,

        /// <summary>
        /// valignq ymm {k1}{z}, ymm, ymm, imm8 | EVEX.NDS.256.66.0F3A.W1 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignq ymm {k1}{z}, ymm, ymm, imm8","EVEX.NDS.256.66.0F3A.W1 03 /r ib")]
        valignq_ymm_k1z_ymm_ymm_imm8 = 1937,

        /// <summary>
        /// valignq ymm, ymm, m256, imm8 | EVEX.NDS.256.66.0F3A.W1 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignq ymm, ymm, m256, imm8","EVEX.NDS.256.66.0F3A.W1 03 /r ib")]
        valignq_ymm_ymm_m256_imm8 = 1938,

        /// <summary>
        /// valignq ymm, ymm, m64bcst, imm8 | EVEX.NDS.256.66.0F3A.W1 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignq ymm, ymm, m64bcst, imm8","EVEX.NDS.256.66.0F3A.W1 03 /r ib")]
        valignq_ymm_ymm_m64bcst_imm8 = 1939,

        /// <summary>
        /// valignq ymm, ymm, ymm, imm8 | EVEX.NDS.256.66.0F3A.W1 03 /r ib | Shift right and merge vectors ymm2 and ymm3/m256/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.
        /// </summary>
        [Symbol("valignq ymm, ymm, ymm, imm8","EVEX.NDS.256.66.0F3A.W1 03 /r ib")]
        valignq_ymm_ymm_ymm_imm8 = 1940,

        /// <summary>
        /// valignq zmm {k1}{z}, zmm, m512, imm8 | EVEX.NDS.512.66.0F3A.W1 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignq zmm {k1}{z}, zmm, m512, imm8","EVEX.NDS.512.66.0F3A.W1 03 /r ib")]
        valignq_zmm_k1z_zmm_m512_imm8 = 1941,

        /// <summary>
        /// valignq zmm {k1}{z}, zmm, m64bcst, imm8 | EVEX.NDS.512.66.0F3A.W1 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignq zmm {k1}{z}, zmm, m64bcst, imm8","EVEX.NDS.512.66.0F3A.W1 03 /r ib")]
        valignq_zmm_k1z_zmm_m64bcst_imm8 = 1942,

        /// <summary>
        /// valignq zmm {k1}{z}, zmm, zmm, imm8 | EVEX.NDS.512.66.0F3A.W1 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignq zmm {k1}{z}, zmm, zmm, imm8","EVEX.NDS.512.66.0F3A.W1 03 /r ib")]
        valignq_zmm_k1z_zmm_zmm_imm8 = 1943,

        /// <summary>
        /// valignq zmm, zmm, m512, imm8 | EVEX.NDS.512.66.0F3A.W1 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignq zmm, zmm, m512, imm8","EVEX.NDS.512.66.0F3A.W1 03 /r ib")]
        valignq_zmm_zmm_m512_imm8 = 1944,

        /// <summary>
        /// valignq zmm, zmm, m64bcst, imm8 | EVEX.NDS.512.66.0F3A.W1 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignq zmm, zmm, m64bcst, imm8","EVEX.NDS.512.66.0F3A.W1 03 /r ib")]
        valignq_zmm_zmm_m64bcst_imm8 = 1945,

        /// <summary>
        /// valignq zmm, zmm, zmm, imm8 | EVEX.NDS.512.66.0F3A.W1 03 /r ib | Shift right and merge vectors zmm2 and zmm3/m512/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.
        /// </summary>
        [Symbol("valignq zmm, zmm, zmm, imm8","EVEX.NDS.512.66.0F3A.W1 03 /r ib")]
        valignq_zmm_zmm_zmm_imm8 = 1946,

        /// <summary>
        /// vbroadcasti128 ymm, m128 | VEX.256.66.0F38.W0 5A /r | Broadcast 128 bits of integer data in mem to low and high 128-bits in ymm1.
        /// </summary>
        [Symbol("vbroadcasti128 ymm, m128","VEX.256.66.0F38.W0 5A /r")]
        vbroadcasti128_ymm_m128 = 1947,

        /// <summary>
        /// vbroadcasti32x2 xmm {k1}{z}, m64 | EVEX.128.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 xmm {k1}{z}, m64","EVEX.128.66.0F38.W0 59 /r")]
        vbroadcasti32x2_xmm_k1z_m64 = 1948,

        /// <summary>
        /// vbroadcasti32x2 xmm {k1}{z}, r8 | EVEX.128.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 xmm {k1}{z}, r8","EVEX.128.66.0F38.W0 59 /r")]
        vbroadcasti32x2_xmm_k1z_r8 = 1949,

        /// <summary>
        /// vbroadcasti32x2 xmm, m64 | EVEX.128.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 xmm, m64","EVEX.128.66.0F38.W0 59 /r")]
        vbroadcasti32x2_xmm_m64 = 1950,

        /// <summary>
        /// vbroadcasti32x2 xmm, r8 | EVEX.128.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 xmm, r8","EVEX.128.66.0F38.W0 59 /r")]
        vbroadcasti32x2_xmm_r8 = 1951,

        /// <summary>
        /// vbroadcasti32x2 ymm {k1}{z}, m64 | EVEX.256.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 ymm {k1}{z}, m64","EVEX.256.66.0F38.W0 59 /r")]
        vbroadcasti32x2_ymm_k1z_m64 = 1952,

        /// <summary>
        /// vbroadcasti32x2 ymm {k1}{z}, r8 | EVEX.256.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 ymm {k1}{z}, r8","EVEX.256.66.0F38.W0 59 /r")]
        vbroadcasti32x2_ymm_k1z_r8 = 1953,

        /// <summary>
        /// vbroadcasti32x2 ymm, m64 | EVEX.256.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 ymm, m64","EVEX.256.66.0F38.W0 59 /r")]
        vbroadcasti32x2_ymm_m64 = 1954,

        /// <summary>
        /// vbroadcasti32x2 ymm, r8 | EVEX.256.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 ymm, r8","EVEX.256.66.0F38.W0 59 /r")]
        vbroadcasti32x2_ymm_r8 = 1955,

        /// <summary>
        /// vbroadcasti32x2 zmm {k1}{z}, m64 | EVEX.512.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 zmm {k1}{z}, m64","EVEX.512.66.0F38.W0 59 /r")]
        vbroadcasti32x2_zmm_k1z_m64 = 1956,

        /// <summary>
        /// vbroadcasti32x2 zmm {k1}{z}, r8 | EVEX.512.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 zmm {k1}{z}, r8","EVEX.512.66.0F38.W0 59 /r")]
        vbroadcasti32x2_zmm_k1z_r8 = 1957,

        /// <summary>
        /// vbroadcasti32x2 zmm, m64 | EVEX.512.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 zmm, m64","EVEX.512.66.0F38.W0 59 /r")]
        vbroadcasti32x2_zmm_m64 = 1958,

        /// <summary>
        /// vbroadcasti32x2 zmm, r8 | EVEX.512.66.0F38.W0 59 /r | Broadcast two dword elements in source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x2 zmm, r8","EVEX.512.66.0F38.W0 59 /r")]
        vbroadcasti32x2_zmm_r8 = 1959,

        /// <summary>
        /// vbroadcasti32x4 ymm {k1}{z}, m128 | EVEX.256.66.0F38.W0 5A /r | Broadcast 128 bits of 4 doubleword integer data in mem to locations in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x4 ymm {k1}{z}, m128","EVEX.256.66.0F38.W0 5A /r")]
        vbroadcasti32x4_ymm_k1z_m128 = 1960,

        /// <summary>
        /// vbroadcasti32x4 ymm, m128 | EVEX.256.66.0F38.W0 5A /r | Broadcast 128 bits of 4 doubleword integer data in mem to locations in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x4 ymm, m128","EVEX.256.66.0F38.W0 5A /r")]
        vbroadcasti32x4_ymm_m128 = 1961,

        /// <summary>
        /// vbroadcasti32x4 zmm {k1}{z}, m128 | EVEX.512.66.0F38.W0 5A /r | Broadcast 128 bits of 4 doubleword integer data in mem to locations in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x4 zmm {k1}{z}, m128","EVEX.512.66.0F38.W0 5A /r")]
        vbroadcasti32x4_zmm_k1z_m128 = 1962,

        /// <summary>
        /// vbroadcasti32x4 zmm, m128 | EVEX.512.66.0F38.W0 5A /r | Broadcast 128 bits of 4 doubleword integer data in mem to locations in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x4 zmm, m128","EVEX.512.66.0F38.W0 5A /r")]
        vbroadcasti32x4_zmm_m128 = 1963,

        /// <summary>
        /// vbroadcasti32x8 zmm {k1}{z}, m256 | EVEX.512.66.0F38.W0 5B /r | Broadcast 256 bits of 8 doubleword integer data in mem to locations in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x8 zmm {k1}{z}, m256","EVEX.512.66.0F38.W0 5B /r")]
        vbroadcasti32x8_zmm_k1z_m256 = 1964,

        /// <summary>
        /// vbroadcasti32x8 zmm, m256 | EVEX.512.66.0F38.W0 5B /r | Broadcast 256 bits of 8 doubleword integer data in mem to locations in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti32x8 zmm, m256","EVEX.512.66.0F38.W0 5B /r")]
        vbroadcasti32x8_zmm_m256 = 1965,

        /// <summary>
        /// vbroadcasti64x2 ymm {k1}{z}, m128 | EVEX.256.66.0F38.W1 5A /r | Broadcast 128 bits of 2 quadword integer data in mem to locations in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti64x2 ymm {k1}{z}, m128","EVEX.256.66.0F38.W1 5A /r")]
        vbroadcasti64x2_ymm_k1z_m128 = 1966,

        /// <summary>
        /// vbroadcasti64x2 ymm, m128 | EVEX.256.66.0F38.W1 5A /r | Broadcast 128 bits of 2 quadword integer data in mem to locations in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti64x2 ymm, m128","EVEX.256.66.0F38.W1 5A /r")]
        vbroadcasti64x2_ymm_m128 = 1967,

        /// <summary>
        /// vbroadcasti64x2 zmm {k1}{z}, m128 | EVEX.512.66.0F38.W1 5A /r | Broadcast 128 bits of 2 quadword integer data in mem to locations in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti64x2 zmm {k1}{z}, m128","EVEX.512.66.0F38.W1 5A /r")]
        vbroadcasti64x2_zmm_k1z_m128 = 1968,

        /// <summary>
        /// vbroadcasti64x2 zmm, m128 | EVEX.512.66.0F38.W1 5A /r | Broadcast 128 bits of 2 quadword integer data in mem to locations in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti64x2 zmm, m128","EVEX.512.66.0F38.W1 5A /r")]
        vbroadcasti64x2_zmm_m128 = 1969,

        /// <summary>
        /// vbroadcasti64x4 zmm {k1}{z}, m256 | EVEX.512.66.0F38.W1 5B /r | Broadcast 256 bits of 4 quadword integer data in mem to locations in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti64x4 zmm {k1}{z}, m256","EVEX.512.66.0F38.W1 5B /r")]
        vbroadcasti64x4_zmm_k1z_m256 = 1970,

        /// <summary>
        /// vbroadcasti64x4 zmm, m256 | EVEX.512.66.0F38.W1 5B /r | Broadcast 256 bits of 4 quadword integer data in mem to locations in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vbroadcasti64x4 zmm, m256","EVEX.512.66.0F38.W1 5B /r")]
        vbroadcasti64x4_zmm_m256 = 1971,

        /// <summary>
        /// vcmpps k1 {k2}, xmm, m128, imm8 | EVEX.128.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in xmm3/m128/m32bcst and xmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1 {k2}, xmm, m128, imm8","EVEX.128.0F.W0 C2 /r ib")]
        vcmpps_k1_k2_xmm_m128_imm8 = 1972,

        /// <summary>
        /// vcmpps k1 {k2}, xmm, m32bcst, imm8 | EVEX.128.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in xmm3/m128/m32bcst and xmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1 {k2}, xmm, m32bcst, imm8","EVEX.128.0F.W0 C2 /r ib")]
        vcmpps_k1_k2_xmm_m32bcst_imm8 = 1973,

        /// <summary>
        /// vcmpps k1 {k2}, xmm, xmm, imm8 | EVEX.128.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in xmm3/m128/m32bcst and xmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1 {k2}, xmm, xmm, imm8","EVEX.128.0F.W0 C2 /r ib")]
        vcmpps_k1_k2_xmm_xmm_imm8 = 1974,

        /// <summary>
        /// vcmpps k1 {k2}, ymm, m256, imm8 | EVEX.256.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in ymm3/m256/m32bcst and ymm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1 {k2}, ymm, m256, imm8","EVEX.256.0F.W0 C2 /r ib")]
        vcmpps_k1_k2_ymm_m256_imm8 = 1975,

        /// <summary>
        /// vcmpps k1 {k2}, ymm, m32bcst, imm8 | EVEX.256.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in ymm3/m256/m32bcst and ymm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1 {k2}, ymm, m32bcst, imm8","EVEX.256.0F.W0 C2 /r ib")]
        vcmpps_k1_k2_ymm_m32bcst_imm8 = 1976,

        /// <summary>
        /// vcmpps k1 {k2}, ymm, ymm, imm8 | EVEX.256.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in ymm3/m256/m32bcst and ymm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1 {k2}, ymm, ymm, imm8","EVEX.256.0F.W0 C2 /r ib")]
        vcmpps_k1_k2_ymm_ymm_imm8 = 1977,

        /// <summary>
        /// vcmpps k1 {k2}, zmm, m32bcst {k1}, imm8 | EVEX.512.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in zmm3/m512/m32bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1 {k2}, zmm, m32bcst {k1}, imm8","EVEX.512.0F.W0 C2 /r ib")]
        vcmpps_k1_k2_zmm_m32bcst_k1_imm8 = 1978,

        /// <summary>
        /// vcmpps k1 {k2}, zmm, m512 {k1}, imm8 | EVEX.512.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in zmm3/m512/m32bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1 {k2}, zmm, m512 {k1}, imm8","EVEX.512.0F.W0 C2 /r ib")]
        vcmpps_k1_k2_zmm_m512_k1_imm8 = 1979,

        /// <summary>
        /// vcmpps k1 {k2}, zmm, zmm {k1}, imm8 | EVEX.512.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in zmm3/m512/m32bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1 {k2}, zmm, zmm {k1}, imm8","EVEX.512.0F.W0 C2 /r ib")]
        vcmpps_k1_k2_zmm_zmm_k1_imm8 = 1980,

        /// <summary>
        /// vcmpps k1, xmm, m128, imm8 | EVEX.128.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in xmm3/m128/m32bcst and xmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1, xmm, m128, imm8","EVEX.128.0F.W0 C2 /r ib")]
        vcmpps_k1_xmm_m128_imm8 = 1981,

        /// <summary>
        /// vcmpps k1, xmm, m32bcst, imm8 | EVEX.128.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in xmm3/m128/m32bcst and xmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1, xmm, m32bcst, imm8","EVEX.128.0F.W0 C2 /r ib")]
        vcmpps_k1_xmm_m32bcst_imm8 = 1982,

        /// <summary>
        /// vcmpps k1, xmm, xmm, imm8 | EVEX.128.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in xmm3/m128/m32bcst and xmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1, xmm, xmm, imm8","EVEX.128.0F.W0 C2 /r ib")]
        vcmpps_k1_xmm_xmm_imm8 = 1983,

        /// <summary>
        /// vcmpps k1, ymm, m256, imm8 | EVEX.256.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in ymm3/m256/m32bcst and ymm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1, ymm, m256, imm8","EVEX.256.0F.W0 C2 /r ib")]
        vcmpps_k1_ymm_m256_imm8 = 1984,

        /// <summary>
        /// vcmpps k1, ymm, m32bcst, imm8 | EVEX.256.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in ymm3/m256/m32bcst and ymm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1, ymm, m32bcst, imm8","EVEX.256.0F.W0 C2 /r ib")]
        vcmpps_k1_ymm_m32bcst_imm8 = 1985,

        /// <summary>
        /// vcmpps k1, ymm, ymm, imm8 | EVEX.256.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in ymm3/m256/m32bcst and ymm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1, ymm, ymm, imm8","EVEX.256.0F.W0 C2 /r ib")]
        vcmpps_k1_ymm_ymm_imm8 = 1986,

        /// <summary>
        /// vcmpps k1, zmm, m32bcst, imm8 | EVEX.512.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in zmm3/m512/m32bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1, zmm, m32bcst, imm8","EVEX.512.0F.W0 C2 /r ib")]
        vcmpps_k1_zmm_m32bcst_imm8 = 1987,

        /// <summary>
        /// vcmpps k1, zmm, m512, imm8 | EVEX.512.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in zmm3/m512/m32bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1, zmm, m512, imm8","EVEX.512.0F.W0 C2 /r ib")]
        vcmpps_k1_zmm_m512_imm8 = 1988,

        /// <summary>
        /// vcmpps k1, zmm, zmm, imm8 | EVEX.512.0F.W0 C2 /r ib | Compare packed single-precision floating-point values in zmm3/m512/m32bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpps k1, zmm, zmm, imm8","EVEX.512.0F.W0 C2 /r ib")]
        vcmpps_k1_zmm_zmm_imm8 = 1989,

        /// <summary>
        /// vcmpps xmm, xmm, m128, imm8 | VEX.128.0F.WIG C2 /r ib | Compare packed single-precision floating-point values in xmm3/m128 and xmm2 using bits 4:0 of imm8 as a comparison predicate.
        /// </summary>
        [Symbol("vcmpps xmm, xmm, m128, imm8","VEX.128.0F.WIG C2 /r ib")]
        vcmpps_xmm_xmm_m128_imm8 = 1990,

        /// <summary>
        /// vcmpps xmm, xmm, r8, imm8 | VEX.128.0F.WIG C2 /r ib | Compare packed single-precision floating-point values in xmm3/m128 and xmm2 using bits 4:0 of imm8 as a comparison predicate.
        /// </summary>
        [Symbol("vcmpps xmm, xmm, r8, imm8","VEX.128.0F.WIG C2 /r ib")]
        vcmpps_xmm_xmm_r8_imm8 = 1991,

        /// <summary>
        /// vcmpps ymm, ymm, m256, imm8 | VEX.256.0F.WIG C2 /r ib | Compare packed single-precision floating-point values in ymm3/m256 and ymm2 using bits 4:0 of imm8 as a comparison predicate.
        /// </summary>
        [Symbol("vcmpps ymm, ymm, m256, imm8","VEX.256.0F.WIG C2 /r ib")]
        vcmpps_ymm_ymm_m256_imm8 = 1992,

        /// <summary>
        /// vcmpps ymm, ymm, r16, imm8 | VEX.256.0F.WIG C2 /r ib | Compare packed single-precision floating-point values in ymm3/m256 and ymm2 using bits 4:0 of imm8 as a comparison predicate.
        /// </summary>
        [Symbol("vcmpps ymm, ymm, r16, imm8","VEX.256.0F.WIG C2 /r ib")]
        vcmpps_ymm_ymm_r16_imm8 = 1993,

        /// <summary>
        /// vcmpss k1 {k2}, xmm, m32 {k1}, imm8 | EVEX.LIG.F3.0F.W0 C2 /r ib | Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpss k1 {k2}, xmm, m32 {k1}, imm8","EVEX.LIG.F3.0F.W0 C2 /r ib")]
        vcmpss_k1_k2_xmm_m32_k1_imm8 = 1994,

        /// <summary>
        /// vcmpss k1 {k2}, xmm, r8 {k1}, imm8 | EVEX.LIG.F3.0F.W0 C2 /r ib | Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpss k1 {k2}, xmm, r8 {k1}, imm8","EVEX.LIG.F3.0F.W0 C2 /r ib")]
        vcmpss_k1_k2_xmm_r8_k1_imm8 = 1995,

        /// <summary>
        /// vcmpss k1, xmm, m32, imm8 | EVEX.LIG.F3.0F.W0 C2 /r ib | Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpss k1, xmm, m32, imm8","EVEX.LIG.F3.0F.W0 C2 /r ib")]
        vcmpss_k1_xmm_m32_imm8 = 1996,

        /// <summary>
        /// vcmpss k1, xmm, r8, imm8 | EVEX.LIG.F3.0F.W0 C2 /r ib | Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vcmpss k1, xmm, r8, imm8","EVEX.LIG.F3.0F.W0 C2 /r ib")]
        vcmpss_k1_xmm_r8_imm8 = 1997,

        /// <summary>
        /// vcmpss xmm, xmm, m32, imm8 | VEX.LIG.F3.0F.WIG C2 /r ib | Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate.
        /// </summary>
        [Symbol("vcmpss xmm, xmm, m32, imm8","VEX.LIG.F3.0F.WIG C2 /r ib")]
        vcmpss_xmm_xmm_m32_imm8 = 1998,

        /// <summary>
        /// vcmpss xmm, xmm, r8, imm8 | VEX.LIG.F3.0F.WIG C2 /r ib | Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate.
        /// </summary>
        [Symbol("vcmpss xmm, xmm, r8, imm8","VEX.LIG.F3.0F.WIG C2 /r ib")]
        vcmpss_xmm_xmm_r8_imm8 = 1999,

        /// <summary>
        /// vdbpsadbw xmm {k1}{z}, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from xmm2 with unsigned bytes of dword blocks transformed from xmm3/m128 using the shuffle controls in imm8. Results are written to xmm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw xmm {k1}{z}, xmm, m128, imm8","EVEX.128.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_xmm_k1z_xmm_m128_imm8 = 2000,

        /// <summary>
        /// vdbpsadbw xmm {k1}{z}, xmm, r8, imm8 | EVEX.128.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from xmm2 with unsigned bytes of dword blocks transformed from xmm3/m128 using the shuffle controls in imm8. Results are written to xmm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw xmm {k1}{z}, xmm, r8, imm8","EVEX.128.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_xmm_k1z_xmm_r8_imm8 = 2001,

        /// <summary>
        /// vdbpsadbw xmm, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from xmm2 with unsigned bytes of dword blocks transformed from xmm3/m128 using the shuffle controls in imm8. Results are written to xmm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw xmm, xmm, m128, imm8","EVEX.128.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_xmm_xmm_m128_imm8 = 2002,

        /// <summary>
        /// vdbpsadbw xmm, xmm, r8, imm8 | EVEX.128.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from xmm2 with unsigned bytes of dword blocks transformed from xmm3/m128 using the shuffle controls in imm8. Results are written to xmm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw xmm, xmm, r8, imm8","EVEX.128.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_xmm_xmm_r8_imm8 = 2003,

        /// <summary>
        /// vdbpsadbw ymm {k1}{z}, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from ymm2 with unsigned bytes of dword blocks transformed from ymm3/m256 using the shuffle controls in imm8. Results are written to ymm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw ymm {k1}{z}, ymm, m256, imm8","EVEX.256.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_ymm_k1z_ymm_m256_imm8 = 2004,

        /// <summary>
        /// vdbpsadbw ymm {k1}{z}, ymm, r16, imm8 | EVEX.256.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from ymm2 with unsigned bytes of dword blocks transformed from ymm3/m256 using the shuffle controls in imm8. Results are written to ymm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw ymm {k1}{z}, ymm, r16, imm8","EVEX.256.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_ymm_k1z_ymm_r16_imm8 = 2005,

        /// <summary>
        /// vdbpsadbw ymm, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from ymm2 with unsigned bytes of dword blocks transformed from ymm3/m256 using the shuffle controls in imm8. Results are written to ymm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw ymm, ymm, m256, imm8","EVEX.256.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_ymm_ymm_m256_imm8 = 2006,

        /// <summary>
        /// vdbpsadbw ymm, ymm, r16, imm8 | EVEX.256.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from ymm2 with unsigned bytes of dword blocks transformed from ymm3/m256 using the shuffle controls in imm8. Results are written to ymm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw ymm, ymm, r16, imm8","EVEX.256.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_ymm_ymm_r16_imm8 = 2007,

        /// <summary>
        /// vdbpsadbw zmm {k1}{z}, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from zmm2 with unsigned bytes of dword blocks transformed from zmm3/m512 using the shuffle controls in imm8. Results are written to zmm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw zmm {k1}{z}, zmm, m512, imm8","EVEX.512.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_zmm_k1z_zmm_m512_imm8 = 2008,

        /// <summary>
        /// vdbpsadbw zmm {k1}{z}, zmm, r32, imm8 | EVEX.512.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from zmm2 with unsigned bytes of dword blocks transformed from zmm3/m512 using the shuffle controls in imm8. Results are written to zmm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw zmm {k1}{z}, zmm, r32, imm8","EVEX.512.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_zmm_k1z_zmm_r32_imm8 = 2009,

        /// <summary>
        /// vdbpsadbw zmm, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from zmm2 with unsigned bytes of dword blocks transformed from zmm3/m512 using the shuffle controls in imm8. Results are written to zmm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw zmm, zmm, m512, imm8","EVEX.512.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_zmm_zmm_m512_imm8 = 2010,

        /// <summary>
        /// vdbpsadbw zmm, zmm, r32, imm8 | EVEX.512.66.0F3A.W0 42 /r ib | Compute packed SAD word results of unsigned bytes in dword block from zmm2 with unsigned bytes of dword blocks transformed from zmm3/m512 using the shuffle controls in imm8. Results are written to zmm1 under the writemask k1.
        /// </summary>
        [Symbol("vdbpsadbw zmm, zmm, r32, imm8","EVEX.512.66.0F3A.W0 42 /r ib")]
        vdbpsadbw_zmm_zmm_r32_imm8 = 2011,

        /// <summary>
        /// vextracti128 m128, ymm, imm8 | VEX.256.66.0F3A.W0 39 /r ib | Extract 128 bits of integer data from ymm2 and store results in xmm1/m128.
        /// </summary>
        [Symbol("vextracti128 m128, ymm, imm8","VEX.256.66.0F3A.W0 39 /r ib")]
        vextracti128_m128_ymm_imm8 = 2012,

        /// <summary>
        /// vextracti128 r8, ymm, imm8 | VEX.256.66.0F3A.W0 39 /r ib | Extract 128 bits of integer data from ymm2 and store results in xmm1/m128.
        /// </summary>
        [Symbol("vextracti128 r8, ymm, imm8","VEX.256.66.0F3A.W0 39 /r ib")]
        vextracti128_r8_ymm_imm8 = 2013,

        /// <summary>
        /// vextracti32x4 m128 {k1}{z}, ymm, imm8 | EVEX.256.66.0F3A.W0 39 /r ib | Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x4 m128 {k1}{z}, ymm, imm8","EVEX.256.66.0F3A.W0 39 /r ib")]
        vextracti32x4_m128_k1z_ymm_imm8 = 2014,

        /// <summary>
        /// vextracti32x4 m128 {k1}{z}, zmm, imm8 | EVEX.512.66.0F3A.W0 39 /r ib | Extract 128 bits of double-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x4 m128 {k1}{z}, zmm, imm8","EVEX.512.66.0F3A.W0 39 /r ib")]
        vextracti32x4_m128_k1z_zmm_imm8 = 2015,

        /// <summary>
        /// vextracti32x4 m128, ymm, imm8 | EVEX.256.66.0F3A.W0 39 /r ib | Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x4 m128, ymm, imm8","EVEX.256.66.0F3A.W0 39 /r ib")]
        vextracti32x4_m128_ymm_imm8 = 2016,

        /// <summary>
        /// vextracti32x4 m128, zmm, imm8 | EVEX.512.66.0F3A.W0 39 /r ib | Extract 128 bits of double-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x4 m128, zmm, imm8","EVEX.512.66.0F3A.W0 39 /r ib")]
        vextracti32x4_m128_zmm_imm8 = 2017,

        /// <summary>
        /// vextracti32x4 r8 {k1}{z}, ymm, imm8 | EVEX.256.66.0F3A.W0 39 /r ib | Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x4 r8 {k1}{z}, ymm, imm8","EVEX.256.66.0F3A.W0 39 /r ib")]
        vextracti32x4_r8_k1z_ymm_imm8 = 2018,

        /// <summary>
        /// vextracti32x4 r8 {k1}{z}, zmm, imm8 | EVEX.512.66.0F3A.W0 39 /r ib | Extract 128 bits of double-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x4 r8 {k1}{z}, zmm, imm8","EVEX.512.66.0F3A.W0 39 /r ib")]
        vextracti32x4_r8_k1z_zmm_imm8 = 2019,

        /// <summary>
        /// vextracti32x4 r8, ymm, imm8 | EVEX.256.66.0F3A.W0 39 /r ib | Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x4 r8, ymm, imm8","EVEX.256.66.0F3A.W0 39 /r ib")]
        vextracti32x4_r8_ymm_imm8 = 2020,

        /// <summary>
        /// vextracti32x4 r8, zmm, imm8 | EVEX.512.66.0F3A.W0 39 /r ib | Extract 128 bits of double-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x4 r8, zmm, imm8","EVEX.512.66.0F3A.W0 39 /r ib")]
        vextracti32x4_r8_zmm_imm8 = 2021,

        /// <summary>
        /// vextracti32x8 m256 {k1}{z}, zmm, imm8 | EVEX.512.66.0F3A.W0 3B /r ib | Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x8 m256 {k1}{z}, zmm, imm8","EVEX.512.66.0F3A.W0 3B /r ib")]
        vextracti32x8_m256_k1z_zmm_imm8 = 2022,

        /// <summary>
        /// vextracti32x8 m256, zmm, imm8 | EVEX.512.66.0F3A.W0 3B /r ib | Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x8 m256, zmm, imm8","EVEX.512.66.0F3A.W0 3B /r ib")]
        vextracti32x8_m256_zmm_imm8 = 2023,

        /// <summary>
        /// vextracti32x8 r16 {k1}{z}, zmm, imm8 | EVEX.512.66.0F3A.W0 3B /r ib | Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x8 r16 {k1}{z}, zmm, imm8","EVEX.512.66.0F3A.W0 3B /r ib")]
        vextracti32x8_r16_k1z_zmm_imm8 = 2024,

        /// <summary>
        /// vextracti32x8 r16, zmm, imm8 | EVEX.512.66.0F3A.W0 3B /r ib | Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti32x8 r16, zmm, imm8","EVEX.512.66.0F3A.W0 3B /r ib")]
        vextracti32x8_r16_zmm_imm8 = 2025,

        /// <summary>
        /// vextracti64x2 m128 {k1}{z}, ymm, imm8 | EVEX.256.66.0F3A.W1 39 /r ib | Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x2 m128 {k1}{z}, ymm, imm8","EVEX.256.66.0F3A.W1 39 /r ib")]
        vextracti64x2_m128_k1z_ymm_imm8 = 2026,

        /// <summary>
        /// vextracti64x2 m128 {k1}{z}, zmm, imm8 | EVEX.512.66.0F3A.W1 39 /r ib | Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x2 m128 {k1}{z}, zmm, imm8","EVEX.512.66.0F3A.W1 39 /r ib")]
        vextracti64x2_m128_k1z_zmm_imm8 = 2027,

        /// <summary>
        /// vextracti64x2 m128, ymm, imm8 | EVEX.256.66.0F3A.W1 39 /r ib | Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x2 m128, ymm, imm8","EVEX.256.66.0F3A.W1 39 /r ib")]
        vextracti64x2_m128_ymm_imm8 = 2028,

        /// <summary>
        /// vextracti64x2 m128, zmm, imm8 | EVEX.512.66.0F3A.W1 39 /r ib | Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x2 m128, zmm, imm8","EVEX.512.66.0F3A.W1 39 /r ib")]
        vextracti64x2_m128_zmm_imm8 = 2029,

        /// <summary>
        /// vextracti64x2 r8 {k1}{z}, ymm, imm8 | EVEX.256.66.0F3A.W1 39 /r ib | Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x2 r8 {k1}{z}, ymm, imm8","EVEX.256.66.0F3A.W1 39 /r ib")]
        vextracti64x2_r8_k1z_ymm_imm8 = 2030,

        /// <summary>
        /// vextracti64x2 r8 {k1}{z}, zmm, imm8 | EVEX.512.66.0F3A.W1 39 /r ib | Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x2 r8 {k1}{z}, zmm, imm8","EVEX.512.66.0F3A.W1 39 /r ib")]
        vextracti64x2_r8_k1z_zmm_imm8 = 2031,

        /// <summary>
        /// vextracti64x2 r8, ymm, imm8 | EVEX.256.66.0F3A.W1 39 /r ib | Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x2 r8, ymm, imm8","EVEX.256.66.0F3A.W1 39 /r ib")]
        vextracti64x2_r8_ymm_imm8 = 2032,

        /// <summary>
        /// vextracti64x2 r8, zmm, imm8 | EVEX.512.66.0F3A.W1 39 /r ib | Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x2 r8, zmm, imm8","EVEX.512.66.0F3A.W1 39 /r ib")]
        vextracti64x2_r8_zmm_imm8 = 2033,

        /// <summary>
        /// vextracti64x4 m256 {k1}{z}, zmm, imm8 | EVEX.512.66.0F3A.W1 3B /r ib | Extract 256 bits of quad-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x4 m256 {k1}{z}, zmm, imm8","EVEX.512.66.0F3A.W1 3B /r ib")]
        vextracti64x4_m256_k1z_zmm_imm8 = 2034,

        /// <summary>
        /// vextracti64x4 m256, zmm, imm8 | EVEX.512.66.0F3A.W1 3B /r ib | Extract 256 bits of quad-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x4 m256, zmm, imm8","EVEX.512.66.0F3A.W1 3B /r ib")]
        vextracti64x4_m256_zmm_imm8 = 2035,

        /// <summary>
        /// vextracti64x4 r16 {k1}{z}, zmm, imm8 | EVEX.512.66.0F3A.W1 3B /r ib | Extract 256 bits of quad-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x4 r16 {k1}{z}, zmm, imm8","EVEX.512.66.0F3A.W1 3B /r ib")]
        vextracti64x4_r16_k1z_zmm_imm8 = 2036,

        /// <summary>
        /// vextracti64x4 r16, zmm, imm8 | EVEX.512.66.0F3A.W1 3B /r ib | Extract 256 bits of quad-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.
        /// </summary>
        [Symbol("vextracti64x4 r16, zmm, imm8","EVEX.512.66.0F3A.W1 3B /r ib")]
        vextracti64x4_r16_zmm_imm8 = 2037,

        /// <summary>
        /// vinserti128 ymm, ymm, m128, imm8 | VEX.256.66.0F3A.W0 38 /r ib | Insert 128 bits of integer data from xmm3/m128 and the remaining values from ymm2 into ymm1.
        /// </summary>
        [Symbol("vinserti128 ymm, ymm, m128, imm8","VEX.256.66.0F3A.W0 38 /r ib")]
        vinserti128_ymm_ymm_m128_imm8 = 2038,

        /// <summary>
        /// vinserti128 ymm, ymm, r8, imm8 | VEX.256.66.0F3A.W0 38 /r ib | Insert 128 bits of integer data from xmm3/m128 and the remaining values from ymm2 into ymm1.
        /// </summary>
        [Symbol("vinserti128 ymm, ymm, r8, imm8","VEX.256.66.0F3A.W0 38 /r ib")]
        vinserti128_ymm_ymm_r8_imm8 = 2039,

        /// <summary>
        /// vinserti32x4 ymm {k1}{z}, ymm, m128, imm8 | EVEX.256.66.0F3A.W0 38 /r ib | Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x4 ymm {k1}{z}, ymm, m128, imm8","EVEX.256.66.0F3A.W0 38 /r ib")]
        vinserti32x4_ymm_k1z_ymm_m128_imm8 = 2040,

        /// <summary>
        /// vinserti32x4 ymm {k1}{z}, ymm, r8, imm8 | EVEX.256.66.0F3A.W0 38 /r ib | Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x4 ymm {k1}{z}, ymm, r8, imm8","EVEX.256.66.0F3A.W0 38 /r ib")]
        vinserti32x4_ymm_k1z_ymm_r8_imm8 = 2041,

        /// <summary>
        /// vinserti32x4 ymm, ymm, m128, imm8 | EVEX.256.66.0F3A.W0 38 /r ib | Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x4 ymm, ymm, m128, imm8","EVEX.256.66.0F3A.W0 38 /r ib")]
        vinserti32x4_ymm_ymm_m128_imm8 = 2042,

        /// <summary>
        /// vinserti32x4 ymm, ymm, r8, imm8 | EVEX.256.66.0F3A.W0 38 /r ib | Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x4 ymm, ymm, r8, imm8","EVEX.256.66.0F3A.W0 38 /r ib")]
        vinserti32x4_ymm_ymm_r8_imm8 = 2043,

        /// <summary>
        /// vinserti32x4 zmm {k1}{z}, zmm, m128, imm8 | EVEX.512.66.0F3A.W0 38 /r ib | Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x4 zmm {k1}{z}, zmm, m128, imm8","EVEX.512.66.0F3A.W0 38 /r ib")]
        vinserti32x4_zmm_k1z_zmm_m128_imm8 = 2044,

        /// <summary>
        /// vinserti32x4 zmm {k1}{z}, zmm, r8, imm8 | EVEX.512.66.0F3A.W0 38 /r ib | Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x4 zmm {k1}{z}, zmm, r8, imm8","EVEX.512.66.0F3A.W0 38 /r ib")]
        vinserti32x4_zmm_k1z_zmm_r8_imm8 = 2045,

        /// <summary>
        /// vinserti32x4 zmm, zmm, m128, imm8 | EVEX.512.66.0F3A.W0 38 /r ib | Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x4 zmm, zmm, m128, imm8","EVEX.512.66.0F3A.W0 38 /r ib")]
        vinserti32x4_zmm_zmm_m128_imm8 = 2046,

        /// <summary>
        /// vinserti32x4 zmm, zmm, r8, imm8 | EVEX.512.66.0F3A.W0 38 /r ib | Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x4 zmm, zmm, r8, imm8","EVEX.512.66.0F3A.W0 38 /r ib")]
        vinserti32x4_zmm_zmm_r8_imm8 = 2047,

        /// <summary>
        /// vinserti32x8 zmm {k1}{z}, zmm, m256, imm8 | EVEX.512.66.0F3A.W0 3A /r ib | Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x8 zmm {k1}{z}, zmm, m256, imm8","EVEX.512.66.0F3A.W0 3A /r ib")]
        vinserti32x8_zmm_k1z_zmm_m256_imm8 = 2048,

        /// <summary>
        /// vinserti32x8 zmm {k1}{z}, zmm, r16, imm8 | EVEX.512.66.0F3A.W0 3A /r ib | Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x8 zmm {k1}{z}, zmm, r16, imm8","EVEX.512.66.0F3A.W0 3A /r ib")]
        vinserti32x8_zmm_k1z_zmm_r16_imm8 = 2049,

        /// <summary>
        /// vinserti32x8 zmm, zmm, m256, imm8 | EVEX.512.66.0F3A.W0 3A /r ib | Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x8 zmm, zmm, m256, imm8","EVEX.512.66.0F3A.W0 3A /r ib")]
        vinserti32x8_zmm_zmm_m256_imm8 = 2050,

        /// <summary>
        /// vinserti32x8 zmm, zmm, r16, imm8 | EVEX.512.66.0F3A.W0 3A /r ib | Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti32x8 zmm, zmm, r16, imm8","EVEX.512.66.0F3A.W0 3A /r ib")]
        vinserti32x8_zmm_zmm_r16_imm8 = 2051,

        /// <summary>
        /// vinserti64x2 ymm {k1}{z}, ymm, m128, imm8 | EVEX.256.66.0F3A.W1 38 /r ib | Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x2 ymm {k1}{z}, ymm, m128, imm8","EVEX.256.66.0F3A.W1 38 /r ib")]
        vinserti64x2_ymm_k1z_ymm_m128_imm8 = 2052,

        /// <summary>
        /// vinserti64x2 ymm {k1}{z}, ymm, r8, imm8 | EVEX.256.66.0F3A.W1 38 /r ib | Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x2 ymm {k1}{z}, ymm, r8, imm8","EVEX.256.66.0F3A.W1 38 /r ib")]
        vinserti64x2_ymm_k1z_ymm_r8_imm8 = 2053,

        /// <summary>
        /// vinserti64x2 ymm, ymm, m128, imm8 | EVEX.256.66.0F3A.W1 38 /r ib | Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x2 ymm, ymm, m128, imm8","EVEX.256.66.0F3A.W1 38 /r ib")]
        vinserti64x2_ymm_ymm_m128_imm8 = 2054,

        /// <summary>
        /// vinserti64x2 ymm, ymm, r8, imm8 | EVEX.256.66.0F3A.W1 38 /r ib | Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x2 ymm, ymm, r8, imm8","EVEX.256.66.0F3A.W1 38 /r ib")]
        vinserti64x2_ymm_ymm_r8_imm8 = 2055,

        /// <summary>
        /// vinserti64x2 zmm {k1}{z}, zmm, m128, imm8 | EVEX.512.66.0F3A.W1 38 /r ib | Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x2 zmm {k1}{z}, zmm, m128, imm8","EVEX.512.66.0F3A.W1 38 /r ib")]
        vinserti64x2_zmm_k1z_zmm_m128_imm8 = 2056,

        /// <summary>
        /// vinserti64x2 zmm {k1}{z}, zmm, r8, imm8 | EVEX.512.66.0F3A.W1 38 /r ib | Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x2 zmm {k1}{z}, zmm, r8, imm8","EVEX.512.66.0F3A.W1 38 /r ib")]
        vinserti64x2_zmm_k1z_zmm_r8_imm8 = 2057,

        /// <summary>
        /// vinserti64x2 zmm, zmm, m128, imm8 | EVEX.512.66.0F3A.W1 38 /r ib | Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x2 zmm, zmm, m128, imm8","EVEX.512.66.0F3A.W1 38 /r ib")]
        vinserti64x2_zmm_zmm_m128_imm8 = 2058,

        /// <summary>
        /// vinserti64x2 zmm, zmm, r8, imm8 | EVEX.512.66.0F3A.W1 38 /r ib | Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x2 zmm, zmm, r8, imm8","EVEX.512.66.0F3A.W1 38 /r ib")]
        vinserti64x2_zmm_zmm_r8_imm8 = 2059,

        /// <summary>
        /// vinserti64x4 zmm {k1}{z}, zmm, m256, imm8 | EVEX.512.66.0F3A.W1 3A /r ib | Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x4 zmm {k1}{z}, zmm, m256, imm8","EVEX.512.66.0F3A.W1 3A /r ib")]
        vinserti64x4_zmm_k1z_zmm_m256_imm8 = 2060,

        /// <summary>
        /// vinserti64x4 zmm {k1}{z}, zmm, r16, imm8 | EVEX.512.66.0F3A.W1 3A /r ib | Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x4 zmm {k1}{z}, zmm, r16, imm8","EVEX.512.66.0F3A.W1 3A /r ib")]
        vinserti64x4_zmm_k1z_zmm_r16_imm8 = 2061,

        /// <summary>
        /// vinserti64x4 zmm, zmm, m256, imm8 | EVEX.512.66.0F3A.W1 3A /r ib | Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x4 zmm, zmm, m256, imm8","EVEX.512.66.0F3A.W1 3A /r ib")]
        vinserti64x4_zmm_zmm_m256_imm8 = 2062,

        /// <summary>
        /// vinserti64x4 zmm, zmm, r16, imm8 | EVEX.512.66.0F3A.W1 3A /r ib | Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.
        /// </summary>
        [Symbol("vinserti64x4 zmm, zmm, r16, imm8","EVEX.512.66.0F3A.W1 3A /r ib")]
        vinserti64x4_zmm_zmm_r16_imm8 = 2063,

        /// <summary>
        /// vlddqu xmm, m128 | VEX.128.F2.0F.WIG F0 /r | Load unaligned packed integer values from mem to xmm1.
        /// </summary>
        [Symbol("vlddqu xmm, m128","VEX.128.F2.0F.WIG F0 /r")]
        vlddqu_xmm_m128 = 2064,

        /// <summary>
        /// vlddqu ymm, m256 | VEX.256.F2.0F.WIG F0 /r | Load unaligned packed integer values from mem to ymm1.
        /// </summary>
        [Symbol("vlddqu ymm, m256","VEX.256.F2.0F.WIG F0 /r")]
        vlddqu_ymm_m256 = 2065,

        /// <summary>
        /// vmaskmovdqu xmm, xmm | VEX.128.66.0F.WIG F7 /r | Selectively write bytes from xmm1 to memory location using the byte mask in xmm2. The default memory location is specified by DS:DI/EDI/RDI.
        /// </summary>
        [Symbol("vmaskmovdqu xmm, xmm","VEX.128.66.0F.WIG F7 /r")]
        vmaskmovdqu_xmm_xmm = 2066,

        /// <summary>
        /// vmaskmovpd m128, xmm, xmm | VEX.128.66.0F38.W0 2F /r | Conditionally store packed double-precision values from xmm2 using mask in xmm1.
        /// </summary>
        [Symbol("vmaskmovpd m128, xmm, xmm","VEX.128.66.0F38.W0 2F /r")]
        vmaskmovpd_m128_xmm_xmm = 2067,

        /// <summary>
        /// vmaskmovpd m256, ymm, ymm | VEX.256.66.0F38.W0 2F /r | Conditionally store packed double-precision values from ymm2 using mask in ymm1.
        /// </summary>
        [Symbol("vmaskmovpd m256, ymm, ymm","VEX.256.66.0F38.W0 2F /r")]
        vmaskmovpd_m256_ymm_ymm = 2068,

        /// <summary>
        /// vmaskmovpd xmm, xmm, m128 | VEX.128.66.0F38.W0 2D /r | Conditionally load packed double-precision values from m128 using mask in xmm2 and store in xmm1.
        /// </summary>
        [Symbol("vmaskmovpd xmm, xmm, m128","VEX.128.66.0F38.W0 2D /r")]
        vmaskmovpd_xmm_xmm_m128 = 2069,

        /// <summary>
        /// vmaskmovpd ymm, ymm, m256 | VEX.256.66.0F38.W0 2D /r | Conditionally load packed double-precision values from m256 using mask in ymm2 and store in ymm1.
        /// </summary>
        [Symbol("vmaskmovpd ymm, ymm, m256","VEX.256.66.0F38.W0 2D /r")]
        vmaskmovpd_ymm_ymm_m256 = 2070,

        /// <summary>
        /// vmaskmovps m128, xmm, xmm | VEX.128.66.0F38.W0 2E /r | Conditionally store packed single-precision values from xmm2 using mask in xmm1.
        /// </summary>
        [Symbol("vmaskmovps m128, xmm, xmm","VEX.128.66.0F38.W0 2E /r")]
        vmaskmovps_m128_xmm_xmm = 2071,

        /// <summary>
        /// vmaskmovps m256, ymm, ymm | VEX.256.66.0F38.W0 2E /r | Conditionally store packed single-precision values from ymm2 using mask in ymm1.
        /// </summary>
        [Symbol("vmaskmovps m256, ymm, ymm","VEX.256.66.0F38.W0 2E /r")]
        vmaskmovps_m256_ymm_ymm = 2072,

        /// <summary>
        /// vmaskmovps xmm, xmm, m128 | VEX.128.66.0F38.W0 2C /r | Conditionally load packed single-precision values from m128 using mask in xmm2 and store in xmm1.
        /// </summary>
        [Symbol("vmaskmovps xmm, xmm, m128","VEX.128.66.0F38.W0 2C /r")]
        vmaskmovps_xmm_xmm_m128 = 2073,

        /// <summary>
        /// vmaskmovps ymm, ymm, m256 | VEX.256.66.0F38.W0 2C /r | Conditionally load packed single-precision values from m256 using mask in ymm2 and store in ymm1.
        /// </summary>
        [Symbol("vmaskmovps ymm, ymm, m256","VEX.256.66.0F38.W0 2C /r")]
        vmaskmovps_ymm_ymm_m256 = 2074,

        /// <summary>
        /// vmovapd m128 {k1}{z}, xmm | EVEX.128.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovapd m128 {k1}{z}, xmm","EVEX.128.66.0F.W1 29 /r")]
        vmovapd_m128_k1z_xmm = 2075,

        /// <summary>
        /// vmovapd m128, xmm | EVEX.128.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovapd m128, xmm","EVEX.128.66.0F.W1 29 /r")]
        vmovapd_m128_xmm = 2076,

        /// <summary>
        /// vmovapd m128, xmm | VEX.128.66.0F.WIG 29 /r | Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("vmovapd m128, xmm","VEX.128.66.0F.WIG 29 /r")]
        vmovapd_m128_xmm_vex = 2077,

        /// <summary>
        /// vmovapd m256 {k1}{z}, ymm | EVEX.256.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovapd m256 {k1}{z}, ymm","EVEX.256.66.0F.W1 29 /r")]
        vmovapd_m256_k1z_ymm = 2078,

        /// <summary>
        /// vmovapd m256, ymm | EVEX.256.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovapd m256, ymm","EVEX.256.66.0F.W1 29 /r")]
        vmovapd_m256_ymm = 2079,

        /// <summary>
        /// vmovapd m256, ymm | VEX.256.66.0F.WIG 29 /r | Move aligned packed double-precision floating-point values from ymm1 to ymm2/mem.
        /// </summary>
        [Symbol("vmovapd m256, ymm","VEX.256.66.0F.WIG 29 /r")]
        vmovapd_m256_ymm_vex = 2080,

        /// <summary>
        /// vmovapd m512 {k1}{z}, zmm | EVEX.512.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovapd m512 {k1}{z}, zmm","EVEX.512.66.0F.W1 29 /r")]
        vmovapd_m512_k1z_zmm = 2081,

        /// <summary>
        /// vmovapd m512, zmm | EVEX.512.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovapd m512, zmm","EVEX.512.66.0F.W1 29 /r")]
        vmovapd_m512_zmm = 2082,

        /// <summary>
        /// vmovapd r16 {k1}{z}, ymm | EVEX.256.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovapd r16 {k1}{z}, ymm","EVEX.256.66.0F.W1 29 /r")]
        vmovapd_r16_k1z_ymm = 2083,

        /// <summary>
        /// vmovapd r16, ymm | EVEX.256.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovapd r16, ymm","EVEX.256.66.0F.W1 29 /r")]
        vmovapd_r16_ymm = 2084,

        /// <summary>
        /// vmovapd r16, ymm | VEX.256.66.0F.WIG 29 /r | Move aligned packed double-precision floating-point values from ymm1 to ymm2/mem.
        /// </summary>
        [Symbol("vmovapd r16, ymm","VEX.256.66.0F.WIG 29 /r")]
        vmovapd_r16_ymm_vex = 2085,

        /// <summary>
        /// vmovapd r32 {k1}{z}, zmm | EVEX.512.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovapd r32 {k1}{z}, zmm","EVEX.512.66.0F.W1 29 /r")]
        vmovapd_r32_k1z_zmm = 2086,

        /// <summary>
        /// vmovapd r32, zmm | EVEX.512.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovapd r32, zmm","EVEX.512.66.0F.W1 29 /r")]
        vmovapd_r32_zmm = 2087,

        /// <summary>
        /// vmovapd r8 {k1}{z}, xmm | EVEX.128.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovapd r8 {k1}{z}, xmm","EVEX.128.66.0F.W1 29 /r")]
        vmovapd_r8_k1z_xmm = 2088,

        /// <summary>
        /// vmovapd r8, xmm | EVEX.128.66.0F.W1 29 /r | Move aligned packed double-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovapd r8, xmm","EVEX.128.66.0F.W1 29 /r")]
        vmovapd_r8_xmm = 2089,

        /// <summary>
        /// vmovapd r8, xmm | VEX.128.66.0F.WIG 29 /r | Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("vmovapd r8, xmm","VEX.128.66.0F.WIG 29 /r")]
        vmovapd_r8_xmm_vex = 2090,

        /// <summary>
        /// vmovapd xmm {k1}{z}, m128 | EVEX.128.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd xmm {k1}{z}, m128","EVEX.128.66.0F.W1 28 /r")]
        vmovapd_xmm_k1z_m128 = 2091,

        /// <summary>
        /// vmovapd xmm {k1}{z}, r8 | EVEX.128.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd xmm {k1}{z}, r8","EVEX.128.66.0F.W1 28 /r")]
        vmovapd_xmm_k1z_r8 = 2092,

        /// <summary>
        /// vmovapd xmm, m128 | EVEX.128.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd xmm, m128","EVEX.128.66.0F.W1 28 /r")]
        vmovapd_xmm_m128 = 2093,

        /// <summary>
        /// vmovapd xmm, m128 | VEX.128.66.0F.WIG 28 /r | Move aligned packed double-precision floating-point values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("vmovapd xmm, m128","VEX.128.66.0F.WIG 28 /r")]
        vmovapd_xmm_m128_vex = 2094,

        /// <summary>
        /// vmovapd xmm, r8 | EVEX.128.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd xmm, r8","EVEX.128.66.0F.W1 28 /r")]
        vmovapd_xmm_r8 = 2095,

        /// <summary>
        /// vmovapd xmm, r8 | VEX.128.66.0F.WIG 28 /r | Move aligned packed double-precision floating-point values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("vmovapd xmm, r8","VEX.128.66.0F.WIG 28 /r")]
        vmovapd_xmm_r8_vex = 2096,

        /// <summary>
        /// vmovapd ymm {k1}{z}, m256 | EVEX.256.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd ymm {k1}{z}, m256","EVEX.256.66.0F.W1 28 /r")]
        vmovapd_ymm_k1z_m256 = 2097,

        /// <summary>
        /// vmovapd ymm {k1}{z}, r16 | EVEX.256.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd ymm {k1}{z}, r16","EVEX.256.66.0F.W1 28 /r")]
        vmovapd_ymm_k1z_r16 = 2098,

        /// <summary>
        /// vmovapd ymm, m256 | EVEX.256.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd ymm, m256","EVEX.256.66.0F.W1 28 /r")]
        vmovapd_ymm_m256 = 2099,

        /// <summary>
        /// vmovapd ymm, m256 | VEX.256.66.0F.WIG 28 /r | Move aligned packed double-precision floating-point values from ymm2/mem to ymm1.
        /// </summary>
        [Symbol("vmovapd ymm, m256","VEX.256.66.0F.WIG 28 /r")]
        vmovapd_ymm_m256_vex = 2100,

        /// <summary>
        /// vmovapd ymm, r16 | EVEX.256.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd ymm, r16","EVEX.256.66.0F.W1 28 /r")]
        vmovapd_ymm_r16 = 2101,

        /// <summary>
        /// vmovapd ymm, r16 | VEX.256.66.0F.WIG 28 /r | Move aligned packed double-precision floating-point values from ymm2/mem to ymm1.
        /// </summary>
        [Symbol("vmovapd ymm, r16","VEX.256.66.0F.WIG 28 /r")]
        vmovapd_ymm_r16_vex = 2102,

        /// <summary>
        /// vmovapd zmm {k1}{z}, m512 | EVEX.512.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd zmm {k1}{z}, m512","EVEX.512.66.0F.W1 28 /r")]
        vmovapd_zmm_k1z_m512 = 2103,

        /// <summary>
        /// vmovapd zmm {k1}{z}, r32 | EVEX.512.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd zmm {k1}{z}, r32","EVEX.512.66.0F.W1 28 /r")]
        vmovapd_zmm_k1z_r32 = 2104,

        /// <summary>
        /// vmovapd zmm, m512 | EVEX.512.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd zmm, m512","EVEX.512.66.0F.W1 28 /r")]
        vmovapd_zmm_m512 = 2105,

        /// <summary>
        /// vmovapd zmm, r32 | EVEX.512.66.0F.W1 28 /r | Move aligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovapd zmm, r32","EVEX.512.66.0F.W1 28 /r")]
        vmovapd_zmm_r32 = 2106,

        /// <summary>
        /// vmovaps m128 {k1}{z}, xmm | EVEX.128.0F.W0 29 /r | Move aligned packed single-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovaps m128 {k1}{z}, xmm","EVEX.128.0F.W0 29 /r")]
        vmovaps_m128_k1z_xmm = 2107,

        /// <summary>
        /// vmovaps m128, xmm | EVEX.128.0F.W0 29 /r | Move aligned packed single-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovaps m128, xmm","EVEX.128.0F.W0 29 /r")]
        vmovaps_m128_xmm = 2108,

        /// <summary>
        /// vmovaps m128, xmm | VEX.128.0F.WIG 29 /r | Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("vmovaps m128, xmm","VEX.128.0F.WIG 29 /r")]
        vmovaps_m128_xmm_vex = 2109,

        /// <summary>
        /// vmovaps m256 {k1}{z}, ymm | EVEX.256.0F.W0 29 /r | Move aligned packed single-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovaps m256 {k1}{z}, ymm","EVEX.256.0F.W0 29 /r")]
        vmovaps_m256_k1z_ymm = 2110,

        /// <summary>
        /// vmovaps m256, ymm | EVEX.256.0F.W0 29 /r | Move aligned packed single-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovaps m256, ymm","EVEX.256.0F.W0 29 /r")]
        vmovaps_m256_ymm = 2111,

        /// <summary>
        /// vmovaps m256, ymm | VEX.256.0F.WIG 29 /r | Move aligned packed single-precision floating-point values from ymm1 to ymm2/mem.
        /// </summary>
        [Symbol("vmovaps m256, ymm","VEX.256.0F.WIG 29 /r")]
        vmovaps_m256_ymm_vex = 2112,

        /// <summary>
        /// vmovaps m512 {k1}{z}, zmm | EVEX.512.0F.W0 29 /r | Move aligned packed single-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovaps m512 {k1}{z}, zmm","EVEX.512.0F.W0 29 /r")]
        vmovaps_m512_k1z_zmm = 2113,

        /// <summary>
        /// vmovaps m512, zmm | EVEX.512.0F.W0 29 /r | Move aligned packed single-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovaps m512, zmm","EVEX.512.0F.W0 29 /r")]
        vmovaps_m512_zmm = 2114,

        /// <summary>
        /// vmovaps r16 {k1}{z}, ymm | EVEX.256.0F.W0 29 /r | Move aligned packed single-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovaps r16 {k1}{z}, ymm","EVEX.256.0F.W0 29 /r")]
        vmovaps_r16_k1z_ymm = 2115,

        /// <summary>
        /// vmovaps r16, ymm | EVEX.256.0F.W0 29 /r | Move aligned packed single-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovaps r16, ymm","EVEX.256.0F.W0 29 /r")]
        vmovaps_r16_ymm = 2116,

        /// <summary>
        /// vmovaps r16, ymm | VEX.256.0F.WIG 29 /r | Move aligned packed single-precision floating-point values from ymm1 to ymm2/mem.
        /// </summary>
        [Symbol("vmovaps r16, ymm","VEX.256.0F.WIG 29 /r")]
        vmovaps_r16_ymm_vex = 2117,

        /// <summary>
        /// vmovaps r32 {k1}{z}, zmm | EVEX.512.0F.W0 29 /r | Move aligned packed single-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovaps r32 {k1}{z}, zmm","EVEX.512.0F.W0 29 /r")]
        vmovaps_r32_k1z_zmm = 2118,

        /// <summary>
        /// vmovaps r32, zmm | EVEX.512.0F.W0 29 /r | Move aligned packed single-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovaps r32, zmm","EVEX.512.0F.W0 29 /r")]
        vmovaps_r32_zmm = 2119,

        /// <summary>
        /// vmovaps r8 {k1}{z}, xmm | EVEX.128.0F.W0 29 /r | Move aligned packed single-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovaps r8 {k1}{z}, xmm","EVEX.128.0F.W0 29 /r")]
        vmovaps_r8_k1z_xmm = 2120,

        /// <summary>
        /// vmovaps r8, xmm | EVEX.128.0F.W0 29 /r | Move aligned packed single-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovaps r8, xmm","EVEX.128.0F.W0 29 /r")]
        vmovaps_r8_xmm = 2121,

        /// <summary>
        /// vmovaps r8, xmm | VEX.128.0F.WIG 29 /r | Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("vmovaps r8, xmm","VEX.128.0F.WIG 29 /r")]
        vmovaps_r8_xmm_vex = 2122,

        /// <summary>
        /// vmovaps xmm {k1}{z}, m128 | EVEX.128.0F.W0 28 /r | Move aligned packed single-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps xmm {k1}{z}, m128","EVEX.128.0F.W0 28 /r")]
        vmovaps_xmm_k1z_m128 = 2123,

        /// <summary>
        /// vmovaps xmm {k1}{z}, r8 | EVEX.128.0F.W0 28 /r | Move aligned packed single-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps xmm {k1}{z}, r8","EVEX.128.0F.W0 28 /r")]
        vmovaps_xmm_k1z_r8 = 2124,

        /// <summary>
        /// vmovaps xmm, m128 | EVEX.128.0F.W0 28 /r | Move aligned packed single-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps xmm, m128","EVEX.128.0F.W0 28 /r")]
        vmovaps_xmm_m128 = 2125,

        /// <summary>
        /// vmovaps xmm, m128 | VEX.128.0F.WIG 28 /r | Move aligned packed single-precision floating-point values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("vmovaps xmm, m128","VEX.128.0F.WIG 28 /r")]
        vmovaps_xmm_m128_vex = 2126,

        /// <summary>
        /// vmovaps xmm, r8 | EVEX.128.0F.W0 28 /r | Move aligned packed single-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps xmm, r8","EVEX.128.0F.W0 28 /r")]
        vmovaps_xmm_r8 = 2127,

        /// <summary>
        /// vmovaps xmm, r8 | VEX.128.0F.WIG 28 /r | Move aligned packed single-precision floating-point values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("vmovaps xmm, r8","VEX.128.0F.WIG 28 /r")]
        vmovaps_xmm_r8_vex = 2128,

        /// <summary>
        /// vmovaps ymm {k1}{z}, m256 | EVEX.256.0F.W0 28 /r | Move aligned packed single-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps ymm {k1}{z}, m256","EVEX.256.0F.W0 28 /r")]
        vmovaps_ymm_k1z_m256 = 2129,

        /// <summary>
        /// vmovaps ymm {k1}{z}, r16 | EVEX.256.0F.W0 28 /r | Move aligned packed single-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps ymm {k1}{z}, r16","EVEX.256.0F.W0 28 /r")]
        vmovaps_ymm_k1z_r16 = 2130,

        /// <summary>
        /// vmovaps ymm, m256 | EVEX.256.0F.W0 28 /r | Move aligned packed single-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps ymm, m256","EVEX.256.0F.W0 28 /r")]
        vmovaps_ymm_m256 = 2131,

        /// <summary>
        /// vmovaps ymm, m256 | VEX.256.0F.WIG 28 /r | Move aligned packed single-precision floating-point values from ymm2/mem to ymm1.
        /// </summary>
        [Symbol("vmovaps ymm, m256","VEX.256.0F.WIG 28 /r")]
        vmovaps_ymm_m256_vex = 2132,

        /// <summary>
        /// vmovaps ymm, r16 | EVEX.256.0F.W0 28 /r | Move aligned packed single-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps ymm, r16","EVEX.256.0F.W0 28 /r")]
        vmovaps_ymm_r16 = 2133,

        /// <summary>
        /// vmovaps ymm, r16 | VEX.256.0F.WIG 28 /r | Move aligned packed single-precision floating-point values from ymm2/mem to ymm1.
        /// </summary>
        [Symbol("vmovaps ymm, r16","VEX.256.0F.WIG 28 /r")]
        vmovaps_ymm_r16_vex = 2134,

        /// <summary>
        /// vmovaps zmm {k1}{z}, m512 | EVEX.512.0F.W0 28 /r | Move aligned packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps zmm {k1}{z}, m512","EVEX.512.0F.W0 28 /r")]
        vmovaps_zmm_k1z_m512 = 2135,

        /// <summary>
        /// vmovaps zmm {k1}{z}, r32 | EVEX.512.0F.W0 28 /r | Move aligned packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps zmm {k1}{z}, r32","EVEX.512.0F.W0 28 /r")]
        vmovaps_zmm_k1z_r32 = 2136,

        /// <summary>
        /// vmovaps zmm, m512 | EVEX.512.0F.W0 28 /r | Move aligned packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps zmm, m512","EVEX.512.0F.W0 28 /r")]
        vmovaps_zmm_m512 = 2137,

        /// <summary>
        /// vmovaps zmm, r32 | EVEX.512.0F.W0 28 /r | Move aligned packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovaps zmm, r32","EVEX.512.0F.W0 28 /r")]
        vmovaps_zmm_r32 = 2138,

        /// <summary>
        /// vmovd m32, xmm | EVEX.128.66.0F.W0 7E /r | Move doubleword from xmm1 register to r/m32.
        /// </summary>
        [Symbol("vmovd m32, xmm","EVEX.128.66.0F.W0 7E /r")]
        vmovd_m32_xmm = 2139,

        /// <summary>
        /// vmovd m32, xmm | VEX.128.66.0F.W0 7E /r | Move doubleword from xmm1 register to r/m32.
        /// </summary>
        [Symbol("vmovd m32, xmm","VEX.128.66.0F.W0 7E /r")]
        vmovd_m32_xmm_vex = 2140,

        /// <summary>
        /// vmovd r32, xmm | EVEX.128.66.0F.W0 7E /r | Move doubleword from xmm1 register to r/m32.
        /// </summary>
        [Symbol("vmovd r32, xmm","EVEX.128.66.0F.W0 7E /r")]
        vmovd_r32_xmm = 2141,

        /// <summary>
        /// vmovd r32, xmm | VEX.128.66.0F.W0 7E /r | Move doubleword from xmm1 register to r/m32.
        /// </summary>
        [Symbol("vmovd r32, xmm","VEX.128.66.0F.W0 7E /r")]
        vmovd_r32_xmm_vex = 2142,

        /// <summary>
        /// vmovd xmm, m32 | VEX.128.66.0F.W0 6E /r | Move doubleword from r/m32 to xmm1.
        /// </summary>
        [Symbol("vmovd xmm, m32","VEX.128.66.0F.W0 6E /r")]
        vmovd_xmm_m32 = 2143,

        /// <summary>
        /// vmovd xmm, m32 | EVEX.128.66.0F.W0 6E /r | Move doubleword from r/m32 to xmm1.
        /// </summary>
        [Symbol("vmovd xmm, m32","EVEX.128.66.0F.W0 6E /r")]
        vmovd_xmm_m32_evex = 2144,

        /// <summary>
        /// vmovd xmm, r32 | VEX.128.66.0F.W0 6E /r | Move doubleword from r/m32 to xmm1.
        /// </summary>
        [Symbol("vmovd xmm, r32","VEX.128.66.0F.W0 6E /r")]
        vmovd_xmm_r32 = 2145,

        /// <summary>
        /// vmovd xmm, r32 | EVEX.128.66.0F.W0 6E /r | Move doubleword from r/m32 to xmm1.
        /// </summary>
        [Symbol("vmovd xmm, r32","EVEX.128.66.0F.W0 6E /r")]
        vmovd_xmm_r32_evex = 2146,

        /// <summary>
        /// vmovdqa m128, xmm | VEX.128.66.0F.WIG 7F /r | Move aligned packed integer values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("vmovdqa m128, xmm","VEX.128.66.0F.WIG 7F /r")]
        vmovdqa_m128_xmm = 2147,

        /// <summary>
        /// vmovdqa m256, ymm | VEX.256.66.0F.WIG 7F /r | Move aligned packed integer values from ymm1 to ymm2/mem.
        /// </summary>
        [Symbol("vmovdqa m256, ymm","VEX.256.66.0F.WIG 7F /r")]
        vmovdqa_m256_ymm = 2148,

        /// <summary>
        /// vmovdqa r16, ymm | VEX.256.66.0F.WIG 7F /r | Move aligned packed integer values from ymm1 to ymm2/mem.
        /// </summary>
        [Symbol("vmovdqa r16, ymm","VEX.256.66.0F.WIG 7F /r")]
        vmovdqa_r16_ymm = 2149,

        /// <summary>
        /// vmovdqa r8, xmm | VEX.128.66.0F.WIG 7F /r | Move aligned packed integer values from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("vmovdqa r8, xmm","VEX.128.66.0F.WIG 7F /r")]
        vmovdqa_r8_xmm = 2150,

        /// <summary>
        /// vmovdqa xmm, m128 | VEX.128.66.0F.WIG 6F /r | Move aligned packed integer values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("vmovdqa xmm, m128","VEX.128.66.0F.WIG 6F /r")]
        vmovdqa_xmm_m128 = 2151,

        /// <summary>
        /// vmovdqa xmm, r8 | VEX.128.66.0F.WIG 6F /r | Move aligned packed integer values from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("vmovdqa xmm, r8","VEX.128.66.0F.WIG 6F /r")]
        vmovdqa_xmm_r8 = 2152,

        /// <summary>
        /// vmovdqa ymm, m256 | VEX.256.66.0F.WIG 6F /r | Move aligned packed integer values from ymm2/mem to ymm1.
        /// </summary>
        [Symbol("vmovdqa ymm, m256","VEX.256.66.0F.WIG 6F /r")]
        vmovdqa_ymm_m256 = 2153,

        /// <summary>
        /// vmovdqa ymm, r16 | VEX.256.66.0F.WIG 6F /r | Move aligned packed integer values from ymm2/mem to ymm1.
        /// </summary>
        [Symbol("vmovdqa ymm, r16","VEX.256.66.0F.WIG 6F /r")]
        vmovdqa_ymm_r16 = 2154,

        /// <summary>
        /// vmovdqa32 m128 {k1}{z}, xmm | EVEX.128.66.0F.W0 7F /r | Move aligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 m128 {k1}{z}, xmm","EVEX.128.66.0F.W0 7F /r")]
        vmovdqa32_m128_k1z_xmm = 2155,

        /// <summary>
        /// vmovdqa32 m128, xmm | EVEX.128.66.0F.W0 7F /r | Move aligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 m128, xmm","EVEX.128.66.0F.W0 7F /r")]
        vmovdqa32_m128_xmm = 2156,

        /// <summary>
        /// vmovdqa32 m256 {k1}{z}, ymm | EVEX.256.66.0F.W0 7F /r | Move aligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 m256 {k1}{z}, ymm","EVEX.256.66.0F.W0 7F /r")]
        vmovdqa32_m256_k1z_ymm = 2157,

        /// <summary>
        /// vmovdqa32 m256, ymm | EVEX.256.66.0F.W0 7F /r | Move aligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 m256, ymm","EVEX.256.66.0F.W0 7F /r")]
        vmovdqa32_m256_ymm = 2158,

        /// <summary>
        /// vmovdqa32 m512 {k1}{z}, zmm | EVEX.512.66.0F.W0 7F /r | Move aligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 m512 {k1}{z}, zmm","EVEX.512.66.0F.W0 7F /r")]
        vmovdqa32_m512_k1z_zmm = 2159,

        /// <summary>
        /// vmovdqa32 m512, zmm | EVEX.512.66.0F.W0 7F /r | Move aligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 m512, zmm","EVEX.512.66.0F.W0 7F /r")]
        vmovdqa32_m512_zmm = 2160,

        /// <summary>
        /// vmovdqa32 r16 {k1}{z}, ymm | EVEX.256.66.0F.W0 7F /r | Move aligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 r16 {k1}{z}, ymm","EVEX.256.66.0F.W0 7F /r")]
        vmovdqa32_r16_k1z_ymm = 2161,

        /// <summary>
        /// vmovdqa32 r16, ymm | EVEX.256.66.0F.W0 7F /r | Move aligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 r16, ymm","EVEX.256.66.0F.W0 7F /r")]
        vmovdqa32_r16_ymm = 2162,

        /// <summary>
        /// vmovdqa32 r32 {k1}{z}, zmm | EVEX.512.66.0F.W0 7F /r | Move aligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 r32 {k1}{z}, zmm","EVEX.512.66.0F.W0 7F /r")]
        vmovdqa32_r32_k1z_zmm = 2163,

        /// <summary>
        /// vmovdqa32 r32, zmm | EVEX.512.66.0F.W0 7F /r | Move aligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 r32, zmm","EVEX.512.66.0F.W0 7F /r")]
        vmovdqa32_r32_zmm = 2164,

        /// <summary>
        /// vmovdqa32 r8 {k1}{z}, xmm | EVEX.128.66.0F.W0 7F /r | Move aligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 r8 {k1}{z}, xmm","EVEX.128.66.0F.W0 7F /r")]
        vmovdqa32_r8_k1z_xmm = 2165,

        /// <summary>
        /// vmovdqa32 r8, xmm | EVEX.128.66.0F.W0 7F /r | Move aligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 r8, xmm","EVEX.128.66.0F.W0 7F /r")]
        vmovdqa32_r8_xmm = 2166,

        /// <summary>
        /// vmovdqa32 xmm {k1}{z}, m128 | EVEX.128.66.0F.W0 6F /r | Move aligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 xmm {k1}{z}, m128","EVEX.128.66.0F.W0 6F /r")]
        vmovdqa32_xmm_k1z_m128 = 2167,

        /// <summary>
        /// vmovdqa32 xmm {k1}{z}, r8 | EVEX.128.66.0F.W0 6F /r | Move aligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 xmm {k1}{z}, r8","EVEX.128.66.0F.W0 6F /r")]
        vmovdqa32_xmm_k1z_r8 = 2168,

        /// <summary>
        /// vmovdqa32 xmm, m128 | EVEX.128.66.0F.W0 6F /r | Move aligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 xmm, m128","EVEX.128.66.0F.W0 6F /r")]
        vmovdqa32_xmm_m128 = 2169,

        /// <summary>
        /// vmovdqa32 xmm, r8 | EVEX.128.66.0F.W0 6F /r | Move aligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 xmm, r8","EVEX.128.66.0F.W0 6F /r")]
        vmovdqa32_xmm_r8 = 2170,

        /// <summary>
        /// vmovdqa32 ymm {k1}{z}, m256 | EVEX.256.66.0F.W0 6F /r | Move aligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 ymm {k1}{z}, m256","EVEX.256.66.0F.W0 6F /r")]
        vmovdqa32_ymm_k1z_m256 = 2171,

        /// <summary>
        /// vmovdqa32 ymm {k1}{z}, r16 | EVEX.256.66.0F.W0 6F /r | Move aligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 ymm {k1}{z}, r16","EVEX.256.66.0F.W0 6F /r")]
        vmovdqa32_ymm_k1z_r16 = 2172,

        /// <summary>
        /// vmovdqa32 ymm, m256 | EVEX.256.66.0F.W0 6F /r | Move aligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 ymm, m256","EVEX.256.66.0F.W0 6F /r")]
        vmovdqa32_ymm_m256 = 2173,

        /// <summary>
        /// vmovdqa32 ymm, r16 | EVEX.256.66.0F.W0 6F /r | Move aligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 ymm, r16","EVEX.256.66.0F.W0 6F /r")]
        vmovdqa32_ymm_r16 = 2174,

        /// <summary>
        /// vmovdqa32 zmm {k1}{z}, m512 | EVEX.512.66.0F.W0 6F /r | Move aligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 zmm {k1}{z}, m512","EVEX.512.66.0F.W0 6F /r")]
        vmovdqa32_zmm_k1z_m512 = 2175,

        /// <summary>
        /// vmovdqa32 zmm {k1}{z}, r32 | EVEX.512.66.0F.W0 6F /r | Move aligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 zmm {k1}{z}, r32","EVEX.512.66.0F.W0 6F /r")]
        vmovdqa32_zmm_k1z_r32 = 2176,

        /// <summary>
        /// vmovdqa32 zmm, m512 | EVEX.512.66.0F.W0 6F /r | Move aligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 zmm, m512","EVEX.512.66.0F.W0 6F /r")]
        vmovdqa32_zmm_m512 = 2177,

        /// <summary>
        /// vmovdqa32 zmm, r32 | EVEX.512.66.0F.W0 6F /r | Move aligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa32 zmm, r32","EVEX.512.66.0F.W0 6F /r")]
        vmovdqa32_zmm_r32 = 2178,

        /// <summary>
        /// vmovdqa64 m128 {k1}{z}, xmm | EVEX.128.66.0F.W1 7F /r | Move aligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 m128 {k1}{z}, xmm","EVEX.128.66.0F.W1 7F /r")]
        vmovdqa64_m128_k1z_xmm = 2179,

        /// <summary>
        /// vmovdqa64 m128, xmm | EVEX.128.66.0F.W1 7F /r | Move aligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 m128, xmm","EVEX.128.66.0F.W1 7F /r")]
        vmovdqa64_m128_xmm = 2180,

        /// <summary>
        /// vmovdqa64 m256 {k1}{z}, ymm | EVEX.256.66.0F.W1 7F /r | Move aligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 m256 {k1}{z}, ymm","EVEX.256.66.0F.W1 7F /r")]
        vmovdqa64_m256_k1z_ymm = 2181,

        /// <summary>
        /// vmovdqa64 m256, ymm | EVEX.256.66.0F.W1 7F /r | Move aligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 m256, ymm","EVEX.256.66.0F.W1 7F /r")]
        vmovdqa64_m256_ymm = 2182,

        /// <summary>
        /// vmovdqa64 m512 {k1}{z}, zmm | EVEX.512.66.0F.W1 7F /r | Move aligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 m512 {k1}{z}, zmm","EVEX.512.66.0F.W1 7F /r")]
        vmovdqa64_m512_k1z_zmm = 2183,

        /// <summary>
        /// vmovdqa64 m512, zmm | EVEX.512.66.0F.W1 7F /r | Move aligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 m512, zmm","EVEX.512.66.0F.W1 7F /r")]
        vmovdqa64_m512_zmm = 2184,

        /// <summary>
        /// vmovdqa64 r16 {k1}{z}, ymm | EVEX.256.66.0F.W1 7F /r | Move aligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 r16 {k1}{z}, ymm","EVEX.256.66.0F.W1 7F /r")]
        vmovdqa64_r16_k1z_ymm = 2185,

        /// <summary>
        /// vmovdqa64 r16, ymm | EVEX.256.66.0F.W1 7F /r | Move aligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 r16, ymm","EVEX.256.66.0F.W1 7F /r")]
        vmovdqa64_r16_ymm = 2186,

        /// <summary>
        /// vmovdqa64 r32 {k1}{z}, zmm | EVEX.512.66.0F.W1 7F /r | Move aligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 r32 {k1}{z}, zmm","EVEX.512.66.0F.W1 7F /r")]
        vmovdqa64_r32_k1z_zmm = 2187,

        /// <summary>
        /// vmovdqa64 r32, zmm | EVEX.512.66.0F.W1 7F /r | Move aligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 r32, zmm","EVEX.512.66.0F.W1 7F /r")]
        vmovdqa64_r32_zmm = 2188,

        /// <summary>
        /// vmovdqa64 r8 {k1}{z}, xmm | EVEX.128.66.0F.W1 7F /r | Move aligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 r8 {k1}{z}, xmm","EVEX.128.66.0F.W1 7F /r")]
        vmovdqa64_r8_k1z_xmm = 2189,

        /// <summary>
        /// vmovdqa64 r8, xmm | EVEX.128.66.0F.W1 7F /r | Move aligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 r8, xmm","EVEX.128.66.0F.W1 7F /r")]
        vmovdqa64_r8_xmm = 2190,

        /// <summary>
        /// vmovdqa64 xmm {k1}{z}, m128 | EVEX.128.66.0F.W1 6F /r | Move aligned quadword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 xmm {k1}{z}, m128","EVEX.128.66.0F.W1 6F /r")]
        vmovdqa64_xmm_k1z_m128 = 2191,

        /// <summary>
        /// vmovdqa64 xmm {k1}{z}, r8 | EVEX.128.66.0F.W1 6F /r | Move aligned quadword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 xmm {k1}{z}, r8","EVEX.128.66.0F.W1 6F /r")]
        vmovdqa64_xmm_k1z_r8 = 2192,

        /// <summary>
        /// vmovdqa64 xmm, m128 | EVEX.128.66.0F.W1 6F /r | Move aligned quadword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 xmm, m128","EVEX.128.66.0F.W1 6F /r")]
        vmovdqa64_xmm_m128 = 2193,

        /// <summary>
        /// vmovdqa64 xmm, r8 | EVEX.128.66.0F.W1 6F /r | Move aligned quadword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 xmm, r8","EVEX.128.66.0F.W1 6F /r")]
        vmovdqa64_xmm_r8 = 2194,

        /// <summary>
        /// vmovdqa64 ymm {k1}{z}, m256 | EVEX.256.66.0F.W1 6F /r | Move aligned quadword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 ymm {k1}{z}, m256","EVEX.256.66.0F.W1 6F /r")]
        vmovdqa64_ymm_k1z_m256 = 2195,

        /// <summary>
        /// vmovdqa64 ymm {k1}{z}, r16 | EVEX.256.66.0F.W1 6F /r | Move aligned quadword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 ymm {k1}{z}, r16","EVEX.256.66.0F.W1 6F /r")]
        vmovdqa64_ymm_k1z_r16 = 2196,

        /// <summary>
        /// vmovdqa64 ymm, m256 | EVEX.256.66.0F.W1 6F /r | Move aligned quadword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 ymm, m256","EVEX.256.66.0F.W1 6F /r")]
        vmovdqa64_ymm_m256 = 2197,

        /// <summary>
        /// vmovdqa64 ymm, r16 | EVEX.256.66.0F.W1 6F /r | Move aligned quadword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 ymm, r16","EVEX.256.66.0F.W1 6F /r")]
        vmovdqa64_ymm_r16 = 2198,

        /// <summary>
        /// vmovdqa64 zmm {k1}{z}, m512 | EVEX.512.66.0F.W1 6F /r | Move aligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 zmm {k1}{z}, m512","EVEX.512.66.0F.W1 6F /r")]
        vmovdqa64_zmm_k1z_m512 = 2199,

        /// <summary>
        /// vmovdqa64 zmm {k1}{z}, r32 | EVEX.512.66.0F.W1 6F /r | Move aligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 zmm {k1}{z}, r32","EVEX.512.66.0F.W1 6F /r")]
        vmovdqa64_zmm_k1z_r32 = 2200,

        /// <summary>
        /// vmovdqa64 zmm, m512 | EVEX.512.66.0F.W1 6F /r | Move aligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 zmm, m512","EVEX.512.66.0F.W1 6F /r")]
        vmovdqa64_zmm_m512 = 2201,

        /// <summary>
        /// vmovdqa64 zmm, r32 | EVEX.512.66.0F.W1 6F /r | Move aligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqa64 zmm, r32","EVEX.512.66.0F.W1 6F /r")]
        vmovdqa64_zmm_r32 = 2202,

        /// <summary>
        /// vmovdqu m128, xmm | VEX.128.F3.0F.WIG 7F /r | Move unaligned packed integer values from xmm1 to xmm2/m128.
        /// </summary>
        [Symbol("vmovdqu m128, xmm","VEX.128.F3.0F.WIG 7F /r")]
        vmovdqu_m128_xmm = 2203,

        /// <summary>
        /// vmovdqu m256, ymm | VEX.256.F3.0F.WIG 7F /r | Move unaligned packed integer values from ymm1 to ymm2/m256.
        /// </summary>
        [Symbol("vmovdqu m256, ymm","VEX.256.F3.0F.WIG 7F /r")]
        vmovdqu_m256_ymm = 2204,

        /// <summary>
        /// vmovdqu r16, ymm | VEX.256.F3.0F.WIG 7F /r | Move unaligned packed integer values from ymm1 to ymm2/m256.
        /// </summary>
        [Symbol("vmovdqu r16, ymm","VEX.256.F3.0F.WIG 7F /r")]
        vmovdqu_r16_ymm = 2205,

        /// <summary>
        /// vmovdqu r8, xmm | VEX.128.F3.0F.WIG 7F /r | Move unaligned packed integer values from xmm1 to xmm2/m128.
        /// </summary>
        [Symbol("vmovdqu r8, xmm","VEX.128.F3.0F.WIG 7F /r")]
        vmovdqu_r8_xmm = 2206,

        /// <summary>
        /// vmovdqu xmm, m128 | VEX.128.F3.0F.WIG 6F /r | Move unaligned packed integer values from xmm2/m128 to xmm1.
        /// </summary>
        [Symbol("vmovdqu xmm, m128","VEX.128.F3.0F.WIG 6F /r")]
        vmovdqu_xmm_m128 = 2207,

        /// <summary>
        /// vmovdqu xmm, r8 | VEX.128.F3.0F.WIG 6F /r | Move unaligned packed integer values from xmm2/m128 to xmm1.
        /// </summary>
        [Symbol("vmovdqu xmm, r8","VEX.128.F3.0F.WIG 6F /r")]
        vmovdqu_xmm_r8 = 2208,

        /// <summary>
        /// vmovdqu ymm, m256 | VEX.256.F3.0F.WIG 6F /r | Move unaligned packed integer values from ymm2/m256 to ymm1.
        /// </summary>
        [Symbol("vmovdqu ymm, m256","VEX.256.F3.0F.WIG 6F /r")]
        vmovdqu_ymm_m256 = 2209,

        /// <summary>
        /// vmovdqu ymm, r16 | VEX.256.F3.0F.WIG 6F /r | Move unaligned packed integer values from ymm2/m256 to ymm1.
        /// </summary>
        [Symbol("vmovdqu ymm, r16","VEX.256.F3.0F.WIG 6F /r")]
        vmovdqu_ymm_r16 = 2210,

        /// <summary>
        /// vmovdqu16 m128 {k1}{z}, xmm | EVEX.128.F2.0F.W1 7F /r | Move unaligned packed word integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 m128 {k1}{z}, xmm","EVEX.128.F2.0F.W1 7F /r")]
        vmovdqu16_m128_k1z_xmm = 2211,

        /// <summary>
        /// vmovdqu16 m128, xmm | EVEX.128.F2.0F.W1 7F /r | Move unaligned packed word integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 m128, xmm","EVEX.128.F2.0F.W1 7F /r")]
        vmovdqu16_m128_xmm = 2212,

        /// <summary>
        /// vmovdqu16 m256 {k1}{z}, ymm | EVEX.256.F2.0F.W1 7F /r | Move unaligned packed word integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 m256 {k1}{z}, ymm","EVEX.256.F2.0F.W1 7F /r")]
        vmovdqu16_m256_k1z_ymm = 2213,

        /// <summary>
        /// vmovdqu16 m256, ymm | EVEX.256.F2.0F.W1 7F /r | Move unaligned packed word integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 m256, ymm","EVEX.256.F2.0F.W1 7F /r")]
        vmovdqu16_m256_ymm = 2214,

        /// <summary>
        /// vmovdqu16 m512 {k1}{z}, zmm | EVEX.512.F2.0F.W1 7F /r | Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 m512 {k1}{z}, zmm","EVEX.512.F2.0F.W1 7F /r")]
        vmovdqu16_m512_k1z_zmm = 2215,

        /// <summary>
        /// vmovdqu16 m512, zmm | EVEX.512.F2.0F.W1 7F /r | Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 m512, zmm","EVEX.512.F2.0F.W1 7F /r")]
        vmovdqu16_m512_zmm = 2216,

        /// <summary>
        /// vmovdqu16 r16 {k1}{z}, ymm | EVEX.256.F2.0F.W1 7F /r | Move unaligned packed word integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 r16 {k1}{z}, ymm","EVEX.256.F2.0F.W1 7F /r")]
        vmovdqu16_r16_k1z_ymm = 2217,

        /// <summary>
        /// vmovdqu16 r16, ymm | EVEX.256.F2.0F.W1 7F /r | Move unaligned packed word integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 r16, ymm","EVEX.256.F2.0F.W1 7F /r")]
        vmovdqu16_r16_ymm = 2218,

        /// <summary>
        /// vmovdqu16 r32 {k1}{z}, zmm | EVEX.512.F2.0F.W1 7F /r | Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 r32 {k1}{z}, zmm","EVEX.512.F2.0F.W1 7F /r")]
        vmovdqu16_r32_k1z_zmm = 2219,

        /// <summary>
        /// vmovdqu16 r32, zmm | EVEX.512.F2.0F.W1 7F /r | Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 r32, zmm","EVEX.512.F2.0F.W1 7F /r")]
        vmovdqu16_r32_zmm = 2220,

        /// <summary>
        /// vmovdqu16 r8 {k1}{z}, xmm | EVEX.128.F2.0F.W1 7F /r | Move unaligned packed word integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 r8 {k1}{z}, xmm","EVEX.128.F2.0F.W1 7F /r")]
        vmovdqu16_r8_k1z_xmm = 2221,

        /// <summary>
        /// vmovdqu16 r8, xmm | EVEX.128.F2.0F.W1 7F /r | Move unaligned packed word integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 r8, xmm","EVEX.128.F2.0F.W1 7F /r")]
        vmovdqu16_r8_xmm = 2222,

        /// <summary>
        /// vmovdqu16 xmm {k1}{z}, m128 | EVEX.128.F2.0F.W1 6F /r | Move unaligned packed word integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 xmm {k1}{z}, m128","EVEX.128.F2.0F.W1 6F /r")]
        vmovdqu16_xmm_k1z_m128 = 2223,

        /// <summary>
        /// vmovdqu16 xmm {k1}{z}, r8 | EVEX.128.F2.0F.W1 6F /r | Move unaligned packed word integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 xmm {k1}{z}, r8","EVEX.128.F2.0F.W1 6F /r")]
        vmovdqu16_xmm_k1z_r8 = 2224,

        /// <summary>
        /// vmovdqu16 xmm, m128 | EVEX.128.F2.0F.W1 6F /r | Move unaligned packed word integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 xmm, m128","EVEX.128.F2.0F.W1 6F /r")]
        vmovdqu16_xmm_m128 = 2225,

        /// <summary>
        /// vmovdqu16 xmm, r8 | EVEX.128.F2.0F.W1 6F /r | Move unaligned packed word integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 xmm, r8","EVEX.128.F2.0F.W1 6F /r")]
        vmovdqu16_xmm_r8 = 2226,

        /// <summary>
        /// vmovdqu16 ymm {k1}{z}, m256 | EVEX.256.F2.0F.W1 6F /r | Move unaligned packed word integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 ymm {k1}{z}, m256","EVEX.256.F2.0F.W1 6F /r")]
        vmovdqu16_ymm_k1z_m256 = 2227,

        /// <summary>
        /// vmovdqu16 ymm {k1}{z}, r16 | EVEX.256.F2.0F.W1 6F /r | Move unaligned packed word integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 ymm {k1}{z}, r16","EVEX.256.F2.0F.W1 6F /r")]
        vmovdqu16_ymm_k1z_r16 = 2228,

        /// <summary>
        /// vmovdqu16 ymm, m256 | EVEX.256.F2.0F.W1 6F /r | Move unaligned packed word integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 ymm, m256","EVEX.256.F2.0F.W1 6F /r")]
        vmovdqu16_ymm_m256 = 2229,

        /// <summary>
        /// vmovdqu16 ymm, r16 | EVEX.256.F2.0F.W1 6F /r | Move unaligned packed word integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 ymm, r16","EVEX.256.F2.0F.W1 6F /r")]
        vmovdqu16_ymm_r16 = 2230,

        /// <summary>
        /// vmovdqu16 zmm {k1}{z}, m512 | EVEX.512.F2.0F.W1 6F /r | Move unaligned packed word integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 zmm {k1}{z}, m512","EVEX.512.F2.0F.W1 6F /r")]
        vmovdqu16_zmm_k1z_m512 = 2231,

        /// <summary>
        /// vmovdqu16 zmm {k1}{z}, r32 | EVEX.512.F2.0F.W1 6F /r | Move unaligned packed word integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 zmm {k1}{z}, r32","EVEX.512.F2.0F.W1 6F /r")]
        vmovdqu16_zmm_k1z_r32 = 2232,

        /// <summary>
        /// vmovdqu16 zmm, m512 | EVEX.512.F2.0F.W1 6F /r | Move unaligned packed word integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 zmm, m512","EVEX.512.F2.0F.W1 6F /r")]
        vmovdqu16_zmm_m512 = 2233,

        /// <summary>
        /// vmovdqu16 zmm, r32 | EVEX.512.F2.0F.W1 6F /r | Move unaligned packed word integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu16 zmm, r32","EVEX.512.F2.0F.W1 6F /r")]
        vmovdqu16_zmm_r32 = 2234,

        /// <summary>
        /// vmovdqu32 m128 {k1}{z}, xmm | EVEX.128.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 m128 {k1}{z}, xmm","EVEX.128.F3.0F.W0 7F /r")]
        vmovdqu32_m128_k1z_xmm = 2235,

        /// <summary>
        /// vmovdqu32 m128, xmm | EVEX.128.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 m128, xmm","EVEX.128.F3.0F.W0 7F /r")]
        vmovdqu32_m128_xmm = 2236,

        /// <summary>
        /// vmovdqu32 m256 {k1}{z}, ymm | EVEX.256.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 m256 {k1}{z}, ymm","EVEX.256.F3.0F.W0 7F /r")]
        vmovdqu32_m256_k1z_ymm = 2237,

        /// <summary>
        /// vmovdqu32 m256, ymm | EVEX.256.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 m256, ymm","EVEX.256.F3.0F.W0 7F /r")]
        vmovdqu32_m256_ymm = 2238,

        /// <summary>
        /// vmovdqu32 m512 {k1}{z}, zmm | EVEX.512.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 m512 {k1}{z}, zmm","EVEX.512.F3.0F.W0 7F /r")]
        vmovdqu32_m512_k1z_zmm = 2239,

        /// <summary>
        /// vmovdqu32 m512, zmm | EVEX.512.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 m512, zmm","EVEX.512.F3.0F.W0 7F /r")]
        vmovdqu32_m512_zmm = 2240,

        /// <summary>
        /// vmovdqu32 r16 {k1}{z}, ymm | EVEX.256.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 r16 {k1}{z}, ymm","EVEX.256.F3.0F.W0 7F /r")]
        vmovdqu32_r16_k1z_ymm = 2241,

        /// <summary>
        /// vmovdqu32 r16, ymm | EVEX.256.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 r16, ymm","EVEX.256.F3.0F.W0 7F /r")]
        vmovdqu32_r16_ymm = 2242,

        /// <summary>
        /// vmovdqu32 r32 {k1}{z}, zmm | EVEX.512.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 r32 {k1}{z}, zmm","EVEX.512.F3.0F.W0 7F /r")]
        vmovdqu32_r32_k1z_zmm = 2243,

        /// <summary>
        /// vmovdqu32 r32, zmm | EVEX.512.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 r32, zmm","EVEX.512.F3.0F.W0 7F /r")]
        vmovdqu32_r32_zmm = 2244,

        /// <summary>
        /// vmovdqu32 r8 {k1}{z}, xmm | EVEX.128.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 r8 {k1}{z}, xmm","EVEX.128.F3.0F.W0 7F /r")]
        vmovdqu32_r8_k1z_xmm = 2245,

        /// <summary>
        /// vmovdqu32 r8, xmm | EVEX.128.F3.0F.W0 7F /r | Move unaligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 r8, xmm","EVEX.128.F3.0F.W0 7F /r")]
        vmovdqu32_r8_xmm = 2246,

        /// <summary>
        /// vmovdqu32 xmm {k1}{z}, m128 | EVEX.128.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 xmm {k1}{z}, m128","EVEX.128.F3.0F.W0 6F /r")]
        vmovdqu32_xmm_k1z_m128 = 2247,

        /// <summary>
        /// vmovdqu32 xmm {k1}{z}, r8 | EVEX.128.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 xmm {k1}{z}, r8","EVEX.128.F3.0F.W0 6F /r")]
        vmovdqu32_xmm_k1z_r8 = 2248,

        /// <summary>
        /// vmovdqu32 xmm, m128 | EVEX.128.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 xmm, m128","EVEX.128.F3.0F.W0 6F /r")]
        vmovdqu32_xmm_m128 = 2249,

        /// <summary>
        /// vmovdqu32 xmm, r8 | EVEX.128.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 xmm, r8","EVEX.128.F3.0F.W0 6F /r")]
        vmovdqu32_xmm_r8 = 2250,

        /// <summary>
        /// vmovdqu32 ymm {k1}{z}, m256 | EVEX.256.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 ymm {k1}{z}, m256","EVEX.256.F3.0F.W0 6F /r")]
        vmovdqu32_ymm_k1z_m256 = 2251,

        /// <summary>
        /// vmovdqu32 ymm {k1}{z}, r16 | EVEX.256.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 ymm {k1}{z}, r16","EVEX.256.F3.0F.W0 6F /r")]
        vmovdqu32_ymm_k1z_r16 = 2252,

        /// <summary>
        /// vmovdqu32 ymm, m256 | EVEX.256.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 ymm, m256","EVEX.256.F3.0F.W0 6F /r")]
        vmovdqu32_ymm_m256 = 2253,

        /// <summary>
        /// vmovdqu32 ymm, r16 | EVEX.256.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 ymm, r16","EVEX.256.F3.0F.W0 6F /r")]
        vmovdqu32_ymm_r16 = 2254,

        /// <summary>
        /// vmovdqu32 zmm {k1}{z}, m512 | EVEX.512.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 zmm {k1}{z}, m512","EVEX.512.F3.0F.W0 6F /r")]
        vmovdqu32_zmm_k1z_m512 = 2255,

        /// <summary>
        /// vmovdqu32 zmm {k1}{z}, r32 | EVEX.512.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 zmm {k1}{z}, r32","EVEX.512.F3.0F.W0 6F /r")]
        vmovdqu32_zmm_k1z_r32 = 2256,

        /// <summary>
        /// vmovdqu32 zmm, m512 | EVEX.512.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 zmm, m512","EVEX.512.F3.0F.W0 6F /r")]
        vmovdqu32_zmm_m512 = 2257,

        /// <summary>
        /// vmovdqu32 zmm, r32 | EVEX.512.F3.0F.W0 6F /r | Move unaligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu32 zmm, r32","EVEX.512.F3.0F.W0 6F /r")]
        vmovdqu32_zmm_r32 = 2258,

        /// <summary>
        /// vmovdqu64 m128 {k1}{z}, xmm | EVEX.128.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 m128 {k1}{z}, xmm","EVEX.128.F3.0F.W1 7F /r")]
        vmovdqu64_m128_k1z_xmm = 2259,

        /// <summary>
        /// vmovdqu64 m128, xmm | EVEX.128.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 m128, xmm","EVEX.128.F3.0F.W1 7F /r")]
        vmovdqu64_m128_xmm = 2260,

        /// <summary>
        /// vmovdqu64 m256 {k1}{z}, ymm | EVEX.256.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 m256 {k1}{z}, ymm","EVEX.256.F3.0F.W1 7F /r")]
        vmovdqu64_m256_k1z_ymm = 2261,

        /// <summary>
        /// vmovdqu64 m256, ymm | EVEX.256.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 m256, ymm","EVEX.256.F3.0F.W1 7F /r")]
        vmovdqu64_m256_ymm = 2262,

        /// <summary>
        /// vmovdqu64 m512 {k1}{z}, zmm | EVEX.512.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 m512 {k1}{z}, zmm","EVEX.512.F3.0F.W1 7F /r")]
        vmovdqu64_m512_k1z_zmm = 2263,

        /// <summary>
        /// vmovdqu64 m512, zmm | EVEX.512.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 m512, zmm","EVEX.512.F3.0F.W1 7F /r")]
        vmovdqu64_m512_zmm = 2264,

        /// <summary>
        /// vmovdqu64 r16 {k1}{z}, ymm | EVEX.256.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 r16 {k1}{z}, ymm","EVEX.256.F3.0F.W1 7F /r")]
        vmovdqu64_r16_k1z_ymm = 2265,

        /// <summary>
        /// vmovdqu64 r16, ymm | EVEX.256.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 r16, ymm","EVEX.256.F3.0F.W1 7F /r")]
        vmovdqu64_r16_ymm = 2266,

        /// <summary>
        /// vmovdqu64 r32 {k1}{z}, zmm | EVEX.512.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 r32 {k1}{z}, zmm","EVEX.512.F3.0F.W1 7F /r")]
        vmovdqu64_r32_k1z_zmm = 2267,

        /// <summary>
        /// vmovdqu64 r32, zmm | EVEX.512.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 r32, zmm","EVEX.512.F3.0F.W1 7F /r")]
        vmovdqu64_r32_zmm = 2268,

        /// <summary>
        /// vmovdqu64 r8 {k1}{z}, xmm | EVEX.128.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 r8 {k1}{z}, xmm","EVEX.128.F3.0F.W1 7F /r")]
        vmovdqu64_r8_k1z_xmm = 2269,

        /// <summary>
        /// vmovdqu64 r8, xmm | EVEX.128.F3.0F.W1 7F /r | Move unaligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 r8, xmm","EVEX.128.F3.0F.W1 7F /r")]
        vmovdqu64_r8_xmm = 2270,

        /// <summary>
        /// vmovdqu64 xmm {k1}{z}, m128 | EVEX.128.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 xmm {k1}{z}, m128","EVEX.128.F3.0F.W1 6F /r")]
        vmovdqu64_xmm_k1z_m128 = 2271,

        /// <summary>
        /// vmovdqu64 xmm {k1}{z}, r8 | EVEX.128.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 xmm {k1}{z}, r8","EVEX.128.F3.0F.W1 6F /r")]
        vmovdqu64_xmm_k1z_r8 = 2272,

        /// <summary>
        /// vmovdqu64 xmm, m128 | EVEX.128.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 xmm, m128","EVEX.128.F3.0F.W1 6F /r")]
        vmovdqu64_xmm_m128 = 2273,

        /// <summary>
        /// vmovdqu64 xmm, r8 | EVEX.128.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 xmm, r8","EVEX.128.F3.0F.W1 6F /r")]
        vmovdqu64_xmm_r8 = 2274,

        /// <summary>
        /// vmovdqu64 ymm {k1}{z}, m256 | EVEX.256.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 ymm {k1}{z}, m256","EVEX.256.F3.0F.W1 6F /r")]
        vmovdqu64_ymm_k1z_m256 = 2275,

        /// <summary>
        /// vmovdqu64 ymm {k1}{z}, r16 | EVEX.256.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 ymm {k1}{z}, r16","EVEX.256.F3.0F.W1 6F /r")]
        vmovdqu64_ymm_k1z_r16 = 2276,

        /// <summary>
        /// vmovdqu64 ymm, m256 | EVEX.256.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 ymm, m256","EVEX.256.F3.0F.W1 6F /r")]
        vmovdqu64_ymm_m256 = 2277,

        /// <summary>
        /// vmovdqu64 ymm, r16 | EVEX.256.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 ymm, r16","EVEX.256.F3.0F.W1 6F /r")]
        vmovdqu64_ymm_r16 = 2278,

        /// <summary>
        /// vmovdqu64 zmm {k1}{z}, m512 | EVEX.512.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 zmm {k1}{z}, m512","EVEX.512.F3.0F.W1 6F /r")]
        vmovdqu64_zmm_k1z_m512 = 2279,

        /// <summary>
        /// vmovdqu64 zmm {k1}{z}, r32 | EVEX.512.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 zmm {k1}{z}, r32","EVEX.512.F3.0F.W1 6F /r")]
        vmovdqu64_zmm_k1z_r32 = 2280,

        /// <summary>
        /// vmovdqu64 zmm, m512 | EVEX.512.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 zmm, m512","EVEX.512.F3.0F.W1 6F /r")]
        vmovdqu64_zmm_m512 = 2281,

        /// <summary>
        /// vmovdqu64 zmm, r32 | EVEX.512.F3.0F.W1 6F /r | Move unaligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu64 zmm, r32","EVEX.512.F3.0F.W1 6F /r")]
        vmovdqu64_zmm_r32 = 2282,

        /// <summary>
        /// vmovdqu8 m128 {k1}{z}, xmm | EVEX.128.F2.0F.W0 7F /r | Move unaligned packed byte integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 m128 {k1}{z}, xmm","EVEX.128.F2.0F.W0 7F /r")]
        vmovdqu8_m128_k1z_xmm = 2283,

        /// <summary>
        /// vmovdqu8 m128, xmm | EVEX.128.F2.0F.W0 7F /r | Move unaligned packed byte integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 m128, xmm","EVEX.128.F2.0F.W0 7F /r")]
        vmovdqu8_m128_xmm = 2284,

        /// <summary>
        /// vmovdqu8 m256 {k1}{z}, ymm | EVEX.256.F2.0F.W0 7F /r | Move unaligned packed byte integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 m256 {k1}{z}, ymm","EVEX.256.F2.0F.W0 7F /r")]
        vmovdqu8_m256_k1z_ymm = 2285,

        /// <summary>
        /// vmovdqu8 m256, ymm | EVEX.256.F2.0F.W0 7F /r | Move unaligned packed byte integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 m256, ymm","EVEX.256.F2.0F.W0 7F /r")]
        vmovdqu8_m256_ymm = 2286,

        /// <summary>
        /// vmovdqu8 m512 {k1}{z}, zmm | EVEX.512.F2.0F.W0 7F /r | Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 m512 {k1}{z}, zmm","EVEX.512.F2.0F.W0 7F /r")]
        vmovdqu8_m512_k1z_zmm = 2287,

        /// <summary>
        /// vmovdqu8 m512, zmm | EVEX.512.F2.0F.W0 7F /r | Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 m512, zmm","EVEX.512.F2.0F.W0 7F /r")]
        vmovdqu8_m512_zmm = 2288,

        /// <summary>
        /// vmovdqu8 r16 {k1}{z}, ymm | EVEX.256.F2.0F.W0 7F /r | Move unaligned packed byte integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 r16 {k1}{z}, ymm","EVEX.256.F2.0F.W0 7F /r")]
        vmovdqu8_r16_k1z_ymm = 2289,

        /// <summary>
        /// vmovdqu8 r16, ymm | EVEX.256.F2.0F.W0 7F /r | Move unaligned packed byte integer values from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 r16, ymm","EVEX.256.F2.0F.W0 7F /r")]
        vmovdqu8_r16_ymm = 2290,

        /// <summary>
        /// vmovdqu8 r32 {k1}{z}, zmm | EVEX.512.F2.0F.W0 7F /r | Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 r32 {k1}{z}, zmm","EVEX.512.F2.0F.W0 7F /r")]
        vmovdqu8_r32_k1z_zmm = 2291,

        /// <summary>
        /// vmovdqu8 r32, zmm | EVEX.512.F2.0F.W0 7F /r | Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 r32, zmm","EVEX.512.F2.0F.W0 7F /r")]
        vmovdqu8_r32_zmm = 2292,

        /// <summary>
        /// vmovdqu8 r8 {k1}{z}, xmm | EVEX.128.F2.0F.W0 7F /r | Move unaligned packed byte integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 r8 {k1}{z}, xmm","EVEX.128.F2.0F.W0 7F /r")]
        vmovdqu8_r8_k1z_xmm = 2293,

        /// <summary>
        /// vmovdqu8 r8, xmm | EVEX.128.F2.0F.W0 7F /r | Move unaligned packed byte integer values from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 r8, xmm","EVEX.128.F2.0F.W0 7F /r")]
        vmovdqu8_r8_xmm = 2294,

        /// <summary>
        /// vmovdqu8 xmm {k1}{z}, m128 | EVEX.128.F2.0F.W0 6F /r | Move unaligned packed byte integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 xmm {k1}{z}, m128","EVEX.128.F2.0F.W0 6F /r")]
        vmovdqu8_xmm_k1z_m128 = 2295,

        /// <summary>
        /// vmovdqu8 xmm {k1}{z}, r8 | EVEX.128.F2.0F.W0 6F /r | Move unaligned packed byte integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 xmm {k1}{z}, r8","EVEX.128.F2.0F.W0 6F /r")]
        vmovdqu8_xmm_k1z_r8 = 2296,

        /// <summary>
        /// vmovdqu8 xmm, m128 | EVEX.128.F2.0F.W0 6F /r | Move unaligned packed byte integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 xmm, m128","EVEX.128.F2.0F.W0 6F /r")]
        vmovdqu8_xmm_m128 = 2297,

        /// <summary>
        /// vmovdqu8 xmm, r8 | EVEX.128.F2.0F.W0 6F /r | Move unaligned packed byte integer values from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 xmm, r8","EVEX.128.F2.0F.W0 6F /r")]
        vmovdqu8_xmm_r8 = 2298,

        /// <summary>
        /// vmovdqu8 ymm {k1}{z}, m256 | EVEX.256.F2.0F.W0 6F /r | Move unaligned packed byte integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 ymm {k1}{z}, m256","EVEX.256.F2.0F.W0 6F /r")]
        vmovdqu8_ymm_k1z_m256 = 2299,

        /// <summary>
        /// vmovdqu8 ymm {k1}{z}, r16 | EVEX.256.F2.0F.W0 6F /r | Move unaligned packed byte integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 ymm {k1}{z}, r16","EVEX.256.F2.0F.W0 6F /r")]
        vmovdqu8_ymm_k1z_r16 = 2300,

        /// <summary>
        /// vmovdqu8 ymm, m256 | EVEX.256.F2.0F.W0 6F /r | Move unaligned packed byte integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 ymm, m256","EVEX.256.F2.0F.W0 6F /r")]
        vmovdqu8_ymm_m256 = 2301,

        /// <summary>
        /// vmovdqu8 ymm, r16 | EVEX.256.F2.0F.W0 6F /r | Move unaligned packed byte integer values from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 ymm, r16","EVEX.256.F2.0F.W0 6F /r")]
        vmovdqu8_ymm_r16 = 2302,

        /// <summary>
        /// vmovdqu8 zmm {k1}{z}, m512 | EVEX.512.F2.0F.W0 6F /r | Move unaligned packed byte integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 zmm {k1}{z}, m512","EVEX.512.F2.0F.W0 6F /r")]
        vmovdqu8_zmm_k1z_m512 = 2303,

        /// <summary>
        /// vmovdqu8 zmm {k1}{z}, r32 | EVEX.512.F2.0F.W0 6F /r | Move unaligned packed byte integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 zmm {k1}{z}, r32","EVEX.512.F2.0F.W0 6F /r")]
        vmovdqu8_zmm_k1z_r32 = 2304,

        /// <summary>
        /// vmovdqu8 zmm, m512 | EVEX.512.F2.0F.W0 6F /r | Move unaligned packed byte integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 zmm, m512","EVEX.512.F2.0F.W0 6F /r")]
        vmovdqu8_zmm_m512 = 2305,

        /// <summary>
        /// vmovdqu8 zmm, r32 | EVEX.512.F2.0F.W0 6F /r | Move unaligned packed byte integer values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovdqu8 zmm, r32","EVEX.512.F2.0F.W0 6F /r")]
        vmovdqu8_zmm_r32 = 2306,

        /// <summary>
        /// vmovq m64, xmm | EVEX.128.66.0F.W1 7E /r | Move quadword from xmm1 register to r/m64.
        /// </summary>
        [Symbol("vmovq m64, xmm","EVEX.128.66.0F.W1 7E /r")]
        vmovq_m64_xmm = 2307,

        /// <summary>
        /// vmovq m64, xmm | EVEX.128.66.0F.W1 D6 /r | Move quadword from xmm2 register to xmm1/m64.
        /// </summary>
        [Symbol("vmovq m64, xmm","EVEX.128.66.0F.W1 D6 /r")]
        vmovq_m64_xmm_evex = 2308,

        /// <summary>
        /// vmovq m64, xmm | VEX.128.66.0F.W1 7E /r | Move quadword from xmm1 register to r/m64.
        /// </summary>
        [Symbol("vmovq m64, xmm","VEX.128.66.0F.W1 7E /r")]
        vmovq_m64_xmm_vex = 2309,

        /// <summary>
        /// vmovq r64, xmm | EVEX.128.66.0F.W1 7E /r | Move quadword from xmm1 register to r/m64.
        /// </summary>
        [Symbol("vmovq r64, xmm","EVEX.128.66.0F.W1 7E /r")]
        vmovq_r64_xmm = 2310,

        /// <summary>
        /// vmovq r64, xmm | VEX.128.66.0F.W1 7E /r | Move quadword from xmm1 register to r/m64.
        /// </summary>
        [Symbol("vmovq r64, xmm","VEX.128.66.0F.W1 7E /r")]
        vmovq_r64_xmm_vex = 2311,

        /// <summary>
        /// vmovq r8, xmm | VEX.128.66.0F.WIG D6 /r | Move quadword from xmm2 register to xmm1/m64.
        /// </summary>
        [Symbol("vmovq r8, xmm","VEX.128.66.0F.WIG D6 /r")]
        vmovq_r8_xmm = 2312,

        /// <summary>
        /// vmovq r8, xmm | EVEX.128.66.0F.W1 D6 /r | Move quadword from xmm2 register to xmm1/m64.
        /// </summary>
        [Symbol("vmovq r8, xmm","EVEX.128.66.0F.W1 D6 /r")]
        vmovq_r8_xmm_evex = 2313,

        /// <summary>
        /// vmovq xmm, m64 | EVEX.128.66.0F.W1 6E /r | Move quadword from r/m64 to xmm1.
        /// </summary>
        [Symbol("vmovq xmm, m64","EVEX.128.66.0F.W1 6E /r")]
        vmovq_xmm_m64 = 2314,

        /// <summary>
        /// vmovq xmm, m64 | EVEX.128.F3.0F.W1 7E /r | Move quadword from xmm2/m64 to xmm1.
        /// </summary>
        [Symbol("vmovq xmm, m64","EVEX.128.F3.0F.W1 7E /r")]
        vmovq_xmm_m64_evex = 2315,

        /// <summary>
        /// vmovq xmm, m64 | VEX.128.66.0F.W1 6E /r | Move quadword from r/m64 to xmm1.
        /// </summary>
        [Symbol("vmovq xmm, m64","VEX.128.66.0F.W1 6E /r")]
        vmovq_xmm_m64_vex = 2316,

        /// <summary>
        /// vmovq xmm, r64 | EVEX.128.66.0F.W1 6E /r | Move quadword from r/m64 to xmm1.
        /// </summary>
        [Symbol("vmovq xmm, r64","EVEX.128.66.0F.W1 6E /r")]
        vmovq_xmm_r64 = 2317,

        /// <summary>
        /// vmovq xmm, r64 | VEX.128.66.0F.W1 6E /r | Move quadword from r/m64 to xmm1.
        /// </summary>
        [Symbol("vmovq xmm, r64","VEX.128.66.0F.W1 6E /r")]
        vmovq_xmm_r64_vex = 2318,

        /// <summary>
        /// vmovq xmm, r8 | VEX.128.F3.0F.WIG 7E /r | Move quadword from xmm2 to xmm1.
        /// </summary>
        [Symbol("vmovq xmm, r8","VEX.128.F3.0F.WIG 7E /r")]
        vmovq_xmm_r8 = 2319,

        /// <summary>
        /// vmovq xmm, r8 | EVEX.128.F3.0F.W1 7E /r | Move quadword from xmm2/m64 to xmm1.
        /// </summary>
        [Symbol("vmovq xmm, r8","EVEX.128.F3.0F.W1 7E /r")]
        vmovq_xmm_r8_evex = 2320,

        /// <summary>
        /// vmovupd m128 {k1}{z}, xmm | EVEX.128.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovupd m128 {k1}{z}, xmm","EVEX.128.66.0F.W1 11 /r")]
        vmovupd_m128_k1z_xmm = 2321,

        /// <summary>
        /// vmovupd m128, xmm | EVEX.128.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovupd m128, xmm","EVEX.128.66.0F.W1 11 /r")]
        vmovupd_m128_xmm = 2322,

        /// <summary>
        /// vmovupd m128, xmm | VEX.128.66.0F.WIG 11 /r | Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("vmovupd m128, xmm","VEX.128.66.0F.WIG 11 /r")]
        vmovupd_m128_xmm_vex = 2323,

        /// <summary>
        /// vmovupd m256 {k1}{z}, ymm | EVEX.256.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovupd m256 {k1}{z}, ymm","EVEX.256.66.0F.W1 11 /r")]
        vmovupd_m256_k1z_ymm = 2324,

        /// <summary>
        /// vmovupd m256, ymm | EVEX.256.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovupd m256, ymm","EVEX.256.66.0F.W1 11 /r")]
        vmovupd_m256_ymm = 2325,

        /// <summary>
        /// vmovupd m256, ymm | VEX.256.66.0F.WIG 11 /r | Move unaligned packed double-precision floating-point from ymm1 to ymm2/mem.
        /// </summary>
        [Symbol("vmovupd m256, ymm","VEX.256.66.0F.WIG 11 /r")]
        vmovupd_m256_ymm_vex = 2326,

        /// <summary>
        /// vmovupd m512 {k1}{z}, zmm | EVEX.512.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovupd m512 {k1}{z}, zmm","EVEX.512.66.0F.W1 11 /r")]
        vmovupd_m512_k1z_zmm = 2327,

        /// <summary>
        /// vmovupd m512, zmm | EVEX.512.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovupd m512, zmm","EVEX.512.66.0F.W1 11 /r")]
        vmovupd_m512_zmm = 2328,

        /// <summary>
        /// vmovupd r16 {k1}{z}, ymm | EVEX.256.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovupd r16 {k1}{z}, ymm","EVEX.256.66.0F.W1 11 /r")]
        vmovupd_r16_k1z_ymm = 2329,

        /// <summary>
        /// vmovupd r16, ymm | EVEX.256.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point from ymm1 to ymm2/m256 using writemask k1.
        /// </summary>
        [Symbol("vmovupd r16, ymm","EVEX.256.66.0F.W1 11 /r")]
        vmovupd_r16_ymm = 2330,

        /// <summary>
        /// vmovupd r16, ymm | VEX.256.66.0F.WIG 11 /r | Move unaligned packed double-precision floating-point from ymm1 to ymm2/mem.
        /// </summary>
        [Symbol("vmovupd r16, ymm","VEX.256.66.0F.WIG 11 /r")]
        vmovupd_r16_ymm_vex = 2331,

        /// <summary>
        /// vmovupd r32 {k1}{z}, zmm | EVEX.512.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovupd r32 {k1}{z}, zmm","EVEX.512.66.0F.W1 11 /r")]
        vmovupd_r32_k1z_zmm = 2332,

        /// <summary>
        /// vmovupd r32, zmm | EVEX.512.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.
        /// </summary>
        [Symbol("vmovupd r32, zmm","EVEX.512.66.0F.W1 11 /r")]
        vmovupd_r32_zmm = 2333,

        /// <summary>
        /// vmovupd r8 {k1}{z}, xmm | EVEX.128.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovupd r8 {k1}{z}, xmm","EVEX.128.66.0F.W1 11 /r")]
        vmovupd_r8_k1z_xmm = 2334,

        /// <summary>
        /// vmovupd r8, xmm | EVEX.128.66.0F.W1 11 /r | Move unaligned packed double-precision floating-point from xmm1 to xmm2/m128 using writemask k1.
        /// </summary>
        [Symbol("vmovupd r8, xmm","EVEX.128.66.0F.W1 11 /r")]
        vmovupd_r8_xmm = 2335,

        /// <summary>
        /// vmovupd r8, xmm | VEX.128.66.0F.WIG 11 /r | Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem.
        /// </summary>
        [Symbol("vmovupd r8, xmm","VEX.128.66.0F.WIG 11 /r")]
        vmovupd_r8_xmm_vex = 2336,

        /// <summary>
        /// vmovupd xmm {k1}{z}, m128 | EVEX.128.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd xmm {k1}{z}, m128","EVEX.128.66.0F.W1 10 /r")]
        vmovupd_xmm_k1z_m128 = 2337,

        /// <summary>
        /// vmovupd xmm {k1}{z}, r8 | EVEX.128.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd xmm {k1}{z}, r8","EVEX.128.66.0F.W1 10 /r")]
        vmovupd_xmm_k1z_r8 = 2338,

        /// <summary>
        /// vmovupd xmm, m128 | EVEX.128.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd xmm, m128","EVEX.128.66.0F.W1 10 /r")]
        vmovupd_xmm_m128 = 2339,

        /// <summary>
        /// vmovupd xmm, m128 | VEX.128.66.0F.WIG 10 /r | Move unaligned packed double-precision floating-point from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("vmovupd xmm, m128","VEX.128.66.0F.WIG 10 /r")]
        vmovupd_xmm_m128_vex = 2340,

        /// <summary>
        /// vmovupd xmm, r8 | EVEX.128.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point from xmm2/m128 to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd xmm, r8","EVEX.128.66.0F.W1 10 /r")]
        vmovupd_xmm_r8 = 2341,

        /// <summary>
        /// vmovupd xmm, r8 | VEX.128.66.0F.WIG 10 /r | Move unaligned packed double-precision floating-point from xmm2/mem to xmm1.
        /// </summary>
        [Symbol("vmovupd xmm, r8","VEX.128.66.0F.WIG 10 /r")]
        vmovupd_xmm_r8_vex = 2342,

        /// <summary>
        /// vmovupd ymm {k1}{z}, m256 | EVEX.256.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd ymm {k1}{z}, m256","EVEX.256.66.0F.W1 10 /r")]
        vmovupd_ymm_k1z_m256 = 2343,

        /// <summary>
        /// vmovupd ymm {k1}{z}, r16 | EVEX.256.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd ymm {k1}{z}, r16","EVEX.256.66.0F.W1 10 /r")]
        vmovupd_ymm_k1z_r16 = 2344,

        /// <summary>
        /// vmovupd ymm, m256 | EVEX.256.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd ymm, m256","EVEX.256.66.0F.W1 10 /r")]
        vmovupd_ymm_m256 = 2345,

        /// <summary>
        /// vmovupd ymm, m256 | VEX.256.66.0F.WIG 10 /r | Move unaligned packed double-precision floating-point from ymm2/mem to ymm1.
        /// </summary>
        [Symbol("vmovupd ymm, m256","VEX.256.66.0F.WIG 10 /r")]
        vmovupd_ymm_m256_vex = 2346,

        /// <summary>
        /// vmovupd ymm, r16 | EVEX.256.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point from ymm2/m256 to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd ymm, r16","EVEX.256.66.0F.W1 10 /r")]
        vmovupd_ymm_r16 = 2347,

        /// <summary>
        /// vmovupd ymm, r16 | VEX.256.66.0F.WIG 10 /r | Move unaligned packed double-precision floating-point from ymm2/mem to ymm1.
        /// </summary>
        [Symbol("vmovupd ymm, r16","VEX.256.66.0F.WIG 10 /r")]
        vmovupd_ymm_r16_vex = 2348,

        /// <summary>
        /// vmovupd zmm {k1}{z}, m512 | EVEX.512.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd zmm {k1}{z}, m512","EVEX.512.66.0F.W1 10 /r")]
        vmovupd_zmm_k1z_m512 = 2349,

        /// <summary>
        /// vmovupd zmm {k1}{z}, r32 | EVEX.512.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd zmm {k1}{z}, r32","EVEX.512.66.0F.W1 10 /r")]
        vmovupd_zmm_k1z_r32 = 2350,

        /// <summary>
        /// vmovupd zmm, m512 | EVEX.512.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd zmm, m512","EVEX.512.66.0F.W1 10 /r")]
        vmovupd_zmm_m512 = 2351,

        /// <summary>
        /// vmovupd zmm, r32 | EVEX.512.66.0F.W1 10 /r | Move unaligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vmovupd zmm, r32","EVEX.512.66.0F.W1 10 /r")]
        vmovupd_zmm_r32 = 2352,

        /// <summary>
        /// vmpsadbw xmm, xmm, m128, imm8 | VEX.128.66.0F3A.WIG 42 /r ib | Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and xmm3/m128 and writes the results in xmm1. Starting offsets within xmm2 and xmm3/m128 are determined by imm8.
        /// </summary>
        [Symbol("vmpsadbw xmm, xmm, m128, imm8","VEX.128.66.0F3A.WIG 42 /r ib")]
        vmpsadbw_xmm_xmm_m128_imm8 = 2353,

        /// <summary>
        /// vmpsadbw xmm, xmm, r8, imm8 | VEX.128.66.0F3A.WIG 42 /r ib | Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and xmm3/m128 and writes the results in xmm1. Starting offsets within xmm2 and xmm3/m128 are determined by imm8.
        /// </summary>
        [Symbol("vmpsadbw xmm, xmm, r8, imm8","VEX.128.66.0F3A.WIG 42 /r ib")]
        vmpsadbw_xmm_xmm_r8_imm8 = 2354,

        /// <summary>
        /// vmpsadbw ymm, ymm, m256, imm8 | VEX.256.66.0F3A.WIG 42 /r ib | Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and ymm3/m128 and writes the results in ymm1. Starting offsets within ymm2 and xmm3/m128 are determined by imm8.
        /// </summary>
        [Symbol("vmpsadbw ymm, ymm, m256, imm8","VEX.256.66.0F3A.WIG 42 /r ib")]
        vmpsadbw_ymm_ymm_m256_imm8 = 2355,

        /// <summary>
        /// vmpsadbw ymm, ymm, r16, imm8 | VEX.256.66.0F3A.WIG 42 /r ib | Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and ymm3/m128 and writes the results in ymm1. Starting offsets within ymm2 and xmm3/m128 are determined by imm8.
        /// </summary>
        [Symbol("vmpsadbw ymm, ymm, r16, imm8","VEX.256.66.0F3A.WIG 42 /r ib")]
        vmpsadbw_ymm_ymm_r16_imm8 = 2356,

        /// <summary>
        /// vpabsb xmm {k1}{z}, m128 | EVEX.128.66.0F38.WIG 1C /r | Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb xmm {k1}{z}, m128","EVEX.128.66.0F38.WIG 1C /r")]
        vpabsb_xmm_k1z_m128 = 2357,

        /// <summary>
        /// vpabsb xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 1C /r | Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 1C /r")]
        vpabsb_xmm_k1z_r8 = 2358,

        /// <summary>
        /// vpabsb xmm, m128 | EVEX.128.66.0F38.WIG 1C /r | Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb xmm, m128","EVEX.128.66.0F38.WIG 1C /r")]
        vpabsb_xmm_m128 = 2359,

        /// <summary>
        /// vpabsb xmm, m128 | VEX.128.66.0F38.WIG 1C /r | Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("vpabsb xmm, m128","VEX.128.66.0F38.WIG 1C /r")]
        vpabsb_xmm_m128_vex = 2360,

        /// <summary>
        /// vpabsb xmm, r8 | EVEX.128.66.0F38.WIG 1C /r | Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb xmm, r8","EVEX.128.66.0F38.WIG 1C /r")]
        vpabsb_xmm_r8 = 2361,

        /// <summary>
        /// vpabsb xmm, r8 | VEX.128.66.0F38.WIG 1C /r | Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("vpabsb xmm, r8","VEX.128.66.0F38.WIG 1C /r")]
        vpabsb_xmm_r8_vex = 2362,

        /// <summary>
        /// vpabsb ymm {k1}{z}, m256 | EVEX.256.66.0F38.WIG 1C /r | Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb ymm {k1}{z}, m256","EVEX.256.66.0F38.WIG 1C /r")]
        vpabsb_ymm_k1z_m256 = 2363,

        /// <summary>
        /// vpabsb ymm {k1}{z}, r16 | EVEX.256.66.0F38.WIG 1C /r | Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb ymm {k1}{z}, r16","EVEX.256.66.0F38.WIG 1C /r")]
        vpabsb_ymm_k1z_r16 = 2364,

        /// <summary>
        /// vpabsb ymm, m256 | EVEX.256.66.0F38.WIG 1C /r | Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb ymm, m256","EVEX.256.66.0F38.WIG 1C /r")]
        vpabsb_ymm_m256 = 2365,

        /// <summary>
        /// vpabsb ymm, m256 | VEX.256.66.0F38.WIG 1C /r | Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1.
        /// </summary>
        [Symbol("vpabsb ymm, m256","VEX.256.66.0F38.WIG 1C /r")]
        vpabsb_ymm_m256_vex = 2366,

        /// <summary>
        /// vpabsb ymm, r16 | EVEX.256.66.0F38.WIG 1C /r | Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb ymm, r16","EVEX.256.66.0F38.WIG 1C /r")]
        vpabsb_ymm_r16 = 2367,

        /// <summary>
        /// vpabsb ymm, r16 | VEX.256.66.0F38.WIG 1C /r | Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1.
        /// </summary>
        [Symbol("vpabsb ymm, r16","VEX.256.66.0F38.WIG 1C /r")]
        vpabsb_ymm_r16_vex = 2368,

        /// <summary>
        /// vpabsb zmm {k1}{z}, m512 | EVEX.512.66.0F38.WIG 1C /r | Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb zmm {k1}{z}, m512","EVEX.512.66.0F38.WIG 1C /r")]
        vpabsb_zmm_k1z_m512 = 2369,

        /// <summary>
        /// vpabsb zmm {k1}{z}, r32 | EVEX.512.66.0F38.WIG 1C /r | Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb zmm {k1}{z}, r32","EVEX.512.66.0F38.WIG 1C /r")]
        vpabsb_zmm_k1z_r32 = 2370,

        /// <summary>
        /// vpabsb zmm, m512 | EVEX.512.66.0F38.WIG 1C /r | Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb zmm, m512","EVEX.512.66.0F38.WIG 1C /r")]
        vpabsb_zmm_m512 = 2371,

        /// <summary>
        /// vpabsb zmm, r32 | EVEX.512.66.0F38.WIG 1C /r | Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsb zmm, r32","EVEX.512.66.0F38.WIG 1C /r")]
        vpabsb_zmm_r32 = 2372,

        /// <summary>
        /// vpabsd xmm {k1}{z}, m128 | EVEX.128.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd xmm {k1}{z}, m128","EVEX.128.66.0F38.W0 1E /r")]
        vpabsd_xmm_k1z_m128 = 2373,

        /// <summary>
        /// vpabsd xmm {k1}{z}, m32bcst | EVEX.128.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd xmm {k1}{z}, m32bcst","EVEX.128.66.0F38.W0 1E /r")]
        vpabsd_xmm_k1z_m32bcst = 2374,

        /// <summary>
        /// vpabsd xmm {k1}{z}, xmm | EVEX.128.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd xmm {k1}{z}, xmm","EVEX.128.66.0F38.W0 1E /r")]
        vpabsd_xmm_k1z_xmm = 2375,

        /// <summary>
        /// vpabsd xmm, m128 | EVEX.128.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd xmm, m128","EVEX.128.66.0F38.W0 1E /r")]
        vpabsd_xmm_m128 = 2376,

        /// <summary>
        /// vpabsd xmm, m128 | VEX.128.66.0F38.WIG 1E /r | Compute the absolute value of 32- bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("vpabsd xmm, m128","VEX.128.66.0F38.WIG 1E /r")]
        vpabsd_xmm_m128_vex = 2377,

        /// <summary>
        /// vpabsd xmm, m32bcst | EVEX.128.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd xmm, m32bcst","EVEX.128.66.0F38.W0 1E /r")]
        vpabsd_xmm_m32bcst = 2378,

        /// <summary>
        /// vpabsd xmm, r8 | VEX.128.66.0F38.WIG 1E /r | Compute the absolute value of 32- bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("vpabsd xmm, r8","VEX.128.66.0F38.WIG 1E /r")]
        vpabsd_xmm_r8 = 2379,

        /// <summary>
        /// vpabsd xmm, xmm | EVEX.128.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd xmm, xmm","EVEX.128.66.0F38.W0 1E /r")]
        vpabsd_xmm_xmm = 2380,

        /// <summary>
        /// vpabsd ymm {k1}{z}, m256 | EVEX.256.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd ymm {k1}{z}, m256","EVEX.256.66.0F38.W0 1E /r")]
        vpabsd_ymm_k1z_m256 = 2381,

        /// <summary>
        /// vpabsd ymm {k1}{z}, m32bcst | EVEX.256.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd ymm {k1}{z}, m32bcst","EVEX.256.66.0F38.W0 1E /r")]
        vpabsd_ymm_k1z_m32bcst = 2382,

        /// <summary>
        /// vpabsd ymm {k1}{z}, ymm | EVEX.256.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd ymm {k1}{z}, ymm","EVEX.256.66.0F38.W0 1E /r")]
        vpabsd_ymm_k1z_ymm = 2383,

        /// <summary>
        /// vpabsd ymm, m256 | EVEX.256.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd ymm, m256","EVEX.256.66.0F38.W0 1E /r")]
        vpabsd_ymm_m256 = 2384,

        /// <summary>
        /// vpabsd ymm, m256 | VEX.256.66.0F38.WIG 1E /r | Compute the absolute value of 32-bit integers in ymm2/m256 and store UNSIGNED result in ymm1.
        /// </summary>
        [Symbol("vpabsd ymm, m256","VEX.256.66.0F38.WIG 1E /r")]
        vpabsd_ymm_m256_vex = 2385,

        /// <summary>
        /// vpabsd ymm, m32bcst | EVEX.256.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd ymm, m32bcst","EVEX.256.66.0F38.W0 1E /r")]
        vpabsd_ymm_m32bcst = 2386,

        /// <summary>
        /// vpabsd ymm, r16 | VEX.256.66.0F38.WIG 1E /r | Compute the absolute value of 32-bit integers in ymm2/m256 and store UNSIGNED result in ymm1.
        /// </summary>
        [Symbol("vpabsd ymm, r16","VEX.256.66.0F38.WIG 1E /r")]
        vpabsd_ymm_r16 = 2387,

        /// <summary>
        /// vpabsd ymm, ymm | EVEX.256.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd ymm, ymm","EVEX.256.66.0F38.W0 1E /r")]
        vpabsd_ymm_ymm = 2388,

        /// <summary>
        /// vpabsd zmm {k1}{z}, m32bcst | EVEX.512.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd zmm {k1}{z}, m32bcst","EVEX.512.66.0F38.W0 1E /r")]
        vpabsd_zmm_k1z_m32bcst = 2389,

        /// <summary>
        /// vpabsd zmm {k1}{z}, m512 | EVEX.512.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd zmm {k1}{z}, m512","EVEX.512.66.0F38.W0 1E /r")]
        vpabsd_zmm_k1z_m512 = 2390,

        /// <summary>
        /// vpabsd zmm {k1}{z}, zmm | EVEX.512.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd zmm {k1}{z}, zmm","EVEX.512.66.0F38.W0 1E /r")]
        vpabsd_zmm_k1z_zmm = 2391,

        /// <summary>
        /// vpabsd zmm, m32bcst | EVEX.512.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd zmm, m32bcst","EVEX.512.66.0F38.W0 1E /r")]
        vpabsd_zmm_m32bcst = 2392,

        /// <summary>
        /// vpabsd zmm, m512 | EVEX.512.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd zmm, m512","EVEX.512.66.0F38.W0 1E /r")]
        vpabsd_zmm_m512 = 2393,

        /// <summary>
        /// vpabsd zmm, zmm | EVEX.512.66.0F38.W0 1E /r | Compute the absolute value of 32-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsd zmm, zmm","EVEX.512.66.0F38.W0 1E /r")]
        vpabsd_zmm_zmm = 2394,

        /// <summary>
        /// vpabsq xmm {k1}{z}, m128 | EVEX.128.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq xmm {k1}{z}, m128","EVEX.128.66.0F38.W1 1F /r")]
        vpabsq_xmm_k1z_m128 = 2395,

        /// <summary>
        /// vpabsq xmm {k1}{z}, m64bcst | EVEX.128.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq xmm {k1}{z}, m64bcst","EVEX.128.66.0F38.W1 1F /r")]
        vpabsq_xmm_k1z_m64bcst = 2396,

        /// <summary>
        /// vpabsq xmm {k1}{z}, xmm | EVEX.128.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq xmm {k1}{z}, xmm","EVEX.128.66.0F38.W1 1F /r")]
        vpabsq_xmm_k1z_xmm = 2397,

        /// <summary>
        /// vpabsq xmm, m128 | EVEX.128.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq xmm, m128","EVEX.128.66.0F38.W1 1F /r")]
        vpabsq_xmm_m128 = 2398,

        /// <summary>
        /// vpabsq xmm, m64bcst | EVEX.128.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq xmm, m64bcst","EVEX.128.66.0F38.W1 1F /r")]
        vpabsq_xmm_m64bcst = 2399,

        /// <summary>
        /// vpabsq xmm, xmm | EVEX.128.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq xmm, xmm","EVEX.128.66.0F38.W1 1F /r")]
        vpabsq_xmm_xmm = 2400,

        /// <summary>
        /// vpabsq ymm {k1}{z}, m256 | EVEX.256.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq ymm {k1}{z}, m256","EVEX.256.66.0F38.W1 1F /r")]
        vpabsq_ymm_k1z_m256 = 2401,

        /// <summary>
        /// vpabsq ymm {k1}{z}, m64bcst | EVEX.256.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq ymm {k1}{z}, m64bcst","EVEX.256.66.0F38.W1 1F /r")]
        vpabsq_ymm_k1z_m64bcst = 2402,

        /// <summary>
        /// vpabsq ymm {k1}{z}, ymm | EVEX.256.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq ymm {k1}{z}, ymm","EVEX.256.66.0F38.W1 1F /r")]
        vpabsq_ymm_k1z_ymm = 2403,

        /// <summary>
        /// vpabsq ymm, m256 | EVEX.256.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq ymm, m256","EVEX.256.66.0F38.W1 1F /r")]
        vpabsq_ymm_m256 = 2404,

        /// <summary>
        /// vpabsq ymm, m64bcst | EVEX.256.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq ymm, m64bcst","EVEX.256.66.0F38.W1 1F /r")]
        vpabsq_ymm_m64bcst = 2405,

        /// <summary>
        /// vpabsq ymm, ymm | EVEX.256.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq ymm, ymm","EVEX.256.66.0F38.W1 1F /r")]
        vpabsq_ymm_ymm = 2406,

        /// <summary>
        /// vpabsq zmm {k1}{z}, m512 | EVEX.512.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq zmm {k1}{z}, m512","EVEX.512.66.0F38.W1 1F /r")]
        vpabsq_zmm_k1z_m512 = 2407,

        /// <summary>
        /// vpabsq zmm {k1}{z}, m64bcst | EVEX.512.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq zmm {k1}{z}, m64bcst","EVEX.512.66.0F38.W1 1F /r")]
        vpabsq_zmm_k1z_m64bcst = 2408,

        /// <summary>
        /// vpabsq zmm {k1}{z}, zmm | EVEX.512.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq zmm {k1}{z}, zmm","EVEX.512.66.0F38.W1 1F /r")]
        vpabsq_zmm_k1z_zmm = 2409,

        /// <summary>
        /// vpabsq zmm, m512 | EVEX.512.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq zmm, m512","EVEX.512.66.0F38.W1 1F /r")]
        vpabsq_zmm_m512 = 2410,

        /// <summary>
        /// vpabsq zmm, m64bcst | EVEX.512.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq zmm, m64bcst","EVEX.512.66.0F38.W1 1F /r")]
        vpabsq_zmm_m64bcst = 2411,

        /// <summary>
        /// vpabsq zmm, zmm | EVEX.512.66.0F38.W1 1F /r | Compute the absolute value of 64-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsq zmm, zmm","EVEX.512.66.0F38.W1 1F /r")]
        vpabsq_zmm_zmm = 2412,

        /// <summary>
        /// vpabsw xmm {k1}{z}, m128 | EVEX.128.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw xmm {k1}{z}, m128","EVEX.128.66.0F38.WIG 1D /r")]
        vpabsw_xmm_k1z_m128 = 2413,

        /// <summary>
        /// vpabsw xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 1D /r")]
        vpabsw_xmm_k1z_r8 = 2414,

        /// <summary>
        /// vpabsw xmm, m128 | EVEX.128.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw xmm, m128","EVEX.128.66.0F38.WIG 1D /r")]
        vpabsw_xmm_m128 = 2415,

        /// <summary>
        /// vpabsw xmm, m128 | VEX.128.66.0F38.WIG 1D /r | Compute the absolute value of 16- bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("vpabsw xmm, m128","VEX.128.66.0F38.WIG 1D /r")]
        vpabsw_xmm_m128_vex = 2416,

        /// <summary>
        /// vpabsw xmm, r8 | EVEX.128.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw xmm, r8","EVEX.128.66.0F38.WIG 1D /r")]
        vpabsw_xmm_r8 = 2417,

        /// <summary>
        /// vpabsw xmm, r8 | VEX.128.66.0F38.WIG 1D /r | Compute the absolute value of 16- bit integers in xmm2/m128 and store UNSIGNED result in xmm1.
        /// </summary>
        [Symbol("vpabsw xmm, r8","VEX.128.66.0F38.WIG 1D /r")]
        vpabsw_xmm_r8_vex = 2418,

        /// <summary>
        /// vpabsw ymm {k1}{z}, m256 | EVEX.256.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw ymm {k1}{z}, m256","EVEX.256.66.0F38.WIG 1D /r")]
        vpabsw_ymm_k1z_m256 = 2419,

        /// <summary>
        /// vpabsw ymm {k1}{z}, r16 | EVEX.256.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw ymm {k1}{z}, r16","EVEX.256.66.0F38.WIG 1D /r")]
        vpabsw_ymm_k1z_r16 = 2420,

        /// <summary>
        /// vpabsw ymm, m256 | EVEX.256.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw ymm, m256","EVEX.256.66.0F38.WIG 1D /r")]
        vpabsw_ymm_m256 = 2421,

        /// <summary>
        /// vpabsw ymm, m256 | VEX.256.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1.
        /// </summary>
        [Symbol("vpabsw ymm, m256","VEX.256.66.0F38.WIG 1D /r")]
        vpabsw_ymm_m256_vex = 2422,

        /// <summary>
        /// vpabsw ymm, r16 | EVEX.256.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw ymm, r16","EVEX.256.66.0F38.WIG 1D /r")]
        vpabsw_ymm_r16 = 2423,

        /// <summary>
        /// vpabsw ymm, r16 | VEX.256.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1.
        /// </summary>
        [Symbol("vpabsw ymm, r16","VEX.256.66.0F38.WIG 1D /r")]
        vpabsw_ymm_r16_vex = 2424,

        /// <summary>
        /// vpabsw zmm {k1}{z}, m512 | EVEX.512.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw zmm {k1}{z}, m512","EVEX.512.66.0F38.WIG 1D /r")]
        vpabsw_zmm_k1z_m512 = 2425,

        /// <summary>
        /// vpabsw zmm {k1}{z}, r32 | EVEX.512.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw zmm {k1}{z}, r32","EVEX.512.66.0F38.WIG 1D /r")]
        vpabsw_zmm_k1z_r32 = 2426,

        /// <summary>
        /// vpabsw zmm, m512 | EVEX.512.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw zmm, m512","EVEX.512.66.0F38.WIG 1D /r")]
        vpabsw_zmm_m512 = 2427,

        /// <summary>
        /// vpabsw zmm, r32 | EVEX.512.66.0F38.WIG 1D /r | Compute the absolute value of 16-bit integers in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpabsw zmm, r32","EVEX.512.66.0F38.WIG 1D /r")]
        vpabsw_zmm_r32 = 2428,

        /// <summary>
        /// vpackssdw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 6B /r | Converts packed signed doubleword integers from xmm2 and from xmm3/m128/m32bcst into packed signed word integers in xmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpackssdw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 6B /r")]
        vpackssdw_xmm_k1z_xmm_m128 = 2429,

        /// <summary>
        /// vpackssdw xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F.W0 6B /r | Converts packed signed doubleword integers from xmm2 and from xmm3/m128/m32bcst into packed signed word integers in xmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpackssdw xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F.W0 6B /r")]
        vpackssdw_xmm_k1z_xmm_m32bcst = 2430,

        /// <summary>
        /// vpackssdw xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W0 6B /r | Converts packed signed doubleword integers from xmm2 and from xmm3/m128/m32bcst into packed signed word integers in xmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpackssdw xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W0 6B /r")]
        vpackssdw_xmm_k1z_xmm_xmm = 2431,

        /// <summary>
        /// vpackssdw xmm, xmm, m128 | EVEX.128.66.0F.W0 6B /r | Converts packed signed doubleword integers from xmm2 and from xmm3/m128/m32bcst into packed signed word integers in xmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpackssdw xmm, xmm, m128","EVEX.128.66.0F.W0 6B /r")]
        vpackssdw_xmm_xmm_m128 = 2432,

        /// <summary>
        /// vpackssdw xmm, xmm, m128 | VEX.128.66.0F.WIG 6B /r | Converts 4 packed signed doubleword integers from xmm2 and from xmm3/m128 into 8 packed signed word integers in xmm1 using signed saturation.
        /// </summary>
        [Symbol("vpackssdw xmm, xmm, m128","VEX.128.66.0F.WIG 6B /r")]
        vpackssdw_xmm_xmm_m128_vex = 2433,

        /// <summary>
        /// vpackssdw xmm, xmm, m32bcst | EVEX.128.66.0F.W0 6B /r | Converts packed signed doubleword integers from xmm2 and from xmm3/m128/m32bcst into packed signed word integers in xmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpackssdw xmm, xmm, m32bcst","EVEX.128.66.0F.W0 6B /r")]
        vpackssdw_xmm_xmm_m32bcst = 2434,

        /// <summary>
        /// vpackssdw xmm, xmm, r8 | VEX.128.66.0F.WIG 6B /r | Converts 4 packed signed doubleword integers from xmm2 and from xmm3/m128 into 8 packed signed word integers in xmm1 using signed saturation.
        /// </summary>
        [Symbol("vpackssdw xmm, xmm, r8","VEX.128.66.0F.WIG 6B /r")]
        vpackssdw_xmm_xmm_r8 = 2435,

        /// <summary>
        /// vpackssdw xmm, xmm, xmm | EVEX.128.66.0F.W0 6B /r | Converts packed signed doubleword integers from xmm2 and from xmm3/m128/m32bcst into packed signed word integers in xmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpackssdw xmm, xmm, xmm","EVEX.128.66.0F.W0 6B /r")]
        vpackssdw_xmm_xmm_xmm = 2436,

        /// <summary>
        /// vpackssdw ymm, ymm, m256 | VEX.256.66.0F.WIG 6B /r | Converts 8 packed signed doubleword integers from ymm2 and from ymm3/m256 into 16 packed signed word integers in ymm1 using signed saturation.
        /// </summary>
        [Symbol("vpackssdw ymm, ymm, m256","VEX.256.66.0F.WIG 6B /r")]
        vpackssdw_ymm_ymm_m256 = 2437,

        /// <summary>
        /// vpackssdw ymm, ymm, r16 | VEX.256.66.0F.WIG 6B /r | Converts 8 packed signed doubleword integers from ymm2 and from ymm3/m256 into 16 packed signed word integers in ymm1 using signed saturation.
        /// </summary>
        [Symbol("vpackssdw ymm, ymm, r16","VEX.256.66.0F.WIG 6B /r")]
        vpackssdw_ymm_ymm_r16 = 2438,

        /// <summary>
        /// vpacksswb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG 63 /r | Converts packed signed word integers from xmm2 and from xmm3/m128 into packed signed byte integers in xmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG 63 /r")]
        vpacksswb_xmm_k1z_xmm_m128 = 2439,

        /// <summary>
        /// vpacksswb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG 63 /r | Converts packed signed word integers from xmm2 and from xmm3/m128 into packed signed byte integers in xmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG 63 /r")]
        vpacksswb_xmm_k1z_xmm_r8 = 2440,

        /// <summary>
        /// vpacksswb xmm, xmm, m128 | EVEX.128.66.0F.WIG 63 /r | Converts packed signed word integers from xmm2 and from xmm3/m128 into packed signed byte integers in xmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb xmm, xmm, m128","EVEX.128.66.0F.WIG 63 /r")]
        vpacksswb_xmm_xmm_m128 = 2441,

        /// <summary>
        /// vpacksswb xmm, xmm, m128 | VEX.128.66.0F.WIG 63 /r | Converts 8 packed signed word integers from xmm2 and from xmm3/m128 into 16 packed signed byte integers in xmm1 using signed saturation.
        /// </summary>
        [Symbol("vpacksswb xmm, xmm, m128","VEX.128.66.0F.WIG 63 /r")]
        vpacksswb_xmm_xmm_m128_vex = 2442,

        /// <summary>
        /// vpacksswb xmm, xmm, r8 | EVEX.128.66.0F.WIG 63 /r | Converts packed signed word integers from xmm2 and from xmm3/m128 into packed signed byte integers in xmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb xmm, xmm, r8","EVEX.128.66.0F.WIG 63 /r")]
        vpacksswb_xmm_xmm_r8 = 2443,

        /// <summary>
        /// vpacksswb xmm, xmm, r8 | VEX.128.66.0F.WIG 63 /r | Converts 8 packed signed word integers from xmm2 and from xmm3/m128 into 16 packed signed byte integers in xmm1 using signed saturation.
        /// </summary>
        [Symbol("vpacksswb xmm, xmm, r8","VEX.128.66.0F.WIG 63 /r")]
        vpacksswb_xmm_xmm_r8_vex = 2444,

        /// <summary>
        /// vpacksswb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG 63 /r | Converts packed signed word integers from ymm2 and from ymm3/m256 into packed signed byte integers in ymm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG 63 /r")]
        vpacksswb_ymm_k1z_ymm_m256 = 2445,

        /// <summary>
        /// vpacksswb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG 63 /r | Converts packed signed word integers from ymm2 and from ymm3/m256 into packed signed byte integers in ymm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG 63 /r")]
        vpacksswb_ymm_k1z_ymm_r16 = 2446,

        /// <summary>
        /// vpacksswb ymm, ymm, m256 | EVEX.256.66.0F.WIG 63 /r | Converts packed signed word integers from ymm2 and from ymm3/m256 into packed signed byte integers in ymm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb ymm, ymm, m256","EVEX.256.66.0F.WIG 63 /r")]
        vpacksswb_ymm_ymm_m256 = 2447,

        /// <summary>
        /// vpacksswb ymm, ymm, m256 | VEX.256.66.0F.WIG 63 /r | Converts 16 packed signed word integers from ymm2 and from ymm3/m256 into 32 packed signed byte integers in ymm1 using signed saturation.
        /// </summary>
        [Symbol("vpacksswb ymm, ymm, m256","VEX.256.66.0F.WIG 63 /r")]
        vpacksswb_ymm_ymm_m256_vex = 2448,

        /// <summary>
        /// vpacksswb ymm, ymm, r16 | EVEX.256.66.0F.WIG 63 /r | Converts packed signed word integers from ymm2 and from ymm3/m256 into packed signed byte integers in ymm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb ymm, ymm, r16","EVEX.256.66.0F.WIG 63 /r")]
        vpacksswb_ymm_ymm_r16 = 2449,

        /// <summary>
        /// vpacksswb ymm, ymm, r16 | VEX.256.66.0F.WIG 63 /r | Converts 16 packed signed word integers from ymm2 and from ymm3/m256 into 32 packed signed byte integers in ymm1 using signed saturation.
        /// </summary>
        [Symbol("vpacksswb ymm, ymm, r16","VEX.256.66.0F.WIG 63 /r")]
        vpacksswb_ymm_ymm_r16_vex = 2450,

        /// <summary>
        /// vpacksswb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG 63 /r | Converts packed signed word integers from zmm2 and from zmm3/m512 into packed signed byte integers in zmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG 63 /r")]
        vpacksswb_zmm_k1z_zmm_m512 = 2451,

        /// <summary>
        /// vpacksswb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG 63 /r | Converts packed signed word integers from zmm2 and from zmm3/m512 into packed signed byte integers in zmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG 63 /r")]
        vpacksswb_zmm_k1z_zmm_r32 = 2452,

        /// <summary>
        /// vpacksswb zmm, zmm, m512 | EVEX.512.66.0F.WIG 63 /r | Converts packed signed word integers from zmm2 and from zmm3/m512 into packed signed byte integers in zmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb zmm, zmm, m512","EVEX.512.66.0F.WIG 63 /r")]
        vpacksswb_zmm_zmm_m512 = 2453,

        /// <summary>
        /// vpacksswb zmm, zmm, r32 | EVEX.512.66.0F.WIG 63 /r | Converts packed signed word integers from zmm2 and from zmm3/m512 into packed signed byte integers in zmm1 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpacksswb zmm, zmm, r32","EVEX.512.66.0F.WIG 63 /r")]
        vpacksswb_zmm_zmm_r32 = 2454,

        /// <summary>
        /// vpackusdw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 2B /r | Convert packed signed doubleword integers from xmm2 and packed signed doubleword integers from xmm3/m128/m32bcst into packed unsigned word integers in xmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 2B /r")]
        vpackusdw_xmm_k1z_xmm_m128 = 2455,

        /// <summary>
        /// vpackusdw xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 2B /r | Convert packed signed doubleword integers from xmm2 and packed signed doubleword integers from xmm3/m128/m32bcst into packed unsigned word integers in xmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 2B /r")]
        vpackusdw_xmm_k1z_xmm_m32bcst = 2456,

        /// <summary>
        /// vpackusdw xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 2B /r | Convert packed signed doubleword integers from xmm2 and packed signed doubleword integers from xmm3/m128/m32bcst into packed unsigned word integers in xmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 2B /r")]
        vpackusdw_xmm_k1z_xmm_xmm = 2457,

        /// <summary>
        /// vpackusdw xmm, xmm, m128 | EVEX.128.66.0F38.W0 2B /r | Convert packed signed doubleword integers from xmm2 and packed signed doubleword integers from xmm3/m128/m32bcst into packed unsigned word integers in xmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw xmm, xmm, m128","EVEX.128.66.0F38.W0 2B /r")]
        vpackusdw_xmm_xmm_m128 = 2458,

        /// <summary>
        /// vpackusdw xmm, xmm, m128 | VEX.128.66.0F38 2B /r | Convert 4 packed signed doubleword integers from xmm2 and 4 packed signed doubleword integers from xmm3/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation.
        /// </summary>
        [Symbol("vpackusdw xmm, xmm, m128","VEX.128.66.0F38 2B /r")]
        vpackusdw_xmm_xmm_m128_vex = 2459,

        /// <summary>
        /// vpackusdw xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 2B /r | Convert packed signed doubleword integers from xmm2 and packed signed doubleword integers from xmm3/m128/m32bcst into packed unsigned word integers in xmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 2B /r")]
        vpackusdw_xmm_xmm_m32bcst = 2460,

        /// <summary>
        /// vpackusdw xmm, xmm, r8 | VEX.128.66.0F38 2B /r | Convert 4 packed signed doubleword integers from xmm2 and 4 packed signed doubleword integers from xmm3/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation.
        /// </summary>
        [Symbol("vpackusdw xmm, xmm, r8","VEX.128.66.0F38 2B /r")]
        vpackusdw_xmm_xmm_r8 = 2461,

        /// <summary>
        /// vpackusdw xmm, xmm, xmm | EVEX.128.66.0F38.W0 2B /r | Convert packed signed doubleword integers from xmm2 and packed signed doubleword integers from xmm3/m128/m32bcst into packed unsigned word integers in xmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw xmm, xmm, xmm","EVEX.128.66.0F38.W0 2B /r")]
        vpackusdw_xmm_xmm_xmm = 2462,

        /// <summary>
        /// vpackusdw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 2B /r | Convert packed signed doubleword integers from ymm2 and packed signed doubleword integers from ymm3/m256/m32bcst into packed unsigned word integers in ymm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 2B /r")]
        vpackusdw_ymm_k1z_ymm_m256 = 2463,

        /// <summary>
        /// vpackusdw ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 2B /r | Convert packed signed doubleword integers from ymm2 and packed signed doubleword integers from ymm3/m256/m32bcst into packed unsigned word integers in ymm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 2B /r")]
        vpackusdw_ymm_k1z_ymm_m32bcst = 2464,

        /// <summary>
        /// vpackusdw ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 2B /r | Convert packed signed doubleword integers from ymm2 and packed signed doubleword integers from ymm3/m256/m32bcst into packed unsigned word integers in ymm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 2B /r")]
        vpackusdw_ymm_k1z_ymm_ymm = 2465,

        /// <summary>
        /// vpackusdw ymm, ymm, m256 | EVEX.256.66.0F38.W0 2B /r | Convert packed signed doubleword integers from ymm2 and packed signed doubleword integers from ymm3/m256/m32bcst into packed unsigned word integers in ymm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw ymm, ymm, m256","EVEX.256.66.0F38.W0 2B /r")]
        vpackusdw_ymm_ymm_m256 = 2466,

        /// <summary>
        /// vpackusdw ymm, ymm, m256 | VEX.256.66.0F38 2B /r | Convert 8 packed signed doubleword integers from ymm2 and 8 packed signed doubleword integers from ymm3/m256 into 16 packed unsigned word integers in ymm1 using unsigned saturation.
        /// </summary>
        [Symbol("vpackusdw ymm, ymm, m256","VEX.256.66.0F38 2B /r")]
        vpackusdw_ymm_ymm_m256_vex = 2467,

        /// <summary>
        /// vpackusdw ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 2B /r | Convert packed signed doubleword integers from ymm2 and packed signed doubleword integers from ymm3/m256/m32bcst into packed unsigned word integers in ymm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 2B /r")]
        vpackusdw_ymm_ymm_m32bcst = 2468,

        /// <summary>
        /// vpackusdw ymm, ymm, r16 | VEX.256.66.0F38 2B /r | Convert 8 packed signed doubleword integers from ymm2 and 8 packed signed doubleword integers from ymm3/m256 into 16 packed unsigned word integers in ymm1 using unsigned saturation.
        /// </summary>
        [Symbol("vpackusdw ymm, ymm, r16","VEX.256.66.0F38 2B /r")]
        vpackusdw_ymm_ymm_r16 = 2469,

        /// <summary>
        /// vpackusdw ymm, ymm, ymm | EVEX.256.66.0F38.W0 2B /r | Convert packed signed doubleword integers from ymm2 and packed signed doubleword integers from ymm3/m256/m32bcst into packed unsigned word integers in ymm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw ymm, ymm, ymm","EVEX.256.66.0F38.W0 2B /r")]
        vpackusdw_ymm_ymm_ymm = 2470,

        /// <summary>
        /// vpackusdw zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 2B /r | Convert packed signed doubleword integers from zmm2 and packed signed doubleword integers from zmm3/m512/m32bcst into packed unsigned word integers in zmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 2B /r")]
        vpackusdw_zmm_k1z_zmm_m32bcst = 2471,

        /// <summary>
        /// vpackusdw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 2B /r | Convert packed signed doubleword integers from zmm2 and packed signed doubleword integers from zmm3/m512/m32bcst into packed unsigned word integers in zmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 2B /r")]
        vpackusdw_zmm_k1z_zmm_m512 = 2472,

        /// <summary>
        /// vpackusdw zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 2B /r | Convert packed signed doubleword integers from zmm2 and packed signed doubleword integers from zmm3/m512/m32bcst into packed unsigned word integers in zmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 2B /r")]
        vpackusdw_zmm_k1z_zmm_zmm = 2473,

        /// <summary>
        /// vpackusdw zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 2B /r | Convert packed signed doubleword integers from zmm2 and packed signed doubleword integers from zmm3/m512/m32bcst into packed unsigned word integers in zmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 2B /r")]
        vpackusdw_zmm_zmm_m32bcst = 2474,

        /// <summary>
        /// vpackusdw zmm, zmm, m512 | EVEX.512.66.0F38.W0 2B /r | Convert packed signed doubleword integers from zmm2 and packed signed doubleword integers from zmm3/m512/m32bcst into packed unsigned word integers in zmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw zmm, zmm, m512","EVEX.512.66.0F38.W0 2B /r")]
        vpackusdw_zmm_zmm_m512 = 2475,

        /// <summary>
        /// vpackusdw zmm, zmm, zmm | EVEX.512.66.0F38.W0 2B /r | Convert packed signed doubleword integers from zmm2 and packed signed doubleword integers from zmm3/m512/m32bcst into packed unsigned word integers in zmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackusdw zmm, zmm, zmm","EVEX.512.66.0F38.W0 2B /r")]
        vpackusdw_zmm_zmm_zmm = 2476,

        /// <summary>
        /// vpackuswb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG 67 /r | Converts signed word integers from xmm2 and signed word integers from xmm3/m128 into unsigned byte integers in xmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG 67 /r")]
        vpackuswb_xmm_k1z_xmm_m128 = 2477,

        /// <summary>
        /// vpackuswb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG 67 /r | Converts signed word integers from xmm2 and signed word integers from xmm3/m128 into unsigned byte integers in xmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG 67 /r")]
        vpackuswb_xmm_k1z_xmm_r8 = 2478,

        /// <summary>
        /// vpackuswb xmm, xmm, m128 | EVEX.128.66.0F.WIG 67 /r | Converts signed word integers from xmm2 and signed word integers from xmm3/m128 into unsigned byte integers in xmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb xmm, xmm, m128","EVEX.128.66.0F.WIG 67 /r")]
        vpackuswb_xmm_xmm_m128 = 2479,

        /// <summary>
        /// vpackuswb xmm, xmm, m128 | VEX.128.66.0F.WIG 67 /r | Converts 8 signed word integers from xmm2 and 8 signed word integers from xmm3/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation.
        /// </summary>
        [Symbol("vpackuswb xmm, xmm, m128","VEX.128.66.0F.WIG 67 /r")]
        vpackuswb_xmm_xmm_m128_vex = 2480,

        /// <summary>
        /// vpackuswb xmm, xmm, r8 | EVEX.128.66.0F.WIG 67 /r | Converts signed word integers from xmm2 and signed word integers from xmm3/m128 into unsigned byte integers in xmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb xmm, xmm, r8","EVEX.128.66.0F.WIG 67 /r")]
        vpackuswb_xmm_xmm_r8 = 2481,

        /// <summary>
        /// vpackuswb xmm, xmm, r8 | VEX.128.66.0F.WIG 67 /r | Converts 8 signed word integers from xmm2 and 8 signed word integers from xmm3/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation.
        /// </summary>
        [Symbol("vpackuswb xmm, xmm, r8","VEX.128.66.0F.WIG 67 /r")]
        vpackuswb_xmm_xmm_r8_vex = 2482,

        /// <summary>
        /// vpackuswb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG 67 /r | Converts signed word integers from ymm2 and signed word integers from ymm3/m256 into unsigned byte integers in ymm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG 67 /r")]
        vpackuswb_ymm_k1z_ymm_m256 = 2483,

        /// <summary>
        /// vpackuswb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG 67 /r | Converts signed word integers from ymm2 and signed word integers from ymm3/m256 into unsigned byte integers in ymm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG 67 /r")]
        vpackuswb_ymm_k1z_ymm_r16 = 2484,

        /// <summary>
        /// vpackuswb ymm, ymm, m256 | EVEX.256.66.0F.WIG 67 /r | Converts signed word integers from ymm2 and signed word integers from ymm3/m256 into unsigned byte integers in ymm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb ymm, ymm, m256","EVEX.256.66.0F.WIG 67 /r")]
        vpackuswb_ymm_ymm_m256 = 2485,

        /// <summary>
        /// vpackuswb ymm, ymm, m256 | VEX.256.66.0F.WIG 67 /r | Converts 16 signed word integers from ymm2 and 16signed word integers from ymm3/m256 into 32 unsigned byte integers in ymm1 using unsigned saturation.
        /// </summary>
        [Symbol("vpackuswb ymm, ymm, m256","VEX.256.66.0F.WIG 67 /r")]
        vpackuswb_ymm_ymm_m256_vex = 2486,

        /// <summary>
        /// vpackuswb ymm, ymm, r16 | EVEX.256.66.0F.WIG 67 /r | Converts signed word integers from ymm2 and signed word integers from ymm3/m256 into unsigned byte integers in ymm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb ymm, ymm, r16","EVEX.256.66.0F.WIG 67 /r")]
        vpackuswb_ymm_ymm_r16 = 2487,

        /// <summary>
        /// vpackuswb ymm, ymm, r16 | VEX.256.66.0F.WIG 67 /r | Converts 16 signed word integers from ymm2 and 16signed word integers from ymm3/m256 into 32 unsigned byte integers in ymm1 using unsigned saturation.
        /// </summary>
        [Symbol("vpackuswb ymm, ymm, r16","VEX.256.66.0F.WIG 67 /r")]
        vpackuswb_ymm_ymm_r16_vex = 2488,

        /// <summary>
        /// vpackuswb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG 67 /r | Converts signed word integers from zmm2 and signed word integers from zmm3/m512 into unsigned byte integers in zmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG 67 /r")]
        vpackuswb_zmm_k1z_zmm_m512 = 2489,

        /// <summary>
        /// vpackuswb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG 67 /r | Converts signed word integers from zmm2 and signed word integers from zmm3/m512 into unsigned byte integers in zmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG 67 /r")]
        vpackuswb_zmm_k1z_zmm_r32 = 2490,

        /// <summary>
        /// vpackuswb zmm, zmm, m512 | EVEX.512.66.0F.WIG 67 /r | Converts signed word integers from zmm2 and signed word integers from zmm3/m512 into unsigned byte integers in zmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb zmm, zmm, m512","EVEX.512.66.0F.WIG 67 /r")]
        vpackuswb_zmm_zmm_m512 = 2491,

        /// <summary>
        /// vpackuswb zmm, zmm, r32 | EVEX.512.66.0F.WIG 67 /r | Converts signed word integers from zmm2 and signed word integers from zmm3/m512 into unsigned byte integers in zmm1 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpackuswb zmm, zmm, r32","EVEX.512.66.0F.WIG 67 /r")]
        vpackuswb_zmm_zmm_r32 = 2492,

        /// <summary>
        /// vpaddb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG FC /r | Add packed byte integers from xmm2, and xmm3/m128 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG FC /r")]
        vpaddb_xmm_k1z_xmm_m128 = 2493,

        /// <summary>
        /// vpaddb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG FC /r | Add packed byte integers from xmm2, and xmm3/m128 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG FC /r")]
        vpaddb_xmm_k1z_xmm_r8 = 2494,

        /// <summary>
        /// vpaddb xmm, xmm, m128 | EVEX.128.66.0F.WIG FC /r | Add packed byte integers from xmm2, and xmm3/m128 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb xmm, xmm, m128","EVEX.128.66.0F.WIG FC /r")]
        vpaddb_xmm_xmm_m128 = 2495,

        /// <summary>
        /// vpaddb xmm, xmm, m128 | VEX.128.66.0F.WIG FC /r | Add packed byte integers from xmm2, and xmm3/m128 and store in xmm1.
        /// </summary>
        [Symbol("vpaddb xmm, xmm, m128","VEX.128.66.0F.WIG FC /r")]
        vpaddb_xmm_xmm_m128_vex = 2496,

        /// <summary>
        /// vpaddb xmm, xmm, r8 | EVEX.128.66.0F.WIG FC /r | Add packed byte integers from xmm2, and xmm3/m128 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb xmm, xmm, r8","EVEX.128.66.0F.WIG FC /r")]
        vpaddb_xmm_xmm_r8 = 2497,

        /// <summary>
        /// vpaddb xmm, xmm, r8 | VEX.128.66.0F.WIG FC /r | Add packed byte integers from xmm2, and xmm3/m128 and store in xmm1.
        /// </summary>
        [Symbol("vpaddb xmm, xmm, r8","VEX.128.66.0F.WIG FC /r")]
        vpaddb_xmm_xmm_r8_vex = 2498,

        /// <summary>
        /// vpaddb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG FC /r | Add packed byte integers from ymm2, and ymm3/m256 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG FC /r")]
        vpaddb_ymm_k1z_ymm_m256 = 2499,

        /// <summary>
        /// vpaddb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG FC /r | Add packed byte integers from ymm2, and ymm3/m256 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG FC /r")]
        vpaddb_ymm_k1z_ymm_r16 = 2500,

        /// <summary>
        /// vpaddb ymm, ymm, m256 | EVEX.256.66.0F.WIG FC /r | Add packed byte integers from ymm2, and ymm3/m256 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb ymm, ymm, m256","EVEX.256.66.0F.WIG FC /r")]
        vpaddb_ymm_ymm_m256 = 2501,

        /// <summary>
        /// vpaddb ymm, ymm, m256 | VEX.256.66.0F.WIG FC /r | Add packed byte integers from ymm2, and ymm3/m256 and store in ymm1.
        /// </summary>
        [Symbol("vpaddb ymm, ymm, m256","VEX.256.66.0F.WIG FC /r")]
        vpaddb_ymm_ymm_m256_vex = 2502,

        /// <summary>
        /// vpaddb ymm, ymm, r16 | EVEX.256.66.0F.WIG FC /r | Add packed byte integers from ymm2, and ymm3/m256 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb ymm, ymm, r16","EVEX.256.66.0F.WIG FC /r")]
        vpaddb_ymm_ymm_r16 = 2503,

        /// <summary>
        /// vpaddb ymm, ymm, r16 | VEX.256.66.0F.WIG FC /r | Add packed byte integers from ymm2, and ymm3/m256 and store in ymm1.
        /// </summary>
        [Symbol("vpaddb ymm, ymm, r16","VEX.256.66.0F.WIG FC /r")]
        vpaddb_ymm_ymm_r16_vex = 2504,

        /// <summary>
        /// vpaddb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG FC /r | Add packed byte integers from zmm2, and zmm3/m512 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG FC /r")]
        vpaddb_zmm_k1z_zmm_m512 = 2505,

        /// <summary>
        /// vpaddb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG FC /r | Add packed byte integers from zmm2, and zmm3/m512 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG FC /r")]
        vpaddb_zmm_k1z_zmm_r32 = 2506,

        /// <summary>
        /// vpaddb zmm, zmm, m512 | EVEX.512.66.0F.WIG FC /r | Add packed byte integers from zmm2, and zmm3/m512 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb zmm, zmm, m512","EVEX.512.66.0F.WIG FC /r")]
        vpaddb_zmm_zmm_m512 = 2507,

        /// <summary>
        /// vpaddb zmm, zmm, r32 | EVEX.512.66.0F.WIG FC /r | Add packed byte integers from zmm2, and zmm3/m512 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddb zmm, zmm, r32","EVEX.512.66.0F.WIG FC /r")]
        vpaddb_zmm_zmm_r32 = 2508,

        /// <summary>
        /// vpaddd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 FE /r | Add packed doubleword integers from xmm2, and xmm3/m128/m32bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 FE /r")]
        vpaddd_xmm_k1z_xmm_m128 = 2509,

        /// <summary>
        /// vpaddd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F.W0 FE /r | Add packed doubleword integers from xmm2, and xmm3/m128/m32bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F.W0 FE /r")]
        vpaddd_xmm_k1z_xmm_m32bcst = 2510,

        /// <summary>
        /// vpaddd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W0 FE /r | Add packed doubleword integers from xmm2, and xmm3/m128/m32bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W0 FE /r")]
        vpaddd_xmm_k1z_xmm_xmm = 2511,

        /// <summary>
        /// vpaddd xmm, xmm, m128 | EVEX.128.66.0F.W0 FE /r | Add packed doubleword integers from xmm2, and xmm3/m128/m32bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd xmm, xmm, m128","EVEX.128.66.0F.W0 FE /r")]
        vpaddd_xmm_xmm_m128 = 2512,

        /// <summary>
        /// vpaddd xmm, xmm, m128 | VEX.128.66.0F.WIG FE /r | Add packed doubleword integers from xmm2, xmm3/m128 and store in xmm1.
        /// </summary>
        [Symbol("vpaddd xmm, xmm, m128","VEX.128.66.0F.WIG FE /r")]
        vpaddd_xmm_xmm_m128_vex = 2513,

        /// <summary>
        /// vpaddd xmm, xmm, m32bcst | EVEX.128.66.0F.W0 FE /r | Add packed doubleword integers from xmm2, and xmm3/m128/m32bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd xmm, xmm, m32bcst","EVEX.128.66.0F.W0 FE /r")]
        vpaddd_xmm_xmm_m32bcst = 2514,

        /// <summary>
        /// vpaddd xmm, xmm, r8 | VEX.128.66.0F.WIG FE /r | Add packed doubleword integers from xmm2, xmm3/m128 and store in xmm1.
        /// </summary>
        [Symbol("vpaddd xmm, xmm, r8","VEX.128.66.0F.WIG FE /r")]
        vpaddd_xmm_xmm_r8 = 2515,

        /// <summary>
        /// vpaddd xmm, xmm, xmm | EVEX.128.66.0F.W0 FE /r | Add packed doubleword integers from xmm2, and xmm3/m128/m32bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd xmm, xmm, xmm","EVEX.128.66.0F.W0 FE /r")]
        vpaddd_xmm_xmm_xmm = 2516,

        /// <summary>
        /// vpaddd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W0 FE /r | Add packed doubleword integers from ymm2, ymm3/m256/m32bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W0 FE /r")]
        vpaddd_ymm_k1z_ymm_m256 = 2517,

        /// <summary>
        /// vpaddd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F.W0 FE /r | Add packed doubleword integers from ymm2, ymm3/m256/m32bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F.W0 FE /r")]
        vpaddd_ymm_k1z_ymm_m32bcst = 2518,

        /// <summary>
        /// vpaddd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W0 FE /r | Add packed doubleword integers from ymm2, ymm3/m256/m32bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W0 FE /r")]
        vpaddd_ymm_k1z_ymm_ymm = 2519,

        /// <summary>
        /// vpaddd ymm, ymm, m256 | EVEX.256.66.0F.W0 FE /r | Add packed doubleword integers from ymm2, ymm3/m256/m32bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd ymm, ymm, m256","EVEX.256.66.0F.W0 FE /r")]
        vpaddd_ymm_ymm_m256 = 2520,

        /// <summary>
        /// vpaddd ymm, ymm, m256 | VEX.256.66.0F.WIG FE /r | Add packed doubleword integers from ymm2, ymm3/m256 and store in ymm1.
        /// </summary>
        [Symbol("vpaddd ymm, ymm, m256","VEX.256.66.0F.WIG FE /r")]
        vpaddd_ymm_ymm_m256_vex = 2521,

        /// <summary>
        /// vpaddd ymm, ymm, m32bcst | EVEX.256.66.0F.W0 FE /r | Add packed doubleword integers from ymm2, ymm3/m256/m32bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd ymm, ymm, m32bcst","EVEX.256.66.0F.W0 FE /r")]
        vpaddd_ymm_ymm_m32bcst = 2522,

        /// <summary>
        /// vpaddd ymm, ymm, r16 | VEX.256.66.0F.WIG FE /r | Add packed doubleword integers from ymm2, ymm3/m256 and store in ymm1.
        /// </summary>
        [Symbol("vpaddd ymm, ymm, r16","VEX.256.66.0F.WIG FE /r")]
        vpaddd_ymm_ymm_r16 = 2523,

        /// <summary>
        /// vpaddd ymm, ymm, ymm | EVEX.256.66.0F.W0 FE /r | Add packed doubleword integers from ymm2, ymm3/m256/m32bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd ymm, ymm, ymm","EVEX.256.66.0F.W0 FE /r")]
        vpaddd_ymm_ymm_ymm = 2524,

        /// <summary>
        /// vpaddd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F.W0 FE /r | Add packed doubleword integers from zmm2, zmm3/m512/m32bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F.W0 FE /r")]
        vpaddd_zmm_k1z_zmm_m32bcst = 2525,

        /// <summary>
        /// vpaddd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W0 FE /r | Add packed doubleword integers from zmm2, zmm3/m512/m32bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W0 FE /r")]
        vpaddd_zmm_k1z_zmm_m512 = 2526,

        /// <summary>
        /// vpaddd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W0 FE /r | Add packed doubleword integers from zmm2, zmm3/m512/m32bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W0 FE /r")]
        vpaddd_zmm_k1z_zmm_zmm = 2527,

        /// <summary>
        /// vpaddd zmm, zmm, m32bcst | EVEX.512.66.0F.W0 FE /r | Add packed doubleword integers from zmm2, zmm3/m512/m32bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd zmm, zmm, m32bcst","EVEX.512.66.0F.W0 FE /r")]
        vpaddd_zmm_zmm_m32bcst = 2528,

        /// <summary>
        /// vpaddd zmm, zmm, m512 | EVEX.512.66.0F.W0 FE /r | Add packed doubleword integers from zmm2, zmm3/m512/m32bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd zmm, zmm, m512","EVEX.512.66.0F.W0 FE /r")]
        vpaddd_zmm_zmm_m512 = 2529,

        /// <summary>
        /// vpaddd zmm, zmm, zmm | EVEX.512.66.0F.W0 FE /r | Add packed doubleword integers from zmm2, zmm3/m512/m32bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddd zmm, zmm, zmm","EVEX.512.66.0F.W0 FE /r")]
        vpaddd_zmm_zmm_zmm = 2530,

        /// <summary>
        /// vpaddq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 D4 /r | Add packed quadword integers from xmm2, and xmm3/m128/m64bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 D4 /r")]
        vpaddq_xmm_k1z_xmm_m128 = 2531,

        /// <summary>
        /// vpaddq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F.W1 D4 /r | Add packed quadword integers from xmm2, and xmm3/m128/m64bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F.W1 D4 /r")]
        vpaddq_xmm_k1z_xmm_m64bcst = 2532,

        /// <summary>
        /// vpaddq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W1 D4 /r | Add packed quadword integers from xmm2, and xmm3/m128/m64bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W1 D4 /r")]
        vpaddq_xmm_k1z_xmm_xmm = 2533,

        /// <summary>
        /// vpaddq xmm, xmm, m128 | EVEX.128.66.0F.W1 D4 /r | Add packed quadword integers from xmm2, and xmm3/m128/m64bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq xmm, xmm, m128","EVEX.128.66.0F.W1 D4 /r")]
        vpaddq_xmm_xmm_m128 = 2534,

        /// <summary>
        /// vpaddq xmm, xmm, m128 | VEX.128.66.0F.WIG D4 /r | Add packed quadword integers from xmm2, xmm3/m128 and store in xmm1.
        /// </summary>
        [Symbol("vpaddq xmm, xmm, m128","VEX.128.66.0F.WIG D4 /r")]
        vpaddq_xmm_xmm_m128_vex = 2535,

        /// <summary>
        /// vpaddq xmm, xmm, m64bcst | EVEX.128.66.0F.W1 D4 /r | Add packed quadword integers from xmm2, and xmm3/m128/m64bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq xmm, xmm, m64bcst","EVEX.128.66.0F.W1 D4 /r")]
        vpaddq_xmm_xmm_m64bcst = 2536,

        /// <summary>
        /// vpaddq xmm, xmm, r8 | VEX.128.66.0F.WIG D4 /r | Add packed quadword integers from xmm2, xmm3/m128 and store in xmm1.
        /// </summary>
        [Symbol("vpaddq xmm, xmm, r8","VEX.128.66.0F.WIG D4 /r")]
        vpaddq_xmm_xmm_r8 = 2537,

        /// <summary>
        /// vpaddq xmm, xmm, xmm | EVEX.128.66.0F.W1 D4 /r | Add packed quadword integers from xmm2, and xmm3/m128/m64bcst and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq xmm, xmm, xmm","EVEX.128.66.0F.W1 D4 /r")]
        vpaddq_xmm_xmm_xmm = 2538,

        /// <summary>
        /// vpaddq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W1 D4 /r | Add packed quadword integers from ymm2, ymm3/m256/m64bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W1 D4 /r")]
        vpaddq_ymm_k1z_ymm_m256 = 2539,

        /// <summary>
        /// vpaddq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F.W1 D4 /r | Add packed quadword integers from ymm2, ymm3/m256/m64bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F.W1 D4 /r")]
        vpaddq_ymm_k1z_ymm_m64bcst = 2540,

        /// <summary>
        /// vpaddq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W1 D4 /r | Add packed quadword integers from ymm2, ymm3/m256/m64bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W1 D4 /r")]
        vpaddq_ymm_k1z_ymm_ymm = 2541,

        /// <summary>
        /// vpaddq ymm, ymm, m256 | EVEX.256.66.0F.W1 D4 /r | Add packed quadword integers from ymm2, ymm3/m256/m64bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq ymm, ymm, m256","EVEX.256.66.0F.W1 D4 /r")]
        vpaddq_ymm_ymm_m256 = 2542,

        /// <summary>
        /// vpaddq ymm, ymm, m256 | VEX.256.66.0F.WIG D4 /r | Add packed quadword integers from ymm2, ymm3/m256 and store in ymm1.
        /// </summary>
        [Symbol("vpaddq ymm, ymm, m256","VEX.256.66.0F.WIG D4 /r")]
        vpaddq_ymm_ymm_m256_vex = 2543,

        /// <summary>
        /// vpaddq ymm, ymm, m64bcst | EVEX.256.66.0F.W1 D4 /r | Add packed quadword integers from ymm2, ymm3/m256/m64bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq ymm, ymm, m64bcst","EVEX.256.66.0F.W1 D4 /r")]
        vpaddq_ymm_ymm_m64bcst = 2544,

        /// <summary>
        /// vpaddq ymm, ymm, r16 | VEX.256.66.0F.WIG D4 /r | Add packed quadword integers from ymm2, ymm3/m256 and store in ymm1.
        /// </summary>
        [Symbol("vpaddq ymm, ymm, r16","VEX.256.66.0F.WIG D4 /r")]
        vpaddq_ymm_ymm_r16 = 2545,

        /// <summary>
        /// vpaddq ymm, ymm, ymm | EVEX.256.66.0F.W1 D4 /r | Add packed quadword integers from ymm2, ymm3/m256/m64bcst and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq ymm, ymm, ymm","EVEX.256.66.0F.W1 D4 /r")]
        vpaddq_ymm_ymm_ymm = 2546,

        /// <summary>
        /// vpaddq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W1 D4 /r | Add packed quadword integers from zmm2, zmm3/m512/m64bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W1 D4 /r")]
        vpaddq_zmm_k1z_zmm_m512 = 2547,

        /// <summary>
        /// vpaddq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F.W1 D4 /r | Add packed quadword integers from zmm2, zmm3/m512/m64bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F.W1 D4 /r")]
        vpaddq_zmm_k1z_zmm_m64bcst = 2548,

        /// <summary>
        /// vpaddq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W1 D4 /r | Add packed quadword integers from zmm2, zmm3/m512/m64bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W1 D4 /r")]
        vpaddq_zmm_k1z_zmm_zmm = 2549,

        /// <summary>
        /// vpaddq zmm, zmm, m512 | EVEX.512.66.0F.W1 D4 /r | Add packed quadword integers from zmm2, zmm3/m512/m64bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq zmm, zmm, m512","EVEX.512.66.0F.W1 D4 /r")]
        vpaddq_zmm_zmm_m512 = 2550,

        /// <summary>
        /// vpaddq zmm, zmm, m64bcst | EVEX.512.66.0F.W1 D4 /r | Add packed quadword integers from zmm2, zmm3/m512/m64bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq zmm, zmm, m64bcst","EVEX.512.66.0F.W1 D4 /r")]
        vpaddq_zmm_zmm_m64bcst = 2551,

        /// <summary>
        /// vpaddq zmm, zmm, zmm | EVEX.512.66.0F.W1 D4 /r | Add packed quadword integers from zmm2, zmm3/m512/m64bcst and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddq zmm, zmm, zmm","EVEX.512.66.0F.W1 D4 /r")]
        vpaddq_zmm_zmm_zmm = 2552,

        /// <summary>
        /// vpaddsb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG EC /r | Add packed signed byte integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG EC /r")]
        vpaddsb_xmm_k1z_xmm_m128 = 2553,

        /// <summary>
        /// vpaddsb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG EC /r | Add packed signed byte integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG EC /r")]
        vpaddsb_xmm_k1z_xmm_r8 = 2554,

        /// <summary>
        /// vpaddsb xmm, xmm, m128 | EVEX.128.66.0F.WIG EC /r | Add packed signed byte integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb xmm, xmm, m128","EVEX.128.66.0F.WIG EC /r")]
        vpaddsb_xmm_xmm_m128 = 2555,

        /// <summary>
        /// vpaddsb xmm, xmm, m128 | VEX.128.66.0F.WIG EC /r | Add packed signed byte integers from xmm3/m128 and xmm2 saturate the results.
        /// </summary>
        [Symbol("vpaddsb xmm, xmm, m128","VEX.128.66.0F.WIG EC /r")]
        vpaddsb_xmm_xmm_m128_vex = 2556,

        /// <summary>
        /// vpaddsb xmm, xmm, r8 | EVEX.128.66.0F.WIG EC /r | Add packed signed byte integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb xmm, xmm, r8","EVEX.128.66.0F.WIG EC /r")]
        vpaddsb_xmm_xmm_r8 = 2557,

        /// <summary>
        /// vpaddsb xmm, xmm, r8 | VEX.128.66.0F.WIG EC /r | Add packed signed byte integers from xmm3/m128 and xmm2 saturate the results.
        /// </summary>
        [Symbol("vpaddsb xmm, xmm, r8","VEX.128.66.0F.WIG EC /r")]
        vpaddsb_xmm_xmm_r8_vex = 2558,

        /// <summary>
        /// vpaddsb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG EC /r | Add packed signed byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG EC /r")]
        vpaddsb_ymm_k1z_ymm_m256 = 2559,

        /// <summary>
        /// vpaddsb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG EC /r | Add packed signed byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG EC /r")]
        vpaddsb_ymm_k1z_ymm_r16 = 2560,

        /// <summary>
        /// vpaddsb ymm, ymm, m256 | EVEX.256.66.0F.WIG EC /r | Add packed signed byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb ymm, ymm, m256","EVEX.256.66.0F.WIG EC /r")]
        vpaddsb_ymm_ymm_m256 = 2561,

        /// <summary>
        /// vpaddsb ymm, ymm, m256 | VEX.256.66.0F.WIG EC /r | Add packed signed byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
        /// </summary>
        [Symbol("vpaddsb ymm, ymm, m256","VEX.256.66.0F.WIG EC /r")]
        vpaddsb_ymm_ymm_m256_vex = 2562,

        /// <summary>
        /// vpaddsb ymm, ymm, r16 | EVEX.256.66.0F.WIG EC /r | Add packed signed byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb ymm, ymm, r16","EVEX.256.66.0F.WIG EC /r")]
        vpaddsb_ymm_ymm_r16 = 2563,

        /// <summary>
        /// vpaddsb ymm, ymm, r16 | VEX.256.66.0F.WIG EC /r | Add packed signed byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
        /// </summary>
        [Symbol("vpaddsb ymm, ymm, r16","VEX.256.66.0F.WIG EC /r")]
        vpaddsb_ymm_ymm_r16_vex = 2564,

        /// <summary>
        /// vpaddsb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG EC /r | Add packed signed byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG EC /r")]
        vpaddsb_zmm_k1z_zmm_m512 = 2565,

        /// <summary>
        /// vpaddsb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG EC /r | Add packed signed byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG EC /r")]
        vpaddsb_zmm_k1z_zmm_r32 = 2566,

        /// <summary>
        /// vpaddsb zmm, zmm, m512 | EVEX.512.66.0F.WIG EC /r | Add packed signed byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb zmm, zmm, m512","EVEX.512.66.0F.WIG EC /r")]
        vpaddsb_zmm_zmm_m512 = 2567,

        /// <summary>
        /// vpaddsb zmm, zmm, r32 | EVEX.512.66.0F.WIG EC /r | Add packed signed byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsb zmm, zmm, r32","EVEX.512.66.0F.WIG EC /r")]
        vpaddsb_zmm_zmm_r32 = 2568,

        /// <summary>
        /// vpaddsw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG ED /r | Add packed signed word integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG ED /r")]
        vpaddsw_xmm_k1z_xmm_m128 = 2569,

        /// <summary>
        /// vpaddsw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG ED /r | Add packed signed word integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG ED /r")]
        vpaddsw_xmm_k1z_xmm_r8 = 2570,

        /// <summary>
        /// vpaddsw xmm, xmm, m128 | EVEX.128.66.0F.WIG ED /r | Add packed signed word integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw xmm, xmm, m128","EVEX.128.66.0F.WIG ED /r")]
        vpaddsw_xmm_xmm_m128 = 2571,

        /// <summary>
        /// vpaddsw xmm, xmm, m128 | VEX.128.66.0F.WIG ED /r | Add packed signed word integers from xmm3/m128 and xmm2 and saturate the results.
        /// </summary>
        [Symbol("vpaddsw xmm, xmm, m128","VEX.128.66.0F.WIG ED /r")]
        vpaddsw_xmm_xmm_m128_vex = 2572,

        /// <summary>
        /// vpaddsw xmm, xmm, r8 | EVEX.128.66.0F.WIG ED /r | Add packed signed word integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw xmm, xmm, r8","EVEX.128.66.0F.WIG ED /r")]
        vpaddsw_xmm_xmm_r8 = 2573,

        /// <summary>
        /// vpaddsw xmm, xmm, r8 | VEX.128.66.0F.WIG ED /r | Add packed signed word integers from xmm3/m128 and xmm2 and saturate the results.
        /// </summary>
        [Symbol("vpaddsw xmm, xmm, r8","VEX.128.66.0F.WIG ED /r")]
        vpaddsw_xmm_xmm_r8_vex = 2574,

        /// <summary>
        /// vpaddsw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG ED /r | Add packed signed word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG ED /r")]
        vpaddsw_ymm_k1z_ymm_m256 = 2575,

        /// <summary>
        /// vpaddsw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG ED /r | Add packed signed word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG ED /r")]
        vpaddsw_ymm_k1z_ymm_r16 = 2576,

        /// <summary>
        /// vpaddsw ymm, ymm, m256 | EVEX.256.66.0F.WIG ED /r | Add packed signed word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw ymm, ymm, m256","EVEX.256.66.0F.WIG ED /r")]
        vpaddsw_ymm_ymm_m256 = 2577,

        /// <summary>
        /// vpaddsw ymm, ymm, m256 | VEX.256.66.0F.WIG ED /r | Add packed signed word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
        /// </summary>
        [Symbol("vpaddsw ymm, ymm, m256","VEX.256.66.0F.WIG ED /r")]
        vpaddsw_ymm_ymm_m256_vex = 2578,

        /// <summary>
        /// vpaddsw ymm, ymm, r16 | EVEX.256.66.0F.WIG ED /r | Add packed signed word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw ymm, ymm, r16","EVEX.256.66.0F.WIG ED /r")]
        vpaddsw_ymm_ymm_r16 = 2579,

        /// <summary>
        /// vpaddsw ymm, ymm, r16 | VEX.256.66.0F.WIG ED /r | Add packed signed word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1.
        /// </summary>
        [Symbol("vpaddsw ymm, ymm, r16","VEX.256.66.0F.WIG ED /r")]
        vpaddsw_ymm_ymm_r16_vex = 2580,

        /// <summary>
        /// vpaddsw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG ED /r | Add packed signed word integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG ED /r")]
        vpaddsw_zmm_k1z_zmm_m512 = 2581,

        /// <summary>
        /// vpaddsw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG ED /r | Add packed signed word integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG ED /r")]
        vpaddsw_zmm_k1z_zmm_r32 = 2582,

        /// <summary>
        /// vpaddsw zmm, zmm, m512 | EVEX.512.66.0F.WIG ED /r | Add packed signed word integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw zmm, zmm, m512","EVEX.512.66.0F.WIG ED /r")]
        vpaddsw_zmm_zmm_m512 = 2583,

        /// <summary>
        /// vpaddsw zmm, zmm, r32 | EVEX.512.66.0F.WIG ED /r | Add packed signed word integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddsw zmm, zmm, r32","EVEX.512.66.0F.WIG ED /r")]
        vpaddsw_zmm_zmm_r32 = 2584,

        /// <summary>
        /// vpaddusb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG DC /r | Add packed unsigned byte integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG DC /r")]
        vpaddusb_xmm_k1z_xmm_m128 = 2585,

        /// <summary>
        /// vpaddusb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG DC /r | Add packed unsigned byte integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG DC /r")]
        vpaddusb_xmm_k1z_xmm_r8 = 2586,

        /// <summary>
        /// vpaddusb xmm, xmm, m128 | EVEX.128.66.0F.WIG DC /r | Add packed unsigned byte integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb xmm, xmm, m128","EVEX.128.66.0F.WIG DC /r")]
        vpaddusb_xmm_xmm_m128 = 2587,

        /// <summary>
        /// vpaddusb xmm, xmm, m128 | VEX.128.66.0F.WIG DC /r | Add packed unsigned byte integers from xmm3/m128 to xmm2 and saturate the results.
        /// </summary>
        [Symbol("vpaddusb xmm, xmm, m128","VEX.128.66.0F.WIG DC /r")]
        vpaddusb_xmm_xmm_m128_vex = 2588,

        /// <summary>
        /// vpaddusb xmm, xmm, r8 | EVEX.128.66.0F.WIG DC /r | Add packed unsigned byte integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb xmm, xmm, r8","EVEX.128.66.0F.WIG DC /r")]
        vpaddusb_xmm_xmm_r8 = 2589,

        /// <summary>
        /// vpaddusb xmm, xmm, r8 | VEX.128.66.0F.WIG DC /r | Add packed unsigned byte integers from xmm3/m128 to xmm2 and saturate the results.
        /// </summary>
        [Symbol("vpaddusb xmm, xmm, r8","VEX.128.66.0F.WIG DC /r")]
        vpaddusb_xmm_xmm_r8_vex = 2590,

        /// <summary>
        /// vpaddusb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG DC /r | Add packed unsigned byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG DC /r")]
        vpaddusb_ymm_k1z_ymm_m256 = 2591,

        /// <summary>
        /// vpaddusb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG DC /r | Add packed unsigned byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG DC /r")]
        vpaddusb_ymm_k1z_ymm_r16 = 2592,

        /// <summary>
        /// vpaddusb ymm, ymm, m256 | EVEX.256.66.0F.WIG DC /r | Add packed unsigned byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb ymm, ymm, m256","EVEX.256.66.0F.WIG DC /r")]
        vpaddusb_ymm_ymm_m256 = 2593,

        /// <summary>
        /// vpaddusb ymm, ymm, m256 | VEX.256.66.0F.WIG DC /r | Add packed unsigned byte integers from ymm2 , and ymm3/m256 and store the saturated results in ymm1.
        /// </summary>
        [Symbol("vpaddusb ymm, ymm, m256","VEX.256.66.0F.WIG DC /r")]
        vpaddusb_ymm_ymm_m256_vex = 2594,

        /// <summary>
        /// vpaddusb ymm, ymm, r16 | EVEX.256.66.0F.WIG DC /r | Add packed unsigned byte integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb ymm, ymm, r16","EVEX.256.66.0F.WIG DC /r")]
        vpaddusb_ymm_ymm_r16 = 2595,

        /// <summary>
        /// vpaddusb ymm, ymm, r16 | VEX.256.66.0F.WIG DC /r | Add packed unsigned byte integers from ymm2 , and ymm3/m256 and store the saturated results in ymm1.
        /// </summary>
        [Symbol("vpaddusb ymm, ymm, r16","VEX.256.66.0F.WIG DC /r")]
        vpaddusb_ymm_ymm_r16_vex = 2596,

        /// <summary>
        /// vpaddusb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG DC /r | Add packed unsigned byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG DC /r")]
        vpaddusb_zmm_k1z_zmm_m512 = 2597,

        /// <summary>
        /// vpaddusb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG DC /r | Add packed unsigned byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG DC /r")]
        vpaddusb_zmm_k1z_zmm_r32 = 2598,

        /// <summary>
        /// vpaddusb zmm, zmm, m512 | EVEX.512.66.0F.WIG DC /r | Add packed unsigned byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb zmm, zmm, m512","EVEX.512.66.0F.WIG DC /r")]
        vpaddusb_zmm_zmm_m512 = 2599,

        /// <summary>
        /// vpaddusb zmm, zmm, r32 | EVEX.512.66.0F.WIG DC /r | Add packed unsigned byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusb zmm, zmm, r32","EVEX.512.66.0F.WIG DC /r")]
        vpaddusb_zmm_zmm_r32 = 2600,

        /// <summary>
        /// vpaddusw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG DD /r | Add packed unsigned word integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG DD /r")]
        vpaddusw_xmm_k1z_xmm_m128 = 2601,

        /// <summary>
        /// vpaddusw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG DD /r | Add packed unsigned word integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG DD /r")]
        vpaddusw_xmm_k1z_xmm_r8 = 2602,

        /// <summary>
        /// vpaddusw xmm, xmm, m128 | EVEX.128.66.0F.WIG DD /r | Add packed unsigned word integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusw xmm, xmm, m128","EVEX.128.66.0F.WIG DD /r")]
        vpaddusw_xmm_xmm_m128 = 2603,

        /// <summary>
        /// vpaddusw xmm, xmm, m128 | VEX.128.66.0F.WIG DD /r | Add packed unsigned word integers from xmm3/m128 to xmm2 and saturate the results.
        /// </summary>
        [Symbol("vpaddusw xmm, xmm, m128","VEX.128.66.0F.WIG DD /r")]
        vpaddusw_xmm_xmm_m128_vex = 2604,

        /// <summary>
        /// vpaddusw xmm, xmm, r8 | EVEX.128.66.0F.WIG DD /r | Add packed unsigned word integers from xmm2, and xmm3/m128 and store the saturated results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusw xmm, xmm, r8","EVEX.128.66.0F.WIG DD /r")]
        vpaddusw_xmm_xmm_r8 = 2605,

        /// <summary>
        /// vpaddusw xmm, xmm, r8 | VEX.128.66.0F.WIG DD /r | Add packed unsigned word integers from xmm3/m128 to xmm2 and saturate the results.
        /// </summary>
        [Symbol("vpaddusw xmm, xmm, r8","VEX.128.66.0F.WIG DD /r")]
        vpaddusw_xmm_xmm_r8_vex = 2606,

        /// <summary>
        /// vpaddusw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG DD /r | Add packed unsigned word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG DD /r")]
        vpaddusw_ymm_k1z_ymm_m256 = 2607,

        /// <summary>
        /// vpaddusw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG DD /r | Add packed unsigned word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG DD /r")]
        vpaddusw_ymm_k1z_ymm_r16 = 2608,

        /// <summary>
        /// vpaddusw ymm, ymm, m256 | EVEX.256.66.0F.WIG DD /r | Add packed unsigned word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusw ymm, ymm, m256","EVEX.256.66.0F.WIG DD /r")]
        vpaddusw_ymm_ymm_m256 = 2609,

        /// <summary>
        /// vpaddusw ymm, ymm, m256 | VEX.256.66.0F.WIG DD /r | Add packed unsigned word integers from ymm2 , and ymm3/m256 and store the saturated results in ymm1.
        /// </summary>
        [Symbol("vpaddusw ymm, ymm, m256","VEX.256.66.0F.WIG DD /r")]
        vpaddusw_ymm_ymm_m256_vex = 2610,

        /// <summary>
        /// vpaddusw ymm, ymm, r16 | EVEX.256.66.0F.WIG DD /r | Add packed unsigned word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpaddusw ymm, ymm, r16","EVEX.256.66.0F.WIG DD /r")]
        vpaddusw_ymm_ymm_r16 = 2611,

        /// <summary>
        /// vpaddusw ymm, ymm, r16 | VEX.256.66.0F.WIG DD /r | Add packed unsigned word integers from ymm2 , and ymm3/m256 and store the saturated results in ymm1.
        /// </summary>
        [Symbol("vpaddusw ymm, ymm, r16","VEX.256.66.0F.WIG DD /r")]
        vpaddusw_ymm_ymm_r16_vex = 2612,

        /// <summary>
        /// vpaddw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG FD /r | Add packed word integers from xmm2, and xmm3/m128 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG FD /r")]
        vpaddw_xmm_k1z_xmm_m128 = 2613,

        /// <summary>
        /// vpaddw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG FD /r | Add packed word integers from xmm2, and xmm3/m128 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG FD /r")]
        vpaddw_xmm_k1z_xmm_r8 = 2614,

        /// <summary>
        /// vpaddw xmm, xmm, m128 | EVEX.128.66.0F.WIG FD /r | Add packed word integers from xmm2, and xmm3/m128 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw xmm, xmm, m128","EVEX.128.66.0F.WIG FD /r")]
        vpaddw_xmm_xmm_m128 = 2615,

        /// <summary>
        /// vpaddw xmm, xmm, m128 | VEX.128.66.0F.WIG FD /r | Add packed word integers from xmm2, xmm3/m128 and store in xmm1.
        /// </summary>
        [Symbol("vpaddw xmm, xmm, m128","VEX.128.66.0F.WIG FD /r")]
        vpaddw_xmm_xmm_m128_vex = 2616,

        /// <summary>
        /// vpaddw xmm, xmm, r8 | EVEX.128.66.0F.WIG FD /r | Add packed word integers from xmm2, and xmm3/m128 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw xmm, xmm, r8","EVEX.128.66.0F.WIG FD /r")]
        vpaddw_xmm_xmm_r8 = 2617,

        /// <summary>
        /// vpaddw xmm, xmm, r8 | VEX.128.66.0F.WIG FD /r | Add packed word integers from xmm2, xmm3/m128 and store in xmm1.
        /// </summary>
        [Symbol("vpaddw xmm, xmm, r8","VEX.128.66.0F.WIG FD /r")]
        vpaddw_xmm_xmm_r8_vex = 2618,

        /// <summary>
        /// vpaddw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG FD /r | Add packed word integers from ymm2, and ymm3/m256 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG FD /r")]
        vpaddw_ymm_k1z_ymm_m256 = 2619,

        /// <summary>
        /// vpaddw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG FD /r | Add packed word integers from ymm2, and ymm3/m256 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG FD /r")]
        vpaddw_ymm_k1z_ymm_r16 = 2620,

        /// <summary>
        /// vpaddw ymm, ymm, m256 | EVEX.256.66.0F.WIG FD /r | Add packed word integers from ymm2, and ymm3/m256 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw ymm, ymm, m256","EVEX.256.66.0F.WIG FD /r")]
        vpaddw_ymm_ymm_m256 = 2621,

        /// <summary>
        /// vpaddw ymm, ymm, m256 | VEX.256.66.0F.WIG FD /r | Add packed word integers from ymm2, ymm3/m256 and store in ymm1.
        /// </summary>
        [Symbol("vpaddw ymm, ymm, m256","VEX.256.66.0F.WIG FD /r")]
        vpaddw_ymm_ymm_m256_vex = 2622,

        /// <summary>
        /// vpaddw ymm, ymm, r16 | EVEX.256.66.0F.WIG FD /r | Add packed word integers from ymm2, and ymm3/m256 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw ymm, ymm, r16","EVEX.256.66.0F.WIG FD /r")]
        vpaddw_ymm_ymm_r16 = 2623,

        /// <summary>
        /// vpaddw ymm, ymm, r16 | VEX.256.66.0F.WIG FD /r | Add packed word integers from ymm2, ymm3/m256 and store in ymm1.
        /// </summary>
        [Symbol("vpaddw ymm, ymm, r16","VEX.256.66.0F.WIG FD /r")]
        vpaddw_ymm_ymm_r16_vex = 2624,

        /// <summary>
        /// vpaddw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG FD /r | Add packed word integers from zmm2, and zmm3/m512 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG FD /r")]
        vpaddw_zmm_k1z_zmm_m512 = 2625,

        /// <summary>
        /// vpaddw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG FD /r | Add packed word integers from zmm2, and zmm3/m512 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG FD /r")]
        vpaddw_zmm_k1z_zmm_r32 = 2626,

        /// <summary>
        /// vpaddw zmm, zmm, m512 | EVEX.512.66.0F.WIG FD /r | Add packed word integers from zmm2, and zmm3/m512 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw zmm, zmm, m512","EVEX.512.66.0F.WIG FD /r")]
        vpaddw_zmm_zmm_m512 = 2627,

        /// <summary>
        /// vpaddw zmm, zmm, r32 | EVEX.512.66.0F.WIG FD /r | Add packed word integers from zmm2, and zmm3/m512 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpaddw zmm, zmm, r32","EVEX.512.66.0F.WIG FD /r")]
        vpaddw_zmm_zmm_r32 = 2628,

        /// <summary>
        /// vpand xmm, xmm, m128 | VEX.128.66.0F.WIG DB /r | Bitwise AND of xmm3/m128 and xmm.
        /// </summary>
        [Symbol("vpand xmm, xmm, m128","VEX.128.66.0F.WIG DB /r")]
        vpand_xmm_xmm_m128 = 2629,

        /// <summary>
        /// vpand xmm, xmm, r8 | VEX.128.66.0F.WIG DB /r | Bitwise AND of xmm3/m128 and xmm.
        /// </summary>
        [Symbol("vpand xmm, xmm, r8","VEX.128.66.0F.WIG DB /r")]
        vpand_xmm_xmm_r8 = 2630,

        /// <summary>
        /// vpand ymm, ymm, m256 | VEX.256.66.0F.WIG DB /r | Bitwise AND of ymm2 , and ymm3/m256 and store result in ymm1.
        /// </summary>
        [Symbol("vpand ymm, ymm, m256","VEX.256.66.0F.WIG DB /r")]
        vpand_ymm_ymm_m256 = 2631,

        /// <summary>
        /// vpand ymm, ymm, r16 | VEX.256.66.0F.WIG DB /r | Bitwise AND of ymm2 , and ymm3/m256 and store result in ymm1.
        /// </summary>
        [Symbol("vpand ymm, ymm, r16","VEX.256.66.0F.WIG DB /r")]
        vpand_ymm_ymm_r16 = 2632,

        /// <summary>
        /// vpandd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 DB /r")]
        vpandd_xmm_k1z_xmm_m128 = 2633,

        /// <summary>
        /// vpandd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F.W0 DB /r")]
        vpandd_xmm_k1z_xmm_m32bcst = 2634,

        /// <summary>
        /// vpandd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W0 DB /r")]
        vpandd_xmm_k1z_xmm_xmm = 2635,

        /// <summary>
        /// vpandd xmm, xmm, m128 | EVEX.128.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd xmm, xmm, m128","EVEX.128.66.0F.W0 DB /r")]
        vpandd_xmm_xmm_m128 = 2636,

        /// <summary>
        /// vpandd xmm, xmm, m32bcst | EVEX.128.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd xmm, xmm, m32bcst","EVEX.128.66.0F.W0 DB /r")]
        vpandd_xmm_xmm_m32bcst = 2637,

        /// <summary>
        /// vpandd xmm, xmm, xmm | EVEX.128.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd xmm, xmm, xmm","EVEX.128.66.0F.W0 DB /r")]
        vpandd_xmm_xmm_xmm = 2638,

        /// <summary>
        /// vpandd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W0 DB /r")]
        vpandd_ymm_k1z_ymm_m256 = 2639,

        /// <summary>
        /// vpandd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F.W0 DB /r")]
        vpandd_ymm_k1z_ymm_m32bcst = 2640,

        /// <summary>
        /// vpandd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W0 DB /r")]
        vpandd_ymm_k1z_ymm_ymm = 2641,

        /// <summary>
        /// vpandd ymm, ymm, m256 | EVEX.256.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd ymm, ymm, m256","EVEX.256.66.0F.W0 DB /r")]
        vpandd_ymm_ymm_m256 = 2642,

        /// <summary>
        /// vpandd ymm, ymm, m32bcst | EVEX.256.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd ymm, ymm, m32bcst","EVEX.256.66.0F.W0 DB /r")]
        vpandd_ymm_ymm_m32bcst = 2643,

        /// <summary>
        /// vpandd ymm, ymm, ymm | EVEX.256.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd ymm, ymm, ymm","EVEX.256.66.0F.W0 DB /r")]
        vpandd_ymm_ymm_ymm = 2644,

        /// <summary>
        /// vpandd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F.W0 DB /r")]
        vpandd_zmm_k1z_zmm_m32bcst = 2645,

        /// <summary>
        /// vpandd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W0 DB /r")]
        vpandd_zmm_k1z_zmm_m512 = 2646,

        /// <summary>
        /// vpandd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W0 DB /r")]
        vpandd_zmm_k1z_zmm_zmm = 2647,

        /// <summary>
        /// vpandd zmm, zmm, m32bcst | EVEX.512.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd zmm, zmm, m32bcst","EVEX.512.66.0F.W0 DB /r")]
        vpandd_zmm_zmm_m32bcst = 2648,

        /// <summary>
        /// vpandd zmm, zmm, m512 | EVEX.512.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd zmm, zmm, m512","EVEX.512.66.0F.W0 DB /r")]
        vpandd_zmm_zmm_m512 = 2649,

        /// <summary>
        /// vpandd zmm, zmm, zmm | EVEX.512.66.0F.W0 DB /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandd zmm, zmm, zmm","EVEX.512.66.0F.W0 DB /r")]
        vpandd_zmm_zmm_zmm = 2650,

        /// <summary>
        /// vpandn xmm, xmm, m128 | VEX.128.66.0F.WIG DF /r | Bitwise AND NOT of xmm3/m128 and xmm2.
        /// </summary>
        [Symbol("vpandn xmm, xmm, m128","VEX.128.66.0F.WIG DF /r")]
        vpandn_xmm_xmm_m128 = 2651,

        /// <summary>
        /// vpandn xmm, xmm, r8 | VEX.128.66.0F.WIG DF /r | Bitwise AND NOT of xmm3/m128 and xmm2.
        /// </summary>
        [Symbol("vpandn xmm, xmm, r8","VEX.128.66.0F.WIG DF /r")]
        vpandn_xmm_xmm_r8 = 2652,

        /// <summary>
        /// vpandn ymm, ymm, m256 | VEX.256.66.0F.WIG DF /r | Bitwise AND NOT of ymm2 , and ymm3/m256 and store result in ymm1.
        /// </summary>
        [Symbol("vpandn ymm, ymm, m256","VEX.256.66.0F.WIG DF /r")]
        vpandn_ymm_ymm_m256 = 2653,

        /// <summary>
        /// vpandn ymm, ymm, r16 | VEX.256.66.0F.WIG DF /r | Bitwise AND NOT of ymm2 , and ymm3/m256 and store result in ymm1.
        /// </summary>
        [Symbol("vpandn ymm, ymm, r16","VEX.256.66.0F.WIG DF /r")]
        vpandn_ymm_ymm_r16 = 2654,

        /// <summary>
        /// vpandnd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 DF /r")]
        vpandnd_xmm_k1z_xmm_m128 = 2655,

        /// <summary>
        /// vpandnd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F.W0 DF /r")]
        vpandnd_xmm_k1z_xmm_m32bcst = 2656,

        /// <summary>
        /// vpandnd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W0 DF /r")]
        vpandnd_xmm_k1z_xmm_xmm = 2657,

        /// <summary>
        /// vpandnd xmm, xmm, m128 | EVEX.128.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd xmm, xmm, m128","EVEX.128.66.0F.W0 DF /r")]
        vpandnd_xmm_xmm_m128 = 2658,

        /// <summary>
        /// vpandnd xmm, xmm, m32bcst | EVEX.128.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd xmm, xmm, m32bcst","EVEX.128.66.0F.W0 DF /r")]
        vpandnd_xmm_xmm_m32bcst = 2659,

        /// <summary>
        /// vpandnd xmm, xmm, xmm | EVEX.128.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd xmm, xmm, xmm","EVEX.128.66.0F.W0 DF /r")]
        vpandnd_xmm_xmm_xmm = 2660,

        /// <summary>
        /// vpandnd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W0 DF /r")]
        vpandnd_ymm_k1z_ymm_m256 = 2661,

        /// <summary>
        /// vpandnd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F.W0 DF /r")]
        vpandnd_ymm_k1z_ymm_m32bcst = 2662,

        /// <summary>
        /// vpandnd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W0 DF /r")]
        vpandnd_ymm_k1z_ymm_ymm = 2663,

        /// <summary>
        /// vpandnd ymm, ymm, m256 | EVEX.256.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd ymm, ymm, m256","EVEX.256.66.0F.W0 DF /r")]
        vpandnd_ymm_ymm_m256 = 2664,

        /// <summary>
        /// vpandnd ymm, ymm, m32bcst | EVEX.256.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd ymm, ymm, m32bcst","EVEX.256.66.0F.W0 DF /r")]
        vpandnd_ymm_ymm_m32bcst = 2665,

        /// <summary>
        /// vpandnd ymm, ymm, ymm | EVEX.256.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd ymm, ymm, ymm","EVEX.256.66.0F.W0 DF /r")]
        vpandnd_ymm_ymm_ymm = 2666,

        /// <summary>
        /// vpandnd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F.W0 DF /r")]
        vpandnd_zmm_k1z_zmm_m32bcst = 2667,

        /// <summary>
        /// vpandnd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W0 DF /r")]
        vpandnd_zmm_k1z_zmm_m512 = 2668,

        /// <summary>
        /// vpandnd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W0 DF /r")]
        vpandnd_zmm_k1z_zmm_zmm = 2669,

        /// <summary>
        /// vpandnd zmm, zmm, m32bcst | EVEX.512.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd zmm, zmm, m32bcst","EVEX.512.66.0F.W0 DF /r")]
        vpandnd_zmm_zmm_m32bcst = 2670,

        /// <summary>
        /// vpandnd zmm, zmm, m512 | EVEX.512.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd zmm, zmm, m512","EVEX.512.66.0F.W0 DF /r")]
        vpandnd_zmm_zmm_m512 = 2671,

        /// <summary>
        /// vpandnd zmm, zmm, zmm | EVEX.512.66.0F.W0 DF /r | Bitwise AND NOT of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnd zmm, zmm, zmm","EVEX.512.66.0F.W0 DF /r")]
        vpandnd_zmm_zmm_zmm = 2672,

        /// <summary>
        /// vpandnq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 DF /r")]
        vpandnq_xmm_k1z_xmm_m128 = 2673,

        /// <summary>
        /// vpandnq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F.W1 DF /r")]
        vpandnq_xmm_k1z_xmm_m64bcst = 2674,

        /// <summary>
        /// vpandnq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W1 DF /r")]
        vpandnq_xmm_k1z_xmm_xmm = 2675,

        /// <summary>
        /// vpandnq xmm, xmm, m128 | EVEX.128.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq xmm, xmm, m128","EVEX.128.66.0F.W1 DF /r")]
        vpandnq_xmm_xmm_m128 = 2676,

        /// <summary>
        /// vpandnq xmm, xmm, m64bcst | EVEX.128.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq xmm, xmm, m64bcst","EVEX.128.66.0F.W1 DF /r")]
        vpandnq_xmm_xmm_m64bcst = 2677,

        /// <summary>
        /// vpandnq xmm, xmm, xmm | EVEX.128.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq xmm, xmm, xmm","EVEX.128.66.0F.W1 DF /r")]
        vpandnq_xmm_xmm_xmm = 2678,

        /// <summary>
        /// vpandnq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W1 DF /r")]
        vpandnq_ymm_k1z_ymm_m256 = 2679,

        /// <summary>
        /// vpandnq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F.W1 DF /r")]
        vpandnq_ymm_k1z_ymm_m64bcst = 2680,

        /// <summary>
        /// vpandnq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W1 DF /r")]
        vpandnq_ymm_k1z_ymm_ymm = 2681,

        /// <summary>
        /// vpandnq ymm, ymm, m256 | EVEX.256.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq ymm, ymm, m256","EVEX.256.66.0F.W1 DF /r")]
        vpandnq_ymm_ymm_m256 = 2682,

        /// <summary>
        /// vpandnq ymm, ymm, m64bcst | EVEX.256.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq ymm, ymm, m64bcst","EVEX.256.66.0F.W1 DF /r")]
        vpandnq_ymm_ymm_m64bcst = 2683,

        /// <summary>
        /// vpandnq ymm, ymm, ymm | EVEX.256.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq ymm, ymm, ymm","EVEX.256.66.0F.W1 DF /r")]
        vpandnq_ymm_ymm_ymm = 2684,

        /// <summary>
        /// vpandnq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W1 DF /r")]
        vpandnq_zmm_k1z_zmm_m512 = 2685,

        /// <summary>
        /// vpandnq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F.W1 DF /r")]
        vpandnq_zmm_k1z_zmm_m64bcst = 2686,

        /// <summary>
        /// vpandnq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W1 DF /r")]
        vpandnq_zmm_k1z_zmm_zmm = 2687,

        /// <summary>
        /// vpandnq zmm, zmm, m512 | EVEX.512.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq zmm, zmm, m512","EVEX.512.66.0F.W1 DF /r")]
        vpandnq_zmm_zmm_m512 = 2688,

        /// <summary>
        /// vpandnq zmm, zmm, m64bcst | EVEX.512.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq zmm, zmm, m64bcst","EVEX.512.66.0F.W1 DF /r")]
        vpandnq_zmm_zmm_m64bcst = 2689,

        /// <summary>
        /// vpandnq zmm, zmm, zmm | EVEX.512.66.0F.W1 DF /r | Bitwise AND NOT of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandnq zmm, zmm, zmm","EVEX.512.66.0F.W1 DF /r")]
        vpandnq_zmm_zmm_zmm = 2690,

        /// <summary>
        /// vpandq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 DB /r")]
        vpandq_xmm_k1z_xmm_m128 = 2691,

        /// <summary>
        /// vpandq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F.W1 DB /r")]
        vpandq_xmm_k1z_xmm_m64bcst = 2692,

        /// <summary>
        /// vpandq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W1 DB /r")]
        vpandq_xmm_k1z_xmm_xmm = 2693,

        /// <summary>
        /// vpandq xmm, xmm, m128 | EVEX.128.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq xmm, xmm, m128","EVEX.128.66.0F.W1 DB /r")]
        vpandq_xmm_xmm_m128 = 2694,

        /// <summary>
        /// vpandq xmm, xmm, m64bcst | EVEX.128.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq xmm, xmm, m64bcst","EVEX.128.66.0F.W1 DB /r")]
        vpandq_xmm_xmm_m64bcst = 2695,

        /// <summary>
        /// vpandq xmm, xmm, xmm | EVEX.128.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq xmm, xmm, xmm","EVEX.128.66.0F.W1 DB /r")]
        vpandq_xmm_xmm_xmm = 2696,

        /// <summary>
        /// vpandq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W1 DB /r")]
        vpandq_ymm_k1z_ymm_m256 = 2697,

        /// <summary>
        /// vpandq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F.W1 DB /r")]
        vpandq_ymm_k1z_ymm_m64bcst = 2698,

        /// <summary>
        /// vpandq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W1 DB /r")]
        vpandq_ymm_k1z_ymm_ymm = 2699,

        /// <summary>
        /// vpandq ymm, ymm, m256 | EVEX.256.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq ymm, ymm, m256","EVEX.256.66.0F.W1 DB /r")]
        vpandq_ymm_ymm_m256 = 2700,

        /// <summary>
        /// vpandq ymm, ymm, m64bcst | EVEX.256.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq ymm, ymm, m64bcst","EVEX.256.66.0F.W1 DB /r")]
        vpandq_ymm_ymm_m64bcst = 2701,

        /// <summary>
        /// vpandq ymm, ymm, ymm | EVEX.256.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq ymm, ymm, ymm","EVEX.256.66.0F.W1 DB /r")]
        vpandq_ymm_ymm_ymm = 2702,

        /// <summary>
        /// vpandq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W1 DB /r")]
        vpandq_zmm_k1z_zmm_m512 = 2703,

        /// <summary>
        /// vpandq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F.W1 DB /r")]
        vpandq_zmm_k1z_zmm_m64bcst = 2704,

        /// <summary>
        /// vpandq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W1 DB /r")]
        vpandq_zmm_k1z_zmm_zmm = 2705,

        /// <summary>
        /// vpandq zmm, zmm, m512 | EVEX.512.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq zmm, zmm, m512","EVEX.512.66.0F.W1 DB /r")]
        vpandq_zmm_zmm_m512 = 2706,

        /// <summary>
        /// vpandq zmm, zmm, m64bcst | EVEX.512.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq zmm, zmm, m64bcst","EVEX.512.66.0F.W1 DB /r")]
        vpandq_zmm_zmm_m64bcst = 2707,

        /// <summary>
        /// vpandq zmm, zmm, zmm | EVEX.512.66.0F.W1 DB /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpandq zmm, zmm, zmm","EVEX.512.66.0F.W1 DB /r")]
        vpandq_zmm_zmm_zmm = 2708,

        /// <summary>
        /// vpavgb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG E0 /r | Average packed unsigned byte integers from xmm2, and xmm3/m128 with rounding and store to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG E0 /r")]
        vpavgb_xmm_k1z_xmm_m128 = 2709,

        /// <summary>
        /// vpavgb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG E0 /r | Average packed unsigned byte integers from xmm2, and xmm3/m128 with rounding and store to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG E0 /r")]
        vpavgb_xmm_k1z_xmm_r8 = 2710,

        /// <summary>
        /// vpavgb xmm, xmm, m128 | EVEX.128.66.0F.WIG E0 /r | Average packed unsigned byte integers from xmm2, and xmm3/m128 with rounding and store to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb xmm, xmm, m128","EVEX.128.66.0F.WIG E0 /r")]
        vpavgb_xmm_xmm_m128 = 2711,

        /// <summary>
        /// vpavgb xmm, xmm, m128 | VEX.128.66.0F.WIG E0 /r | Average packed unsigned byte integers from xmm3/m128 and xmm2 with rounding.
        /// </summary>
        [Symbol("vpavgb xmm, xmm, m128","VEX.128.66.0F.WIG E0 /r")]
        vpavgb_xmm_xmm_m128_vex = 2712,

        /// <summary>
        /// vpavgb xmm, xmm, r8 | EVEX.128.66.0F.WIG E0 /r | Average packed unsigned byte integers from xmm2, and xmm3/m128 with rounding and store to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb xmm, xmm, r8","EVEX.128.66.0F.WIG E0 /r")]
        vpavgb_xmm_xmm_r8 = 2713,

        /// <summary>
        /// vpavgb xmm, xmm, r8 | VEX.128.66.0F.WIG E0 /r | Average packed unsigned byte integers from xmm3/m128 and xmm2 with rounding.
        /// </summary>
        [Symbol("vpavgb xmm, xmm, r8","VEX.128.66.0F.WIG E0 /r")]
        vpavgb_xmm_xmm_r8_vex = 2714,

        /// <summary>
        /// vpavgb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG E0 /r | Average packed unsigned byte integers from ymm2, and ymm3/m256 with rounding and store to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG E0 /r")]
        vpavgb_ymm_k1z_ymm_m256 = 2715,

        /// <summary>
        /// vpavgb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG E0 /r | Average packed unsigned byte integers from ymm2, and ymm3/m256 with rounding and store to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG E0 /r")]
        vpavgb_ymm_k1z_ymm_r16 = 2716,

        /// <summary>
        /// vpavgb ymm, ymm, m256 | EVEX.256.66.0F.WIG E0 /r | Average packed unsigned byte integers from ymm2, and ymm3/m256 with rounding and store to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb ymm, ymm, m256","EVEX.256.66.0F.WIG E0 /r")]
        vpavgb_ymm_ymm_m256 = 2717,

        /// <summary>
        /// vpavgb ymm, ymm, m256 | VEX.256.66.0F.WIG E0 /r | Average packed unsigned byte integers from ymm2, and ymm3/m256 with rounding and store to ymm1.
        /// </summary>
        [Symbol("vpavgb ymm, ymm, m256","VEX.256.66.0F.WIG E0 /r")]
        vpavgb_ymm_ymm_m256_vex = 2718,

        /// <summary>
        /// vpavgb ymm, ymm, r16 | EVEX.256.66.0F.WIG E0 /r | Average packed unsigned byte integers from ymm2, and ymm3/m256 with rounding and store to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb ymm, ymm, r16","EVEX.256.66.0F.WIG E0 /r")]
        vpavgb_ymm_ymm_r16 = 2719,

        /// <summary>
        /// vpavgb ymm, ymm, r16 | VEX.256.66.0F.WIG E0 /r | Average packed unsigned byte integers from ymm2, and ymm3/m256 with rounding and store to ymm1.
        /// </summary>
        [Symbol("vpavgb ymm, ymm, r16","VEX.256.66.0F.WIG E0 /r")]
        vpavgb_ymm_ymm_r16_vex = 2720,

        /// <summary>
        /// vpavgb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG E0 /r | Average packed unsigned byte integers from zmm2, and zmm3/m512 with rounding and store to zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG E0 /r")]
        vpavgb_zmm_k1z_zmm_m512 = 2721,

        /// <summary>
        /// vpavgb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG E0 /r | Average packed unsigned byte integers from zmm2, and zmm3/m512 with rounding and store to zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG E0 /r")]
        vpavgb_zmm_k1z_zmm_r32 = 2722,

        /// <summary>
        /// vpavgb zmm, zmm, m512 | EVEX.512.66.0F.WIG E0 /r | Average packed unsigned byte integers from zmm2, and zmm3/m512 with rounding and store to zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb zmm, zmm, m512","EVEX.512.66.0F.WIG E0 /r")]
        vpavgb_zmm_zmm_m512 = 2723,

        /// <summary>
        /// vpavgb zmm, zmm, r32 | EVEX.512.66.0F.WIG E0 /r | Average packed unsigned byte integers from zmm2, and zmm3/m512 with rounding and store to zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgb zmm, zmm, r32","EVEX.512.66.0F.WIG E0 /r")]
        vpavgb_zmm_zmm_r32 = 2724,

        /// <summary>
        /// vpavgw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG E3 /r | Average packed unsigned word integers from xmm2, xmm3/m128 with rounding to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG E3 /r")]
        vpavgw_xmm_k1z_xmm_m128 = 2725,

        /// <summary>
        /// vpavgw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG E3 /r | Average packed unsigned word integers from xmm2, xmm3/m128 with rounding to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG E3 /r")]
        vpavgw_xmm_k1z_xmm_r8 = 2726,

        /// <summary>
        /// vpavgw xmm, xmm, m128 | EVEX.128.66.0F.WIG E3 /r | Average packed unsigned word integers from xmm2, xmm3/m128 with rounding to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw xmm, xmm, m128","EVEX.128.66.0F.WIG E3 /r")]
        vpavgw_xmm_xmm_m128 = 2727,

        /// <summary>
        /// vpavgw xmm, xmm, m128 | VEX.128.66.0F.WIG E3 /r | Average packed unsigned word integers from xmm3/m128 and xmm2 with rounding.
        /// </summary>
        [Symbol("vpavgw xmm, xmm, m128","VEX.128.66.0F.WIG E3 /r")]
        vpavgw_xmm_xmm_m128_vex = 2728,

        /// <summary>
        /// vpavgw xmm, xmm, r8 | EVEX.128.66.0F.WIG E3 /r | Average packed unsigned word integers from xmm2, xmm3/m128 with rounding to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw xmm, xmm, r8","EVEX.128.66.0F.WIG E3 /r")]
        vpavgw_xmm_xmm_r8 = 2729,

        /// <summary>
        /// vpavgw xmm, xmm, r8 | VEX.128.66.0F.WIG E3 /r | Average packed unsigned word integers from xmm3/m128 and xmm2 with rounding.
        /// </summary>
        [Symbol("vpavgw xmm, xmm, r8","VEX.128.66.0F.WIG E3 /r")]
        vpavgw_xmm_xmm_r8_vex = 2730,

        /// <summary>
        /// vpavgw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG E3 /r | Average packed unsigned word integers from ymm2, ymm3/m256 with rounding to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG E3 /r")]
        vpavgw_ymm_k1z_ymm_m256 = 2731,

        /// <summary>
        /// vpavgw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG E3 /r | Average packed unsigned word integers from ymm2, ymm3/m256 with rounding to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG E3 /r")]
        vpavgw_ymm_k1z_ymm_r16 = 2732,

        /// <summary>
        /// vpavgw ymm, ymm, m256 | EVEX.256.66.0F.WIG E3 /r | Average packed unsigned word integers from ymm2, ymm3/m256 with rounding to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw ymm, ymm, m256","EVEX.256.66.0F.WIG E3 /r")]
        vpavgw_ymm_ymm_m256 = 2733,

        /// <summary>
        /// vpavgw ymm, ymm, m256 | VEX.256.66.0F.WIG E3 /r | Average packed unsigned word integers from ymm2 , ymm3/m256 with rounding to ymm1.
        /// </summary>
        [Symbol("vpavgw ymm, ymm, m256","VEX.256.66.0F.WIG E3 /r")]
        vpavgw_ymm_ymm_m256_vex = 2734,

        /// <summary>
        /// vpavgw ymm, ymm, r16 | EVEX.256.66.0F.WIG E3 /r | Average packed unsigned word integers from ymm2, ymm3/m256 with rounding to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw ymm, ymm, r16","EVEX.256.66.0F.WIG E3 /r")]
        vpavgw_ymm_ymm_r16 = 2735,

        /// <summary>
        /// vpavgw ymm, ymm, r16 | VEX.256.66.0F.WIG E3 /r | Average packed unsigned word integers from ymm2 , ymm3/m256 with rounding to ymm1.
        /// </summary>
        [Symbol("vpavgw ymm, ymm, r16","VEX.256.66.0F.WIG E3 /r")]
        vpavgw_ymm_ymm_r16_vex = 2736,

        /// <summary>
        /// vpavgw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG E3 /r | Average packed unsigned word integers from zmm2, zmm3/m512 with rounding to zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG E3 /r")]
        vpavgw_zmm_k1z_zmm_m512 = 2737,

        /// <summary>
        /// vpavgw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG E3 /r | Average packed unsigned word integers from zmm2, zmm3/m512 with rounding to zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG E3 /r")]
        vpavgw_zmm_k1z_zmm_r32 = 2738,

        /// <summary>
        /// vpavgw zmm, zmm, m512 | EVEX.512.66.0F.WIG E3 /r | Average packed unsigned word integers from zmm2, zmm3/m512 with rounding to zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw zmm, zmm, m512","EVEX.512.66.0F.WIG E3 /r")]
        vpavgw_zmm_zmm_m512 = 2739,

        /// <summary>
        /// vpavgw zmm, zmm, r32 | EVEX.512.66.0F.WIG E3 /r | Average packed unsigned word integers from zmm2, zmm3/m512 with rounding to zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpavgw zmm, zmm, r32","EVEX.512.66.0F.WIG E3 /r")]
        vpavgw_zmm_zmm_r32 = 2740,

        /// <summary>
        /// vpblendmb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 66 /r | Blend byte integer vector xmm2 and byte vector xmm3/m128 and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 66 /r")]
        vpblendmb_xmm_k1z_xmm_m128 = 2741,

        /// <summary>
        /// vpblendmb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.W0 66 /r | Blend byte integer vector xmm2 and byte vector xmm3/m128 and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.W0 66 /r")]
        vpblendmb_xmm_k1z_xmm_r8 = 2742,

        /// <summary>
        /// vpblendmb xmm, xmm, m128 | EVEX.128.66.0F38.W0 66 /r | Blend byte integer vector xmm2 and byte vector xmm3/m128 and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb xmm, xmm, m128","EVEX.128.66.0F38.W0 66 /r")]
        vpblendmb_xmm_xmm_m128 = 2743,

        /// <summary>
        /// vpblendmb xmm, xmm, r8 | EVEX.128.66.0F38.W0 66 /r | Blend byte integer vector xmm2 and byte vector xmm3/m128 and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb xmm, xmm, r8","EVEX.128.66.0F38.W0 66 /r")]
        vpblendmb_xmm_xmm_r8 = 2744,

        /// <summary>
        /// vpblendmb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 66 /r | Blend byte integer vector ymm2 and byte vector ymm3/m256 and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 66 /r")]
        vpblendmb_ymm_k1z_ymm_m256 = 2745,

        /// <summary>
        /// vpblendmb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.W0 66 /r | Blend byte integer vector ymm2 and byte vector ymm3/m256 and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.W0 66 /r")]
        vpblendmb_ymm_k1z_ymm_r16 = 2746,

        /// <summary>
        /// vpblendmb ymm, ymm, m256 | EVEX.256.66.0F38.W0 66 /r | Blend byte integer vector ymm2 and byte vector ymm3/m256 and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb ymm, ymm, m256","EVEX.256.66.0F38.W0 66 /r")]
        vpblendmb_ymm_ymm_m256 = 2747,

        /// <summary>
        /// vpblendmb ymm, ymm, r16 | EVEX.256.66.0F38.W0 66 /r | Blend byte integer vector ymm2 and byte vector ymm3/m256 and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb ymm, ymm, r16","EVEX.256.66.0F38.W0 66 /r")]
        vpblendmb_ymm_ymm_r16 = 2748,

        /// <summary>
        /// vpblendmb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 66 /r | Blend byte integer vector zmm2 and byte vector zmm3/m512 and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 66 /r")]
        vpblendmb_zmm_k1z_zmm_m512 = 2749,

        /// <summary>
        /// vpblendmb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.W0 66 /r | Blend byte integer vector zmm2 and byte vector zmm3/m512 and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.W0 66 /r")]
        vpblendmb_zmm_k1z_zmm_r32 = 2750,

        /// <summary>
        /// vpblendmb zmm, zmm, m512 | EVEX.512.66.0F38.W0 66 /r | Blend byte integer vector zmm2 and byte vector zmm3/m512 and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb zmm, zmm, m512","EVEX.512.66.0F38.W0 66 /r")]
        vpblendmb_zmm_zmm_m512 = 2751,

        /// <summary>
        /// vpblendmb zmm, zmm, r32 | EVEX.512.66.0F38.W0 66 /r | Blend byte integer vector zmm2 and byte vector zmm3/m512 and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmb zmm, zmm, r32","EVEX.512.66.0F38.W0 66 /r")]
        vpblendmb_zmm_zmm_r32 = 2752,

        /// <summary>
        /// vpblendmd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 64 /r | Blend doubleword integer vector xmm2 and doubleword vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 64 /r")]
        vpblendmd_xmm_k1z_xmm_m128 = 2753,

        /// <summary>
        /// vpblendmd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 64 /r | Blend doubleword integer vector xmm2 and doubleword vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 64 /r")]
        vpblendmd_xmm_k1z_xmm_m32bcst = 2754,

        /// <summary>
        /// vpblendmd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 64 /r | Blend doubleword integer vector xmm2 and doubleword vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 64 /r")]
        vpblendmd_xmm_k1z_xmm_xmm = 2755,

        /// <summary>
        /// vpblendmd xmm, xmm, m128 | EVEX.128.66.0F38.W0 64 /r | Blend doubleword integer vector xmm2 and doubleword vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd xmm, xmm, m128","EVEX.128.66.0F38.W0 64 /r")]
        vpblendmd_xmm_xmm_m128 = 2756,

        /// <summary>
        /// vpblendmd xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 64 /r | Blend doubleword integer vector xmm2 and doubleword vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 64 /r")]
        vpblendmd_xmm_xmm_m32bcst = 2757,

        /// <summary>
        /// vpblendmd xmm, xmm, xmm | EVEX.128.66.0F38.W0 64 /r | Blend doubleword integer vector xmm2 and doubleword vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd xmm, xmm, xmm","EVEX.128.66.0F38.W0 64 /r")]
        vpblendmd_xmm_xmm_xmm = 2758,

        /// <summary>
        /// vpblendmd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 64 /r | Blend doubleword integer vector ymm2 and doubleword vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 64 /r")]
        vpblendmd_ymm_k1z_ymm_m256 = 2759,

        /// <summary>
        /// vpblendmd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 64 /r | Blend doubleword integer vector ymm2 and doubleword vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 64 /r")]
        vpblendmd_ymm_k1z_ymm_m32bcst = 2760,

        /// <summary>
        /// vpblendmd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 64 /r | Blend doubleword integer vector ymm2 and doubleword vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 64 /r")]
        vpblendmd_ymm_k1z_ymm_ymm = 2761,

        /// <summary>
        /// vpblendmd ymm, ymm, m256 | EVEX.256.66.0F38.W0 64 /r | Blend doubleword integer vector ymm2 and doubleword vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd ymm, ymm, m256","EVEX.256.66.0F38.W0 64 /r")]
        vpblendmd_ymm_ymm_m256 = 2762,

        /// <summary>
        /// vpblendmd ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 64 /r | Blend doubleword integer vector ymm2 and doubleword vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 64 /r")]
        vpblendmd_ymm_ymm_m32bcst = 2763,

        /// <summary>
        /// vpblendmd ymm, ymm, ymm | EVEX.256.66.0F38.W0 64 /r | Blend doubleword integer vector ymm2 and doubleword vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd ymm, ymm, ymm","EVEX.256.66.0F38.W0 64 /r")]
        vpblendmd_ymm_ymm_ymm = 2764,

        /// <summary>
        /// vpblendmd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 64 /r | Blend doubleword integer vector zmm2 and doubleword vector zmm3/m512/m32bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 64 /r")]
        vpblendmd_zmm_k1z_zmm_m32bcst = 2765,

        /// <summary>
        /// vpblendmd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 64 /r | Blend doubleword integer vector zmm2 and doubleword vector zmm3/m512/m32bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 64 /r")]
        vpblendmd_zmm_k1z_zmm_m512 = 2766,

        /// <summary>
        /// vpblendmd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 64 /r | Blend doubleword integer vector zmm2 and doubleword vector zmm3/m512/m32bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 64 /r")]
        vpblendmd_zmm_k1z_zmm_zmm = 2767,

        /// <summary>
        /// vpblendmd zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 64 /r | Blend doubleword integer vector zmm2 and doubleword vector zmm3/m512/m32bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 64 /r")]
        vpblendmd_zmm_zmm_m32bcst = 2768,

        /// <summary>
        /// vpblendmd zmm, zmm, m512 | EVEX.512.66.0F38.W0 64 /r | Blend doubleword integer vector zmm2 and doubleword vector zmm3/m512/m32bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd zmm, zmm, m512","EVEX.512.66.0F38.W0 64 /r")]
        vpblendmd_zmm_zmm_m512 = 2769,

        /// <summary>
        /// vpblendmd zmm, zmm, zmm | EVEX.512.66.0F38.W0 64 /r | Blend doubleword integer vector zmm2 and doubleword vector zmm3/m512/m32bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmd zmm, zmm, zmm","EVEX.512.66.0F38.W0 64 /r")]
        vpblendmd_zmm_zmm_zmm = 2770,

        /// <summary>
        /// vpblendmq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 64 /r | Blend quadword integer vector xmm2 and quadword vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 64 /r")]
        vpblendmq_xmm_k1z_xmm_m128 = 2771,

        /// <summary>
        /// vpblendmq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 64 /r | Blend quadword integer vector xmm2 and quadword vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 64 /r")]
        vpblendmq_xmm_k1z_xmm_m64bcst = 2772,

        /// <summary>
        /// vpblendmq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 64 /r | Blend quadword integer vector xmm2 and quadword vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 64 /r")]
        vpblendmq_xmm_k1z_xmm_xmm = 2773,

        /// <summary>
        /// vpblendmq xmm, xmm, m128 | EVEX.128.66.0F38.W1 64 /r | Blend quadword integer vector xmm2 and quadword vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq xmm, xmm, m128","EVEX.128.66.0F38.W1 64 /r")]
        vpblendmq_xmm_xmm_m128 = 2774,

        /// <summary>
        /// vpblendmq xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 64 /r | Blend quadword integer vector xmm2 and quadword vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 64 /r")]
        vpblendmq_xmm_xmm_m64bcst = 2775,

        /// <summary>
        /// vpblendmq xmm, xmm, xmm | EVEX.128.66.0F38.W1 64 /r | Blend quadword integer vector xmm2 and quadword vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq xmm, xmm, xmm","EVEX.128.66.0F38.W1 64 /r")]
        vpblendmq_xmm_xmm_xmm = 2776,

        /// <summary>
        /// vpblendmq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 64 /r | Blend quadword integer vector ymm2 and quadword vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 64 /r")]
        vpblendmq_ymm_k1z_ymm_m256 = 2777,

        /// <summary>
        /// vpblendmq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 64 /r | Blend quadword integer vector ymm2 and quadword vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 64 /r")]
        vpblendmq_ymm_k1z_ymm_m64bcst = 2778,

        /// <summary>
        /// vpblendmq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 64 /r | Blend quadword integer vector ymm2 and quadword vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 64 /r")]
        vpblendmq_ymm_k1z_ymm_ymm = 2779,

        /// <summary>
        /// vpblendmq ymm, ymm, m256 | EVEX.256.66.0F38.W1 64 /r | Blend quadword integer vector ymm2 and quadword vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq ymm, ymm, m256","EVEX.256.66.0F38.W1 64 /r")]
        vpblendmq_ymm_ymm_m256 = 2780,

        /// <summary>
        /// vpblendmq ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 64 /r | Blend quadword integer vector ymm2 and quadword vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 64 /r")]
        vpblendmq_ymm_ymm_m64bcst = 2781,

        /// <summary>
        /// vpblendmq ymm, ymm, ymm | EVEX.256.66.0F38.W1 64 /r | Blend quadword integer vector ymm2 and quadword vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq ymm, ymm, ymm","EVEX.256.66.0F38.W1 64 /r")]
        vpblendmq_ymm_ymm_ymm = 2782,

        /// <summary>
        /// vpblendmq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 64 /r | Blend quadword integer vector zmm2 and quadword vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 64 /r")]
        vpblendmq_zmm_k1z_zmm_m512 = 2783,

        /// <summary>
        /// vpblendmq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 64 /r | Blend quadword integer vector zmm2 and quadword vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 64 /r")]
        vpblendmq_zmm_k1z_zmm_m64bcst = 2784,

        /// <summary>
        /// vpblendmq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 64 /r | Blend quadword integer vector zmm2 and quadword vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 64 /r")]
        vpblendmq_zmm_k1z_zmm_zmm = 2785,

        /// <summary>
        /// vpblendmq zmm, zmm, m512 | EVEX.512.66.0F38.W1 64 /r | Blend quadword integer vector zmm2 and quadword vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq zmm, zmm, m512","EVEX.512.66.0F38.W1 64 /r")]
        vpblendmq_zmm_zmm_m512 = 2786,

        /// <summary>
        /// vpblendmq zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 64 /r | Blend quadword integer vector zmm2 and quadword vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 64 /r")]
        vpblendmq_zmm_zmm_m64bcst = 2787,

        /// <summary>
        /// vpblendmq zmm, zmm, zmm | EVEX.512.66.0F38.W1 64 /r | Blend quadword integer vector zmm2 and quadword vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmq zmm, zmm, zmm","EVEX.512.66.0F38.W1 64 /r")]
        vpblendmq_zmm_zmm_zmm = 2788,

        /// <summary>
        /// vpblendmw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 66 /r | Blend word integer vector xmm2 and word vector xmm3/m128 and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 66 /r")]
        vpblendmw_xmm_k1z_xmm_m128 = 2789,

        /// <summary>
        /// vpblendmw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.W1 66 /r | Blend word integer vector xmm2 and word vector xmm3/m128 and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.W1 66 /r")]
        vpblendmw_xmm_k1z_xmm_r8 = 2790,

        /// <summary>
        /// vpblendmw xmm, xmm, m128 | EVEX.128.66.0F38.W1 66 /r | Blend word integer vector xmm2 and word vector xmm3/m128 and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw xmm, xmm, m128","EVEX.128.66.0F38.W1 66 /r")]
        vpblendmw_xmm_xmm_m128 = 2791,

        /// <summary>
        /// vpblendmw xmm, xmm, r8 | EVEX.128.66.0F38.W1 66 /r | Blend word integer vector xmm2 and word vector xmm3/m128 and store the result in xmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw xmm, xmm, r8","EVEX.128.66.0F38.W1 66 /r")]
        vpblendmw_xmm_xmm_r8 = 2792,

        /// <summary>
        /// vpblendmw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 66 /r | Blend word integer vector ymm2 and word vector ymm3/m256 and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 66 /r")]
        vpblendmw_ymm_k1z_ymm_m256 = 2793,

        /// <summary>
        /// vpblendmw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.W1 66 /r | Blend word integer vector ymm2 and word vector ymm3/m256 and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.W1 66 /r")]
        vpblendmw_ymm_k1z_ymm_r16 = 2794,

        /// <summary>
        /// vpblendmw ymm, ymm, m256 | EVEX.256.66.0F38.W1 66 /r | Blend word integer vector ymm2 and word vector ymm3/m256 and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw ymm, ymm, m256","EVEX.256.66.0F38.W1 66 /r")]
        vpblendmw_ymm_ymm_m256 = 2795,

        /// <summary>
        /// vpblendmw ymm, ymm, r16 | EVEX.256.66.0F38.W1 66 /r | Blend word integer vector ymm2 and word vector ymm3/m256 and store the result in ymm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw ymm, ymm, r16","EVEX.256.66.0F38.W1 66 /r")]
        vpblendmw_ymm_ymm_r16 = 2796,

        /// <summary>
        /// vpblendmw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 66 /r | Blend word integer vector zmm2 and word vector zmm3/m512 and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 66 /r")]
        vpblendmw_zmm_k1z_zmm_m512 = 2797,

        /// <summary>
        /// vpblendmw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.W1 66 /r | Blend word integer vector zmm2 and word vector zmm3/m512 and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.W1 66 /r")]
        vpblendmw_zmm_k1z_zmm_r32 = 2798,

        /// <summary>
        /// vpblendmw zmm, zmm, m512 | EVEX.512.66.0F38.W1 66 /r | Blend word integer vector zmm2 and word vector zmm3/m512 and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw zmm, zmm, m512","EVEX.512.66.0F38.W1 66 /r")]
        vpblendmw_zmm_zmm_m512 = 2799,

        /// <summary>
        /// vpblendmw zmm, zmm, r32 | EVEX.512.66.0F38.W1 66 /r | Blend word integer vector zmm2 and word vector zmm3/m512 and store the result in zmm1, under control mask.
        /// </summary>
        [Symbol("vpblendmw zmm, zmm, r32","EVEX.512.66.0F38.W1 66 /r")]
        vpblendmw_zmm_zmm_r32 = 2800,

        /// <summary>
        /// vpbroadcastb xmm {k1}{z}, m8 | EVEX.128.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb xmm {k1}{z}, m8","EVEX.128.66.0F38.W0 78 /r")]
        vpbroadcastb_xmm_k1z_m8 = 2801,

        /// <summary>
        /// vpbroadcastb xmm {k1}{z}, r8 | EVEX.128.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb xmm {k1}{z}, r8","EVEX.128.66.0F38.W0 78 /r")]
        vpbroadcastb_xmm_k1z_r8 = 2802,

        /// <summary>
        /// vpbroadcastb xmm, m8 | EVEX.128.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb xmm, m8","EVEX.128.66.0F38.W0 78 /r")]
        vpbroadcastb_xmm_m8 = 2803,

        /// <summary>
        /// vpbroadcastb xmm, m8 | VEX.128.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to sixteen locations in xmm1.
        /// </summary>
        [Symbol("vpbroadcastb xmm, m8","VEX.128.66.0F38.W0 78 /r")]
        vpbroadcastb_xmm_m8_vex = 2804,

        /// <summary>
        /// vpbroadcastb xmm, r8 | EVEX.128.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb xmm, r8","EVEX.128.66.0F38.W0 78 /r")]
        vpbroadcastb_xmm_r8 = 2805,

        /// <summary>
        /// vpbroadcastb xmm, r8 | VEX.128.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to sixteen locations in xmm1.
        /// </summary>
        [Symbol("vpbroadcastb xmm, r8","VEX.128.66.0F38.W0 78 /r")]
        vpbroadcastb_xmm_r8_vex = 2806,

        /// <summary>
        /// vpbroadcastb ymm {k1}{z}, m8 | EVEX.256.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb ymm {k1}{z}, m8","EVEX.256.66.0F38.W0 78 /r")]
        vpbroadcastb_ymm_k1z_m8 = 2807,

        /// <summary>
        /// vpbroadcastb ymm {k1}{z}, r8 | EVEX.256.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb ymm {k1}{z}, r8","EVEX.256.66.0F38.W0 78 /r")]
        vpbroadcastb_ymm_k1z_r8 = 2808,

        /// <summary>
        /// vpbroadcastb ymm, m8 | EVEX.256.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb ymm, m8","EVEX.256.66.0F38.W0 78 /r")]
        vpbroadcastb_ymm_m8 = 2809,

        /// <summary>
        /// vpbroadcastb ymm, m8 | VEX.256.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to thirty-two locations in ymm1.
        /// </summary>
        [Symbol("vpbroadcastb ymm, m8","VEX.256.66.0F38.W0 78 /r")]
        vpbroadcastb_ymm_m8_vex = 2810,

        /// <summary>
        /// vpbroadcastb ymm, r8 | EVEX.256.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb ymm, r8","EVEX.256.66.0F38.W0 78 /r")]
        vpbroadcastb_ymm_r8 = 2811,

        /// <summary>
        /// vpbroadcastb ymm, r8 | VEX.256.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to thirty-two locations in ymm1.
        /// </summary>
        [Symbol("vpbroadcastb ymm, r8","VEX.256.66.0F38.W0 78 /r")]
        vpbroadcastb_ymm_r8_vex = 2812,

        /// <summary>
        /// vpbroadcastb zmm {k1}{z}, m8 | EVEX.512.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to 64 locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb zmm {k1}{z}, m8","EVEX.512.66.0F38.W0 78 /r")]
        vpbroadcastb_zmm_k1z_m8 = 2813,

        /// <summary>
        /// vpbroadcastb zmm {k1}{z}, r8 | EVEX.512.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to 64 locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb zmm {k1}{z}, r8","EVEX.512.66.0F38.W0 78 /r")]
        vpbroadcastb_zmm_k1z_r8 = 2814,

        /// <summary>
        /// vpbroadcastb zmm, m8 | EVEX.512.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to 64 locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb zmm, m8","EVEX.512.66.0F38.W0 78 /r")]
        vpbroadcastb_zmm_m8 = 2815,

        /// <summary>
        /// vpbroadcastb zmm, r8 | EVEX.512.66.0F38.W0 78 /r | Broadcast a byte integer in the source operand to 64 locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastb zmm, r8","EVEX.512.66.0F38.W0 78 /r")]
        vpbroadcastb_zmm_r8 = 2816,

        /// <summary>
        /// vpbroadcastd xmm {k1}{z}, m32 | EVEX.128.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd xmm {k1}{z}, m32","EVEX.128.66.0F38.W0 58 /r")]
        vpbroadcastd_xmm_k1z_m32 = 2817,

        /// <summary>
        /// vpbroadcastd xmm {k1}{z}, r8 | EVEX.128.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd xmm {k1}{z}, r8","EVEX.128.66.0F38.W0 58 /r")]
        vpbroadcastd_xmm_k1z_r8 = 2818,

        /// <summary>
        /// vpbroadcastd xmm, m32 | EVEX.128.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd xmm, m32","EVEX.128.66.0F38.W0 58 /r")]
        vpbroadcastd_xmm_m32 = 2819,

        /// <summary>
        /// vpbroadcastd xmm, m32 | VEX.128.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to four locations in xmm1.
        /// </summary>
        [Symbol("vpbroadcastd xmm, m32","VEX.128.66.0F38.W0 58 /r")]
        vpbroadcastd_xmm_m32_vex = 2820,

        /// <summary>
        /// vpbroadcastd xmm, r8 | EVEX.128.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd xmm, r8","EVEX.128.66.0F38.W0 58 /r")]
        vpbroadcastd_xmm_r8 = 2821,

        /// <summary>
        /// vpbroadcastd xmm, r8 | VEX.128.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to four locations in xmm1.
        /// </summary>
        [Symbol("vpbroadcastd xmm, r8","VEX.128.66.0F38.W0 58 /r")]
        vpbroadcastd_xmm_r8_vex = 2822,

        /// <summary>
        /// vpbroadcastd ymm {k1}{z}, m32 | EVEX.256.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd ymm {k1}{z}, m32","EVEX.256.66.0F38.W0 58 /r")]
        vpbroadcastd_ymm_k1z_m32 = 2823,

        /// <summary>
        /// vpbroadcastd ymm {k1}{z}, r8 | EVEX.256.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd ymm {k1}{z}, r8","EVEX.256.66.0F38.W0 58 /r")]
        vpbroadcastd_ymm_k1z_r8 = 2824,

        /// <summary>
        /// vpbroadcastd ymm, m32 | EVEX.256.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd ymm, m32","EVEX.256.66.0F38.W0 58 /r")]
        vpbroadcastd_ymm_m32 = 2825,

        /// <summary>
        /// vpbroadcastd ymm, m32 | VEX.256.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to eight locations in ymm1.
        /// </summary>
        [Symbol("vpbroadcastd ymm, m32","VEX.256.66.0F38.W0 58 /r")]
        vpbroadcastd_ymm_m32_vex = 2826,

        /// <summary>
        /// vpbroadcastd ymm, r8 | EVEX.256.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd ymm, r8","EVEX.256.66.0F38.W0 58 /r")]
        vpbroadcastd_ymm_r8 = 2827,

        /// <summary>
        /// vpbroadcastd ymm, r8 | VEX.256.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to eight locations in ymm1.
        /// </summary>
        [Symbol("vpbroadcastd ymm, r8","VEX.256.66.0F38.W0 58 /r")]
        vpbroadcastd_ymm_r8_vex = 2828,

        /// <summary>
        /// vpbroadcastd zmm {k1}{z}, m32 | EVEX.512.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd zmm {k1}{z}, m32","EVEX.512.66.0F38.W0 58 /r")]
        vpbroadcastd_zmm_k1z_m32 = 2829,

        /// <summary>
        /// vpbroadcastd zmm {k1}{z}, r8 | EVEX.512.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd zmm {k1}{z}, r8","EVEX.512.66.0F38.W0 58 /r")]
        vpbroadcastd_zmm_k1z_r8 = 2830,

        /// <summary>
        /// vpbroadcastd zmm, m32 | EVEX.512.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd zmm, m32","EVEX.512.66.0F38.W0 58 /r")]
        vpbroadcastd_zmm_m32 = 2831,

        /// <summary>
        /// vpbroadcastd zmm, r8 | EVEX.512.66.0F38.W0 58 /r | Broadcast a dword integer in the source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastd zmm, r8","EVEX.512.66.0F38.W0 58 /r")]
        vpbroadcastd_zmm_r8 = 2832,

        /// <summary>
        /// vpbroadcastmb2q xmm, k | EVEX.128.F3.0F38.W1 2A /r | Broadcast low byte value in k1 to two locations in xmm1.
        /// </summary>
        [Symbol("vpbroadcastmb2q xmm, k","EVEX.128.F3.0F38.W1 2A /r")]
        vpbroadcastmb2q_xmm_k = 2833,

        /// <summary>
        /// vpbroadcastmb2q ymm, k | EVEX.256.F3.0F38.W1 2A /r | Broadcast low byte value in k1 to four locations in ymm1.
        /// </summary>
        [Symbol("vpbroadcastmb2q ymm, k","EVEX.256.F3.0F38.W1 2A /r")]
        vpbroadcastmb2q_ymm_k = 2834,

        /// <summary>
        /// vpbroadcastmb2q zmm, k | EVEX.512.F3.0F38.W1 2A /r | Broadcast low byte value in k1 to eight locations in zmm1.
        /// </summary>
        [Symbol("vpbroadcastmb2q zmm, k","EVEX.512.F3.0F38.W1 2A /r")]
        vpbroadcastmb2q_zmm_k = 2835,

        /// <summary>
        /// vpbroadcastmw2d xmm, k | EVEX.128.F3.0F38.W0 3A /r | Broadcast low word value in k1 to four locations in xmm1.
        /// </summary>
        [Symbol("vpbroadcastmw2d xmm, k","EVEX.128.F3.0F38.W0 3A /r")]
        vpbroadcastmw2d_xmm_k = 2836,

        /// <summary>
        /// vpbroadcastmw2d ymm, k | EVEX.256.F3.0F38.W0 3A /r | Broadcast low word value in k1 to eight locations in ymm1.
        /// </summary>
        [Symbol("vpbroadcastmw2d ymm, k","EVEX.256.F3.0F38.W0 3A /r")]
        vpbroadcastmw2d_ymm_k = 2837,

        /// <summary>
        /// vpbroadcastmw2d zmm, k | EVEX.512.F3.0F38.W0 3A /r | Broadcast low word value in k1 to sixteen locations in zmm1.
        /// </summary>
        [Symbol("vpbroadcastmw2d zmm, k","EVEX.512.F3.0F38.W0 3A /r")]
        vpbroadcastmw2d_zmm_k = 2838,

        /// <summary>
        /// vpbroadcastq xmm {k1}{z}, m64 | EVEX.128.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq xmm {k1}{z}, m64","EVEX.128.66.0F38.W1 59 /r")]
        vpbroadcastq_xmm_k1z_m64 = 2839,

        /// <summary>
        /// vpbroadcastq xmm {k1}{z}, r8 | EVEX.128.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq xmm {k1}{z}, r8","EVEX.128.66.0F38.W1 59 /r")]
        vpbroadcastq_xmm_k1z_r8 = 2840,

        /// <summary>
        /// vpbroadcastq xmm, m64 | EVEX.128.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq xmm, m64","EVEX.128.66.0F38.W1 59 /r")]
        vpbroadcastq_xmm_m64 = 2841,

        /// <summary>
        /// vpbroadcastq xmm, m64 | VEX.128.66.0F38.W0 59 /r | Broadcast a qword element in source operand to two locations in xmm1.
        /// </summary>
        [Symbol("vpbroadcastq xmm, m64","VEX.128.66.0F38.W0 59 /r")]
        vpbroadcastq_xmm_m64_vex = 2842,

        /// <summary>
        /// vpbroadcastq xmm, r8 | EVEX.128.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq xmm, r8","EVEX.128.66.0F38.W1 59 /r")]
        vpbroadcastq_xmm_r8 = 2843,

        /// <summary>
        /// vpbroadcastq xmm, r8 | VEX.128.66.0F38.W0 59 /r | Broadcast a qword element in source operand to two locations in xmm1.
        /// </summary>
        [Symbol("vpbroadcastq xmm, r8","VEX.128.66.0F38.W0 59 /r")]
        vpbroadcastq_xmm_r8_vex = 2844,

        /// <summary>
        /// vpbroadcastq ymm {k1}{z}, m64 | EVEX.256.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq ymm {k1}{z}, m64","EVEX.256.66.0F38.W1 59 /r")]
        vpbroadcastq_ymm_k1z_m64 = 2845,

        /// <summary>
        /// vpbroadcastq ymm {k1}{z}, r8 | EVEX.256.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq ymm {k1}{z}, r8","EVEX.256.66.0F38.W1 59 /r")]
        vpbroadcastq_ymm_k1z_r8 = 2846,

        /// <summary>
        /// vpbroadcastq ymm, m64 | EVEX.256.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq ymm, m64","EVEX.256.66.0F38.W1 59 /r")]
        vpbroadcastq_ymm_m64 = 2847,

        /// <summary>
        /// vpbroadcastq ymm, m64 | VEX.256.66.0F38.W0 59 /r | Broadcast a qword element in source operand to four locations in ymm1.
        /// </summary>
        [Symbol("vpbroadcastq ymm, m64","VEX.256.66.0F38.W0 59 /r")]
        vpbroadcastq_ymm_m64_vex = 2848,

        /// <summary>
        /// vpbroadcastq ymm, r8 | EVEX.256.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq ymm, r8","EVEX.256.66.0F38.W1 59 /r")]
        vpbroadcastq_ymm_r8 = 2849,

        /// <summary>
        /// vpbroadcastq ymm, r8 | VEX.256.66.0F38.W0 59 /r | Broadcast a qword element in source operand to four locations in ymm1.
        /// </summary>
        [Symbol("vpbroadcastq ymm, r8","VEX.256.66.0F38.W0 59 /r")]
        vpbroadcastq_ymm_r8_vex = 2850,

        /// <summary>
        /// vpbroadcastq zmm {k1}{z}, m64 | EVEX.512.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq zmm {k1}{z}, m64","EVEX.512.66.0F38.W1 59 /r")]
        vpbroadcastq_zmm_k1z_m64 = 2851,

        /// <summary>
        /// vpbroadcastq zmm {k1}{z}, r8 | EVEX.512.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq zmm {k1}{z}, r8","EVEX.512.66.0F38.W1 59 /r")]
        vpbroadcastq_zmm_k1z_r8 = 2852,

        /// <summary>
        /// vpbroadcastq zmm, m64 | EVEX.512.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq zmm, m64","EVEX.512.66.0F38.W1 59 /r")]
        vpbroadcastq_zmm_m64 = 2853,

        /// <summary>
        /// vpbroadcastq zmm, r8 | EVEX.512.66.0F38.W1 59 /r | Broadcast a qword element in source operand to locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastq zmm, r8","EVEX.512.66.0F38.W1 59 /r")]
        vpbroadcastq_zmm_r8 = 2854,

        /// <summary>
        /// vpbroadcastw xmm {k1}{z}, m16 | EVEX.128.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw xmm {k1}{z}, m16","EVEX.128.66.0F38.W0 79 /r")]
        vpbroadcastw_xmm_k1z_m16 = 2855,

        /// <summary>
        /// vpbroadcastw xmm {k1}{z}, r8 | EVEX.128.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw xmm {k1}{z}, r8","EVEX.128.66.0F38.W0 79 /r")]
        vpbroadcastw_xmm_k1z_r8 = 2856,

        /// <summary>
        /// vpbroadcastw xmm, m16 | EVEX.128.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw xmm, m16","EVEX.128.66.0F38.W0 79 /r")]
        vpbroadcastw_xmm_m16 = 2857,

        /// <summary>
        /// vpbroadcastw xmm, m16 | VEX.128.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to eight locations in xmm1.
        /// </summary>
        [Symbol("vpbroadcastw xmm, m16","VEX.128.66.0F38.W0 79 /r")]
        vpbroadcastw_xmm_m16_vex = 2858,

        /// <summary>
        /// vpbroadcastw xmm, r8 | EVEX.128.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to locations in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw xmm, r8","EVEX.128.66.0F38.W0 79 /r")]
        vpbroadcastw_xmm_r8 = 2859,

        /// <summary>
        /// vpbroadcastw xmm, r8 | VEX.128.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to eight locations in xmm1.
        /// </summary>
        [Symbol("vpbroadcastw xmm, r8","VEX.128.66.0F38.W0 79 /r")]
        vpbroadcastw_xmm_r8_vex = 2860,

        /// <summary>
        /// vpbroadcastw ymm {k1}{z}, m16 | EVEX.256.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw ymm {k1}{z}, m16","EVEX.256.66.0F38.W0 79 /r")]
        vpbroadcastw_ymm_k1z_m16 = 2861,

        /// <summary>
        /// vpbroadcastw ymm {k1}{z}, r8 | EVEX.256.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw ymm {k1}{z}, r8","EVEX.256.66.0F38.W0 79 /r")]
        vpbroadcastw_ymm_k1z_r8 = 2862,

        /// <summary>
        /// vpbroadcastw ymm, m16 | EVEX.256.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw ymm, m16","EVEX.256.66.0F38.W0 79 /r")]
        vpbroadcastw_ymm_m16 = 2863,

        /// <summary>
        /// vpbroadcastw ymm, m16 | VEX.256.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to sixteen locations in ymm1.
        /// </summary>
        [Symbol("vpbroadcastw ymm, m16","VEX.256.66.0F38.W0 79 /r")]
        vpbroadcastw_ymm_m16_vex = 2864,

        /// <summary>
        /// vpbroadcastw ymm, r8 | EVEX.256.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to locations in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw ymm, r8","EVEX.256.66.0F38.W0 79 /r")]
        vpbroadcastw_ymm_r8 = 2865,

        /// <summary>
        /// vpbroadcastw ymm, r8 | VEX.256.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to sixteen locations in ymm1.
        /// </summary>
        [Symbol("vpbroadcastw ymm, r8","VEX.256.66.0F38.W0 79 /r")]
        vpbroadcastw_ymm_r8_vex = 2866,

        /// <summary>
        /// vpbroadcastw zmm {k1}{z}, m16 | EVEX.512.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to 32 locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw zmm {k1}{z}, m16","EVEX.512.66.0F38.W0 79 /r")]
        vpbroadcastw_zmm_k1z_m16 = 2867,

        /// <summary>
        /// vpbroadcastw zmm {k1}{z}, r8 | EVEX.512.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to 32 locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw zmm {k1}{z}, r8","EVEX.512.66.0F38.W0 79 /r")]
        vpbroadcastw_zmm_k1z_r8 = 2868,

        /// <summary>
        /// vpbroadcastw zmm, m16 | EVEX.512.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to 32 locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw zmm, m16","EVEX.512.66.0F38.W0 79 /r")]
        vpbroadcastw_zmm_m16 = 2869,

        /// <summary>
        /// vpbroadcastw zmm, r8 | EVEX.512.66.0F38.W0 79 /r | Broadcast a word integer in the source operand to 32 locations in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpbroadcastw zmm, r8","EVEX.512.66.0F38.W0 79 /r")]
        vpbroadcastw_zmm_r8 = 2870,

        /// <summary>
        /// vpcmpb k1 {k2}, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 3F /r ib | Compare packed signed byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1 {k2}, xmm, m128, imm8","EVEX.128.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_k2_xmm_m128_imm8 = 2871,

        /// <summary>
        /// vpcmpb k1 {k2}, xmm, r8, imm8 | EVEX.128.66.0F3A.W0 3F /r ib | Compare packed signed byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1 {k2}, xmm, r8, imm8","EVEX.128.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_k2_xmm_r8_imm8 = 2872,

        /// <summary>
        /// vpcmpb k1 {k2}, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 3F /r ib | Compare packed signed byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1 {k2}, ymm, m256, imm8","EVEX.256.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_k2_ymm_m256_imm8 = 2873,

        /// <summary>
        /// vpcmpb k1 {k2}, ymm, r16, imm8 | EVEX.256.66.0F3A.W0 3F /r ib | Compare packed signed byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1 {k2}, ymm, r16, imm8","EVEX.256.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_k2_ymm_r16_imm8 = 2874,

        /// <summary>
        /// vpcmpb k1 {k2}, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 3F /r ib | Compare packed signed byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1 {k2}, zmm, m512, imm8","EVEX.512.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_k2_zmm_m512_imm8 = 2875,

        /// <summary>
        /// vpcmpb k1 {k2}, zmm, r32, imm8 | EVEX.512.66.0F3A.W0 3F /r ib | Compare packed signed byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1 {k2}, zmm, r32, imm8","EVEX.512.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_k2_zmm_r32_imm8 = 2876,

        /// <summary>
        /// vpcmpb k1, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 3F /r ib | Compare packed signed byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1, xmm, m128, imm8","EVEX.128.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_xmm_m128_imm8 = 2877,

        /// <summary>
        /// vpcmpb k1, xmm, r8, imm8 | EVEX.128.66.0F3A.W0 3F /r ib | Compare packed signed byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1, xmm, r8, imm8","EVEX.128.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_xmm_r8_imm8 = 2878,

        /// <summary>
        /// vpcmpb k1, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 3F /r ib | Compare packed signed byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1, ymm, m256, imm8","EVEX.256.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_ymm_m256_imm8 = 2879,

        /// <summary>
        /// vpcmpb k1, ymm, r16, imm8 | EVEX.256.66.0F3A.W0 3F /r ib | Compare packed signed byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1, ymm, r16, imm8","EVEX.256.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_ymm_r16_imm8 = 2880,

        /// <summary>
        /// vpcmpb k1, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 3F /r ib | Compare packed signed byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1, zmm, m512, imm8","EVEX.512.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_zmm_m512_imm8 = 2881,

        /// <summary>
        /// vpcmpb k1, zmm, r32, imm8 | EVEX.512.66.0F3A.W0 3F /r ib | Compare packed signed byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpb k1, zmm, r32, imm8","EVEX.512.66.0F3A.W0 3F /r ib")]
        vpcmpb_k1_zmm_r32_imm8 = 2882,

        /// <summary>
        /// vpcmpd k1 {k2}, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1 {k2}, xmm, m128, imm8","EVEX.128.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_k2_xmm_m128_imm8 = 2883,

        /// <summary>
        /// vpcmpd k1 {k2}, xmm, m32bcst, imm8 | EVEX.128.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1 {k2}, xmm, m32bcst, imm8","EVEX.128.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_k2_xmm_m32bcst_imm8 = 2884,

        /// <summary>
        /// vpcmpd k1 {k2}, xmm, xmm, imm8 | EVEX.128.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1 {k2}, xmm, xmm, imm8","EVEX.128.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_k2_xmm_xmm_imm8 = 2885,

        /// <summary>
        /// vpcmpd k1 {k2}, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1 {k2}, ymm, m256, imm8","EVEX.256.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_k2_ymm_m256_imm8 = 2886,

        /// <summary>
        /// vpcmpd k1 {k2}, ymm, m32bcst, imm8 | EVEX.256.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1 {k2}, ymm, m32bcst, imm8","EVEX.256.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_k2_ymm_m32bcst_imm8 = 2887,

        /// <summary>
        /// vpcmpd k1 {k2}, ymm, ymm, imm8 | EVEX.256.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1 {k2}, ymm, ymm, imm8","EVEX.256.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_k2_ymm_ymm_imm8 = 2888,

        /// <summary>
        /// vpcmpd k1 {k2}, zmm, m32bcst, imm8 | EVEX.512.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpd k1 {k2}, zmm, m32bcst, imm8","EVEX.512.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_k2_zmm_m32bcst_imm8 = 2889,

        /// <summary>
        /// vpcmpd k1 {k2}, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpd k1 {k2}, zmm, m512, imm8","EVEX.512.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_k2_zmm_m512_imm8 = 2890,

        /// <summary>
        /// vpcmpd k1 {k2}, zmm, zmm, imm8 | EVEX.512.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpd k1 {k2}, zmm, zmm, imm8","EVEX.512.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_k2_zmm_zmm_imm8 = 2891,

        /// <summary>
        /// vpcmpd k1, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1, xmm, m128, imm8","EVEX.128.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_xmm_m128_imm8 = 2892,

        /// <summary>
        /// vpcmpd k1, xmm, m32bcst, imm8 | EVEX.128.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1, xmm, m32bcst, imm8","EVEX.128.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_xmm_m32bcst_imm8 = 2893,

        /// <summary>
        /// vpcmpd k1, xmm, xmm, imm8 | EVEX.128.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1, xmm, xmm, imm8","EVEX.128.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_xmm_xmm_imm8 = 2894,

        /// <summary>
        /// vpcmpd k1, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1, ymm, m256, imm8","EVEX.256.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_ymm_m256_imm8 = 2895,

        /// <summary>
        /// vpcmpd k1, ymm, m32bcst, imm8 | EVEX.256.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1, ymm, m32bcst, imm8","EVEX.256.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_ymm_m32bcst_imm8 = 2896,

        /// <summary>
        /// vpcmpd k1, ymm, ymm, imm8 | EVEX.256.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpd k1, ymm, ymm, imm8","EVEX.256.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_ymm_ymm_imm8 = 2897,

        /// <summary>
        /// vpcmpd k1, zmm, m32bcst, imm8 | EVEX.512.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpd k1, zmm, m32bcst, imm8","EVEX.512.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_zmm_m32bcst_imm8 = 2898,

        /// <summary>
        /// vpcmpd k1, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpd k1, zmm, m512, imm8","EVEX.512.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_zmm_m512_imm8 = 2899,

        /// <summary>
        /// vpcmpd k1, zmm, zmm, imm8 | EVEX.512.66.0F3A.W0 1F /r ib | Compare packed signed doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpd k1, zmm, zmm, imm8","EVEX.512.66.0F3A.W0 1F /r ib")]
        vpcmpd_k1_zmm_zmm_imm8 = 2900,

        /// <summary>
        /// vpcmpeqb k1 {k2}, xmm, m128 | EVEX.128.66.0F.WIG 74 /r | Compare packed bytes in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1 {k2}, xmm, m128","EVEX.128.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_k2_xmm_m128 = 2901,

        /// <summary>
        /// vpcmpeqb k1 {k2}, xmm, r8 | EVEX.128.66.0F.WIG 74 /r | Compare packed bytes in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1 {k2}, xmm, r8","EVEX.128.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_k2_xmm_r8 = 2902,

        /// <summary>
        /// vpcmpeqb k1 {k2}, ymm, m256 | EVEX.256.66.0F.WIG 74 /r | Compare packed bytes in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1 {k2}, ymm, m256","EVEX.256.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_k2_ymm_m256 = 2903,

        /// <summary>
        /// vpcmpeqb k1 {k2}, ymm, r16 | EVEX.256.66.0F.WIG 74 /r | Compare packed bytes in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1 {k2}, ymm, r16","EVEX.256.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_k2_ymm_r16 = 2904,

        /// <summary>
        /// vpcmpeqb k1 {k2}, zmm, m512 | EVEX.512.66.0F.WIG 74 /r | Compare packed bytes in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1 {k2}, zmm, m512","EVEX.512.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_k2_zmm_m512 = 2905,

        /// <summary>
        /// vpcmpeqb k1 {k2}, zmm, r32 | EVEX.512.66.0F.WIG 74 /r | Compare packed bytes in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1 {k2}, zmm, r32","EVEX.512.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_k2_zmm_r32 = 2906,

        /// <summary>
        /// vpcmpeqb k1, xmm, m128 | EVEX.128.66.0F.WIG 74 /r | Compare packed bytes in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1, xmm, m128","EVEX.128.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_xmm_m128 = 2907,

        /// <summary>
        /// vpcmpeqb k1, xmm, r8 | EVEX.128.66.0F.WIG 74 /r | Compare packed bytes in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1, xmm, r8","EVEX.128.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_xmm_r8 = 2908,

        /// <summary>
        /// vpcmpeqb k1, ymm, m256 | EVEX.256.66.0F.WIG 74 /r | Compare packed bytes in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1, ymm, m256","EVEX.256.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_ymm_m256 = 2909,

        /// <summary>
        /// vpcmpeqb k1, ymm, r16 | EVEX.256.66.0F.WIG 74 /r | Compare packed bytes in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1, ymm, r16","EVEX.256.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_ymm_r16 = 2910,

        /// <summary>
        /// vpcmpeqb k1, zmm, m512 | EVEX.512.66.0F.WIG 74 /r | Compare packed bytes in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1, zmm, m512","EVEX.512.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_zmm_m512 = 2911,

        /// <summary>
        /// vpcmpeqb k1, zmm, r32 | EVEX.512.66.0F.WIG 74 /r | Compare packed bytes in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqb k1, zmm, r32","EVEX.512.66.0F.WIG 74 /r")]
        vpcmpeqb_k1_zmm_r32 = 2912,

        /// <summary>
        /// vpcmpeqb xmm, xmm, m128 | VEX.128.66.0F.WIG 74 /r | Compare packed bytes in xmm3/m128 and xmm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqb xmm, xmm, m128","VEX.128.66.0F.WIG 74 /r")]
        vpcmpeqb_xmm_xmm_m128 = 2913,

        /// <summary>
        /// vpcmpeqb xmm, xmm, r8 | VEX.128.66.0F.WIG 74 /r | Compare packed bytes in xmm3/m128 and xmm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqb xmm, xmm, r8","VEX.128.66.0F.WIG 74 /r")]
        vpcmpeqb_xmm_xmm_r8 = 2914,

        /// <summary>
        /// vpcmpeqb ymm, ymm, m256 | VEX.256.66.0F.WIG 74 /r | Compare packed bytes in ymm3/m256 and ymm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqb ymm, ymm, m256","VEX.256.66.0F.WIG 74 /r")]
        vpcmpeqb_ymm_ymm_m256 = 2915,

        /// <summary>
        /// vpcmpeqb ymm, ymm, r16 | VEX.256.66.0F.WIG 74 /r | Compare packed bytes in ymm3/m256 and ymm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqb ymm, ymm, r16","VEX.256.66.0F.WIG 74 /r")]
        vpcmpeqb_ymm_ymm_r16 = 2916,

        /// <summary>
        /// vpcmpeqd k1 {k2}, xmm, m128 | EVEX.128.66.0F.W0 76 /r | Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1 {k2}, xmm, m128","EVEX.128.66.0F.W0 76 /r")]
        vpcmpeqd_k1_k2_xmm_m128 = 2917,

        /// <summary>
        /// vpcmpeqd k1 {k2}, xmm, m32bcst | EVEX.128.66.0F.W0 76 /r | Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1 {k2}, xmm, m32bcst","EVEX.128.66.0F.W0 76 /r")]
        vpcmpeqd_k1_k2_xmm_m32bcst = 2918,

        /// <summary>
        /// vpcmpeqd k1 {k2}, xmm, xmm | EVEX.128.66.0F.W0 76 /r | Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1 {k2}, xmm, xmm","EVEX.128.66.0F.W0 76 /r")]
        vpcmpeqd_k1_k2_xmm_xmm = 2919,

        /// <summary>
        /// vpcmpeqd k1 {k2}, ymm, m256 | EVEX.256.66.0F.W0 76 /r | Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1 {k2}, ymm, m256","EVEX.256.66.0F.W0 76 /r")]
        vpcmpeqd_k1_k2_ymm_m256 = 2920,

        /// <summary>
        /// vpcmpeqd k1 {k2}, ymm, m32bcst | EVEX.256.66.0F.W0 76 /r | Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1 {k2}, ymm, m32bcst","EVEX.256.66.0F.W0 76 /r")]
        vpcmpeqd_k1_k2_ymm_m32bcst = 2921,

        /// <summary>
        /// vpcmpeqd k1 {k2}, ymm, ymm | EVEX.256.66.0F.W0 76 /r | Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1 {k2}, ymm, ymm","EVEX.256.66.0F.W0 76 /r")]
        vpcmpeqd_k1_k2_ymm_ymm = 2922,

        /// <summary>
        /// vpcmpeqd k1 {k2}, zmm, m32bcst | EVEX.512.66.0F.W0 76 /r | Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.
        /// </summary>
        [Symbol("vpcmpeqd k1 {k2}, zmm, m32bcst","EVEX.512.66.0F.W0 76 /r")]
        vpcmpeqd_k1_k2_zmm_m32bcst = 2923,

        /// <summary>
        /// vpcmpeqd k1 {k2}, zmm, m512 | EVEX.512.66.0F.W0 76 /r | Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.
        /// </summary>
        [Symbol("vpcmpeqd k1 {k2}, zmm, m512","EVEX.512.66.0F.W0 76 /r")]
        vpcmpeqd_k1_k2_zmm_m512 = 2924,

        /// <summary>
        /// vpcmpeqd k1 {k2}, zmm, zmm | EVEX.512.66.0F.W0 76 /r | Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.
        /// </summary>
        [Symbol("vpcmpeqd k1 {k2}, zmm, zmm","EVEX.512.66.0F.W0 76 /r")]
        vpcmpeqd_k1_k2_zmm_zmm = 2925,

        /// <summary>
        /// vpcmpeqd k1, xmm, m128 | EVEX.128.66.0F.W0 76 /r | Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1, xmm, m128","EVEX.128.66.0F.W0 76 /r")]
        vpcmpeqd_k1_xmm_m128 = 2926,

        /// <summary>
        /// vpcmpeqd k1, xmm, m32bcst | EVEX.128.66.0F.W0 76 /r | Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1, xmm, m32bcst","EVEX.128.66.0F.W0 76 /r")]
        vpcmpeqd_k1_xmm_m32bcst = 2927,

        /// <summary>
        /// vpcmpeqd k1, xmm, xmm | EVEX.128.66.0F.W0 76 /r | Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1, xmm, xmm","EVEX.128.66.0F.W0 76 /r")]
        vpcmpeqd_k1_xmm_xmm = 2928,

        /// <summary>
        /// vpcmpeqd k1, ymm, m256 | EVEX.256.66.0F.W0 76 /r | Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1, ymm, m256","EVEX.256.66.0F.W0 76 /r")]
        vpcmpeqd_k1_ymm_m256 = 2929,

        /// <summary>
        /// vpcmpeqd k1, ymm, m32bcst | EVEX.256.66.0F.W0 76 /r | Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1, ymm, m32bcst","EVEX.256.66.0F.W0 76 /r")]
        vpcmpeqd_k1_ymm_m32bcst = 2930,

        /// <summary>
        /// vpcmpeqd k1, ymm, ymm | EVEX.256.66.0F.W0 76 /r | Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqd k1, ymm, ymm","EVEX.256.66.0F.W0 76 /r")]
        vpcmpeqd_k1_ymm_ymm = 2931,

        /// <summary>
        /// vpcmpeqd k1, zmm, m32bcst | EVEX.512.66.0F.W0 76 /r | Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.
        /// </summary>
        [Symbol("vpcmpeqd k1, zmm, m32bcst","EVEX.512.66.0F.W0 76 /r")]
        vpcmpeqd_k1_zmm_m32bcst = 2932,

        /// <summary>
        /// vpcmpeqd k1, zmm, m512 | EVEX.512.66.0F.W0 76 /r | Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.
        /// </summary>
        [Symbol("vpcmpeqd k1, zmm, m512","EVEX.512.66.0F.W0 76 /r")]
        vpcmpeqd_k1_zmm_m512 = 2933,

        /// <summary>
        /// vpcmpeqd k1, zmm, zmm | EVEX.512.66.0F.W0 76 /r | Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.
        /// </summary>
        [Symbol("vpcmpeqd k1, zmm, zmm","EVEX.512.66.0F.W0 76 /r")]
        vpcmpeqd_k1_zmm_zmm = 2934,

        /// <summary>
        /// vpcmpeqd xmm, xmm, m128 | VEX.128.66.0F.WIG 76 /r | Compare packed doublewords in xmm3/m128 and xmm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqd xmm, xmm, m128","VEX.128.66.0F.WIG 76 /r")]
        vpcmpeqd_xmm_xmm_m128 = 2935,

        /// <summary>
        /// vpcmpeqd xmm, xmm, r8 | VEX.128.66.0F.WIG 76 /r | Compare packed doublewords in xmm3/m128 and xmm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqd xmm, xmm, r8","VEX.128.66.0F.WIG 76 /r")]
        vpcmpeqd_xmm_xmm_r8 = 2936,

        /// <summary>
        /// vpcmpeqd ymm, ymm, m256 | VEX.256.66.0F.WIG 76 /r | Compare packed doublewords in ymm3/m256 and ymm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqd ymm, ymm, m256","VEX.256.66.0F.WIG 76 /r")]
        vpcmpeqd_ymm_ymm_m256 = 2937,

        /// <summary>
        /// vpcmpeqd ymm, ymm, r16 | VEX.256.66.0F.WIG 76 /r | Compare packed doublewords in ymm3/m256 and ymm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqd ymm, ymm, r16","VEX.256.66.0F.WIG 76 /r")]
        vpcmpeqd_ymm_ymm_r16 = 2938,

        /// <summary>
        /// vpcmpeqq k1 {k2}, xmm, m128 | EVEX.128.66.0F38.W1 29 /r | Compare Equal between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1 {k2}, xmm, m128","EVEX.128.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_k2_xmm_m128 = 2939,

        /// <summary>
        /// vpcmpeqq k1 {k2}, xmm, m64bcst | EVEX.128.66.0F38.W1 29 /r | Compare Equal between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1 {k2}, xmm, m64bcst","EVEX.128.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_k2_xmm_m64bcst = 2940,

        /// <summary>
        /// vpcmpeqq k1 {k2}, xmm, xmm | EVEX.128.66.0F38.W1 29 /r | Compare Equal between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1 {k2}, xmm, xmm","EVEX.128.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_k2_xmm_xmm = 2941,

        /// <summary>
        /// vpcmpeqq k1 {k2}, ymm, m256 | EVEX.256.66.0F38.W1 29 /r | Compare Equal between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1 {k2}, ymm, m256","EVEX.256.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_k2_ymm_m256 = 2942,

        /// <summary>
        /// vpcmpeqq k1 {k2}, ymm, m64bcst | EVEX.256.66.0F38.W1 29 /r | Compare Equal between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1 {k2}, ymm, m64bcst","EVEX.256.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_k2_ymm_m64bcst = 2943,

        /// <summary>
        /// vpcmpeqq k1 {k2}, ymm, ymm | EVEX.256.66.0F38.W1 29 /r | Compare Equal between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1 {k2}, ymm, ymm","EVEX.256.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_k2_ymm_ymm = 2944,

        /// <summary>
        /// vpcmpeqq k1 {k2}, zmm, m512 | EVEX.512.66.0F38.W1 29 /r | Compare Equal between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1 {k2}, zmm, m512","EVEX.512.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_k2_zmm_m512 = 2945,

        /// <summary>
        /// vpcmpeqq k1 {k2}, zmm, m64bcst | EVEX.512.66.0F38.W1 29 /r | Compare Equal between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1 {k2}, zmm, m64bcst","EVEX.512.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_k2_zmm_m64bcst = 2946,

        /// <summary>
        /// vpcmpeqq k1 {k2}, zmm, zmm | EVEX.512.66.0F38.W1 29 /r | Compare Equal between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1 {k2}, zmm, zmm","EVEX.512.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_k2_zmm_zmm = 2947,

        /// <summary>
        /// vpcmpeqq k1, xmm, m128 | EVEX.128.66.0F38.W1 29 /r | Compare Equal between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1, xmm, m128","EVEX.128.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_xmm_m128 = 2948,

        /// <summary>
        /// vpcmpeqq k1, xmm, m64bcst | EVEX.128.66.0F38.W1 29 /r | Compare Equal between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1, xmm, m64bcst","EVEX.128.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_xmm_m64bcst = 2949,

        /// <summary>
        /// vpcmpeqq k1, xmm, xmm | EVEX.128.66.0F38.W1 29 /r | Compare Equal between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1, xmm, xmm","EVEX.128.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_xmm_xmm = 2950,

        /// <summary>
        /// vpcmpeqq k1, ymm, m256 | EVEX.256.66.0F38.W1 29 /r | Compare Equal between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1, ymm, m256","EVEX.256.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_ymm_m256 = 2951,

        /// <summary>
        /// vpcmpeqq k1, ymm, m64bcst | EVEX.256.66.0F38.W1 29 /r | Compare Equal between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1, ymm, m64bcst","EVEX.256.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_ymm_m64bcst = 2952,

        /// <summary>
        /// vpcmpeqq k1, ymm, ymm | EVEX.256.66.0F38.W1 29 /r | Compare Equal between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1, ymm, ymm","EVEX.256.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_ymm_ymm = 2953,

        /// <summary>
        /// vpcmpeqq k1, zmm, m512 | EVEX.512.66.0F38.W1 29 /r | Compare Equal between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1, zmm, m512","EVEX.512.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_zmm_m512 = 2954,

        /// <summary>
        /// vpcmpeqq k1, zmm, m64bcst | EVEX.512.66.0F38.W1 29 /r | Compare Equal between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1, zmm, m64bcst","EVEX.512.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_zmm_m64bcst = 2955,

        /// <summary>
        /// vpcmpeqq k1, zmm, zmm | EVEX.512.66.0F38.W1 29 /r | Compare Equal between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqq k1, zmm, zmm","EVEX.512.66.0F38.W1 29 /r")]
        vpcmpeqq_k1_zmm_zmm = 2956,

        /// <summary>
        /// vpcmpeqq xmm, xmm, m128 | VEX.128.66.0F38.WIG 29 /r | Compare packed quadwords in xmm3/m128 and xmm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqq xmm, xmm, m128","VEX.128.66.0F38.WIG 29 /r")]
        vpcmpeqq_xmm_xmm_m128 = 2957,

        /// <summary>
        /// vpcmpeqq xmm, xmm, r8 | VEX.128.66.0F38.WIG 29 /r | Compare packed quadwords in xmm3/m128 and xmm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqq xmm, xmm, r8","VEX.128.66.0F38.WIG 29 /r")]
        vpcmpeqq_xmm_xmm_r8 = 2958,

        /// <summary>
        /// vpcmpeqq ymm, ymm, m256 | VEX.256.66.0F38.WIG 29 /r | Compare packed quadwords in ymm3/m256 and ymm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqq ymm, ymm, m256","VEX.256.66.0F38.WIG 29 /r")]
        vpcmpeqq_ymm_ymm_m256 = 2959,

        /// <summary>
        /// vpcmpeqq ymm, ymm, r16 | VEX.256.66.0F38.WIG 29 /r | Compare packed quadwords in ymm3/m256 and ymm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqq ymm, ymm, r16","VEX.256.66.0F38.WIG 29 /r")]
        vpcmpeqq_ymm_ymm_r16 = 2960,

        /// <summary>
        /// vpcmpeqw k1 {k2}, xmm, m128 | EVEX.128.66.0F.WIG 75 /r | Compare packed words in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1 {k2}, xmm, m128","EVEX.128.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_k2_xmm_m128 = 2961,

        /// <summary>
        /// vpcmpeqw k1 {k2}, xmm, r8 | EVEX.128.66.0F.WIG 75 /r | Compare packed words in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1 {k2}, xmm, r8","EVEX.128.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_k2_xmm_r8 = 2962,

        /// <summary>
        /// vpcmpeqw k1 {k2}, ymm, m256 | EVEX.256.66.0F.WIG 75 /r | Compare packed words in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1 {k2}, ymm, m256","EVEX.256.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_k2_ymm_m256 = 2963,

        /// <summary>
        /// vpcmpeqw k1 {k2}, ymm, r16 | EVEX.256.66.0F.WIG 75 /r | Compare packed words in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1 {k2}, ymm, r16","EVEX.256.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_k2_ymm_r16 = 2964,

        /// <summary>
        /// vpcmpeqw k1 {k2}, zmm, m512 | EVEX.512.66.0F.WIG 75 /r | Compare packed words in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1 {k2}, zmm, m512","EVEX.512.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_k2_zmm_m512 = 2965,

        /// <summary>
        /// vpcmpeqw k1 {k2}, zmm, r32 | EVEX.512.66.0F.WIG 75 /r | Compare packed words in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1 {k2}, zmm, r32","EVEX.512.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_k2_zmm_r32 = 2966,

        /// <summary>
        /// vpcmpeqw k1, xmm, m128 | EVEX.128.66.0F.WIG 75 /r | Compare packed words in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1, xmm, m128","EVEX.128.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_xmm_m128 = 2967,

        /// <summary>
        /// vpcmpeqw k1, xmm, r8 | EVEX.128.66.0F.WIG 75 /r | Compare packed words in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1, xmm, r8","EVEX.128.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_xmm_r8 = 2968,

        /// <summary>
        /// vpcmpeqw k1, ymm, m256 | EVEX.256.66.0F.WIG 75 /r | Compare packed words in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1, ymm, m256","EVEX.256.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_ymm_m256 = 2969,

        /// <summary>
        /// vpcmpeqw k1, ymm, r16 | EVEX.256.66.0F.WIG 75 /r | Compare packed words in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1, ymm, r16","EVEX.256.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_ymm_r16 = 2970,

        /// <summary>
        /// vpcmpeqw k1, zmm, m512 | EVEX.512.66.0F.WIG 75 /r | Compare packed words in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1, zmm, m512","EVEX.512.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_zmm_m512 = 2971,

        /// <summary>
        /// vpcmpeqw k1, zmm, r32 | EVEX.512.66.0F.WIG 75 /r | Compare packed words in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpeqw k1, zmm, r32","EVEX.512.66.0F.WIG 75 /r")]
        vpcmpeqw_k1_zmm_r32 = 2972,

        /// <summary>
        /// vpcmpeqw xmm, xmm, m128 | VEX.128.66.0F.WIG 75 /r | Compare packed words in xmm3/m128 and xmm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqw xmm, xmm, m128","VEX.128.66.0F.WIG 75 /r")]
        vpcmpeqw_xmm_xmm_m128 = 2973,

        /// <summary>
        /// vpcmpeqw xmm, xmm, r8 | VEX.128.66.0F.WIG 75 /r | Compare packed words in xmm3/m128 and xmm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqw xmm, xmm, r8","VEX.128.66.0F.WIG 75 /r")]
        vpcmpeqw_xmm_xmm_r8 = 2974,

        /// <summary>
        /// vpcmpeqw ymm, ymm, m256 | VEX.256.66.0F.WIG 75 /r | Compare packed words in ymm3/m256 and ymm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqw ymm, ymm, m256","VEX.256.66.0F.WIG 75 /r")]
        vpcmpeqw_ymm_ymm_m256 = 2975,

        /// <summary>
        /// vpcmpeqw ymm, ymm, r16 | VEX.256.66.0F.WIG 75 /r | Compare packed words in ymm3/m256 and ymm2 for equality.
        /// </summary>
        [Symbol("vpcmpeqw ymm, ymm, r16","VEX.256.66.0F.WIG 75 /r")]
        vpcmpeqw_ymm_ymm_r16 = 2976,

        /// <summary>
        /// vpcmpgtb k1 {k2}, xmm, m128 | EVEX.128.66.0F.WIG 64 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1 {k2}, xmm, m128","EVEX.128.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_k2_xmm_m128 = 2977,

        /// <summary>
        /// vpcmpgtb k1 {k2}, xmm, r8 | EVEX.128.66.0F.WIG 64 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1 {k2}, xmm, r8","EVEX.128.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_k2_xmm_r8 = 2978,

        /// <summary>
        /// vpcmpgtb k1 {k2}, ymm, m256 | EVEX.256.66.0F.WIG 64 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1 {k2}, ymm, m256","EVEX.256.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_k2_ymm_m256 = 2979,

        /// <summary>
        /// vpcmpgtb k1 {k2}, ymm, r16 | EVEX.256.66.0F.WIG 64 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1 {k2}, ymm, r16","EVEX.256.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_k2_ymm_r16 = 2980,

        /// <summary>
        /// vpcmpgtb k1 {k2}, zmm, m512 | EVEX.512.66.0F.WIG 64 /r | Compare packed signed byte integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1 {k2}, zmm, m512","EVEX.512.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_k2_zmm_m512 = 2981,

        /// <summary>
        /// vpcmpgtb k1 {k2}, zmm, r32 | EVEX.512.66.0F.WIG 64 /r | Compare packed signed byte integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1 {k2}, zmm, r32","EVEX.512.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_k2_zmm_r32 = 2982,

        /// <summary>
        /// vpcmpgtb k1, xmm, m128 | EVEX.128.66.0F.WIG 64 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1, xmm, m128","EVEX.128.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_xmm_m128 = 2983,

        /// <summary>
        /// vpcmpgtb k1, xmm, r8 | EVEX.128.66.0F.WIG 64 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1, xmm, r8","EVEX.128.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_xmm_r8 = 2984,

        /// <summary>
        /// vpcmpgtb k1, ymm, m256 | EVEX.256.66.0F.WIG 64 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1, ymm, m256","EVEX.256.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_ymm_m256 = 2985,

        /// <summary>
        /// vpcmpgtb k1, ymm, r16 | EVEX.256.66.0F.WIG 64 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1, ymm, r16","EVEX.256.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_ymm_r16 = 2986,

        /// <summary>
        /// vpcmpgtb k1, zmm, m512 | EVEX.512.66.0F.WIG 64 /r | Compare packed signed byte integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1, zmm, m512","EVEX.512.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_zmm_m512 = 2987,

        /// <summary>
        /// vpcmpgtb k1, zmm, r32 | EVEX.512.66.0F.WIG 64 /r | Compare packed signed byte integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtb k1, zmm, r32","EVEX.512.66.0F.WIG 64 /r")]
        vpcmpgtb_k1_zmm_r32 = 2988,

        /// <summary>
        /// vpcmpgtb xmm, xmm, m128 | VEX.128.66.0F.WIG 64 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than.
        /// </summary>
        [Symbol("vpcmpgtb xmm, xmm, m128","VEX.128.66.0F.WIG 64 /r")]
        vpcmpgtb_xmm_xmm_m128 = 2989,

        /// <summary>
        /// vpcmpgtb xmm, xmm, r8 | VEX.128.66.0F.WIG 64 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than.
        /// </summary>
        [Symbol("vpcmpgtb xmm, xmm, r8","VEX.128.66.0F.WIG 64 /r")]
        vpcmpgtb_xmm_xmm_r8 = 2990,

        /// <summary>
        /// vpcmpgtb ymm, ymm, m256 | VEX.256.66.0F.WIG 64 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than.
        /// </summary>
        [Symbol("vpcmpgtb ymm, ymm, m256","VEX.256.66.0F.WIG 64 /r")]
        vpcmpgtb_ymm_ymm_m256 = 2991,

        /// <summary>
        /// vpcmpgtb ymm, ymm, r16 | VEX.256.66.0F.WIG 64 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than.
        /// </summary>
        [Symbol("vpcmpgtb ymm, ymm, r16","VEX.256.66.0F.WIG 64 /r")]
        vpcmpgtb_ymm_ymm_r16 = 2992,

        /// <summary>
        /// vpcmpgtd k1 {k2}, xmm, m128 | EVEX.128.66.0F.W0 66 /r | Compare Greater between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1 {k2}, xmm, m128","EVEX.128.66.0F.W0 66 /r")]
        vpcmpgtd_k1_k2_xmm_m128 = 2993,

        /// <summary>
        /// vpcmpgtd k1 {k2}, xmm, m32bcst | EVEX.128.66.0F.W0 66 /r | Compare Greater between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1 {k2}, xmm, m32bcst","EVEX.128.66.0F.W0 66 /r")]
        vpcmpgtd_k1_k2_xmm_m32bcst = 2994,

        /// <summary>
        /// vpcmpgtd k1 {k2}, xmm, xmm | EVEX.128.66.0F.W0 66 /r | Compare Greater between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1 {k2}, xmm, xmm","EVEX.128.66.0F.W0 66 /r")]
        vpcmpgtd_k1_k2_xmm_xmm = 2995,

        /// <summary>
        /// vpcmpgtd k1 {k2}, ymm, m256 | EVEX.256.66.0F.W0 66 /r | Compare Greater between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1 {k2}, ymm, m256","EVEX.256.66.0F.W0 66 /r")]
        vpcmpgtd_k1_k2_ymm_m256 = 2996,

        /// <summary>
        /// vpcmpgtd k1 {k2}, ymm, m32bcst | EVEX.256.66.0F.W0 66 /r | Compare Greater between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1 {k2}, ymm, m32bcst","EVEX.256.66.0F.W0 66 /r")]
        vpcmpgtd_k1_k2_ymm_m32bcst = 2997,

        /// <summary>
        /// vpcmpgtd k1 {k2}, ymm, ymm | EVEX.256.66.0F.W0 66 /r | Compare Greater between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1 {k2}, ymm, ymm","EVEX.256.66.0F.W0 66 /r")]
        vpcmpgtd_k1_k2_ymm_ymm = 2998,

        /// <summary>
        /// vpcmpgtd k1 {k2}, zmm, m32bcst | EVEX.512.66.0F.W0 66 /r | Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask. k2.
        /// </summary>
        [Symbol("vpcmpgtd k1 {k2}, zmm, m32bcst","EVEX.512.66.0F.W0 66 /r")]
        vpcmpgtd_k1_k2_zmm_m32bcst = 2999,

        /// <summary>
        /// vpcmpgtd k1 {k2}, zmm, m512 | EVEX.512.66.0F.W0 66 /r | Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask. k2.
        /// </summary>
        [Symbol("vpcmpgtd k1 {k2}, zmm, m512","EVEX.512.66.0F.W0 66 /r")]
        vpcmpgtd_k1_k2_zmm_m512 = 3000,

        /// <summary>
        /// vpcmpgtd k1 {k2}, zmm, zmm | EVEX.512.66.0F.W0 66 /r | Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask. k2.
        /// </summary>
        [Symbol("vpcmpgtd k1 {k2}, zmm, zmm","EVEX.512.66.0F.W0 66 /r")]
        vpcmpgtd_k1_k2_zmm_zmm = 3001,

        /// <summary>
        /// vpcmpgtd k1, xmm, m128 | EVEX.128.66.0F.W0 66 /r | Compare Greater between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1, xmm, m128","EVEX.128.66.0F.W0 66 /r")]
        vpcmpgtd_k1_xmm_m128 = 3002,

        /// <summary>
        /// vpcmpgtd k1, xmm, m32bcst | EVEX.128.66.0F.W0 66 /r | Compare Greater between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1, xmm, m32bcst","EVEX.128.66.0F.W0 66 /r")]
        vpcmpgtd_k1_xmm_m32bcst = 3003,

        /// <summary>
        /// vpcmpgtd k1, xmm, xmm | EVEX.128.66.0F.W0 66 /r | Compare Greater between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1, xmm, xmm","EVEX.128.66.0F.W0 66 /r")]
        vpcmpgtd_k1_xmm_xmm = 3004,

        /// <summary>
        /// vpcmpgtd k1, ymm, m256 | EVEX.256.66.0F.W0 66 /r | Compare Greater between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1, ymm, m256","EVEX.256.66.0F.W0 66 /r")]
        vpcmpgtd_k1_ymm_m256 = 3005,

        /// <summary>
        /// vpcmpgtd k1, ymm, m32bcst | EVEX.256.66.0F.W0 66 /r | Compare Greater between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1, ymm, m32bcst","EVEX.256.66.0F.W0 66 /r")]
        vpcmpgtd_k1_ymm_m32bcst = 3006,

        /// <summary>
        /// vpcmpgtd k1, ymm, ymm | EVEX.256.66.0F.W0 66 /r | Compare Greater between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtd k1, ymm, ymm","EVEX.256.66.0F.W0 66 /r")]
        vpcmpgtd_k1_ymm_ymm = 3007,

        /// <summary>
        /// vpcmpgtd k1, zmm, m32bcst | EVEX.512.66.0F.W0 66 /r | Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask. k2.
        /// </summary>
        [Symbol("vpcmpgtd k1, zmm, m32bcst","EVEX.512.66.0F.W0 66 /r")]
        vpcmpgtd_k1_zmm_m32bcst = 3008,

        /// <summary>
        /// vpcmpgtd k1, zmm, m512 | EVEX.512.66.0F.W0 66 /r | Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask. k2.
        /// </summary>
        [Symbol("vpcmpgtd k1, zmm, m512","EVEX.512.66.0F.W0 66 /r")]
        vpcmpgtd_k1_zmm_m512 = 3009,

        /// <summary>
        /// vpcmpgtd k1, zmm, zmm | EVEX.512.66.0F.W0 66 /r | Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask. k2.
        /// </summary>
        [Symbol("vpcmpgtd k1, zmm, zmm","EVEX.512.66.0F.W0 66 /r")]
        vpcmpgtd_k1_zmm_zmm = 3010,

        /// <summary>
        /// vpcmpgtd xmm, xmm, m128 | VEX.128.66.0F.WIG 66 /r | Compare packed signed doubleword integers in xmm2 and xmm3/m128 for greater than.
        /// </summary>
        [Symbol("vpcmpgtd xmm, xmm, m128","VEX.128.66.0F.WIG 66 /r")]
        vpcmpgtd_xmm_xmm_m128 = 3011,

        /// <summary>
        /// vpcmpgtd xmm, xmm, r8 | VEX.128.66.0F.WIG 66 /r | Compare packed signed doubleword integers in xmm2 and xmm3/m128 for greater than.
        /// </summary>
        [Symbol("vpcmpgtd xmm, xmm, r8","VEX.128.66.0F.WIG 66 /r")]
        vpcmpgtd_xmm_xmm_r8 = 3012,

        /// <summary>
        /// vpcmpgtd ymm, ymm, m256 | VEX.256.66.0F.WIG 66 /r | Compare packed signed doubleword integers in ymm2 and ymm3/m256 for greater than.
        /// </summary>
        [Symbol("vpcmpgtd ymm, ymm, m256","VEX.256.66.0F.WIG 66 /r")]
        vpcmpgtd_ymm_ymm_m256 = 3013,

        /// <summary>
        /// vpcmpgtd ymm, ymm, r16 | VEX.256.66.0F.WIG 66 /r | Compare packed signed doubleword integers in ymm2 and ymm3/m256 for greater than.
        /// </summary>
        [Symbol("vpcmpgtd ymm, ymm, r16","VEX.256.66.0F.WIG 66 /r")]
        vpcmpgtd_ymm_ymm_r16 = 3014,

        /// <summary>
        /// vpcmpgtq k1 {k2}, xmm, m128 | EVEX.128.66.0F38.W1 37 /r | Compare Greater between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1 {k2}, xmm, m128","EVEX.128.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_k2_xmm_m128 = 3015,

        /// <summary>
        /// vpcmpgtq k1 {k2}, xmm, m64bcst | EVEX.128.66.0F38.W1 37 /r | Compare Greater between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1 {k2}, xmm, m64bcst","EVEX.128.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_k2_xmm_m64bcst = 3016,

        /// <summary>
        /// vpcmpgtq k1 {k2}, xmm, xmm | EVEX.128.66.0F38.W1 37 /r | Compare Greater between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1 {k2}, xmm, xmm","EVEX.128.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_k2_xmm_xmm = 3017,

        /// <summary>
        /// vpcmpgtq k1 {k2}, ymm, m256 | EVEX.256.66.0F38.W1 37 /r | Compare Greater between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1 {k2}, ymm, m256","EVEX.256.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_k2_ymm_m256 = 3018,

        /// <summary>
        /// vpcmpgtq k1 {k2}, ymm, m64bcst | EVEX.256.66.0F38.W1 37 /r | Compare Greater between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1 {k2}, ymm, m64bcst","EVEX.256.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_k2_ymm_m64bcst = 3019,

        /// <summary>
        /// vpcmpgtq k1 {k2}, ymm, ymm | EVEX.256.66.0F38.W1 37 /r | Compare Greater between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1 {k2}, ymm, ymm","EVEX.256.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_k2_ymm_ymm = 3020,

        /// <summary>
        /// vpcmpgtq k1 {k2}, zmm, m512 | EVEX.512.66.0F38.W1 37 /r | Compare Greater between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1 {k2}, zmm, m512","EVEX.512.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_k2_zmm_m512 = 3021,

        /// <summary>
        /// vpcmpgtq k1 {k2}, zmm, m64bcst | EVEX.512.66.0F38.W1 37 /r | Compare Greater between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1 {k2}, zmm, m64bcst","EVEX.512.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_k2_zmm_m64bcst = 3022,

        /// <summary>
        /// vpcmpgtq k1 {k2}, zmm, zmm | EVEX.512.66.0F38.W1 37 /r | Compare Greater between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1 {k2}, zmm, zmm","EVEX.512.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_k2_zmm_zmm = 3023,

        /// <summary>
        /// vpcmpgtq k1, xmm, m128 | EVEX.128.66.0F38.W1 37 /r | Compare Greater between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1, xmm, m128","EVEX.128.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_xmm_m128 = 3024,

        /// <summary>
        /// vpcmpgtq k1, xmm, m64bcst | EVEX.128.66.0F38.W1 37 /r | Compare Greater between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1, xmm, m64bcst","EVEX.128.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_xmm_m64bcst = 3025,

        /// <summary>
        /// vpcmpgtq k1, xmm, xmm | EVEX.128.66.0F38.W1 37 /r | Compare Greater between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1, xmm, xmm","EVEX.128.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_xmm_xmm = 3026,

        /// <summary>
        /// vpcmpgtq k1, ymm, m256 | EVEX.256.66.0F38.W1 37 /r | Compare Greater between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1, ymm, m256","EVEX.256.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_ymm_m256 = 3027,

        /// <summary>
        /// vpcmpgtq k1, ymm, m64bcst | EVEX.256.66.0F38.W1 37 /r | Compare Greater between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1, ymm, m64bcst","EVEX.256.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_ymm_m64bcst = 3028,

        /// <summary>
        /// vpcmpgtq k1, ymm, ymm | EVEX.256.66.0F38.W1 37 /r | Compare Greater between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1, ymm, ymm","EVEX.256.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_ymm_ymm = 3029,

        /// <summary>
        /// vpcmpgtq k1, zmm, m512 | EVEX.512.66.0F38.W1 37 /r | Compare Greater between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1, zmm, m512","EVEX.512.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_zmm_m512 = 3030,

        /// <summary>
        /// vpcmpgtq k1, zmm, m64bcst | EVEX.512.66.0F38.W1 37 /r | Compare Greater between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1, zmm, m64bcst","EVEX.512.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_zmm_m64bcst = 3031,

        /// <summary>
        /// vpcmpgtq k1, zmm, zmm | EVEX.512.66.0F38.W1 37 /r | Compare Greater between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtq k1, zmm, zmm","EVEX.512.66.0F38.W1 37 /r")]
        vpcmpgtq_k1_zmm_zmm = 3032,

        /// <summary>
        /// vpcmpgtq xmm, xmm, m128 | VEX.128.66.0F38.WIG 37 /r | Compare packed signed qwords in xmm2 and xmm3/m128 for greater than.
        /// </summary>
        [Symbol("vpcmpgtq xmm, xmm, m128","VEX.128.66.0F38.WIG 37 /r")]
        vpcmpgtq_xmm_xmm_m128 = 3033,

        /// <summary>
        /// vpcmpgtq xmm, xmm, r8 | VEX.128.66.0F38.WIG 37 /r | Compare packed signed qwords in xmm2 and xmm3/m128 for greater than.
        /// </summary>
        [Symbol("vpcmpgtq xmm, xmm, r8","VEX.128.66.0F38.WIG 37 /r")]
        vpcmpgtq_xmm_xmm_r8 = 3034,

        /// <summary>
        /// vpcmpgtq ymm, ymm, m256 | VEX.256.66.0F38.WIG 37 /r | Compare packed signed qwords in ymm2 and ymm3/m256 for greater than.
        /// </summary>
        [Symbol("vpcmpgtq ymm, ymm, m256","VEX.256.66.0F38.WIG 37 /r")]
        vpcmpgtq_ymm_ymm_m256 = 3035,

        /// <summary>
        /// vpcmpgtq ymm, ymm, r16 | VEX.256.66.0F38.WIG 37 /r | Compare packed signed qwords in ymm2 and ymm3/m256 for greater than.
        /// </summary>
        [Symbol("vpcmpgtq ymm, ymm, r16","VEX.256.66.0F38.WIG 37 /r")]
        vpcmpgtq_ymm_ymm_r16 = 3036,

        /// <summary>
        /// vpcmpgtw k1 {k2}, xmm, m128 | EVEX.128.66.0F.WIG 65 /r | Compare packed signed word integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1 {k2}, xmm, m128","EVEX.128.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_k2_xmm_m128 = 3037,

        /// <summary>
        /// vpcmpgtw k1 {k2}, xmm, r8 | EVEX.128.66.0F.WIG 65 /r | Compare packed signed word integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1 {k2}, xmm, r8","EVEX.128.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_k2_xmm_r8 = 3038,

        /// <summary>
        /// vpcmpgtw k1 {k2}, ymm, m256 | EVEX.256.66.0F.WIG 65 /r | Compare packed signed word integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1 {k2}, ymm, m256","EVEX.256.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_k2_ymm_m256 = 3039,

        /// <summary>
        /// vpcmpgtw k1 {k2}, ymm, r16 | EVEX.256.66.0F.WIG 65 /r | Compare packed signed word integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1 {k2}, ymm, r16","EVEX.256.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_k2_ymm_r16 = 3040,

        /// <summary>
        /// vpcmpgtw k1 {k2}, zmm, m512 | EVEX.512.66.0F.WIG 65 /r | Compare packed signed word integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1 {k2}, zmm, m512","EVEX.512.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_k2_zmm_m512 = 3041,

        /// <summary>
        /// vpcmpgtw k1 {k2}, zmm, r32 | EVEX.512.66.0F.WIG 65 /r | Compare packed signed word integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1 {k2}, zmm, r32","EVEX.512.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_k2_zmm_r32 = 3042,

        /// <summary>
        /// vpcmpgtw k1, xmm, m128 | EVEX.128.66.0F.WIG 65 /r | Compare packed signed word integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1, xmm, m128","EVEX.128.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_xmm_m128 = 3043,

        /// <summary>
        /// vpcmpgtw k1, xmm, r8 | EVEX.128.66.0F.WIG 65 /r | Compare packed signed word integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1, xmm, r8","EVEX.128.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_xmm_r8 = 3044,

        /// <summary>
        /// vpcmpgtw k1, ymm, m256 | EVEX.256.66.0F.WIG 65 /r | Compare packed signed word integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1, ymm, m256","EVEX.256.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_ymm_m256 = 3045,

        /// <summary>
        /// vpcmpgtw k1, ymm, r16 | EVEX.256.66.0F.WIG 65 /r | Compare packed signed word integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1, ymm, r16","EVEX.256.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_ymm_r16 = 3046,

        /// <summary>
        /// vpcmpgtw k1, zmm, m512 | EVEX.512.66.0F.WIG 65 /r | Compare packed signed word integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1, zmm, m512","EVEX.512.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_zmm_m512 = 3047,

        /// <summary>
        /// vpcmpgtw k1, zmm, r32 | EVEX.512.66.0F.WIG 65 /r | Compare packed signed word integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.
        /// </summary>
        [Symbol("vpcmpgtw k1, zmm, r32","EVEX.512.66.0F.WIG 65 /r")]
        vpcmpgtw_k1_zmm_r32 = 3048,

        /// <summary>
        /// vpcmpgtw xmm, xmm, m128 | VEX.128.66.0F.WIG 65 /r | Compare packed signed word integers in xmm2 and xmm3/m128 for greater than.
        /// </summary>
        [Symbol("vpcmpgtw xmm, xmm, m128","VEX.128.66.0F.WIG 65 /r")]
        vpcmpgtw_xmm_xmm_m128 = 3049,

        /// <summary>
        /// vpcmpgtw xmm, xmm, r8 | VEX.128.66.0F.WIG 65 /r | Compare packed signed word integers in xmm2 and xmm3/m128 for greater than.
        /// </summary>
        [Symbol("vpcmpgtw xmm, xmm, r8","VEX.128.66.0F.WIG 65 /r")]
        vpcmpgtw_xmm_xmm_r8 = 3050,

        /// <summary>
        /// vpcmpgtw ymm, ymm, m256 | VEX.256.66.0F.WIG 65 /r | Compare packed signed word integers in ymm2 and ymm3/m256 for greater than.
        /// </summary>
        [Symbol("vpcmpgtw ymm, ymm, m256","VEX.256.66.0F.WIG 65 /r")]
        vpcmpgtw_ymm_ymm_m256 = 3051,

        /// <summary>
        /// vpcmpgtw ymm, ymm, r16 | VEX.256.66.0F.WIG 65 /r | Compare packed signed word integers in ymm2 and ymm3/m256 for greater than.
        /// </summary>
        [Symbol("vpcmpgtw ymm, ymm, r16","VEX.256.66.0F.WIG 65 /r")]
        vpcmpgtw_ymm_ymm_r16 = 3052,

        /// <summary>
        /// vpcmpq k1 {k2}, xmm, m128, imm8 | EVEX.128.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1 {k2}, xmm, m128, imm8","EVEX.128.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_k2_xmm_m128_imm8 = 3053,

        /// <summary>
        /// vpcmpq k1 {k2}, xmm, m64bcst, imm8 | EVEX.128.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1 {k2}, xmm, m64bcst, imm8","EVEX.128.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_k2_xmm_m64bcst_imm8 = 3054,

        /// <summary>
        /// vpcmpq k1 {k2}, xmm, xmm, imm8 | EVEX.128.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1 {k2}, xmm, xmm, imm8","EVEX.128.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_k2_xmm_xmm_imm8 = 3055,

        /// <summary>
        /// vpcmpq k1 {k2}, ymm, m256, imm8 | EVEX.256.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1 {k2}, ymm, m256, imm8","EVEX.256.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_k2_ymm_m256_imm8 = 3056,

        /// <summary>
        /// vpcmpq k1 {k2}, ymm, m64bcst, imm8 | EVEX.256.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1 {k2}, ymm, m64bcst, imm8","EVEX.256.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_k2_ymm_m64bcst_imm8 = 3057,

        /// <summary>
        /// vpcmpq k1 {k2}, ymm, ymm, imm8 | EVEX.256.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1 {k2}, ymm, ymm, imm8","EVEX.256.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_k2_ymm_ymm_imm8 = 3058,

        /// <summary>
        /// vpcmpq k1 {k2}, zmm, m512, imm8 | EVEX.512.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1 {k2}, zmm, m512, imm8","EVEX.512.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_k2_zmm_m512_imm8 = 3059,

        /// <summary>
        /// vpcmpq k1 {k2}, zmm, m64bcst, imm8 | EVEX.512.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1 {k2}, zmm, m64bcst, imm8","EVEX.512.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_k2_zmm_m64bcst_imm8 = 3060,

        /// <summary>
        /// vpcmpq k1 {k2}, zmm, zmm, imm8 | EVEX.512.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1 {k2}, zmm, zmm, imm8","EVEX.512.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_k2_zmm_zmm_imm8 = 3061,

        /// <summary>
        /// vpcmpq k1, xmm, m128, imm8 | EVEX.128.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1, xmm, m128, imm8","EVEX.128.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_xmm_m128_imm8 = 3062,

        /// <summary>
        /// vpcmpq k1, xmm, m64bcst, imm8 | EVEX.128.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1, xmm, m64bcst, imm8","EVEX.128.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_xmm_m64bcst_imm8 = 3063,

        /// <summary>
        /// vpcmpq k1, xmm, xmm, imm8 | EVEX.128.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1, xmm, xmm, imm8","EVEX.128.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_xmm_xmm_imm8 = 3064,

        /// <summary>
        /// vpcmpq k1, ymm, m256, imm8 | EVEX.256.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1, ymm, m256, imm8","EVEX.256.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_ymm_m256_imm8 = 3065,

        /// <summary>
        /// vpcmpq k1, ymm, m64bcst, imm8 | EVEX.256.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1, ymm, m64bcst, imm8","EVEX.256.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_ymm_m64bcst_imm8 = 3066,

        /// <summary>
        /// vpcmpq k1, ymm, ymm, imm8 | EVEX.256.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1, ymm, ymm, imm8","EVEX.256.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_ymm_ymm_imm8 = 3067,

        /// <summary>
        /// vpcmpq k1, zmm, m512, imm8 | EVEX.512.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1, zmm, m512, imm8","EVEX.512.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_zmm_m512_imm8 = 3068,

        /// <summary>
        /// vpcmpq k1, zmm, m64bcst, imm8 | EVEX.512.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1, zmm, m64bcst, imm8","EVEX.512.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_zmm_m64bcst_imm8 = 3069,

        /// <summary>
        /// vpcmpq k1, zmm, zmm, imm8 | EVEX.512.66.0F3A.W1 1F /r ib | Compare packed signed quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpq k1, zmm, zmm, imm8","EVEX.512.66.0F3A.W1 1F /r ib")]
        vpcmpq_k1_zmm_zmm_imm8 = 3070,

        /// <summary>
        /// vpcmpub k1 {k2}, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1 {k2}, xmm, m128, imm8","EVEX.128.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_k2_xmm_m128_imm8 = 3071,

        /// <summary>
        /// vpcmpub k1 {k2}, xmm, r8, imm8 | EVEX.128.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1 {k2}, xmm, r8, imm8","EVEX.128.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_k2_xmm_r8_imm8 = 3072,

        /// <summary>
        /// vpcmpub k1 {k2}, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1 {k2}, ymm, m256, imm8","EVEX.256.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_k2_ymm_m256_imm8 = 3073,

        /// <summary>
        /// vpcmpub k1 {k2}, ymm, r16, imm8 | EVEX.256.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1 {k2}, ymm, r16, imm8","EVEX.256.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_k2_ymm_r16_imm8 = 3074,

        /// <summary>
        /// vpcmpub k1 {k2}, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1 {k2}, zmm, m512, imm8","EVEX.512.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_k2_zmm_m512_imm8 = 3075,

        /// <summary>
        /// vpcmpub k1 {k2}, zmm, r32, imm8 | EVEX.512.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1 {k2}, zmm, r32, imm8","EVEX.512.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_k2_zmm_r32_imm8 = 3076,

        /// <summary>
        /// vpcmpub k1, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1, xmm, m128, imm8","EVEX.128.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_xmm_m128_imm8 = 3077,

        /// <summary>
        /// vpcmpub k1, xmm, r8, imm8 | EVEX.128.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1, xmm, r8, imm8","EVEX.128.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_xmm_r8_imm8 = 3078,

        /// <summary>
        /// vpcmpub k1, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1, ymm, m256, imm8","EVEX.256.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_ymm_m256_imm8 = 3079,

        /// <summary>
        /// vpcmpub k1, ymm, r16, imm8 | EVEX.256.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1, ymm, r16, imm8","EVEX.256.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_ymm_r16_imm8 = 3080,

        /// <summary>
        /// vpcmpub k1, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1, zmm, m512, imm8","EVEX.512.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_zmm_m512_imm8 = 3081,

        /// <summary>
        /// vpcmpub k1, zmm, r32, imm8 | EVEX.512.66.0F3A.W0 3E /r ib | Compare packed unsigned byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpub k1, zmm, r32, imm8","EVEX.512.66.0F3A.W0 3E /r ib")]
        vpcmpub_k1_zmm_r32_imm8 = 3082,

        /// <summary>
        /// vpcmpud k1 {k2}, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1 {k2}, xmm, m128, imm8","EVEX.128.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_k2_xmm_m128_imm8 = 3083,

        /// <summary>
        /// vpcmpud k1 {k2}, xmm, m32bcst, imm8 | EVEX.128.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1 {k2}, xmm, m32bcst, imm8","EVEX.128.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_k2_xmm_m32bcst_imm8 = 3084,

        /// <summary>
        /// vpcmpud k1 {k2}, xmm, xmm, imm8 | EVEX.128.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1 {k2}, xmm, xmm, imm8","EVEX.128.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_k2_xmm_xmm_imm8 = 3085,

        /// <summary>
        /// vpcmpud k1 {k2}, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1 {k2}, ymm, m256, imm8","EVEX.256.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_k2_ymm_m256_imm8 = 3086,

        /// <summary>
        /// vpcmpud k1 {k2}, ymm, m32bcst, imm8 | EVEX.256.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1 {k2}, ymm, m32bcst, imm8","EVEX.256.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_k2_ymm_m32bcst_imm8 = 3087,

        /// <summary>
        /// vpcmpud k1 {k2}, ymm, ymm, imm8 | EVEX.256.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1 {k2}, ymm, ymm, imm8","EVEX.256.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_k2_ymm_ymm_imm8 = 3088,

        /// <summary>
        /// vpcmpud k1 {k2}, zmm, m32bcst, imm8 | EVEX.512.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpud k1 {k2}, zmm, m32bcst, imm8","EVEX.512.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_k2_zmm_m32bcst_imm8 = 3089,

        /// <summary>
        /// vpcmpud k1 {k2}, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpud k1 {k2}, zmm, m512, imm8","EVEX.512.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_k2_zmm_m512_imm8 = 3090,

        /// <summary>
        /// vpcmpud k1 {k2}, zmm, zmm, imm8 | EVEX.512.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpud k1 {k2}, zmm, zmm, imm8","EVEX.512.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_k2_zmm_zmm_imm8 = 3091,

        /// <summary>
        /// vpcmpud k1, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1, xmm, m128, imm8","EVEX.128.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_xmm_m128_imm8 = 3092,

        /// <summary>
        /// vpcmpud k1, xmm, m32bcst, imm8 | EVEX.128.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1, xmm, m32bcst, imm8","EVEX.128.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_xmm_m32bcst_imm8 = 3093,

        /// <summary>
        /// vpcmpud k1, xmm, xmm, imm8 | EVEX.128.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1, xmm, xmm, imm8","EVEX.128.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_xmm_xmm_imm8 = 3094,

        /// <summary>
        /// vpcmpud k1, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1, ymm, m256, imm8","EVEX.256.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_ymm_m256_imm8 = 3095,

        /// <summary>
        /// vpcmpud k1, ymm, m32bcst, imm8 | EVEX.256.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1, ymm, m32bcst, imm8","EVEX.256.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_ymm_m32bcst_imm8 = 3096,

        /// <summary>
        /// vpcmpud k1, ymm, ymm, imm8 | EVEX.256.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpud k1, ymm, ymm, imm8","EVEX.256.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_ymm_ymm_imm8 = 3097,

        /// <summary>
        /// vpcmpud k1, zmm, m32bcst, imm8 | EVEX.512.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpud k1, zmm, m32bcst, imm8","EVEX.512.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_zmm_m32bcst_imm8 = 3098,

        /// <summary>
        /// vpcmpud k1, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpud k1, zmm, m512, imm8","EVEX.512.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_zmm_m512_imm8 = 3099,

        /// <summary>
        /// vpcmpud k1, zmm, zmm, imm8 | EVEX.512.66.0F3A.W0 1E /r ib | Compare packed unsigned doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.
        /// </summary>
        [Symbol("vpcmpud k1, zmm, zmm, imm8","EVEX.512.66.0F3A.W0 1E /r ib")]
        vpcmpud_k1_zmm_zmm_imm8 = 3100,

        /// <summary>
        /// vpcmpuq k1 {k2}, xmm, m128, imm8 | EVEX.128.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1 {k2}, xmm, m128, imm8","EVEX.128.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_k2_xmm_m128_imm8 = 3101,

        /// <summary>
        /// vpcmpuq k1 {k2}, xmm, m64bcst, imm8 | EVEX.128.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1 {k2}, xmm, m64bcst, imm8","EVEX.128.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_k2_xmm_m64bcst_imm8 = 3102,

        /// <summary>
        /// vpcmpuq k1 {k2}, xmm, xmm, imm8 | EVEX.128.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1 {k2}, xmm, xmm, imm8","EVEX.128.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_k2_xmm_xmm_imm8 = 3103,

        /// <summary>
        /// vpcmpuq k1 {k2}, ymm, m256, imm8 | EVEX.256.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1 {k2}, ymm, m256, imm8","EVEX.256.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_k2_ymm_m256_imm8 = 3104,

        /// <summary>
        /// vpcmpuq k1 {k2}, ymm, m64bcst, imm8 | EVEX.256.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1 {k2}, ymm, m64bcst, imm8","EVEX.256.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_k2_ymm_m64bcst_imm8 = 3105,

        /// <summary>
        /// vpcmpuq k1 {k2}, ymm, ymm, imm8 | EVEX.256.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1 {k2}, ymm, ymm, imm8","EVEX.256.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_k2_ymm_ymm_imm8 = 3106,

        /// <summary>
        /// vpcmpuq k1 {k2}, zmm, m512, imm8 | EVEX.512.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1 {k2}, zmm, m512, imm8","EVEX.512.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_k2_zmm_m512_imm8 = 3107,

        /// <summary>
        /// vpcmpuq k1 {k2}, zmm, m64bcst, imm8 | EVEX.512.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1 {k2}, zmm, m64bcst, imm8","EVEX.512.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_k2_zmm_m64bcst_imm8 = 3108,

        /// <summary>
        /// vpcmpuq k1 {k2}, zmm, zmm, imm8 | EVEX.512.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1 {k2}, zmm, zmm, imm8","EVEX.512.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_k2_zmm_zmm_imm8 = 3109,

        /// <summary>
        /// vpcmpuq k1, xmm, m128, imm8 | EVEX.128.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1, xmm, m128, imm8","EVEX.128.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_xmm_m128_imm8 = 3110,

        /// <summary>
        /// vpcmpuq k1, xmm, m64bcst, imm8 | EVEX.128.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1, xmm, m64bcst, imm8","EVEX.128.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_xmm_m64bcst_imm8 = 3111,

        /// <summary>
        /// vpcmpuq k1, xmm, xmm, imm8 | EVEX.128.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1, xmm, xmm, imm8","EVEX.128.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_xmm_xmm_imm8 = 3112,

        /// <summary>
        /// vpcmpuq k1, ymm, m256, imm8 | EVEX.256.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1, ymm, m256, imm8","EVEX.256.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_ymm_m256_imm8 = 3113,

        /// <summary>
        /// vpcmpuq k1, ymm, m64bcst, imm8 | EVEX.256.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1, ymm, m64bcst, imm8","EVEX.256.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_ymm_m64bcst_imm8 = 3114,

        /// <summary>
        /// vpcmpuq k1, ymm, ymm, imm8 | EVEX.256.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1, ymm, ymm, imm8","EVEX.256.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_ymm_ymm_imm8 = 3115,

        /// <summary>
        /// vpcmpuq k1, zmm, m512, imm8 | EVEX.512.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1, zmm, m512, imm8","EVEX.512.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_zmm_m512_imm8 = 3116,

        /// <summary>
        /// vpcmpuq k1, zmm, m64bcst, imm8 | EVEX.512.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1, zmm, m64bcst, imm8","EVEX.512.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_zmm_m64bcst_imm8 = 3117,

        /// <summary>
        /// vpcmpuq k1, zmm, zmm, imm8 | EVEX.512.66.0F3A.W1 1E /r ib | Compare packed unsigned quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuq k1, zmm, zmm, imm8","EVEX.512.66.0F3A.W1 1E /r ib")]
        vpcmpuq_k1_zmm_zmm_imm8 = 3118,

        /// <summary>
        /// vpcmpuw k1 {k2}, xmm, m128, imm8 | EVEX.128.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1 {k2}, xmm, m128, imm8","EVEX.128.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_k2_xmm_m128_imm8 = 3119,

        /// <summary>
        /// vpcmpuw k1 {k2}, xmm, r8, imm8 | EVEX.128.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1 {k2}, xmm, r8, imm8","EVEX.128.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_k2_xmm_r8_imm8 = 3120,

        /// <summary>
        /// vpcmpuw k1 {k2}, ymm, m256, imm8 | EVEX.256.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1 {k2}, ymm, m256, imm8","EVEX.256.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_k2_ymm_m256_imm8 = 3121,

        /// <summary>
        /// vpcmpuw k1 {k2}, ymm, r16, imm8 | EVEX.256.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1 {k2}, ymm, r16, imm8","EVEX.256.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_k2_ymm_r16_imm8 = 3122,

        /// <summary>
        /// vpcmpuw k1 {k2}, zmm, m512, imm8 | EVEX.NDS.512.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1 {k2}, zmm, m512, imm8","EVEX.NDS.512.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_k2_zmm_m512_imm8 = 3123,

        /// <summary>
        /// vpcmpuw k1 {k2}, zmm, r32, imm8 | EVEX.NDS.512.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1 {k2}, zmm, r32, imm8","EVEX.NDS.512.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_k2_zmm_r32_imm8 = 3124,

        /// <summary>
        /// vpcmpuw k1, xmm, m128, imm8 | EVEX.128.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1, xmm, m128, imm8","EVEX.128.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_xmm_m128_imm8 = 3125,

        /// <summary>
        /// vpcmpuw k1, xmm, r8, imm8 | EVEX.128.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1, xmm, r8, imm8","EVEX.128.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_xmm_r8_imm8 = 3126,

        /// <summary>
        /// vpcmpuw k1, ymm, m256, imm8 | EVEX.256.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1, ymm, m256, imm8","EVEX.256.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_ymm_m256_imm8 = 3127,

        /// <summary>
        /// vpcmpuw k1, ymm, r16, imm8 | EVEX.256.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1, ymm, r16, imm8","EVEX.256.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_ymm_r16_imm8 = 3128,

        /// <summary>
        /// vpcmpuw k1, zmm, m512, imm8 | EVEX.NDS.512.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1, zmm, m512, imm8","EVEX.NDS.512.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_zmm_m512_imm8 = 3129,

        /// <summary>
        /// vpcmpuw k1, zmm, r32, imm8 | EVEX.NDS.512.66.0F3A.W1 3E /r ib | Compare packed unsigned word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpuw k1, zmm, r32, imm8","EVEX.NDS.512.66.0F3A.W1 3E /r ib")]
        vpcmpuw_k1_zmm_r32_imm8 = 3130,

        /// <summary>
        /// vpcmpw k1 {k2}, xmm, m128, imm8 | EVEX.128.66.0F3A.W1 3F /r ib | Compare packed signed word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1 {k2}, xmm, m128, imm8","EVEX.128.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_k2_xmm_m128_imm8 = 3131,

        /// <summary>
        /// vpcmpw k1 {k2}, xmm, r8, imm8 | EVEX.128.66.0F3A.W1 3F /r ib | Compare packed signed word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1 {k2}, xmm, r8, imm8","EVEX.128.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_k2_xmm_r8_imm8 = 3132,

        /// <summary>
        /// vpcmpw k1 {k2}, ymm, m256, imm8 | EVEX.256.66.0F3A.W1 3F /r ib | Compare packed signed word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1 {k2}, ymm, m256, imm8","EVEX.256.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_k2_ymm_m256_imm8 = 3133,

        /// <summary>
        /// vpcmpw k1 {k2}, ymm, r16, imm8 | EVEX.256.66.0F3A.W1 3F /r ib | Compare packed signed word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1 {k2}, ymm, r16, imm8","EVEX.256.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_k2_ymm_r16_imm8 = 3134,

        /// <summary>
        /// vpcmpw k1 {k2}, zmm, m512, imm8 | EVEX.512.66.0F3A.W1 3F /r ib | Compare packed signed word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1 {k2}, zmm, m512, imm8","EVEX.512.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_k2_zmm_m512_imm8 = 3135,

        /// <summary>
        /// vpcmpw k1 {k2}, zmm, r32, imm8 | EVEX.512.66.0F3A.W1 3F /r ib | Compare packed signed word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1 {k2}, zmm, r32, imm8","EVEX.512.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_k2_zmm_r32_imm8 = 3136,

        /// <summary>
        /// vpcmpw k1, xmm, m128, imm8 | EVEX.128.66.0F3A.W1 3F /r ib | Compare packed signed word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1, xmm, m128, imm8","EVEX.128.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_xmm_m128_imm8 = 3137,

        /// <summary>
        /// vpcmpw k1, xmm, r8, imm8 | EVEX.128.66.0F3A.W1 3F /r ib | Compare packed signed word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1, xmm, r8, imm8","EVEX.128.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_xmm_r8_imm8 = 3138,

        /// <summary>
        /// vpcmpw k1, ymm, m256, imm8 | EVEX.256.66.0F3A.W1 3F /r ib | Compare packed signed word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1, ymm, m256, imm8","EVEX.256.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_ymm_m256_imm8 = 3139,

        /// <summary>
        /// vpcmpw k1, ymm, r16, imm8 | EVEX.256.66.0F3A.W1 3F /r ib | Compare packed signed word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1, ymm, r16, imm8","EVEX.256.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_ymm_r16_imm8 = 3140,

        /// <summary>
        /// vpcmpw k1, zmm, m512, imm8 | EVEX.512.66.0F3A.W1 3F /r ib | Compare packed signed word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1, zmm, m512, imm8","EVEX.512.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_zmm_m512_imm8 = 3141,

        /// <summary>
        /// vpcmpw k1, zmm, r32, imm8 | EVEX.512.66.0F3A.W1 3F /r ib | Compare packed signed word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.
        /// </summary>
        [Symbol("vpcmpw k1, zmm, r32, imm8","EVEX.512.66.0F3A.W1 3F /r ib")]
        vpcmpw_k1_zmm_r32_imm8 = 3142,

        /// <summary>
        /// vpcompressd m128 {k1}{z}, xmm | EVEX.128.66.0F38.W0 8B /r | Compress packed doubleword integer values from xmm2 to xmm1/m128 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd m128 {k1}{z}, xmm","EVEX.128.66.0F38.W0 8B /r")]
        vpcompressd_m128_k1z_xmm = 3143,

        /// <summary>
        /// vpcompressd m128, xmm | EVEX.128.66.0F38.W0 8B /r | Compress packed doubleword integer values from xmm2 to xmm1/m128 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd m128, xmm","EVEX.128.66.0F38.W0 8B /r")]
        vpcompressd_m128_xmm = 3144,

        /// <summary>
        /// vpcompressd m256 {k1}{z}, ymm | EVEX.256.66.0F38.W0 8B /r | Compress packed doubleword integer values from ymm2 to ymm1/m256 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd m256 {k1}{z}, ymm","EVEX.256.66.0F38.W0 8B /r")]
        vpcompressd_m256_k1z_ymm = 3145,

        /// <summary>
        /// vpcompressd m256, ymm | EVEX.256.66.0F38.W0 8B /r | Compress packed doubleword integer values from ymm2 to ymm1/m256 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd m256, ymm","EVEX.256.66.0F38.W0 8B /r")]
        vpcompressd_m256_ymm = 3146,

        /// <summary>
        /// vpcompressd m512 {k1}{z}, zmm | EVEX.512.66.0F38.W0 8B /r | Compress packed doubleword integer values from zmm2 to zmm1/m512 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd m512 {k1}{z}, zmm","EVEX.512.66.0F38.W0 8B /r")]
        vpcompressd_m512_k1z_zmm = 3147,

        /// <summary>
        /// vpcompressd m512, zmm | EVEX.512.66.0F38.W0 8B /r | Compress packed doubleword integer values from zmm2 to zmm1/m512 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd m512, zmm","EVEX.512.66.0F38.W0 8B /r")]
        vpcompressd_m512_zmm = 3148,

        /// <summary>
        /// vpcompressd r16 {k1}{z}, ymm | EVEX.256.66.0F38.W0 8B /r | Compress packed doubleword integer values from ymm2 to ymm1/m256 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd r16 {k1}{z}, ymm","EVEX.256.66.0F38.W0 8B /r")]
        vpcompressd_r16_k1z_ymm = 3149,

        /// <summary>
        /// vpcompressd r16, ymm | EVEX.256.66.0F38.W0 8B /r | Compress packed doubleword integer values from ymm2 to ymm1/m256 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd r16, ymm","EVEX.256.66.0F38.W0 8B /r")]
        vpcompressd_r16_ymm = 3150,

        /// <summary>
        /// vpcompressd r32 {k1}{z}, zmm | EVEX.512.66.0F38.W0 8B /r | Compress packed doubleword integer values from zmm2 to zmm1/m512 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd r32 {k1}{z}, zmm","EVEX.512.66.0F38.W0 8B /r")]
        vpcompressd_r32_k1z_zmm = 3151,

        /// <summary>
        /// vpcompressd r32, zmm | EVEX.512.66.0F38.W0 8B /r | Compress packed doubleword integer values from zmm2 to zmm1/m512 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd r32, zmm","EVEX.512.66.0F38.W0 8B /r")]
        vpcompressd_r32_zmm = 3152,

        /// <summary>
        /// vpcompressd r8 {k1}{z}, xmm | EVEX.128.66.0F38.W0 8B /r | Compress packed doubleword integer values from xmm2 to xmm1/m128 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd r8 {k1}{z}, xmm","EVEX.128.66.0F38.W0 8B /r")]
        vpcompressd_r8_k1z_xmm = 3153,

        /// <summary>
        /// vpcompressd r8, xmm | EVEX.128.66.0F38.W0 8B /r | Compress packed doubleword integer values from xmm2 to xmm1/m128 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressd r8, xmm","EVEX.128.66.0F38.W0 8B /r")]
        vpcompressd_r8_xmm = 3154,

        /// <summary>
        /// vpcompressq m128 {k1}{z}, xmm | EVEX.128.66.0F38.W1 8B /r | Compress packed quadword integer values from xmm2 to xmm1/m128 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq m128 {k1}{z}, xmm","EVEX.128.66.0F38.W1 8B /r")]
        vpcompressq_m128_k1z_xmm = 3155,

        /// <summary>
        /// vpcompressq m128, xmm | EVEX.128.66.0F38.W1 8B /r | Compress packed quadword integer values from xmm2 to xmm1/m128 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq m128, xmm","EVEX.128.66.0F38.W1 8B /r")]
        vpcompressq_m128_xmm = 3156,

        /// <summary>
        /// vpcompressq m256 {k1}{z}, ymm | EVEX.256.66.0F38.W1 8B /r | Compress packed quadword integer values from ymm2 to ymm1/m256 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq m256 {k1}{z}, ymm","EVEX.256.66.0F38.W1 8B /r")]
        vpcompressq_m256_k1z_ymm = 3157,

        /// <summary>
        /// vpcompressq m256, ymm | EVEX.256.66.0F38.W1 8B /r | Compress packed quadword integer values from ymm2 to ymm1/m256 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq m256, ymm","EVEX.256.66.0F38.W1 8B /r")]
        vpcompressq_m256_ymm = 3158,

        /// <summary>
        /// vpcompressq m512 {k1}{z}, zmm | EVEX.512.66.0F38.W1 8B /r | Compress packed quadword integer values from zmm2 to zmm1/m512 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq m512 {k1}{z}, zmm","EVEX.512.66.0F38.W1 8B /r")]
        vpcompressq_m512_k1z_zmm = 3159,

        /// <summary>
        /// vpcompressq m512, zmm | EVEX.512.66.0F38.W1 8B /r | Compress packed quadword integer values from zmm2 to zmm1/m512 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq m512, zmm","EVEX.512.66.0F38.W1 8B /r")]
        vpcompressq_m512_zmm = 3160,

        /// <summary>
        /// vpcompressq r16 {k1}{z}, ymm | EVEX.256.66.0F38.W1 8B /r | Compress packed quadword integer values from ymm2 to ymm1/m256 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq r16 {k1}{z}, ymm","EVEX.256.66.0F38.W1 8B /r")]
        vpcompressq_r16_k1z_ymm = 3161,

        /// <summary>
        /// vpcompressq r16, ymm | EVEX.256.66.0F38.W1 8B /r | Compress packed quadword integer values from ymm2 to ymm1/m256 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq r16, ymm","EVEX.256.66.0F38.W1 8B /r")]
        vpcompressq_r16_ymm = 3162,

        /// <summary>
        /// vpcompressq r32 {k1}{z}, zmm | EVEX.512.66.0F38.W1 8B /r | Compress packed quadword integer values from zmm2 to zmm1/m512 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq r32 {k1}{z}, zmm","EVEX.512.66.0F38.W1 8B /r")]
        vpcompressq_r32_k1z_zmm = 3163,

        /// <summary>
        /// vpcompressq r32, zmm | EVEX.512.66.0F38.W1 8B /r | Compress packed quadword integer values from zmm2 to zmm1/m512 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq r32, zmm","EVEX.512.66.0F38.W1 8B /r")]
        vpcompressq_r32_zmm = 3164,

        /// <summary>
        /// vpcompressq r8 {k1}{z}, xmm | EVEX.128.66.0F38.W1 8B /r | Compress packed quadword integer values from xmm2 to xmm1/m128 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq r8 {k1}{z}, xmm","EVEX.128.66.0F38.W1 8B /r")]
        vpcompressq_r8_k1z_xmm = 3165,

        /// <summary>
        /// vpcompressq r8, xmm | EVEX.128.66.0F38.W1 8B /r | Compress packed quadword integer values from xmm2 to xmm1/m128 using controlmask k1.
        /// </summary>
        [Symbol("vpcompressq r8, xmm","EVEX.128.66.0F38.W1 8B /r")]
        vpcompressq_r8_xmm = 3166,

        /// <summary>
        /// vpconflictd xmm {k1}{z}, m128 | EVEX.128.66.0F38.W0 C4 /r | Detect duplicate double-word values in xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd xmm {k1}{z}, m128","EVEX.128.66.0F38.W0 C4 /r")]
        vpconflictd_xmm_k1z_m128 = 3167,

        /// <summary>
        /// vpconflictd xmm {k1}{z}, m32bcst | EVEX.128.66.0F38.W0 C4 /r | Detect duplicate double-word values in xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd xmm {k1}{z}, m32bcst","EVEX.128.66.0F38.W0 C4 /r")]
        vpconflictd_xmm_k1z_m32bcst = 3168,

        /// <summary>
        /// vpconflictd xmm {k1}{z}, xmm | EVEX.128.66.0F38.W0 C4 /r | Detect duplicate double-word values in xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd xmm {k1}{z}, xmm","EVEX.128.66.0F38.W0 C4 /r")]
        vpconflictd_xmm_k1z_xmm = 3169,

        /// <summary>
        /// vpconflictd xmm, m128 | EVEX.128.66.0F38.W0 C4 /r | Detect duplicate double-word values in xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd xmm, m128","EVEX.128.66.0F38.W0 C4 /r")]
        vpconflictd_xmm_m128 = 3170,

        /// <summary>
        /// vpconflictd xmm, m32bcst | EVEX.128.66.0F38.W0 C4 /r | Detect duplicate double-word values in xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd xmm, m32bcst","EVEX.128.66.0F38.W0 C4 /r")]
        vpconflictd_xmm_m32bcst = 3171,

        /// <summary>
        /// vpconflictd xmm, xmm | EVEX.128.66.0F38.W0 C4 /r | Detect duplicate double-word values in xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd xmm, xmm","EVEX.128.66.0F38.W0 C4 /r")]
        vpconflictd_xmm_xmm = 3172,

        /// <summary>
        /// vpconflictd ymm {k1}{z}, m256 | EVEX.256.66.0F38.W0 C4 /r | Detect duplicate double-word values in ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd ymm {k1}{z}, m256","EVEX.256.66.0F38.W0 C4 /r")]
        vpconflictd_ymm_k1z_m256 = 3173,

        /// <summary>
        /// vpconflictd ymm {k1}{z}, m32bcst | EVEX.256.66.0F38.W0 C4 /r | Detect duplicate double-word values in ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd ymm {k1}{z}, m32bcst","EVEX.256.66.0F38.W0 C4 /r")]
        vpconflictd_ymm_k1z_m32bcst = 3174,

        /// <summary>
        /// vpconflictd ymm {k1}{z}, ymm | EVEX.256.66.0F38.W0 C4 /r | Detect duplicate double-word values in ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd ymm {k1}{z}, ymm","EVEX.256.66.0F38.W0 C4 /r")]
        vpconflictd_ymm_k1z_ymm = 3175,

        /// <summary>
        /// vpconflictd ymm, m256 | EVEX.256.66.0F38.W0 C4 /r | Detect duplicate double-word values in ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd ymm, m256","EVEX.256.66.0F38.W0 C4 /r")]
        vpconflictd_ymm_m256 = 3176,

        /// <summary>
        /// vpconflictd ymm, m32bcst | EVEX.256.66.0F38.W0 C4 /r | Detect duplicate double-word values in ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd ymm, m32bcst","EVEX.256.66.0F38.W0 C4 /r")]
        vpconflictd_ymm_m32bcst = 3177,

        /// <summary>
        /// vpconflictd ymm, ymm | EVEX.256.66.0F38.W0 C4 /r | Detect duplicate double-word values in ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd ymm, ymm","EVEX.256.66.0F38.W0 C4 /r")]
        vpconflictd_ymm_ymm = 3178,

        /// <summary>
        /// vpconflictd zmm {k1}{z}, m32bcst | EVEX.512.66.0F38.W0 C4 /r | Detect duplicate double-word values in zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd zmm {k1}{z}, m32bcst","EVEX.512.66.0F38.W0 C4 /r")]
        vpconflictd_zmm_k1z_m32bcst = 3179,

        /// <summary>
        /// vpconflictd zmm {k1}{z}, m512 | EVEX.512.66.0F38.W0 C4 /r | Detect duplicate double-word values in zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd zmm {k1}{z}, m512","EVEX.512.66.0F38.W0 C4 /r")]
        vpconflictd_zmm_k1z_m512 = 3180,

        /// <summary>
        /// vpconflictd zmm {k1}{z}, zmm | EVEX.512.66.0F38.W0 C4 /r | Detect duplicate double-word values in zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd zmm {k1}{z}, zmm","EVEX.512.66.0F38.W0 C4 /r")]
        vpconflictd_zmm_k1z_zmm = 3181,

        /// <summary>
        /// vpconflictd zmm, m32bcst | EVEX.512.66.0F38.W0 C4 /r | Detect duplicate double-word values in zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd zmm, m32bcst","EVEX.512.66.0F38.W0 C4 /r")]
        vpconflictd_zmm_m32bcst = 3182,

        /// <summary>
        /// vpconflictd zmm, m512 | EVEX.512.66.0F38.W0 C4 /r | Detect duplicate double-word values in zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd zmm, m512","EVEX.512.66.0F38.W0 C4 /r")]
        vpconflictd_zmm_m512 = 3183,

        /// <summary>
        /// vpconflictd zmm, zmm | EVEX.512.66.0F38.W0 C4 /r | Detect duplicate double-word values in zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictd zmm, zmm","EVEX.512.66.0F38.W0 C4 /r")]
        vpconflictd_zmm_zmm = 3184,

        /// <summary>
        /// vpconflictq xmm {k1}{z}, m128 | EVEX.128.66.0F38.W1 C4 /r | Detect duplicate quad-word values in xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq xmm {k1}{z}, m128","EVEX.128.66.0F38.W1 C4 /r")]
        vpconflictq_xmm_k1z_m128 = 3185,

        /// <summary>
        /// vpconflictq xmm {k1}{z}, m64bcst | EVEX.128.66.0F38.W1 C4 /r | Detect duplicate quad-word values in xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq xmm {k1}{z}, m64bcst","EVEX.128.66.0F38.W1 C4 /r")]
        vpconflictq_xmm_k1z_m64bcst = 3186,

        /// <summary>
        /// vpconflictq xmm {k1}{z}, xmm | EVEX.128.66.0F38.W1 C4 /r | Detect duplicate quad-word values in xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq xmm {k1}{z}, xmm","EVEX.128.66.0F38.W1 C4 /r")]
        vpconflictq_xmm_k1z_xmm = 3187,

        /// <summary>
        /// vpconflictq xmm, m128 | EVEX.128.66.0F38.W1 C4 /r | Detect duplicate quad-word values in xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq xmm, m128","EVEX.128.66.0F38.W1 C4 /r")]
        vpconflictq_xmm_m128 = 3188,

        /// <summary>
        /// vpconflictq xmm, m64bcst | EVEX.128.66.0F38.W1 C4 /r | Detect duplicate quad-word values in xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq xmm, m64bcst","EVEX.128.66.0F38.W1 C4 /r")]
        vpconflictq_xmm_m64bcst = 3189,

        /// <summary>
        /// vpconflictq xmm, xmm | EVEX.128.66.0F38.W1 C4 /r | Detect duplicate quad-word values in xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq xmm, xmm","EVEX.128.66.0F38.W1 C4 /r")]
        vpconflictq_xmm_xmm = 3190,

        /// <summary>
        /// vpconflictq ymm {k1}{z}, m256 | EVEX.256.66.0F38.W1 C4 /r | Detect duplicate quad-word values in ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq ymm {k1}{z}, m256","EVEX.256.66.0F38.W1 C4 /r")]
        vpconflictq_ymm_k1z_m256 = 3191,

        /// <summary>
        /// vpconflictq ymm {k1}{z}, m64bcst | EVEX.256.66.0F38.W1 C4 /r | Detect duplicate quad-word values in ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq ymm {k1}{z}, m64bcst","EVEX.256.66.0F38.W1 C4 /r")]
        vpconflictq_ymm_k1z_m64bcst = 3192,

        /// <summary>
        /// vpconflictq ymm {k1}{z}, ymm | EVEX.256.66.0F38.W1 C4 /r | Detect duplicate quad-word values in ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq ymm {k1}{z}, ymm","EVEX.256.66.0F38.W1 C4 /r")]
        vpconflictq_ymm_k1z_ymm = 3193,

        /// <summary>
        /// vpconflictq ymm, m256 | EVEX.256.66.0F38.W1 C4 /r | Detect duplicate quad-word values in ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq ymm, m256","EVEX.256.66.0F38.W1 C4 /r")]
        vpconflictq_ymm_m256 = 3194,

        /// <summary>
        /// vpconflictq ymm, m64bcst | EVEX.256.66.0F38.W1 C4 /r | Detect duplicate quad-word values in ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq ymm, m64bcst","EVEX.256.66.0F38.W1 C4 /r")]
        vpconflictq_ymm_m64bcst = 3195,

        /// <summary>
        /// vpconflictq ymm, ymm | EVEX.256.66.0F38.W1 C4 /r | Detect duplicate quad-word values in ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq ymm, ymm","EVEX.256.66.0F38.W1 C4 /r")]
        vpconflictq_ymm_ymm = 3196,

        /// <summary>
        /// vpconflictq zmm {k1}{z}, m512 | EVEX.512.66.0F38.W1 C4 /r | Detect duplicate quad-word values in zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq zmm {k1}{z}, m512","EVEX.512.66.0F38.W1 C4 /r")]
        vpconflictq_zmm_k1z_m512 = 3197,

        /// <summary>
        /// vpconflictq zmm {k1}{z}, m64bcst | EVEX.512.66.0F38.W1 C4 /r | Detect duplicate quad-word values in zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq zmm {k1}{z}, m64bcst","EVEX.512.66.0F38.W1 C4 /r")]
        vpconflictq_zmm_k1z_m64bcst = 3198,

        /// <summary>
        /// vpconflictq zmm {k1}{z}, zmm | EVEX.512.66.0F38.W1 C4 /r | Detect duplicate quad-word values in zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq zmm {k1}{z}, zmm","EVEX.512.66.0F38.W1 C4 /r")]
        vpconflictq_zmm_k1z_zmm = 3199,

        /// <summary>
        /// vpconflictq zmm, m512 | EVEX.512.66.0F38.W1 C4 /r | Detect duplicate quad-word values in zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq zmm, m512","EVEX.512.66.0F38.W1 C4 /r")]
        vpconflictq_zmm_m512 = 3200,

        /// <summary>
        /// vpconflictq zmm, m64bcst | EVEX.512.66.0F38.W1 C4 /r | Detect duplicate quad-word values in zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq zmm, m64bcst","EVEX.512.66.0F38.W1 C4 /r")]
        vpconflictq_zmm_m64bcst = 3201,

        /// <summary>
        /// vpconflictq zmm, zmm | EVEX.512.66.0F38.W1 C4 /r | Detect duplicate quad-word values in zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpconflictq zmm, zmm","EVEX.512.66.0F38.W1 C4 /r")]
        vpconflictq_zmm_zmm = 3202,

        /// <summary>
        /// vperm2i128 ymm, ymm, m256, imm8 | VEX.256.66.0F3A.W0 46 /r ib | Permute 128-bit integer data in ymm2 and ymm3/mem using controls from imm8 and store result in ymm1.
        /// </summary>
        [Symbol("vperm2i128 ymm, ymm, m256, imm8","VEX.256.66.0F3A.W0 46 /r ib")]
        vperm2i128_ymm_ymm_m256_imm8 = 3203,

        /// <summary>
        /// vperm2i128 ymm, ymm, r16, imm8 | VEX.256.66.0F3A.W0 46 /r ib | Permute 128-bit integer data in ymm2 and ymm3/mem using controls from imm8 and store result in ymm1.
        /// </summary>
        [Symbol("vperm2i128 ymm, ymm, r16, imm8","VEX.256.66.0F3A.W0 46 /r ib")]
        vperm2i128_ymm_ymm_r16_imm8 = 3204,

        /// <summary>
        /// vpermb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 8D /r | Permute bytes in xmm3/m128 using byte indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 8D /r")]
        vpermb_xmm_k1z_xmm_m128 = 3205,

        /// <summary>
        /// vpermb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.W0 8D /r | Permute bytes in xmm3/m128 using byte indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.W0 8D /r")]
        vpermb_xmm_k1z_xmm_r8 = 3206,

        /// <summary>
        /// vpermb xmm, xmm, m128 | EVEX.128.66.0F38.W0 8D /r | Permute bytes in xmm3/m128 using byte indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb xmm, xmm, m128","EVEX.128.66.0F38.W0 8D /r")]
        vpermb_xmm_xmm_m128 = 3207,

        /// <summary>
        /// vpermb xmm, xmm, r8 | EVEX.128.66.0F38.W0 8D /r | Permute bytes in xmm3/m128 using byte indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb xmm, xmm, r8","EVEX.128.66.0F38.W0 8D /r")]
        vpermb_xmm_xmm_r8 = 3208,

        /// <summary>
        /// vpermb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 8D /r | Permute bytes in ymm3/m256 using byte indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 8D /r")]
        vpermb_ymm_k1z_ymm_m256 = 3209,

        /// <summary>
        /// vpermb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.W0 8D /r | Permute bytes in ymm3/m256 using byte indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.W0 8D /r")]
        vpermb_ymm_k1z_ymm_r16 = 3210,

        /// <summary>
        /// vpermb ymm, ymm, m256 | EVEX.256.66.0F38.W0 8D /r | Permute bytes in ymm3/m256 using byte indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb ymm, ymm, m256","EVEX.256.66.0F38.W0 8D /r")]
        vpermb_ymm_ymm_m256 = 3211,

        /// <summary>
        /// vpermb ymm, ymm, r16 | EVEX.256.66.0F38.W0 8D /r | Permute bytes in ymm3/m256 using byte indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb ymm, ymm, r16","EVEX.256.66.0F38.W0 8D /r")]
        vpermb_ymm_ymm_r16 = 3212,

        /// <summary>
        /// vpermb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 8D /r | Permute bytes in zmm3/m512 using byte indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 8D /r")]
        vpermb_zmm_k1z_zmm_m512 = 3213,

        /// <summary>
        /// vpermb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.W0 8D /r | Permute bytes in zmm3/m512 using byte indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.W0 8D /r")]
        vpermb_zmm_k1z_zmm_r32 = 3214,

        /// <summary>
        /// vpermb zmm, zmm, m512 | EVEX.512.66.0F38.W0 8D /r | Permute bytes in zmm3/m512 using byte indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb zmm, zmm, m512","EVEX.512.66.0F38.W0 8D /r")]
        vpermb_zmm_zmm_m512 = 3215,

        /// <summary>
        /// vpermb zmm, zmm, r32 | EVEX.512.66.0F38.W0 8D /r | Permute bytes in zmm3/m512 using byte indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermb zmm, zmm, r32","EVEX.512.66.0F38.W0 8D /r")]
        vpermb_zmm_zmm_r32 = 3216,

        /// <summary>
        /// vpermd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 36 /r | Permute doublewords in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 36 /r")]
        vpermd_ymm_k1z_ymm_m256 = 3217,

        /// <summary>
        /// vpermd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 36 /r | Permute doublewords in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 36 /r")]
        vpermd_ymm_k1z_ymm_m32bcst = 3218,

        /// <summary>
        /// vpermd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 36 /r | Permute doublewords in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 36 /r")]
        vpermd_ymm_k1z_ymm_ymm = 3219,

        /// <summary>
        /// vpermd ymm, ymm, m256 | EVEX.256.66.0F38.W0 36 /r | Permute doublewords in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd ymm, ymm, m256","EVEX.256.66.0F38.W0 36 /r")]
        vpermd_ymm_ymm_m256 = 3220,

        /// <summary>
        /// vpermd ymm, ymm, m256 | VEX.256.66.0F38.W0 36 /r | Permute doublewords in ymm3/m256 using indices in ymm2 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermd ymm, ymm, m256","VEX.256.66.0F38.W0 36 /r")]
        vpermd_ymm_ymm_m256_vex = 3221,

        /// <summary>
        /// vpermd ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 36 /r | Permute doublewords in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 36 /r")]
        vpermd_ymm_ymm_m32bcst = 3222,

        /// <summary>
        /// vpermd ymm, ymm, r16 | VEX.256.66.0F38.W0 36 /r | Permute doublewords in ymm3/m256 using indices in ymm2 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermd ymm, ymm, r16","VEX.256.66.0F38.W0 36 /r")]
        vpermd_ymm_ymm_r16 = 3223,

        /// <summary>
        /// vpermd ymm, ymm, ymm | EVEX.256.66.0F38.W0 36 /r | Permute doublewords in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd ymm, ymm, ymm","EVEX.256.66.0F38.W0 36 /r")]
        vpermd_ymm_ymm_ymm = 3224,

        /// <summary>
        /// vpermd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 36 /r | Permute doublewords in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 36 /r")]
        vpermd_zmm_k1z_zmm_m32bcst = 3225,

        /// <summary>
        /// vpermd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 36 /r | Permute doublewords in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 36 /r")]
        vpermd_zmm_k1z_zmm_m512 = 3226,

        /// <summary>
        /// vpermd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 36 /r | Permute doublewords in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 36 /r")]
        vpermd_zmm_k1z_zmm_zmm = 3227,

        /// <summary>
        /// vpermd zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 36 /r | Permute doublewords in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 36 /r")]
        vpermd_zmm_zmm_m32bcst = 3228,

        /// <summary>
        /// vpermd zmm, zmm, m512 | EVEX.512.66.0F38.W0 36 /r | Permute doublewords in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd zmm, zmm, m512","EVEX.512.66.0F38.W0 36 /r")]
        vpermd_zmm_zmm_m512 = 3229,

        /// <summary>
        /// vpermd zmm, zmm, zmm | EVEX.512.66.0F38.W0 36 /r | Permute doublewords in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermd zmm, zmm, zmm","EVEX.512.66.0F38.W0 36 /r")]
        vpermd_zmm_zmm_zmm = 3230,

        /// <summary>
        /// vpermi2d xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 76 /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 76 /r")]
        vpermi2d_xmm_k1z_xmm_m128 = 3231,

        /// <summary>
        /// vpermi2d xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 76 /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 76 /r")]
        vpermi2d_xmm_k1z_xmm_m32bcst = 3232,

        /// <summary>
        /// vpermi2d xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 76 /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 76 /r")]
        vpermi2d_xmm_k1z_xmm_xmm = 3233,

        /// <summary>
        /// vpermi2d xmm, xmm, m128 | EVEX.128.66.0F38.W0 76 /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d xmm, xmm, m128","EVEX.128.66.0F38.W0 76 /r")]
        vpermi2d_xmm_xmm_m128 = 3234,

        /// <summary>
        /// vpermi2d xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 76 /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 76 /r")]
        vpermi2d_xmm_xmm_m32bcst = 3235,

        /// <summary>
        /// vpermi2d xmm, xmm, xmm | EVEX.128.66.0F38.W0 76 /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d xmm, xmm, xmm","EVEX.128.66.0F38.W0 76 /r")]
        vpermi2d_xmm_xmm_xmm = 3236,

        /// <summary>
        /// vpermi2d ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 76 /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 76 /r")]
        vpermi2d_ymm_k1z_ymm_m256 = 3237,

        /// <summary>
        /// vpermi2d ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 76 /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 76 /r")]
        vpermi2d_ymm_k1z_ymm_m32bcst = 3238,

        /// <summary>
        /// vpermi2d ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 76 /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 76 /r")]
        vpermi2d_ymm_k1z_ymm_ymm = 3239,

        /// <summary>
        /// vpermi2d ymm, ymm, m256 | EVEX.256.66.0F38.W0 76 /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d ymm, ymm, m256","EVEX.256.66.0F38.W0 76 /r")]
        vpermi2d_ymm_ymm_m256 = 3240,

        /// <summary>
        /// vpermi2d ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 76 /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 76 /r")]
        vpermi2d_ymm_ymm_m32bcst = 3241,

        /// <summary>
        /// vpermi2d ymm, ymm, ymm | EVEX.256.66.0F38.W0 76 /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d ymm, ymm, ymm","EVEX.256.66.0F38.W0 76 /r")]
        vpermi2d_ymm_ymm_ymm = 3242,

        /// <summary>
        /// vpermi2d zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 76 /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 76 /r")]
        vpermi2d_zmm_k1z_zmm_m32bcst = 3243,

        /// <summary>
        /// vpermi2d zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 76 /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 76 /r")]
        vpermi2d_zmm_k1z_zmm_m512 = 3244,

        /// <summary>
        /// vpermi2d zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 76 /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 76 /r")]
        vpermi2d_zmm_k1z_zmm_zmm = 3245,

        /// <summary>
        /// vpermi2d zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 76 /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 76 /r")]
        vpermi2d_zmm_zmm_m32bcst = 3246,

        /// <summary>
        /// vpermi2d zmm, zmm, m512 | EVEX.512.66.0F38.W0 76 /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d zmm, zmm, m512","EVEX.512.66.0F38.W0 76 /r")]
        vpermi2d_zmm_zmm_m512 = 3247,

        /// <summary>
        /// vpermi2d zmm, zmm, zmm | EVEX.512.66.0F38.W0 76 /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2d zmm, zmm, zmm","EVEX.512.66.0F38.W0 76 /r")]
        vpermi2d_zmm_zmm_zmm = 3248,

        /// <summary>
        /// vpermi2pd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 77 /r")]
        vpermi2pd_xmm_k1z_xmm_m128 = 3249,

        /// <summary>
        /// vpermi2pd xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 77 /r")]
        vpermi2pd_xmm_k1z_xmm_m64bcst = 3250,

        /// <summary>
        /// vpermi2pd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 77 /r")]
        vpermi2pd_xmm_k1z_xmm_xmm = 3251,

        /// <summary>
        /// vpermi2pd xmm, xmm, m128 | EVEX.128.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd xmm, xmm, m128","EVEX.128.66.0F38.W1 77 /r")]
        vpermi2pd_xmm_xmm_m128 = 3252,

        /// <summary>
        /// vpermi2pd xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 77 /r")]
        vpermi2pd_xmm_xmm_m64bcst = 3253,

        /// <summary>
        /// vpermi2pd xmm, xmm, xmm | EVEX.128.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd xmm, xmm, xmm","EVEX.128.66.0F38.W1 77 /r")]
        vpermi2pd_xmm_xmm_xmm = 3254,

        /// <summary>
        /// vpermi2pd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 77 /r")]
        vpermi2pd_ymm_k1z_ymm_m256 = 3255,

        /// <summary>
        /// vpermi2pd ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 77 /r")]
        vpermi2pd_ymm_k1z_ymm_m64bcst = 3256,

        /// <summary>
        /// vpermi2pd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 77 /r")]
        vpermi2pd_ymm_k1z_ymm_ymm = 3257,

        /// <summary>
        /// vpermi2pd ymm, ymm, m256 | EVEX.256.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd ymm, ymm, m256","EVEX.256.66.0F38.W1 77 /r")]
        vpermi2pd_ymm_ymm_m256 = 3258,

        /// <summary>
        /// vpermi2pd ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 77 /r")]
        vpermi2pd_ymm_ymm_m64bcst = 3259,

        /// <summary>
        /// vpermi2pd ymm, ymm, ymm | EVEX.256.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd ymm, ymm, ymm","EVEX.256.66.0F38.W1 77 /r")]
        vpermi2pd_ymm_ymm_ymm = 3260,

        /// <summary>
        /// vpermi2pd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 77 /r")]
        vpermi2pd_zmm_k1z_zmm_m512 = 3261,

        /// <summary>
        /// vpermi2pd zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 77 /r")]
        vpermi2pd_zmm_k1z_zmm_m64bcst = 3262,

        /// <summary>
        /// vpermi2pd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 77 /r")]
        vpermi2pd_zmm_k1z_zmm_zmm = 3263,

        /// <summary>
        /// vpermi2pd zmm, zmm, m512 | EVEX.512.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd zmm, zmm, m512","EVEX.512.66.0F38.W1 77 /r")]
        vpermi2pd_zmm_zmm_m512 = 3264,

        /// <summary>
        /// vpermi2pd zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 77 /r")]
        vpermi2pd_zmm_zmm_m64bcst = 3265,

        /// <summary>
        /// vpermi2pd zmm, zmm, zmm | EVEX.512.66.0F38.W1 77 /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2pd zmm, zmm, zmm","EVEX.512.66.0F38.W1 77 /r")]
        vpermi2pd_zmm_zmm_zmm = 3266,

        /// <summary>
        /// vpermi2ps xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 77 /r")]
        vpermi2ps_xmm_k1z_xmm_m128 = 3267,

        /// <summary>
        /// vpermi2ps xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 77 /r")]
        vpermi2ps_xmm_k1z_xmm_m32bcst = 3268,

        /// <summary>
        /// vpermi2ps xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 77 /r")]
        vpermi2ps_xmm_k1z_xmm_xmm = 3269,

        /// <summary>
        /// vpermi2ps xmm, xmm, m128 | EVEX.128.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps xmm, xmm, m128","EVEX.128.66.0F38.W0 77 /r")]
        vpermi2ps_xmm_xmm_m128 = 3270,

        /// <summary>
        /// vpermi2ps xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 77 /r")]
        vpermi2ps_xmm_xmm_m32bcst = 3271,

        /// <summary>
        /// vpermi2ps xmm, xmm, xmm | EVEX.128.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps xmm, xmm, xmm","EVEX.128.66.0F38.W0 77 /r")]
        vpermi2ps_xmm_xmm_xmm = 3272,

        /// <summary>
        /// vpermi2ps ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 77 /r")]
        vpermi2ps_ymm_k1z_ymm_m256 = 3273,

        /// <summary>
        /// vpermi2ps ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 77 /r")]
        vpermi2ps_ymm_k1z_ymm_m32bcst = 3274,

        /// <summary>
        /// vpermi2ps ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 77 /r")]
        vpermi2ps_ymm_k1z_ymm_ymm = 3275,

        /// <summary>
        /// vpermi2ps ymm, ymm, m256 | EVEX.256.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps ymm, ymm, m256","EVEX.256.66.0F38.W0 77 /r")]
        vpermi2ps_ymm_ymm_m256 = 3276,

        /// <summary>
        /// vpermi2ps ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 77 /r")]
        vpermi2ps_ymm_ymm_m32bcst = 3277,

        /// <summary>
        /// vpermi2ps ymm, ymm, ymm | EVEX.256.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps ymm, ymm, ymm","EVEX.256.66.0F38.W0 77 /r")]
        vpermi2ps_ymm_ymm_ymm = 3278,

        /// <summary>
        /// vpermi2ps zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 77 /r")]
        vpermi2ps_zmm_k1z_zmm_m32bcst = 3279,

        /// <summary>
        /// vpermi2ps zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 77 /r")]
        vpermi2ps_zmm_k1z_zmm_m512 = 3280,

        /// <summary>
        /// vpermi2ps zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 77 /r")]
        vpermi2ps_zmm_k1z_zmm_zmm = 3281,

        /// <summary>
        /// vpermi2ps zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 77 /r")]
        vpermi2ps_zmm_zmm_m32bcst = 3282,

        /// <summary>
        /// vpermi2ps zmm, zmm, m512 | EVEX.512.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps zmm, zmm, m512","EVEX.512.66.0F38.W0 77 /r")]
        vpermi2ps_zmm_zmm_m512 = 3283,

        /// <summary>
        /// vpermi2ps zmm, zmm, zmm | EVEX.512.66.0F38.W0 77 /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2ps zmm, zmm, zmm","EVEX.512.66.0F38.W0 77 /r")]
        vpermi2ps_zmm_zmm_zmm = 3284,

        /// <summary>
        /// vpermi2q xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 76 /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 76 /r")]
        vpermi2q_xmm_k1z_xmm_m128 = 3285,

        /// <summary>
        /// vpermi2q xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 76 /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 76 /r")]
        vpermi2q_xmm_k1z_xmm_m64bcst = 3286,

        /// <summary>
        /// vpermi2q xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 76 /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 76 /r")]
        vpermi2q_xmm_k1z_xmm_xmm = 3287,

        /// <summary>
        /// vpermi2q xmm, xmm, m128 | EVEX.128.66.0F38.W1 76 /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q xmm, xmm, m128","EVEX.128.66.0F38.W1 76 /r")]
        vpermi2q_xmm_xmm_m128 = 3288,

        /// <summary>
        /// vpermi2q xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 76 /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 76 /r")]
        vpermi2q_xmm_xmm_m64bcst = 3289,

        /// <summary>
        /// vpermi2q xmm, xmm, xmm | EVEX.128.66.0F38.W1 76 /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q xmm, xmm, xmm","EVEX.128.66.0F38.W1 76 /r")]
        vpermi2q_xmm_xmm_xmm = 3290,

        /// <summary>
        /// vpermi2q ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 76 /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 76 /r")]
        vpermi2q_ymm_k1z_ymm_m256 = 3291,

        /// <summary>
        /// vpermi2q ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 76 /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 76 /r")]
        vpermi2q_ymm_k1z_ymm_m64bcst = 3292,

        /// <summary>
        /// vpermi2q ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 76 /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 76 /r")]
        vpermi2q_ymm_k1z_ymm_ymm = 3293,

        /// <summary>
        /// vpermi2q ymm, ymm, m256 | EVEX.256.66.0F38.W1 76 /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q ymm, ymm, m256","EVEX.256.66.0F38.W1 76 /r")]
        vpermi2q_ymm_ymm_m256 = 3294,

        /// <summary>
        /// vpermi2q ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 76 /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 76 /r")]
        vpermi2q_ymm_ymm_m64bcst = 3295,

        /// <summary>
        /// vpermi2q ymm, ymm, ymm | EVEX.256.66.0F38.W1 76 /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q ymm, ymm, ymm","EVEX.256.66.0F38.W1 76 /r")]
        vpermi2q_ymm_ymm_ymm = 3296,

        /// <summary>
        /// vpermi2q zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 76 /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 76 /r")]
        vpermi2q_zmm_k1z_zmm_m512 = 3297,

        /// <summary>
        /// vpermi2q zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 76 /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 76 /r")]
        vpermi2q_zmm_k1z_zmm_m64bcst = 3298,

        /// <summary>
        /// vpermi2q zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 76 /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 76 /r")]
        vpermi2q_zmm_k1z_zmm_zmm = 3299,

        /// <summary>
        /// vpermi2q zmm, zmm, m512 | EVEX.512.66.0F38.W1 76 /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q zmm, zmm, m512","EVEX.512.66.0F38.W1 76 /r")]
        vpermi2q_zmm_zmm_m512 = 3300,

        /// <summary>
        /// vpermi2q zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 76 /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 76 /r")]
        vpermi2q_zmm_zmm_m64bcst = 3301,

        /// <summary>
        /// vpermi2q zmm, zmm, zmm | EVEX.512.66.0F38.W1 76 /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2q zmm, zmm, zmm","EVEX.512.66.0F38.W1 76 /r")]
        vpermi2q_zmm_zmm_zmm = 3302,

        /// <summary>
        /// vpermi2w xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 75 /r | Permute word integers from two tables in xmm3/m128 and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 75 /r")]
        vpermi2w_xmm_k1z_xmm_m128 = 3303,

        /// <summary>
        /// vpermi2w xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.W1 75 /r | Permute word integers from two tables in xmm3/m128 and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.W1 75 /r")]
        vpermi2w_xmm_k1z_xmm_r8 = 3304,

        /// <summary>
        /// vpermi2w xmm, xmm, m128 | EVEX.128.66.0F38.W1 75 /r | Permute word integers from two tables in xmm3/m128 and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w xmm, xmm, m128","EVEX.128.66.0F38.W1 75 /r")]
        vpermi2w_xmm_xmm_m128 = 3305,

        /// <summary>
        /// vpermi2w xmm, xmm, r8 | EVEX.128.66.0F38.W1 75 /r | Permute word integers from two tables in xmm3/m128 and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w xmm, xmm, r8","EVEX.128.66.0F38.W1 75 /r")]
        vpermi2w_xmm_xmm_r8 = 3306,

        /// <summary>
        /// vpermi2w ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 75 /r | Permute word integers from two tables in ymm3/m256 and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 75 /r")]
        vpermi2w_ymm_k1z_ymm_m256 = 3307,

        /// <summary>
        /// vpermi2w ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.W1 75 /r | Permute word integers from two tables in ymm3/m256 and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.W1 75 /r")]
        vpermi2w_ymm_k1z_ymm_r16 = 3308,

        /// <summary>
        /// vpermi2w ymm, ymm, m256 | EVEX.256.66.0F38.W1 75 /r | Permute word integers from two tables in ymm3/m256 and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w ymm, ymm, m256","EVEX.256.66.0F38.W1 75 /r")]
        vpermi2w_ymm_ymm_m256 = 3309,

        /// <summary>
        /// vpermi2w ymm, ymm, r16 | EVEX.256.66.0F38.W1 75 /r | Permute word integers from two tables in ymm3/m256 and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w ymm, ymm, r16","EVEX.256.66.0F38.W1 75 /r")]
        vpermi2w_ymm_ymm_r16 = 3310,

        /// <summary>
        /// vpermi2w zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 75 /r | Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 75 /r")]
        vpermi2w_zmm_k1z_zmm_m512 = 3311,

        /// <summary>
        /// vpermi2w zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.W1 75 /r | Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.W1 75 /r")]
        vpermi2w_zmm_k1z_zmm_r32 = 3312,

        /// <summary>
        /// vpermi2w zmm, zmm, m512 | EVEX.512.66.0F38.W1 75 /r | Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w zmm, zmm, m512","EVEX.512.66.0F38.W1 75 /r")]
        vpermi2w_zmm_zmm_m512 = 3313,

        /// <summary>
        /// vpermi2w zmm, zmm, r32 | EVEX.512.66.0F38.W1 75 /r | Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermi2w zmm, zmm, r32","EVEX.512.66.0F38.W1 75 /r")]
        vpermi2w_zmm_zmm_r32 = 3314,

        /// <summary>
        /// vpermq ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F3A.W1 00 /r ib | Permute qwords in ymm2/m256/m64bcst using indexes in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm {k1}{z}, m256, imm8","EVEX.256.66.0F3A.W1 00 /r ib")]
        vpermq_ymm_k1z_m256_imm8 = 3315,

        /// <summary>
        /// vpermq ymm {k1}{z}, m64bcst, imm8 | EVEX.256.66.0F3A.W1 00 /r ib | Permute qwords in ymm2/m256/m64bcst using indexes in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm {k1}{z}, m64bcst, imm8","EVEX.256.66.0F3A.W1 00 /r ib")]
        vpermq_ymm_k1z_m64bcst_imm8 = 3316,

        /// <summary>
        /// vpermq ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F3A.W1 00 /r ib | Permute qwords in ymm2/m256/m64bcst using indexes in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F3A.W1 00 /r ib")]
        vpermq_ymm_k1z_ymm_imm8 = 3317,

        /// <summary>
        /// vpermq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 36 /r | Permute qwords in ymm3/m256/m64bcst using indexes in ymm2 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 36 /r")]
        vpermq_ymm_k1z_ymm_m256 = 3318,

        /// <summary>
        /// vpermq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 36 /r | Permute qwords in ymm3/m256/m64bcst using indexes in ymm2 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 36 /r")]
        vpermq_ymm_k1z_ymm_m64bcst = 3319,

        /// <summary>
        /// vpermq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 36 /r | Permute qwords in ymm3/m256/m64bcst using indexes in ymm2 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 36 /r")]
        vpermq_ymm_k1z_ymm_ymm = 3320,

        /// <summary>
        /// vpermq ymm, m256, imm8 | EVEX.256.66.0F3A.W1 00 /r ib | Permute qwords in ymm2/m256/m64bcst using indexes in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm, m256, imm8","EVEX.256.66.0F3A.W1 00 /r ib")]
        vpermq_ymm_m256_imm8 = 3321,

        /// <summary>
        /// vpermq ymm, m256, imm8 | VEX.256.66.0F3A.W1 00 /r ib | Permute qwords in ymm2/m256 using indices in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm, m256, imm8","VEX.256.66.0F3A.W1 00 /r ib")]
        vpermq_ymm_m256_imm8_vex = 3322,

        /// <summary>
        /// vpermq ymm, m64bcst, imm8 | EVEX.256.66.0F3A.W1 00 /r ib | Permute qwords in ymm2/m256/m64bcst using indexes in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm, m64bcst, imm8","EVEX.256.66.0F3A.W1 00 /r ib")]
        vpermq_ymm_m64bcst_imm8 = 3323,

        /// <summary>
        /// vpermq ymm, r16, imm8 | VEX.256.66.0F3A.W1 00 /r ib | Permute qwords in ymm2/m256 using indices in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm, r16, imm8","VEX.256.66.0F3A.W1 00 /r ib")]
        vpermq_ymm_r16_imm8 = 3324,

        /// <summary>
        /// vpermq ymm, ymm, imm8 | EVEX.256.66.0F3A.W1 00 /r ib | Permute qwords in ymm2/m256/m64bcst using indexes in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm, ymm, imm8","EVEX.256.66.0F3A.W1 00 /r ib")]
        vpermq_ymm_ymm_imm8 = 3325,

        /// <summary>
        /// vpermq ymm, ymm, m256 | EVEX.256.66.0F38.W1 36 /r | Permute qwords in ymm3/m256/m64bcst using indexes in ymm2 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm, ymm, m256","EVEX.256.66.0F38.W1 36 /r")]
        vpermq_ymm_ymm_m256 = 3326,

        /// <summary>
        /// vpermq ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 36 /r | Permute qwords in ymm3/m256/m64bcst using indexes in ymm2 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 36 /r")]
        vpermq_ymm_ymm_m64bcst = 3327,

        /// <summary>
        /// vpermq ymm, ymm, ymm | EVEX.256.66.0F38.W1 36 /r | Permute qwords in ymm3/m256/m64bcst using indexes in ymm2 and store the result in ymm1.
        /// </summary>
        [Symbol("vpermq ymm, ymm, ymm","EVEX.256.66.0F38.W1 36 /r")]
        vpermq_ymm_ymm_ymm = 3328,

        /// <summary>
        /// vpermq zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F3A.W1 00 /r ib | Permute qwords in zmm2/m512/m64bcst using indices in imm8 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm {k1}{z}, m512, imm8","EVEX.512.66.0F3A.W1 00 /r ib")]
        vpermq_zmm_k1z_m512_imm8 = 3329,

        /// <summary>
        /// vpermq zmm {k1}{z}, m64bcst, imm8 | EVEX.512.66.0F3A.W1 00 /r ib | Permute qwords in zmm2/m512/m64bcst using indices in imm8 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm {k1}{z}, m64bcst, imm8","EVEX.512.66.0F3A.W1 00 /r ib")]
        vpermq_zmm_k1z_m64bcst_imm8 = 3330,

        /// <summary>
        /// vpermq zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F3A.W1 00 /r ib | Permute qwords in zmm2/m512/m64bcst using indices in imm8 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F3A.W1 00 /r ib")]
        vpermq_zmm_k1z_zmm_imm8 = 3331,

        /// <summary>
        /// vpermq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 36 /r | Permute qwords in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 36 /r")]
        vpermq_zmm_k1z_zmm_m512 = 3332,

        /// <summary>
        /// vpermq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 36 /r | Permute qwords in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 36 /r")]
        vpermq_zmm_k1z_zmm_m64bcst = 3333,

        /// <summary>
        /// vpermq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 36 /r | Permute qwords in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 36 /r")]
        vpermq_zmm_k1z_zmm_zmm = 3334,

        /// <summary>
        /// vpermq zmm, m512, imm8 | EVEX.512.66.0F3A.W1 00 /r ib | Permute qwords in zmm2/m512/m64bcst using indices in imm8 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm, m512, imm8","EVEX.512.66.0F3A.W1 00 /r ib")]
        vpermq_zmm_m512_imm8 = 3335,

        /// <summary>
        /// vpermq zmm, m64bcst, imm8 | EVEX.512.66.0F3A.W1 00 /r ib | Permute qwords in zmm2/m512/m64bcst using indices in imm8 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm, m64bcst, imm8","EVEX.512.66.0F3A.W1 00 /r ib")]
        vpermq_zmm_m64bcst_imm8 = 3336,

        /// <summary>
        /// vpermq zmm, zmm, imm8 | EVEX.512.66.0F3A.W1 00 /r ib | Permute qwords in zmm2/m512/m64bcst using indices in imm8 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm, zmm, imm8","EVEX.512.66.0F3A.W1 00 /r ib")]
        vpermq_zmm_zmm_imm8 = 3337,

        /// <summary>
        /// vpermq zmm, zmm, m512 | EVEX.512.66.0F38.W1 36 /r | Permute qwords in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm, zmm, m512","EVEX.512.66.0F38.W1 36 /r")]
        vpermq_zmm_zmm_m512 = 3338,

        /// <summary>
        /// vpermq zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 36 /r | Permute qwords in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 36 /r")]
        vpermq_zmm_zmm_m64bcst = 3339,

        /// <summary>
        /// vpermq zmm, zmm, zmm | EVEX.512.66.0F38.W1 36 /r | Permute qwords in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1.
        /// </summary>
        [Symbol("vpermq zmm, zmm, zmm","EVEX.512.66.0F38.W1 36 /r")]
        vpermq_zmm_zmm_zmm = 3340,

        /// <summary>
        /// vpermt2b xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 7D /r | Permute bytes in xmm3/m128 and xmm1 using byte indexes in xmm2 and store the byte results in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 7D /r")]
        vpermt2b_xmm_k1z_xmm_m128 = 3341,

        /// <summary>
        /// vpermt2b xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.W0 7D /r | Permute bytes in xmm3/m128 and xmm1 using byte indexes in xmm2 and store the byte results in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.W0 7D /r")]
        vpermt2b_xmm_k1z_xmm_r8 = 3342,

        /// <summary>
        /// vpermt2b xmm, xmm, m128 | EVEX.128.66.0F38.W0 7D /r | Permute bytes in xmm3/m128 and xmm1 using byte indexes in xmm2 and store the byte results in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b xmm, xmm, m128","EVEX.128.66.0F38.W0 7D /r")]
        vpermt2b_xmm_xmm_m128 = 3343,

        /// <summary>
        /// vpermt2b xmm, xmm, r8 | EVEX.128.66.0F38.W0 7D /r | Permute bytes in xmm3/m128 and xmm1 using byte indexes in xmm2 and store the byte results in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b xmm, xmm, r8","EVEX.128.66.0F38.W0 7D /r")]
        vpermt2b_xmm_xmm_r8 = 3344,

        /// <summary>
        /// vpermt2b ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 7D /r | Permute bytes in ymm3/m256 and ymm1 using byte indexes in ymm2 and store the byte results in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 7D /r")]
        vpermt2b_ymm_k1z_ymm_m256 = 3345,

        /// <summary>
        /// vpermt2b ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.W0 7D /r | Permute bytes in ymm3/m256 and ymm1 using byte indexes in ymm2 and store the byte results in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.W0 7D /r")]
        vpermt2b_ymm_k1z_ymm_r16 = 3346,

        /// <summary>
        /// vpermt2b ymm, ymm, m256 | EVEX.256.66.0F38.W0 7D /r | Permute bytes in ymm3/m256 and ymm1 using byte indexes in ymm2 and store the byte results in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b ymm, ymm, m256","EVEX.256.66.0F38.W0 7D /r")]
        vpermt2b_ymm_ymm_m256 = 3347,

        /// <summary>
        /// vpermt2b ymm, ymm, r16 | EVEX.256.66.0F38.W0 7D /r | Permute bytes in ymm3/m256 and ymm1 using byte indexes in ymm2 and store the byte results in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b ymm, ymm, r16","EVEX.256.66.0F38.W0 7D /r")]
        vpermt2b_ymm_ymm_r16 = 3348,

        /// <summary>
        /// vpermt2b zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 7D /r | Permute bytes in zmm3/m512 and zmm1 using byte indexes in zmm2 and store the byte results in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 7D /r")]
        vpermt2b_zmm_k1z_zmm_m512 = 3349,

        /// <summary>
        /// vpermt2b zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.W0 7D /r | Permute bytes in zmm3/m512 and zmm1 using byte indexes in zmm2 and store the byte results in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.W0 7D /r")]
        vpermt2b_zmm_k1z_zmm_r32 = 3350,

        /// <summary>
        /// vpermt2b zmm, zmm, m512 | EVEX.512.66.0F38.W0 7D /r | Permute bytes in zmm3/m512 and zmm1 using byte indexes in zmm2 and store the byte results in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b zmm, zmm, m512","EVEX.512.66.0F38.W0 7D /r")]
        vpermt2b_zmm_zmm_m512 = 3351,

        /// <summary>
        /// vpermt2b zmm, zmm, r32 | EVEX.512.66.0F38.W0 7D /r | Permute bytes in zmm3/m512 and zmm1 using byte indexes in zmm2 and store the byte results in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2b zmm, zmm, r32","EVEX.512.66.0F38.W0 7D /r")]
        vpermt2b_zmm_zmm_r32 = 3352,

        /// <summary>
        /// vpermt2d xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 7E /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 7E /r")]
        vpermt2d_xmm_k1z_xmm_m128 = 3353,

        /// <summary>
        /// vpermt2d xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 7E /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 7E /r")]
        vpermt2d_xmm_k1z_xmm_m32bcst = 3354,

        /// <summary>
        /// vpermt2d xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 7E /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 7E /r")]
        vpermt2d_xmm_k1z_xmm_xmm = 3355,

        /// <summary>
        /// vpermt2d xmm, xmm, m128 | EVEX.128.66.0F38.W0 7E /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d xmm, xmm, m128","EVEX.128.66.0F38.W0 7E /r")]
        vpermt2d_xmm_xmm_m128 = 3356,

        /// <summary>
        /// vpermt2d xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 7E /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 7E /r")]
        vpermt2d_xmm_xmm_m32bcst = 3357,

        /// <summary>
        /// vpermt2d xmm, xmm, xmm | EVEX.128.66.0F38.W0 7E /r | Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d xmm, xmm, xmm","EVEX.128.66.0F38.W0 7E /r")]
        vpermt2d_xmm_xmm_xmm = 3358,

        /// <summary>
        /// vpermt2d ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 7E /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 7E /r")]
        vpermt2d_ymm_k1z_ymm_m256 = 3359,

        /// <summary>
        /// vpermt2d ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 7E /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 7E /r")]
        vpermt2d_ymm_k1z_ymm_m32bcst = 3360,

        /// <summary>
        /// vpermt2d ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 7E /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 7E /r")]
        vpermt2d_ymm_k1z_ymm_ymm = 3361,

        /// <summary>
        /// vpermt2d ymm, ymm, m256 | EVEX.256.66.0F38.W0 7E /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d ymm, ymm, m256","EVEX.256.66.0F38.W0 7E /r")]
        vpermt2d_ymm_ymm_m256 = 3362,

        /// <summary>
        /// vpermt2d ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 7E /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 7E /r")]
        vpermt2d_ymm_ymm_m32bcst = 3363,

        /// <summary>
        /// vpermt2d ymm, ymm, ymm | EVEX.256.66.0F38.W0 7E /r | Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d ymm, ymm, ymm","EVEX.256.66.0F38.W0 7E /r")]
        vpermt2d_ymm_ymm_ymm = 3364,

        /// <summary>
        /// vpermt2d zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 7E /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 7E /r")]
        vpermt2d_zmm_k1z_zmm_m32bcst = 3365,

        /// <summary>
        /// vpermt2d zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 7E /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 7E /r")]
        vpermt2d_zmm_k1z_zmm_m512 = 3366,

        /// <summary>
        /// vpermt2d zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 7E /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 7E /r")]
        vpermt2d_zmm_k1z_zmm_zmm = 3367,

        /// <summary>
        /// vpermt2d zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 7E /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 7E /r")]
        vpermt2d_zmm_zmm_m32bcst = 3368,

        /// <summary>
        /// vpermt2d zmm, zmm, m512 | EVEX.512.66.0F38.W0 7E /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d zmm, zmm, m512","EVEX.512.66.0F38.W0 7E /r")]
        vpermt2d_zmm_zmm_m512 = 3369,

        /// <summary>
        /// vpermt2d zmm, zmm, zmm | EVEX.512.66.0F38.W0 7E /r | Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2d zmm, zmm, zmm","EVEX.512.66.0F38.W0 7E /r")]
        vpermt2d_zmm_zmm_zmm = 3370,

        /// <summary>
        /// vpermt2pd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 7F /r")]
        vpermt2pd_xmm_k1z_xmm_m128 = 3371,

        /// <summary>
        /// vpermt2pd xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 7F /r")]
        vpermt2pd_xmm_k1z_xmm_m64bcst = 3372,

        /// <summary>
        /// vpermt2pd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 7F /r")]
        vpermt2pd_xmm_k1z_xmm_xmm = 3373,

        /// <summary>
        /// vpermt2pd xmm, xmm, m128 | EVEX.128.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd xmm, xmm, m128","EVEX.128.66.0F38.W1 7F /r")]
        vpermt2pd_xmm_xmm_m128 = 3374,

        /// <summary>
        /// vpermt2pd xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 7F /r")]
        vpermt2pd_xmm_xmm_m64bcst = 3375,

        /// <summary>
        /// vpermt2pd xmm, xmm, xmm | EVEX.128.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd xmm, xmm, xmm","EVEX.128.66.0F38.W1 7F /r")]
        vpermt2pd_xmm_xmm_xmm = 3376,

        /// <summary>
        /// vpermt2pd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 7F /r")]
        vpermt2pd_ymm_k1z_ymm_m256 = 3377,

        /// <summary>
        /// vpermt2pd ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 7F /r")]
        vpermt2pd_ymm_k1z_ymm_m64bcst = 3378,

        /// <summary>
        /// vpermt2pd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 7F /r")]
        vpermt2pd_ymm_k1z_ymm_ymm = 3379,

        /// <summary>
        /// vpermt2pd ymm, ymm, m256 | EVEX.256.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd ymm, ymm, m256","EVEX.256.66.0F38.W1 7F /r")]
        vpermt2pd_ymm_ymm_m256 = 3380,

        /// <summary>
        /// vpermt2pd ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 7F /r")]
        vpermt2pd_ymm_ymm_m64bcst = 3381,

        /// <summary>
        /// vpermt2pd ymm, ymm, ymm | EVEX.256.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd ymm, ymm, ymm","EVEX.256.66.0F38.W1 7F /r")]
        vpermt2pd_ymm_ymm_ymm = 3382,

        /// <summary>
        /// vpermt2pd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 7F /r")]
        vpermt2pd_zmm_k1z_zmm_m512 = 3383,

        /// <summary>
        /// vpermt2pd zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 7F /r")]
        vpermt2pd_zmm_k1z_zmm_m64bcst = 3384,

        /// <summary>
        /// vpermt2pd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 7F /r")]
        vpermt2pd_zmm_k1z_zmm_zmm = 3385,

        /// <summary>
        /// vpermt2pd zmm, zmm, m512 | EVEX.512.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd zmm, zmm, m512","EVEX.512.66.0F38.W1 7F /r")]
        vpermt2pd_zmm_zmm_m512 = 3386,

        /// <summary>
        /// vpermt2pd zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 7F /r")]
        vpermt2pd_zmm_zmm_m64bcst = 3387,

        /// <summary>
        /// vpermt2pd zmm, zmm, zmm | EVEX.512.66.0F38.W1 7F /r | Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2pd zmm, zmm, zmm","EVEX.512.66.0F38.W1 7F /r")]
        vpermt2pd_zmm_zmm_zmm = 3388,

        /// <summary>
        /// vpermt2ps xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 7F /r")]
        vpermt2ps_xmm_k1z_xmm_m128 = 3389,

        /// <summary>
        /// vpermt2ps xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 7F /r")]
        vpermt2ps_xmm_k1z_xmm_m32bcst = 3390,

        /// <summary>
        /// vpermt2ps xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 7F /r")]
        vpermt2ps_xmm_k1z_xmm_xmm = 3391,

        /// <summary>
        /// vpermt2ps xmm, xmm, m128 | EVEX.128.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps xmm, xmm, m128","EVEX.128.66.0F38.W0 7F /r")]
        vpermt2ps_xmm_xmm_m128 = 3392,

        /// <summary>
        /// vpermt2ps xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 7F /r")]
        vpermt2ps_xmm_xmm_m32bcst = 3393,

        /// <summary>
        /// vpermt2ps xmm, xmm, xmm | EVEX.128.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps xmm, xmm, xmm","EVEX.128.66.0F38.W0 7F /r")]
        vpermt2ps_xmm_xmm_xmm = 3394,

        /// <summary>
        /// vpermt2ps ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 7F /r")]
        vpermt2ps_ymm_k1z_ymm_m256 = 3395,

        /// <summary>
        /// vpermt2ps ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 7F /r")]
        vpermt2ps_ymm_k1z_ymm_m32bcst = 3396,

        /// <summary>
        /// vpermt2ps ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 7F /r")]
        vpermt2ps_ymm_k1z_ymm_ymm = 3397,

        /// <summary>
        /// vpermt2ps ymm, ymm, m256 | EVEX.256.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps ymm, ymm, m256","EVEX.256.66.0F38.W0 7F /r")]
        vpermt2ps_ymm_ymm_m256 = 3398,

        /// <summary>
        /// vpermt2ps ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 7F /r")]
        vpermt2ps_ymm_ymm_m32bcst = 3399,

        /// <summary>
        /// vpermt2ps ymm, ymm, ymm | EVEX.256.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps ymm, ymm, ymm","EVEX.256.66.0F38.W0 7F /r")]
        vpermt2ps_ymm_ymm_ymm = 3400,

        /// <summary>
        /// vpermt2ps zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 7F /r")]
        vpermt2ps_zmm_k1z_zmm_m32bcst = 3401,

        /// <summary>
        /// vpermt2ps zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 7F /r")]
        vpermt2ps_zmm_k1z_zmm_m512 = 3402,

        /// <summary>
        /// vpermt2ps zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 7F /r")]
        vpermt2ps_zmm_k1z_zmm_zmm = 3403,

        /// <summary>
        /// vpermt2ps zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 7F /r")]
        vpermt2ps_zmm_zmm_m32bcst = 3404,

        /// <summary>
        /// vpermt2ps zmm, zmm, m512 | EVEX.512.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps zmm, zmm, m512","EVEX.512.66.0F38.W0 7F /r")]
        vpermt2ps_zmm_zmm_m512 = 3405,

        /// <summary>
        /// vpermt2ps zmm, zmm, zmm | EVEX.512.66.0F38.W0 7F /r | Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2ps zmm, zmm, zmm","EVEX.512.66.0F38.W0 7F /r")]
        vpermt2ps_zmm_zmm_zmm = 3406,

        /// <summary>
        /// vpermt2q xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 7E /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 7E /r")]
        vpermt2q_xmm_k1z_xmm_m128 = 3407,

        /// <summary>
        /// vpermt2q xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 7E /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 7E /r")]
        vpermt2q_xmm_k1z_xmm_m64bcst = 3408,

        /// <summary>
        /// vpermt2q xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 7E /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 7E /r")]
        vpermt2q_xmm_k1z_xmm_xmm = 3409,

        /// <summary>
        /// vpermt2q xmm, xmm, m128 | EVEX.128.66.0F38.W1 7E /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q xmm, xmm, m128","EVEX.128.66.0F38.W1 7E /r")]
        vpermt2q_xmm_xmm_m128 = 3410,

        /// <summary>
        /// vpermt2q xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 7E /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 7E /r")]
        vpermt2q_xmm_xmm_m64bcst = 3411,

        /// <summary>
        /// vpermt2q xmm, xmm, xmm | EVEX.128.66.0F38.W1 7E /r | Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q xmm, xmm, xmm","EVEX.128.66.0F38.W1 7E /r")]
        vpermt2q_xmm_xmm_xmm = 3412,

        /// <summary>
        /// vpermt2q ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 7E /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 7E /r")]
        vpermt2q_ymm_k1z_ymm_m256 = 3413,

        /// <summary>
        /// vpermt2q ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 7E /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 7E /r")]
        vpermt2q_ymm_k1z_ymm_m64bcst = 3414,

        /// <summary>
        /// vpermt2q ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 7E /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 7E /r")]
        vpermt2q_ymm_k1z_ymm_ymm = 3415,

        /// <summary>
        /// vpermt2q ymm, ymm, m256 | EVEX.256.66.0F38.W1 7E /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q ymm, ymm, m256","EVEX.256.66.0F38.W1 7E /r")]
        vpermt2q_ymm_ymm_m256 = 3416,

        /// <summary>
        /// vpermt2q ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 7E /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 7E /r")]
        vpermt2q_ymm_ymm_m64bcst = 3417,

        /// <summary>
        /// vpermt2q ymm, ymm, ymm | EVEX.256.66.0F38.W1 7E /r | Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q ymm, ymm, ymm","EVEX.256.66.0F38.W1 7E /r")]
        vpermt2q_ymm_ymm_ymm = 3418,

        /// <summary>
        /// vpermt2q zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 7E /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 7E /r")]
        vpermt2q_zmm_k1z_zmm_m512 = 3419,

        /// <summary>
        /// vpermt2q zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 7E /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 7E /r")]
        vpermt2q_zmm_k1z_zmm_m64bcst = 3420,

        /// <summary>
        /// vpermt2q zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 7E /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 7E /r")]
        vpermt2q_zmm_k1z_zmm_zmm = 3421,

        /// <summary>
        /// vpermt2q zmm, zmm, m512 | EVEX.512.66.0F38.W1 7E /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q zmm, zmm, m512","EVEX.512.66.0F38.W1 7E /r")]
        vpermt2q_zmm_zmm_m512 = 3422,

        /// <summary>
        /// vpermt2q zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 7E /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 7E /r")]
        vpermt2q_zmm_zmm_m64bcst = 3423,

        /// <summary>
        /// vpermt2q zmm, zmm, zmm | EVEX.512.66.0F38.W1 7E /r | Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2q zmm, zmm, zmm","EVEX.512.66.0F38.W1 7E /r")]
        vpermt2q_zmm_zmm_zmm = 3424,

        /// <summary>
        /// vpermt2w xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 7D /r | Permute word integers from two tables in xmm3/m128 and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 7D /r")]
        vpermt2w_xmm_k1z_xmm_m128 = 3425,

        /// <summary>
        /// vpermt2w xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.W1 7D /r | Permute word integers from two tables in xmm3/m128 and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.W1 7D /r")]
        vpermt2w_xmm_k1z_xmm_r8 = 3426,

        /// <summary>
        /// vpermt2w xmm, xmm, m128 | EVEX.128.66.0F38.W1 7D /r | Permute word integers from two tables in xmm3/m128 and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w xmm, xmm, m128","EVEX.128.66.0F38.W1 7D /r")]
        vpermt2w_xmm_xmm_m128 = 3427,

        /// <summary>
        /// vpermt2w xmm, xmm, r8 | EVEX.128.66.0F38.W1 7D /r | Permute word integers from two tables in xmm3/m128 and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w xmm, xmm, r8","EVEX.128.66.0F38.W1 7D /r")]
        vpermt2w_xmm_xmm_r8 = 3428,

        /// <summary>
        /// vpermt2w ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 7D /r | Permute word integers from two tables in ymm3/m256 and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 7D /r")]
        vpermt2w_ymm_k1z_ymm_m256 = 3429,

        /// <summary>
        /// vpermt2w ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.W1 7D /r | Permute word integers from two tables in ymm3/m256 and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.W1 7D /r")]
        vpermt2w_ymm_k1z_ymm_r16 = 3430,

        /// <summary>
        /// vpermt2w ymm, ymm, m256 | EVEX.256.66.0F38.W1 7D /r | Permute word integers from two tables in ymm3/m256 and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w ymm, ymm, m256","EVEX.256.66.0F38.W1 7D /r")]
        vpermt2w_ymm_ymm_m256 = 3431,

        /// <summary>
        /// vpermt2w ymm, ymm, r16 | EVEX.256.66.0F38.W1 7D /r | Permute word integers from two tables in ymm3/m256 and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w ymm, ymm, r16","EVEX.256.66.0F38.W1 7D /r")]
        vpermt2w_ymm_ymm_r16 = 3432,

        /// <summary>
        /// vpermt2w zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 7D /r | Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 7D /r")]
        vpermt2w_zmm_k1z_zmm_m512 = 3433,

        /// <summary>
        /// vpermt2w zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.W1 7D /r | Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.W1 7D /r")]
        vpermt2w_zmm_k1z_zmm_r32 = 3434,

        /// <summary>
        /// vpermt2w zmm, zmm, m512 | EVEX.512.66.0F38.W1 7D /r | Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w zmm, zmm, m512","EVEX.512.66.0F38.W1 7D /r")]
        vpermt2w_zmm_zmm_m512 = 3435,

        /// <summary>
        /// vpermt2w zmm, zmm, r32 | EVEX.512.66.0F38.W1 7D /r | Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermt2w zmm, zmm, r32","EVEX.512.66.0F38.W1 7D /r")]
        vpermt2w_zmm_zmm_r32 = 3436,

        /// <summary>
        /// vpermw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 8D /r | Permute word integers in xmm3/m128 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 8D /r")]
        vpermw_xmm_k1z_xmm_m128 = 3437,

        /// <summary>
        /// vpermw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.W1 8D /r | Permute word integers in xmm3/m128 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.W1 8D /r")]
        vpermw_xmm_k1z_xmm_r8 = 3438,

        /// <summary>
        /// vpermw xmm, xmm, m128 | EVEX.128.66.0F38.W1 8D /r | Permute word integers in xmm3/m128 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw xmm, xmm, m128","EVEX.128.66.0F38.W1 8D /r")]
        vpermw_xmm_xmm_m128 = 3439,

        /// <summary>
        /// vpermw xmm, xmm, r8 | EVEX.128.66.0F38.W1 8D /r | Permute word integers in xmm3/m128 using indexes in xmm2 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw xmm, xmm, r8","EVEX.128.66.0F38.W1 8D /r")]
        vpermw_xmm_xmm_r8 = 3440,

        /// <summary>
        /// vpermw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 8D /r | Permute word integers in ymm3/m256 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 8D /r")]
        vpermw_ymm_k1z_ymm_m256 = 3441,

        /// <summary>
        /// vpermw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.W1 8D /r | Permute word integers in ymm3/m256 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.W1 8D /r")]
        vpermw_ymm_k1z_ymm_r16 = 3442,

        /// <summary>
        /// vpermw ymm, ymm, m256 | EVEX.256.66.0F38.W1 8D /r | Permute word integers in ymm3/m256 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw ymm, ymm, m256","EVEX.256.66.0F38.W1 8D /r")]
        vpermw_ymm_ymm_m256 = 3443,

        /// <summary>
        /// vpermw ymm, ymm, r16 | EVEX.256.66.0F38.W1 8D /r | Permute word integers in ymm3/m256 using indexes in ymm2 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw ymm, ymm, r16","EVEX.256.66.0F38.W1 8D /r")]
        vpermw_ymm_ymm_r16 = 3444,

        /// <summary>
        /// vpermw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 8D /r | Permute word integers in zmm3/m512 using indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 8D /r")]
        vpermw_zmm_k1z_zmm_m512 = 3445,

        /// <summary>
        /// vpermw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.W1 8D /r | Permute word integers in zmm3/m512 using indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.W1 8D /r")]
        vpermw_zmm_k1z_zmm_r32 = 3446,

        /// <summary>
        /// vpermw zmm, zmm, m512 | EVEX.512.66.0F38.W1 8D /r | Permute word integers in zmm3/m512 using indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw zmm, zmm, m512","EVEX.512.66.0F38.W1 8D /r")]
        vpermw_zmm_zmm_m512 = 3447,

        /// <summary>
        /// vpermw zmm, zmm, r32 | EVEX.512.66.0F38.W1 8D /r | Permute word integers in zmm3/m512 using indexes in zmm2 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpermw zmm, zmm, r32","EVEX.512.66.0F38.W1 8D /r")]
        vpermw_zmm_zmm_r32 = 3448,

        /// <summary>
        /// vpextrb m8, xmm, imm8 | EVEX.128.66.0F3A.WIG 14 /r ib | Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r64/r32 is filled with zeros.
        /// </summary>
        [Symbol("vpextrb m8, xmm, imm8","EVEX.128.66.0F3A.WIG 14 /r ib")]
        vpextrb_m8_xmm_imm8 = 3449,

        /// <summary>
        /// vpextrb m8, xmm, imm8 | VEX.128.66.0F3A.W0 14 /r ib | Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r64/r32 is filled with zeros.
        /// </summary>
        [Symbol("vpextrb m8, xmm, imm8","VEX.128.66.0F3A.W0 14 /r ib")]
        vpextrb_m8_xmm_imm8_vex = 3450,

        /// <summary>
        /// vpextrb r8, xmm, imm8 | EVEX.128.66.0F3A.WIG 14 /r ib | Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r64/r32 is filled with zeros.
        /// </summary>
        [Symbol("vpextrb r8, xmm, imm8","EVEX.128.66.0F3A.WIG 14 /r ib")]
        vpextrb_r8_xmm_imm8 = 3451,

        /// <summary>
        /// vpextrb r8, xmm, imm8 | VEX.128.66.0F3A.W0 14 /r ib | Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r64/r32 is filled with zeros.
        /// </summary>
        [Symbol("vpextrb r8, xmm, imm8","VEX.128.66.0F3A.W0 14 /r ib")]
        vpextrb_r8_xmm_imm8_vex = 3452,

        /// <summary>
        /// vpextrd m32, xmm, imm8 | VEX.128.66.0F3A.W0 16 /r ib | Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.
        /// </summary>
        [Symbol("vpextrd m32, xmm, imm8","VEX.128.66.0F3A.W0 16 /r ib")]
        vpextrd_m32_xmm_imm8 = 3453,

        /// <summary>
        /// vpextrd m32, xmm, imm8 | EVEX.128.66.0F3A.W0 16 /r ib | Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.
        /// </summary>
        [Symbol("vpextrd m32, xmm, imm8","EVEX.128.66.0F3A.W0 16 /r ib")]
        vpextrd_m32_xmm_imm8_evex = 3454,

        /// <summary>
        /// vpextrd r32, xmm, imm8 | VEX.128.66.0F3A.W0 16 /r ib | Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.
        /// </summary>
        [Symbol("vpextrd r32, xmm, imm8","VEX.128.66.0F3A.W0 16 /r ib")]
        vpextrd_r32_xmm_imm8 = 3455,

        /// <summary>
        /// vpextrd r32, xmm, imm8 | EVEX.128.66.0F3A.W0 16 /r ib | Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.
        /// </summary>
        [Symbol("vpextrd r32, xmm, imm8","EVEX.128.66.0F3A.W0 16 /r ib")]
        vpextrd_r32_xmm_imm8_evex = 3456,

        /// <summary>
        /// vpextrq m64, xmm, imm8 | VEX.128.66.0F3A.W1 16 /r ib | Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.
        /// </summary>
        [Symbol("vpextrq m64, xmm, imm8","VEX.128.66.0F3A.W1 16 /r ib")]
        vpextrq_m64_xmm_imm8 = 3457,

        /// <summary>
        /// vpextrq m64, xmm, imm8 | EVEX.128.66.0F3A.W1 16 /r ib | Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.
        /// </summary>
        [Symbol("vpextrq m64, xmm, imm8","EVEX.128.66.0F3A.W1 16 /r ib")]
        vpextrq_m64_xmm_imm8_evex = 3458,

        /// <summary>
        /// vpextrq r64, xmm, imm8 | VEX.128.66.0F3A.W1 16 /r ib | Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.
        /// </summary>
        [Symbol("vpextrq r64, xmm, imm8","VEX.128.66.0F3A.W1 16 /r ib")]
        vpextrq_r64_xmm_imm8 = 3459,

        /// <summary>
        /// vpextrq r64, xmm, imm8 | EVEX.128.66.0F3A.W1 16 /r ib | Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.
        /// </summary>
        [Symbol("vpextrq r64, xmm, imm8","EVEX.128.66.0F3A.W1 16 /r ib")]
        vpextrq_r64_xmm_imm8_evex = 3460,

        /// <summary>
        /// vpextrw m16, xmm, imm8 | VEX.128.66.0F3A.W0 15 /r ib | Extract a word integer value from xmm2 at the source word offset specified by imm8 into reg or m16. The upper bits of r64/r32 is filled with zeros.
        /// </summary>
        [Symbol("vpextrw m16, xmm, imm8","VEX.128.66.0F3A.W0 15 /r ib")]
        vpextrw_m16_xmm_imm8 = 3461,

        /// <summary>
        /// vpextrw m16, xmm, imm8 | EVEX.128.66.0F3A.WIG 15 /r ib | Extract a word integer value from xmm2 at the source word offset specified by imm8 into reg or m16. The upper bits of r64/r32 is filled with zeros.
        /// </summary>
        [Symbol("vpextrw m16, xmm, imm8","EVEX.128.66.0F3A.WIG 15 /r ib")]
        vpextrw_m16_xmm_imm8_evex = 3462,

        /// <summary>
        /// vpextrw r16, xmm, imm8 | VEX.128.66.0F3A.W0 15 /r ib | Extract a word integer value from xmm2 at the source word offset specified by imm8 into reg or m16. The upper bits of r64/r32 is filled with zeros.
        /// </summary>
        [Symbol("vpextrw r16, xmm, imm8","VEX.128.66.0F3A.W0 15 /r ib")]
        vpextrw_r16_xmm_imm8 = 3463,

        /// <summary>
        /// vpextrw r16, xmm, imm8 | EVEX.128.66.0F3A.WIG 15 /r ib | Extract a word integer value from xmm2 at the source word offset specified by imm8 into reg or m16. The upper bits of r64/r32 is filled with zeros.
        /// </summary>
        [Symbol("vpextrw r16, xmm, imm8","EVEX.128.66.0F3A.WIG 15 /r ib")]
        vpextrw_r16_xmm_imm8_evex = 3464,

        /// <summary>
        /// vpextrw reg, xmm, imm8 | VEX.128.66.0F.W0 C5 /r ib | Extract the word specified by imm8 from xmm1 and move it to reg, bits 15:0. Zero-extend the result. The upper bits of r64/r32 is filled with zeros.
        /// </summary>
        [Symbol("vpextrw reg, xmm, imm8","VEX.128.66.0F.W0 C5 /r ib")]
        vpextrw_reg_xmm_imm8 = 3465,

        /// <summary>
        /// vpextrw reg, xmm, imm8 | EVEX.128.66.0F.WIG C5 /r ib | Extract the word specified by imm8 from xmm1 and move it to reg, bits 15:0. Zero-extend the result. The upper bits of r64/r32 is filled with zeros.
        /// </summary>
        [Symbol("vpextrw reg, xmm, imm8","EVEX.128.66.0F.WIG C5 /r ib")]
        vpextrw_reg_xmm_imm8_evex = 3466,

        /// <summary>
        /// vpgatherdd xmm {k1}, vm32x | EVEX.128.66.0F38.W0 90 /vsib | Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdd xmm {k1}, vm32x","EVEX.128.66.0F38.W0 90 /vsib")]
        vpgatherdd_xmm_k1_vm32x = 3467,

        /// <summary>
        /// vpgatherdd xmm, vm32x | EVEX.128.66.0F38.W0 90 /vsib | Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdd xmm, vm32x","EVEX.128.66.0F38.W0 90 /vsib")]
        vpgatherdd_xmm_vm32x = 3468,

        /// <summary>
        /// vpgatherdd xmm, vm32x, xmm | VEX.128.66.0F38.W0 90 /r | Using dword indices specified in vm32x, gather dword values from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.
        /// </summary>
        [Symbol("vpgatherdd xmm, vm32x, xmm","VEX.128.66.0F38.W0 90 /r")]
        vpgatherdd_xmm_vm32x_xmm = 3469,

        /// <summary>
        /// vpgatherdd ymm {k1}, vm32y | EVEX.256.66.0F38.W0 90 /vsib | Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdd ymm {k1}, vm32y","EVEX.256.66.0F38.W0 90 /vsib")]
        vpgatherdd_ymm_k1_vm32y = 3470,

        /// <summary>
        /// vpgatherdd ymm, vm32y | EVEX.256.66.0F38.W0 90 /vsib | Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdd ymm, vm32y","EVEX.256.66.0F38.W0 90 /vsib")]
        vpgatherdd_ymm_vm32y = 3471,

        /// <summary>
        /// vpgatherdd ymm, vm32y, ymm | VEX.256.66.0F38.W0 90 /r | Using dword indices specified in vm32y, gather dword from memory conditioned on mask specified by ymm2. Conditionally gathered elements are merged into ymm1.
        /// </summary>
        [Symbol("vpgatherdd ymm, vm32y, ymm","VEX.256.66.0F38.W0 90 /r")]
        vpgatherdd_ymm_vm32y_ymm = 3472,

        /// <summary>
        /// vpgatherdd zmm {k1}, vm32z | EVEX.512.66.0F38.W0 90 /vsib | Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdd zmm {k1}, vm32z","EVEX.512.66.0F38.W0 90 /vsib")]
        vpgatherdd_zmm_k1_vm32z = 3473,

        /// <summary>
        /// vpgatherdd zmm, vm32z | EVEX.512.66.0F38.W0 90 /vsib | Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdd zmm, vm32z","EVEX.512.66.0F38.W0 90 /vsib")]
        vpgatherdd_zmm_vm32z = 3474,

        /// <summary>
        /// vpgatherdq xmm {k1}, vm32x | EVEX.128.66.0F38.W1 90 /vsib | Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdq xmm {k1}, vm32x","EVEX.128.66.0F38.W1 90 /vsib")]
        vpgatherdq_xmm_k1_vm32x = 3475,

        /// <summary>
        /// vpgatherdq xmm, vm32x | EVEX.128.66.0F38.W1 90 /vsib | Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdq xmm, vm32x","EVEX.128.66.0F38.W1 90 /vsib")]
        vpgatherdq_xmm_vm32x = 3476,

        /// <summary>
        /// vpgatherdq xmm, vm32x, xmm | VEX.128.66.0F38.W1 90 /r | Using dword indices specified in vm32x, gather qword values from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.
        /// </summary>
        [Symbol("vpgatherdq xmm, vm32x, xmm","VEX.128.66.0F38.W1 90 /r")]
        vpgatherdq_xmm_vm32x_xmm = 3477,

        /// <summary>
        /// vpgatherdq ymm {k1}, vm32x | EVEX.256.66.0F38.W1 90 /vsib | Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdq ymm {k1}, vm32x","EVEX.256.66.0F38.W1 90 /vsib")]
        vpgatherdq_ymm_k1_vm32x = 3478,

        /// <summary>
        /// vpgatherdq ymm, vm32x | EVEX.256.66.0F38.W1 90 /vsib | Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdq ymm, vm32x","EVEX.256.66.0F38.W1 90 /vsib")]
        vpgatherdq_ymm_vm32x = 3479,

        /// <summary>
        /// vpgatherdq ymm, vm32x, ymm | VEX.256.66.0F38.W1 90 /r | Using dword indices specified in vm32x, gather qword values from memory conditioned on mask specified by ymm2. Conditionally gathered elements are merged into ymm1.
        /// </summary>
        [Symbol("vpgatherdq ymm, vm32x, ymm","VEX.256.66.0F38.W1 90 /r")]
        vpgatherdq_ymm_vm32x_ymm = 3480,

        /// <summary>
        /// vpgatherdq zmm {k1}, vm32y | EVEX.512.66.0F38.W1 90 /vsib | Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdq zmm {k1}, vm32y","EVEX.512.66.0F38.W1 90 /vsib")]
        vpgatherdq_zmm_k1_vm32y = 3481,

        /// <summary>
        /// vpgatherdq zmm, vm32y | EVEX.512.66.0F38.W1 90 /vsib | Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherdq zmm, vm32y","EVEX.512.66.0F38.W1 90 /vsib")]
        vpgatherdq_zmm_vm32y = 3482,

        /// <summary>
        /// vpgatherqd xmm {k1}, vm64x | EVEX.128.66.0F38.W0 91 /vsib | Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqd xmm {k1}, vm64x","EVEX.128.66.0F38.W0 91 /vsib")]
        vpgatherqd_xmm_k1_vm64x = 3483,

        /// <summary>
        /// vpgatherqd xmm {k1}, vm64y | EVEX.256.66.0F38.W0 91 /vsib | Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqd xmm {k1}, vm64y","EVEX.256.66.0F38.W0 91 /vsib")]
        vpgatherqd_xmm_k1_vm64y = 3484,

        /// <summary>
        /// vpgatherqd xmm, vm64x | EVEX.128.66.0F38.W0 91 /vsib | Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqd xmm, vm64x","EVEX.128.66.0F38.W0 91 /vsib")]
        vpgatherqd_xmm_vm64x = 3485,

        /// <summary>
        /// vpgatherqd xmm, vm64x, xmm | VEX.128.66.0F38.W0 91 /r | Using qword indices specified in vm64x, gather dword values from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.
        /// </summary>
        [Symbol("vpgatherqd xmm, vm64x, xmm","VEX.128.66.0F38.W0 91 /r")]
        vpgatherqd_xmm_vm64x_xmm = 3486,

        /// <summary>
        /// vpgatherqd xmm, vm64y | EVEX.256.66.0F38.W0 91 /vsib | Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqd xmm, vm64y","EVEX.256.66.0F38.W0 91 /vsib")]
        vpgatherqd_xmm_vm64y = 3487,

        /// <summary>
        /// vpgatherqd xmm, vm64y, xmm | VEX.256.66.0F38.W0 91 /r | Using qword indices specified in vm64y, gather dword values from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.
        /// </summary>
        [Symbol("vpgatherqd xmm, vm64y, xmm","VEX.256.66.0F38.W0 91 /r")]
        vpgatherqd_xmm_vm64y_xmm = 3488,

        /// <summary>
        /// vpgatherqd ymm {k1}, vm64z | EVEX.512.66.0F38.W0 91 /vsib | Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqd ymm {k1}, vm64z","EVEX.512.66.0F38.W0 91 /vsib")]
        vpgatherqd_ymm_k1_vm64z = 3489,

        /// <summary>
        /// vpgatherqd ymm, vm64z | EVEX.512.66.0F38.W0 91 /vsib | Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqd ymm, vm64z","EVEX.512.66.0F38.W0 91 /vsib")]
        vpgatherqd_ymm_vm64z = 3490,

        /// <summary>
        /// vpgatherqq xmm {k1}, vm64x | EVEX.128.66.0F38.W1 91 /vsib | Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqq xmm {k1}, vm64x","EVEX.128.66.0F38.W1 91 /vsib")]
        vpgatherqq_xmm_k1_vm64x = 3491,

        /// <summary>
        /// vpgatherqq xmm, vm64x | EVEX.128.66.0F38.W1 91 /vsib | Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqq xmm, vm64x","EVEX.128.66.0F38.W1 91 /vsib")]
        vpgatherqq_xmm_vm64x = 3492,

        /// <summary>
        /// vpgatherqq xmm, vm64x, xmm | VEX.128.66.0F38.W1 91 /r | Using qword indices specified in vm64x, gather qword values from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1.
        /// </summary>
        [Symbol("vpgatherqq xmm, vm64x, xmm","VEX.128.66.0F38.W1 91 /r")]
        vpgatherqq_xmm_vm64x_xmm = 3493,

        /// <summary>
        /// vpgatherqq ymm {k1}, vm64y | EVEX.256.66.0F38.W1 91 /vsib | Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqq ymm {k1}, vm64y","EVEX.256.66.0F38.W1 91 /vsib")]
        vpgatherqq_ymm_k1_vm64y = 3494,

        /// <summary>
        /// vpgatherqq ymm, vm64y | EVEX.256.66.0F38.W1 91 /vsib | Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqq ymm, vm64y","EVEX.256.66.0F38.W1 91 /vsib")]
        vpgatherqq_ymm_vm64y = 3495,

        /// <summary>
        /// vpgatherqq ymm, vm64y, ymm | VEX.256.66.0F38.W1 91 /r | Using qword indices specified in vm64y, gather qword values from memory conditioned on mask specified by ymm2. Conditionally gathered elements are merged into ymm1.
        /// </summary>
        [Symbol("vpgatherqq ymm, vm64y, ymm","VEX.256.66.0F38.W1 91 /r")]
        vpgatherqq_ymm_vm64y_ymm = 3496,

        /// <summary>
        /// vpgatherqq zmm {k1}, vm64z | EVEX.512.66.0F38.W1 91 /vsib | Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqq zmm {k1}, vm64z","EVEX.512.66.0F38.W1 91 /vsib")]
        vpgatherqq_zmm_k1_vm64z = 3497,

        /// <summary>
        /// vpgatherqq zmm, vm64z | EVEX.512.66.0F38.W1 91 /vsib | Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.
        /// </summary>
        [Symbol("vpgatherqq zmm, vm64z","EVEX.512.66.0F38.W1 91 /vsib")]
        vpgatherqq_zmm_vm64z = 3498,

        /// <summary>
        /// vphaddd xmm, xmm, m128 | VEX.128.66.0F38.WIG 02 /r | Add 32-bit integers horizontally, pack to xmm1.
        /// </summary>
        [Symbol("vphaddd xmm, xmm, m128","VEX.128.66.0F38.WIG 02 /r")]
        vphaddd_xmm_xmm_m128 = 3499,

        /// <summary>
        /// vphaddd xmm, xmm, r8 | VEX.128.66.0F38.WIG 02 /r | Add 32-bit integers horizontally, pack to xmm1.
        /// </summary>
        [Symbol("vphaddd xmm, xmm, r8","VEX.128.66.0F38.WIG 02 /r")]
        vphaddd_xmm_xmm_r8 = 3500,

        /// <summary>
        /// vphaddd ymm, ymm, m256 | VEX.256.66.0F38.WIG 02 /r | Add 32-bit signed integers horizontally, pack to ymm1.
        /// </summary>
        [Symbol("vphaddd ymm, ymm, m256","VEX.256.66.0F38.WIG 02 /r")]
        vphaddd_ymm_ymm_m256 = 3501,

        /// <summary>
        /// vphaddd ymm, ymm, r16 | VEX.256.66.0F38.WIG 02 /r | Add 32-bit signed integers horizontally, pack to ymm1.
        /// </summary>
        [Symbol("vphaddd ymm, ymm, r16","VEX.256.66.0F38.WIG 02 /r")]
        vphaddd_ymm_ymm_r16 = 3502,

        /// <summary>
        /// vphaddsw xmm, xmm, m128 | VEX.128.66.0F38.WIG 03 /r | Add 16-bit signed integers horizontally, pack saturated integers to xmm1.
        /// </summary>
        [Symbol("vphaddsw xmm, xmm, m128","VEX.128.66.0F38.WIG 03 /r")]
        vphaddsw_xmm_xmm_m128 = 3503,

        /// <summary>
        /// vphaddsw xmm, xmm, r8 | VEX.128.66.0F38.WIG 03 /r | Add 16-bit signed integers horizontally, pack saturated integers to xmm1.
        /// </summary>
        [Symbol("vphaddsw xmm, xmm, r8","VEX.128.66.0F38.WIG 03 /r")]
        vphaddsw_xmm_xmm_r8 = 3504,

        /// <summary>
        /// vphaddsw ymm, ymm, m256 | VEX.256.66.0F38.WIG 03 /r | Add 16-bit signed integers horizontally, pack saturated integers to ymm1.
        /// </summary>
        [Symbol("vphaddsw ymm, ymm, m256","VEX.256.66.0F38.WIG 03 /r")]
        vphaddsw_ymm_ymm_m256 = 3505,

        /// <summary>
        /// vphaddsw ymm, ymm, r16 | VEX.256.66.0F38.WIG 03 /r | Add 16-bit signed integers horizontally, pack saturated integers to ymm1.
        /// </summary>
        [Symbol("vphaddsw ymm, ymm, r16","VEX.256.66.0F38.WIG 03 /r")]
        vphaddsw_ymm_ymm_r16 = 3506,

        /// <summary>
        /// vphaddw xmm, xmm, m128 | VEX.128.66.0F38.WIG 01 /r | Add 16-bit integers horizontally, pack to xmm1.
        /// </summary>
        [Symbol("vphaddw xmm, xmm, m128","VEX.128.66.0F38.WIG 01 /r")]
        vphaddw_xmm_xmm_m128 = 3507,

        /// <summary>
        /// vphaddw xmm, xmm, r8 | VEX.128.66.0F38.WIG 01 /r | Add 16-bit integers horizontally, pack to xmm1.
        /// </summary>
        [Symbol("vphaddw xmm, xmm, r8","VEX.128.66.0F38.WIG 01 /r")]
        vphaddw_xmm_xmm_r8 = 3508,

        /// <summary>
        /// vphaddw ymm, ymm, m256 | VEX.256.66.0F38.WIG 01 /r | Add 16-bit signed integers horizontally, pack to ymm1.
        /// </summary>
        [Symbol("vphaddw ymm, ymm, m256","VEX.256.66.0F38.WIG 01 /r")]
        vphaddw_ymm_ymm_m256 = 3509,

        /// <summary>
        /// vphaddw ymm, ymm, r16 | VEX.256.66.0F38.WIG 01 /r | Add 16-bit signed integers horizontally, pack to ymm1.
        /// </summary>
        [Symbol("vphaddw ymm, ymm, r16","VEX.256.66.0F38.WIG 01 /r")]
        vphaddw_ymm_ymm_r16 = 3510,

        /// <summary>
        /// vpinsrb xmm, xmm, m8, imm8 | EVEX.128.66.0F3A.WIG 20 /r ib | Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.
        /// </summary>
        [Symbol("vpinsrb xmm, xmm, m8, imm8","EVEX.128.66.0F3A.WIG 20 /r ib")]
        vpinsrb_xmm_xmm_m8_imm8 = 3511,

        /// <summary>
        /// vpinsrb xmm, xmm, m8, imm8 | VEX.128.66.0F3A.W0 20 /r ib | Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.
        /// </summary>
        [Symbol("vpinsrb xmm, xmm, m8, imm8","VEX.128.66.0F3A.W0 20 /r ib")]
        vpinsrb_xmm_xmm_m8_imm8_vex = 3512,

        /// <summary>
        /// vpinsrb xmm, xmm, r32, imm8 | EVEX.128.66.0F3A.WIG 20 /r ib | Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.
        /// </summary>
        [Symbol("vpinsrb xmm, xmm, r32, imm8","EVEX.128.66.0F3A.WIG 20 /r ib")]
        vpinsrb_xmm_xmm_r32_imm8 = 3513,

        /// <summary>
        /// vpinsrb xmm, xmm, r32, imm8 | VEX.128.66.0F3A.W0 20 /r ib | Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.
        /// </summary>
        [Symbol("vpinsrb xmm, xmm, r32, imm8","VEX.128.66.0F3A.W0 20 /r ib")]
        vpinsrb_xmm_xmm_r32_imm8_vex = 3514,

        /// <summary>
        /// vpinsrd xmm, xmm, m32, imm8 | VEX.128.66.0F3A.W0 22 /r ib | Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.
        /// </summary>
        [Symbol("vpinsrd xmm, xmm, m32, imm8","VEX.128.66.0F3A.W0 22 /r ib")]
        vpinsrd_xmm_xmm_m32_imm8 = 3515,

        /// <summary>
        /// vpinsrd xmm, xmm, m32, imm8 | EVEX.128.66.0F3A.W0 22 /r ib | Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.
        /// </summary>
        [Symbol("vpinsrd xmm, xmm, m32, imm8","EVEX.128.66.0F3A.W0 22 /r ib")]
        vpinsrd_xmm_xmm_m32_imm8_evex = 3516,

        /// <summary>
        /// vpinsrd xmm, xmm, r32, imm8 | VEX.128.66.0F3A.W0 22 /r ib | Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.
        /// </summary>
        [Symbol("vpinsrd xmm, xmm, r32, imm8","VEX.128.66.0F3A.W0 22 /r ib")]
        vpinsrd_xmm_xmm_r32_imm8 = 3517,

        /// <summary>
        /// vpinsrd xmm, xmm, r32, imm8 | EVEX.128.66.0F3A.W0 22 /r ib | Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.
        /// </summary>
        [Symbol("vpinsrd xmm, xmm, r32, imm8","EVEX.128.66.0F3A.W0 22 /r ib")]
        vpinsrd_xmm_xmm_r32_imm8_evex = 3518,

        /// <summary>
        /// vpinsrq xmm, xmm, m64, imm8 | VEX.128.66.0F3A.W1 22 /r ib | Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.
        /// </summary>
        [Symbol("vpinsrq xmm, xmm, m64, imm8","VEX.128.66.0F3A.W1 22 /r ib")]
        vpinsrq_xmm_xmm_m64_imm8 = 3519,

        /// <summary>
        /// vpinsrq xmm, xmm, m64, imm8 | EVEX.128.66.0F3A.W1 22 /r ib | Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.
        /// </summary>
        [Symbol("vpinsrq xmm, xmm, m64, imm8","EVEX.128.66.0F3A.W1 22 /r ib")]
        vpinsrq_xmm_xmm_m64_imm8_evex = 3520,

        /// <summary>
        /// vpinsrq xmm, xmm, r64, imm8 | VEX.128.66.0F3A.W1 22 /r ib | Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.
        /// </summary>
        [Symbol("vpinsrq xmm, xmm, r64, imm8","VEX.128.66.0F3A.W1 22 /r ib")]
        vpinsrq_xmm_xmm_r64_imm8 = 3521,

        /// <summary>
        /// vpinsrq xmm, xmm, r64, imm8 | EVEX.128.66.0F3A.W1 22 /r ib | Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.
        /// </summary>
        [Symbol("vpinsrq xmm, xmm, r64, imm8","EVEX.128.66.0F3A.W1 22 /r ib")]
        vpinsrq_xmm_xmm_r64_imm8_evex = 3522,

        /// <summary>
        /// vpinsrw xmm, xmm, m16, imm8 | VEX.128.66.0F.W0 C4 /r ib | Insert a word integer value from r32/m16 and rest from xmm2 into xmm1 at the word offset in imm8.
        /// </summary>
        [Symbol("vpinsrw xmm, xmm, m16, imm8","VEX.128.66.0F.W0 C4 /r ib")]
        vpinsrw_xmm_xmm_m16_imm8 = 3523,

        /// <summary>
        /// vpinsrw xmm, xmm, m16, imm8 | EVEX.128.66.0F.WIG C4 /r ib | Insert a word integer value from r32/m16 and rest from xmm2 into xmm1 at the word offset in imm8.
        /// </summary>
        [Symbol("vpinsrw xmm, xmm, m16, imm8","EVEX.128.66.0F.WIG C4 /r ib")]
        vpinsrw_xmm_xmm_m16_imm8_evex = 3524,

        /// <summary>
        /// vpinsrw xmm, xmm, r32, imm8 | VEX.128.66.0F.W0 C4 /r ib | Insert a word integer value from r32/m16 and rest from xmm2 into xmm1 at the word offset in imm8.
        /// </summary>
        [Symbol("vpinsrw xmm, xmm, r32, imm8","VEX.128.66.0F.W0 C4 /r ib")]
        vpinsrw_xmm_xmm_r32_imm8 = 3525,

        /// <summary>
        /// vpinsrw xmm, xmm, r32, imm8 | EVEX.128.66.0F.WIG C4 /r ib | Insert a word integer value from r32/m16 and rest from xmm2 into xmm1 at the word offset in imm8.
        /// </summary>
        [Symbol("vpinsrw xmm, xmm, r32, imm8","EVEX.128.66.0F.WIG C4 /r ib")]
        vpinsrw_xmm_xmm_r32_imm8_evex = 3526,

        /// <summary>
        /// vplzcntd xmm {k1}{z}, m128 | EVEX.128.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd xmm {k1}{z}, m128","EVEX.128.66.0F38.W0 44 /r")]
        vplzcntd_xmm_k1z_m128 = 3527,

        /// <summary>
        /// vplzcntd xmm {k1}{z}, m32bcst | EVEX.128.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd xmm {k1}{z}, m32bcst","EVEX.128.66.0F38.W0 44 /r")]
        vplzcntd_xmm_k1z_m32bcst = 3528,

        /// <summary>
        /// vplzcntd xmm {k1}{z}, xmm | EVEX.128.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd xmm {k1}{z}, xmm","EVEX.128.66.0F38.W0 44 /r")]
        vplzcntd_xmm_k1z_xmm = 3529,

        /// <summary>
        /// vplzcntd xmm, m128 | EVEX.128.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd xmm, m128","EVEX.128.66.0F38.W0 44 /r")]
        vplzcntd_xmm_m128 = 3530,

        /// <summary>
        /// vplzcntd xmm, m32bcst | EVEX.128.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd xmm, m32bcst","EVEX.128.66.0F38.W0 44 /r")]
        vplzcntd_xmm_m32bcst = 3531,

        /// <summary>
        /// vplzcntd xmm, xmm | EVEX.128.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of xmm2/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd xmm, xmm","EVEX.128.66.0F38.W0 44 /r")]
        vplzcntd_xmm_xmm = 3532,

        /// <summary>
        /// vplzcntd ymm {k1}{z}, m256 | EVEX.256.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd ymm {k1}{z}, m256","EVEX.256.66.0F38.W0 44 /r")]
        vplzcntd_ymm_k1z_m256 = 3533,

        /// <summary>
        /// vplzcntd ymm {k1}{z}, m32bcst | EVEX.256.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd ymm {k1}{z}, m32bcst","EVEX.256.66.0F38.W0 44 /r")]
        vplzcntd_ymm_k1z_m32bcst = 3534,

        /// <summary>
        /// vplzcntd ymm {k1}{z}, ymm | EVEX.256.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd ymm {k1}{z}, ymm","EVEX.256.66.0F38.W0 44 /r")]
        vplzcntd_ymm_k1z_ymm = 3535,

        /// <summary>
        /// vplzcntd ymm, m256 | EVEX.256.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd ymm, m256","EVEX.256.66.0F38.W0 44 /r")]
        vplzcntd_ymm_m256 = 3536,

        /// <summary>
        /// vplzcntd ymm, m32bcst | EVEX.256.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd ymm, m32bcst","EVEX.256.66.0F38.W0 44 /r")]
        vplzcntd_ymm_m32bcst = 3537,

        /// <summary>
        /// vplzcntd ymm, ymm | EVEX.256.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of ymm2/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd ymm, ymm","EVEX.256.66.0F38.W0 44 /r")]
        vplzcntd_ymm_ymm = 3538,

        /// <summary>
        /// vplzcntd zmm {k1}{z}, m32bcst | EVEX.512.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd zmm {k1}{z}, m32bcst","EVEX.512.66.0F38.W0 44 /r")]
        vplzcntd_zmm_k1z_m32bcst = 3539,

        /// <summary>
        /// vplzcntd zmm {k1}{z}, m512 | EVEX.512.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd zmm {k1}{z}, m512","EVEX.512.66.0F38.W0 44 /r")]
        vplzcntd_zmm_k1z_m512 = 3540,

        /// <summary>
        /// vplzcntd zmm {k1}{z}, zmm | EVEX.512.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd zmm {k1}{z}, zmm","EVEX.512.66.0F38.W0 44 /r")]
        vplzcntd_zmm_k1z_zmm = 3541,

        /// <summary>
        /// vplzcntd zmm, m32bcst | EVEX.512.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd zmm, m32bcst","EVEX.512.66.0F38.W0 44 /r")]
        vplzcntd_zmm_m32bcst = 3542,

        /// <summary>
        /// vplzcntd zmm, m512 | EVEX.512.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd zmm, m512","EVEX.512.66.0F38.W0 44 /r")]
        vplzcntd_zmm_m512 = 3543,

        /// <summary>
        /// vplzcntd zmm, zmm | EVEX.512.66.0F38.W0 44 /r | Count the number of leading zero bits in each dword element of zmm2/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntd zmm, zmm","EVEX.512.66.0F38.W0 44 /r")]
        vplzcntd_zmm_zmm = 3544,

        /// <summary>
        /// vplzcntq xmm {k1}{z}, m128 | EVEX.128.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq xmm {k1}{z}, m128","EVEX.128.66.0F38.W1 44 /r")]
        vplzcntq_xmm_k1z_m128 = 3545,

        /// <summary>
        /// vplzcntq xmm {k1}{z}, m64bcst | EVEX.128.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq xmm {k1}{z}, m64bcst","EVEX.128.66.0F38.W1 44 /r")]
        vplzcntq_xmm_k1z_m64bcst = 3546,

        /// <summary>
        /// vplzcntq xmm {k1}{z}, xmm | EVEX.128.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq xmm {k1}{z}, xmm","EVEX.128.66.0F38.W1 44 /r")]
        vplzcntq_xmm_k1z_xmm = 3547,

        /// <summary>
        /// vplzcntq xmm, m128 | EVEX.128.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq xmm, m128","EVEX.128.66.0F38.W1 44 /r")]
        vplzcntq_xmm_m128 = 3548,

        /// <summary>
        /// vplzcntq xmm, m64bcst | EVEX.128.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq xmm, m64bcst","EVEX.128.66.0F38.W1 44 /r")]
        vplzcntq_xmm_m64bcst = 3549,

        /// <summary>
        /// vplzcntq xmm, xmm | EVEX.128.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of xmm2/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq xmm, xmm","EVEX.128.66.0F38.W1 44 /r")]
        vplzcntq_xmm_xmm = 3550,

        /// <summary>
        /// vplzcntq ymm {k1}{z}, m256 | EVEX.256.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq ymm {k1}{z}, m256","EVEX.256.66.0F38.W1 44 /r")]
        vplzcntq_ymm_k1z_m256 = 3551,

        /// <summary>
        /// vplzcntq ymm {k1}{z}, m64bcst | EVEX.256.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq ymm {k1}{z}, m64bcst","EVEX.256.66.0F38.W1 44 /r")]
        vplzcntq_ymm_k1z_m64bcst = 3552,

        /// <summary>
        /// vplzcntq ymm {k1}{z}, ymm | EVEX.256.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq ymm {k1}{z}, ymm","EVEX.256.66.0F38.W1 44 /r")]
        vplzcntq_ymm_k1z_ymm = 3553,

        /// <summary>
        /// vplzcntq ymm, m256 | EVEX.256.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq ymm, m256","EVEX.256.66.0F38.W1 44 /r")]
        vplzcntq_ymm_m256 = 3554,

        /// <summary>
        /// vplzcntq ymm, m64bcst | EVEX.256.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq ymm, m64bcst","EVEX.256.66.0F38.W1 44 /r")]
        vplzcntq_ymm_m64bcst = 3555,

        /// <summary>
        /// vplzcntq ymm, ymm | EVEX.256.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of ymm2/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq ymm, ymm","EVEX.256.66.0F38.W1 44 /r")]
        vplzcntq_ymm_ymm = 3556,

        /// <summary>
        /// vplzcntq zmm {k1}{z}, m512 | EVEX.512.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq zmm {k1}{z}, m512","EVEX.512.66.0F38.W1 44 /r")]
        vplzcntq_zmm_k1z_m512 = 3557,

        /// <summary>
        /// vplzcntq zmm {k1}{z}, m64bcst | EVEX.512.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq zmm {k1}{z}, m64bcst","EVEX.512.66.0F38.W1 44 /r")]
        vplzcntq_zmm_k1z_m64bcst = 3558,

        /// <summary>
        /// vplzcntq zmm {k1}{z}, zmm | EVEX.512.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq zmm {k1}{z}, zmm","EVEX.512.66.0F38.W1 44 /r")]
        vplzcntq_zmm_k1z_zmm = 3559,

        /// <summary>
        /// vplzcntq zmm, m512 | EVEX.512.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq zmm, m512","EVEX.512.66.0F38.W1 44 /r")]
        vplzcntq_zmm_m512 = 3560,

        /// <summary>
        /// vplzcntq zmm, m64bcst | EVEX.512.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq zmm, m64bcst","EVEX.512.66.0F38.W1 44 /r")]
        vplzcntq_zmm_m64bcst = 3561,

        /// <summary>
        /// vplzcntq zmm, zmm | EVEX.512.66.0F38.W1 44 /r | Count the number of leading zero bits in each qword element of zmm2/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vplzcntq zmm, zmm","EVEX.512.66.0F38.W1 44 /r")]
        vplzcntq_zmm_zmm = 3562,

        /// <summary>
        /// vpmaskmovd m128, xmm, xmm | VEX.128.66.0F38.W0 8E /r | Conditionally store dword values from xmm2 using mask in xmm1.
        /// </summary>
        [Symbol("vpmaskmovd m128, xmm, xmm","VEX.128.66.0F38.W0 8E /r")]
        vpmaskmovd_m128_xmm_xmm = 3563,

        /// <summary>
        /// vpmaskmovd m256, ymm, ymm | VEX.256.66.0F38.W0 8E /r | Conditionally store dword values from ymm2 using mask in ymm1.
        /// </summary>
        [Symbol("vpmaskmovd m256, ymm, ymm","VEX.256.66.0F38.W0 8E /r")]
        vpmaskmovd_m256_ymm_ymm = 3564,

        /// <summary>
        /// vpmaskmovd xmm, xmm, m128 | VEX.128.66.0F38.W0 8C /r | Conditionally load dword values from m128 using mask in xmm2 and store in xmm1.
        /// </summary>
        [Symbol("vpmaskmovd xmm, xmm, m128","VEX.128.66.0F38.W0 8C /r")]
        vpmaskmovd_xmm_xmm_m128 = 3565,

        /// <summary>
        /// vpmaskmovd ymm, ymm, m256 | VEX.256.66.0F38.W0 8C /r | Conditionally load dword values from m256 using mask in ymm2 and store in ymm1.
        /// </summary>
        [Symbol("vpmaskmovd ymm, ymm, m256","VEX.256.66.0F38.W0 8C /r")]
        vpmaskmovd_ymm_ymm_m256 = 3566,

        /// <summary>
        /// vpmaskmovq m128, xmm, xmm | VEX.128.66.0F38.W1 8E /r | Conditionally store qword values from xmm2 using mask in xmm1.
        /// </summary>
        [Symbol("vpmaskmovq m128, xmm, xmm","VEX.128.66.0F38.W1 8E /r")]
        vpmaskmovq_m128_xmm_xmm = 3567,

        /// <summary>
        /// vpmaskmovq m256, ymm, ymm | VEX.256.66.0F38.W1 8E /r | Conditionally store qword values from ymm2 using mask in ymm1.
        /// </summary>
        [Symbol("vpmaskmovq m256, ymm, ymm","VEX.256.66.0F38.W1 8E /r")]
        vpmaskmovq_m256_ymm_ymm = 3568,

        /// <summary>
        /// vpmaskmovq xmm, xmm, m128 | VEX.128.66.0F38.W1 8C /r | Conditionally load qword values from m128 using mask in xmm2 and store in xmm1.
        /// </summary>
        [Symbol("vpmaskmovq xmm, xmm, m128","VEX.128.66.0F38.W1 8C /r")]
        vpmaskmovq_xmm_xmm_m128 = 3569,

        /// <summary>
        /// vpmaskmovq ymm, ymm, m256 | VEX.256.66.0F38.W1 8C /r | Conditionally load qword values from m256 using mask in ymm2 and store in ymm1.
        /// </summary>
        [Symbol("vpmaskmovq ymm, ymm, m256","VEX.256.66.0F38.W1 8C /r")]
        vpmaskmovq_ymm_ymm_m256 = 3570,

        /// <summary>
        /// vpmaxsb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.WIG 3C /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.WIG 3C /r")]
        vpmaxsb_xmm_k1z_xmm_m128 = 3571,

        /// <summary>
        /// vpmaxsb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.WIG 3C /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.WIG 3C /r")]
        vpmaxsb_xmm_k1z_xmm_r8 = 3572,

        /// <summary>
        /// vpmaxsb xmm, xmm, m128 | EVEX.128.66.0F38.WIG 3C /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb xmm, xmm, m128","EVEX.128.66.0F38.WIG 3C /r")]
        vpmaxsb_xmm_xmm_m128 = 3573,

        /// <summary>
        /// vpmaxsb xmm, xmm, m128 | VEX.128.66.0F38.WIG 3C /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("vpmaxsb xmm, xmm, m128","VEX.128.66.0F38.WIG 3C /r")]
        vpmaxsb_xmm_xmm_m128_vex = 3574,

        /// <summary>
        /// vpmaxsb xmm, xmm, r8 | EVEX.128.66.0F38.WIG 3C /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb xmm, xmm, r8","EVEX.128.66.0F38.WIG 3C /r")]
        vpmaxsb_xmm_xmm_r8 = 3575,

        /// <summary>
        /// vpmaxsb xmm, xmm, r8 | VEX.128.66.0F38.WIG 3C /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("vpmaxsb xmm, xmm, r8","VEX.128.66.0F38.WIG 3C /r")]
        vpmaxsb_xmm_xmm_r8_vex = 3576,

        /// <summary>
        /// vpmaxsb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.WIG 3C /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.WIG 3C /r")]
        vpmaxsb_ymm_k1z_ymm_m256 = 3577,

        /// <summary>
        /// vpmaxsb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.WIG 3C /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.WIG 3C /r")]
        vpmaxsb_ymm_k1z_ymm_r16 = 3578,

        /// <summary>
        /// vpmaxsb ymm, ymm, m256 | EVEX.256.66.0F38.WIG 3C /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb ymm, ymm, m256","EVEX.256.66.0F38.WIG 3C /r")]
        vpmaxsb_ymm_ymm_m256 = 3579,

        /// <summary>
        /// vpmaxsb ymm, ymm, m256 | VEX.256.66.0F38.WIG 3C /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.
        /// </summary>
        [Symbol("vpmaxsb ymm, ymm, m256","VEX.256.66.0F38.WIG 3C /r")]
        vpmaxsb_ymm_ymm_m256_vex = 3580,

        /// <summary>
        /// vpmaxsb ymm, ymm, r16 | EVEX.256.66.0F38.WIG 3C /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb ymm, ymm, r16","EVEX.256.66.0F38.WIG 3C /r")]
        vpmaxsb_ymm_ymm_r16 = 3581,

        /// <summary>
        /// vpmaxsb ymm, ymm, r16 | VEX.256.66.0F38.WIG 3C /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.
        /// </summary>
        [Symbol("vpmaxsb ymm, ymm, r16","VEX.256.66.0F38.WIG 3C /r")]
        vpmaxsb_ymm_ymm_r16_vex = 3582,

        /// <summary>
        /// vpmaxsb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.WIG 3C /r | Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.WIG 3C /r")]
        vpmaxsb_zmm_k1z_zmm_m512 = 3583,

        /// <summary>
        /// vpmaxsb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.WIG 3C /r | Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.WIG 3C /r")]
        vpmaxsb_zmm_k1z_zmm_r32 = 3584,

        /// <summary>
        /// vpmaxsb zmm, zmm, m512 | EVEX.512.66.0F38.WIG 3C /r | Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb zmm, zmm, m512","EVEX.512.66.0F38.WIG 3C /r")]
        vpmaxsb_zmm_zmm_m512 = 3585,

        /// <summary>
        /// vpmaxsb zmm, zmm, r32 | EVEX.512.66.0F38.WIG 3C /r | Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsb zmm, zmm, r32","EVEX.512.66.0F38.WIG 3C /r")]
        vpmaxsb_zmm_zmm_r32 = 3586,

        /// <summary>
        /// vpmaxsd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 3D /r | Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 3D /r")]
        vpmaxsd_xmm_k1z_xmm_m128 = 3587,

        /// <summary>
        /// vpmaxsd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 3D /r | Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 3D /r")]
        vpmaxsd_xmm_k1z_xmm_m32bcst = 3588,

        /// <summary>
        /// vpmaxsd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 3D /r | Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 3D /r")]
        vpmaxsd_xmm_k1z_xmm_xmm = 3589,

        /// <summary>
        /// vpmaxsd xmm, xmm, m128 | EVEX.128.66.0F38.W0 3D /r | Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd xmm, xmm, m128","EVEX.128.66.0F38.W0 3D /r")]
        vpmaxsd_xmm_xmm_m128 = 3590,

        /// <summary>
        /// vpmaxsd xmm, xmm, m128 | VEX.128.66.0F38.WIG 3D /r | Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("vpmaxsd xmm, xmm, m128","VEX.128.66.0F38.WIG 3D /r")]
        vpmaxsd_xmm_xmm_m128_vex = 3591,

        /// <summary>
        /// vpmaxsd xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 3D /r | Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 3D /r")]
        vpmaxsd_xmm_xmm_m32bcst = 3592,

        /// <summary>
        /// vpmaxsd xmm, xmm, r8 | VEX.128.66.0F38.WIG 3D /r | Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("vpmaxsd xmm, xmm, r8","VEX.128.66.0F38.WIG 3D /r")]
        vpmaxsd_xmm_xmm_r8 = 3593,

        /// <summary>
        /// vpmaxsd xmm, xmm, xmm | EVEX.128.66.0F38.W0 3D /r | Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd xmm, xmm, xmm","EVEX.128.66.0F38.W0 3D /r")]
        vpmaxsd_xmm_xmm_xmm = 3594,

        /// <summary>
        /// vpmaxsd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 3D /r | Compare packed signed dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 3D /r")]
        vpmaxsd_ymm_k1z_ymm_m256 = 3595,

        /// <summary>
        /// vpmaxsd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 3D /r | Compare packed signed dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 3D /r")]
        vpmaxsd_ymm_k1z_ymm_m32bcst = 3596,

        /// <summary>
        /// vpmaxsd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 3D /r | Compare packed signed dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 3D /r")]
        vpmaxsd_ymm_k1z_ymm_ymm = 3597,

        /// <summary>
        /// vpmaxsd ymm, ymm, m256 | EVEX.256.66.0F38.W0 3D /r | Compare packed signed dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd ymm, ymm, m256","EVEX.256.66.0F38.W0 3D /r")]
        vpmaxsd_ymm_ymm_m256 = 3598,

        /// <summary>
        /// vpmaxsd ymm, ymm, m256 | VEX.256.66.0F38.WIG 3D /r | Compare packed signed dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.
        /// </summary>
        [Symbol("vpmaxsd ymm, ymm, m256","VEX.256.66.0F38.WIG 3D /r")]
        vpmaxsd_ymm_ymm_m256_vex = 3599,

        /// <summary>
        /// vpmaxsd ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 3D /r | Compare packed signed dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 3D /r")]
        vpmaxsd_ymm_ymm_m32bcst = 3600,

        /// <summary>
        /// vpmaxsd ymm, ymm, r16 | VEX.256.66.0F38.WIG 3D /r | Compare packed signed dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.
        /// </summary>
        [Symbol("vpmaxsd ymm, ymm, r16","VEX.256.66.0F38.WIG 3D /r")]
        vpmaxsd_ymm_ymm_r16 = 3601,

        /// <summary>
        /// vpmaxsd ymm, ymm, ymm | EVEX.256.66.0F38.W0 3D /r | Compare packed signed dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd ymm, ymm, ymm","EVEX.256.66.0F38.W0 3D /r")]
        vpmaxsd_ymm_ymm_ymm = 3602,

        /// <summary>
        /// vpmaxsd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 3D /r | Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 3D /r")]
        vpmaxsd_zmm_k1z_zmm_m32bcst = 3603,

        /// <summary>
        /// vpmaxsd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 3D /r | Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 3D /r")]
        vpmaxsd_zmm_k1z_zmm_m512 = 3604,

        /// <summary>
        /// vpmaxsd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 3D /r | Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 3D /r")]
        vpmaxsd_zmm_k1z_zmm_zmm = 3605,

        /// <summary>
        /// vpmaxsd zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 3D /r | Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 3D /r")]
        vpmaxsd_zmm_zmm_m32bcst = 3606,

        /// <summary>
        /// vpmaxsd zmm, zmm, m512 | EVEX.512.66.0F38.W0 3D /r | Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd zmm, zmm, m512","EVEX.512.66.0F38.W0 3D /r")]
        vpmaxsd_zmm_zmm_m512 = 3607,

        /// <summary>
        /// vpmaxsd zmm, zmm, zmm | EVEX.512.66.0F38.W0 3D /r | Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsd zmm, zmm, zmm","EVEX.512.66.0F38.W0 3D /r")]
        vpmaxsd_zmm_zmm_zmm = 3608,

        /// <summary>
        /// vpmaxsq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 3D /r | Compare packed signed qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 3D /r")]
        vpmaxsq_xmm_k1z_xmm_m128 = 3609,

        /// <summary>
        /// vpmaxsq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 3D /r | Compare packed signed qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 3D /r")]
        vpmaxsq_xmm_k1z_xmm_m64bcst = 3610,

        /// <summary>
        /// vpmaxsq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 3D /r | Compare packed signed qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 3D /r")]
        vpmaxsq_xmm_k1z_xmm_xmm = 3611,

        /// <summary>
        /// vpmaxsq xmm, xmm, m128 | EVEX.128.66.0F38.W1 3D /r | Compare packed signed qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq xmm, xmm, m128","EVEX.128.66.0F38.W1 3D /r")]
        vpmaxsq_xmm_xmm_m128 = 3612,

        /// <summary>
        /// vpmaxsq xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 3D /r | Compare packed signed qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 3D /r")]
        vpmaxsq_xmm_xmm_m64bcst = 3613,

        /// <summary>
        /// vpmaxsq xmm, xmm, xmm | EVEX.128.66.0F38.W1 3D /r | Compare packed signed qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq xmm, xmm, xmm","EVEX.128.66.0F38.W1 3D /r")]
        vpmaxsq_xmm_xmm_xmm = 3614,

        /// <summary>
        /// vpmaxsq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 3D /r | Compare packed signed qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 3D /r")]
        vpmaxsq_ymm_k1z_ymm_m256 = 3615,

        /// <summary>
        /// vpmaxsq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 3D /r | Compare packed signed qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 3D /r")]
        vpmaxsq_ymm_k1z_ymm_m64bcst = 3616,

        /// <summary>
        /// vpmaxsq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 3D /r | Compare packed signed qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 3D /r")]
        vpmaxsq_ymm_k1z_ymm_ymm = 3617,

        /// <summary>
        /// vpmaxsq ymm, ymm, m256 | EVEX.256.66.0F38.W1 3D /r | Compare packed signed qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq ymm, ymm, m256","EVEX.256.66.0F38.W1 3D /r")]
        vpmaxsq_ymm_ymm_m256 = 3618,

        /// <summary>
        /// vpmaxsq ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 3D /r | Compare packed signed qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 3D /r")]
        vpmaxsq_ymm_ymm_m64bcst = 3619,

        /// <summary>
        /// vpmaxsq ymm, ymm, ymm | EVEX.256.66.0F38.W1 3D /r | Compare packed signed qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq ymm, ymm, ymm","EVEX.256.66.0F38.W1 3D /r")]
        vpmaxsq_ymm_ymm_ymm = 3620,

        /// <summary>
        /// vpmaxsq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 3D /r | Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 3D /r")]
        vpmaxsq_zmm_k1z_zmm_m512 = 3621,

        /// <summary>
        /// vpmaxsq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 3D /r | Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 3D /r")]
        vpmaxsq_zmm_k1z_zmm_m64bcst = 3622,

        /// <summary>
        /// vpmaxsq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 3D /r | Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 3D /r")]
        vpmaxsq_zmm_k1z_zmm_zmm = 3623,

        /// <summary>
        /// vpmaxsq zmm, zmm, m512 | EVEX.512.66.0F38.W1 3D /r | Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq zmm, zmm, m512","EVEX.512.66.0F38.W1 3D /r")]
        vpmaxsq_zmm_zmm_m512 = 3624,

        /// <summary>
        /// vpmaxsq zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 3D /r | Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 3D /r")]
        vpmaxsq_zmm_zmm_m64bcst = 3625,

        /// <summary>
        /// vpmaxsq zmm, zmm, zmm | EVEX.512.66.0F38.W1 3D /r | Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmaxsq zmm, zmm, zmm","EVEX.512.66.0F38.W1 3D /r")]
        vpmaxsq_zmm_zmm_zmm = 3626,

        /// <summary>
        /// vpmaxsw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG EE /r | Compare packed signed word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG EE /r")]
        vpmaxsw_xmm_k1z_xmm_m128 = 3627,

        /// <summary>
        /// vpmaxsw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG EE /r | Compare packed signed word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG EE /r")]
        vpmaxsw_xmm_k1z_xmm_r8 = 3628,

        /// <summary>
        /// vpmaxsw xmm, xmm, m128 | EVEX.128.66.0F.WIG EE /r | Compare packed signed word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw xmm, xmm, m128","EVEX.128.66.0F.WIG EE /r")]
        vpmaxsw_xmm_xmm_m128 = 3629,

        /// <summary>
        /// vpmaxsw xmm, xmm, m128 | VEX.128.66.0F.WIG EE /r | Compare packed signed word integers in xmm3/m128 and xmm2 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("vpmaxsw xmm, xmm, m128","VEX.128.66.0F.WIG EE /r")]
        vpmaxsw_xmm_xmm_m128_vex = 3630,

        /// <summary>
        /// vpmaxsw xmm, xmm, r8 | EVEX.128.66.0F.WIG EE /r | Compare packed signed word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw xmm, xmm, r8","EVEX.128.66.0F.WIG EE /r")]
        vpmaxsw_xmm_xmm_r8 = 3631,

        /// <summary>
        /// vpmaxsw xmm, xmm, r8 | VEX.128.66.0F.WIG EE /r | Compare packed signed word integers in xmm3/m128 and xmm2 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("vpmaxsw xmm, xmm, r8","VEX.128.66.0F.WIG EE /r")]
        vpmaxsw_xmm_xmm_r8_vex = 3632,

        /// <summary>
        /// vpmaxsw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG EE /r | Compare packed signed word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG EE /r")]
        vpmaxsw_ymm_k1z_ymm_m256 = 3633,

        /// <summary>
        /// vpmaxsw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG EE /r | Compare packed signed word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG EE /r")]
        vpmaxsw_ymm_k1z_ymm_r16 = 3634,

        /// <summary>
        /// vpmaxsw ymm, ymm, m256 | EVEX.256.66.0F.WIG EE /r | Compare packed signed word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw ymm, ymm, m256","EVEX.256.66.0F.WIG EE /r")]
        vpmaxsw_ymm_ymm_m256 = 3635,

        /// <summary>
        /// vpmaxsw ymm, ymm, m256 | VEX.256.66.0F.WIG EE /r | Compare packed signed word integers in ymm3/m256 and ymm2 and store packed maximum values in ymm1.
        /// </summary>
        [Symbol("vpmaxsw ymm, ymm, m256","VEX.256.66.0F.WIG EE /r")]
        vpmaxsw_ymm_ymm_m256_vex = 3636,

        /// <summary>
        /// vpmaxsw ymm, ymm, r16 | EVEX.256.66.0F.WIG EE /r | Compare packed signed word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw ymm, ymm, r16","EVEX.256.66.0F.WIG EE /r")]
        vpmaxsw_ymm_ymm_r16 = 3637,

        /// <summary>
        /// vpmaxsw ymm, ymm, r16 | VEX.256.66.0F.WIG EE /r | Compare packed signed word integers in ymm3/m256 and ymm2 and store packed maximum values in ymm1.
        /// </summary>
        [Symbol("vpmaxsw ymm, ymm, r16","VEX.256.66.0F.WIG EE /r")]
        vpmaxsw_ymm_ymm_r16_vex = 3638,

        /// <summary>
        /// vpmaxsw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG EE /r | Compare packed signed word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG EE /r")]
        vpmaxsw_zmm_k1z_zmm_m512 = 3639,

        /// <summary>
        /// vpmaxsw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG EE /r | Compare packed signed word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG EE /r")]
        vpmaxsw_zmm_k1z_zmm_r32 = 3640,

        /// <summary>
        /// vpmaxsw zmm, zmm, m512 | EVEX.512.66.0F.WIG EE /r | Compare packed signed word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw zmm, zmm, m512","EVEX.512.66.0F.WIG EE /r")]
        vpmaxsw_zmm_zmm_m512 = 3641,

        /// <summary>
        /// vpmaxsw zmm, zmm, r32 | EVEX.512.66.0F.WIG EE /r | Compare packed signed word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxsw zmm, zmm, r32","EVEX.512.66.0F.WIG EE /r")]
        vpmaxsw_zmm_zmm_r32 = 3642,

        /// <summary>
        /// vpmaxub xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG DE /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG DE /r")]
        vpmaxub_xmm_k1z_xmm_m128 = 3643,

        /// <summary>
        /// vpmaxub xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG DE /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG DE /r")]
        vpmaxub_xmm_k1z_xmm_r8 = 3644,

        /// <summary>
        /// vpmaxub xmm, xmm, m128 | EVEX.128.66.0F.WIG DE /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub xmm, xmm, m128","EVEX.128.66.0F.WIG DE /r")]
        vpmaxub_xmm_xmm_m128 = 3645,

        /// <summary>
        /// vpmaxub xmm, xmm, m128 | VEX.128.66.0F DE /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("vpmaxub xmm, xmm, m128","VEX.128.66.0F DE /r")]
        vpmaxub_xmm_xmm_m128_vex = 3646,

        /// <summary>
        /// vpmaxub xmm, xmm, r8 | EVEX.128.66.0F.WIG DE /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub xmm, xmm, r8","EVEX.128.66.0F.WIG DE /r")]
        vpmaxub_xmm_xmm_r8 = 3647,

        /// <summary>
        /// vpmaxub xmm, xmm, r8 | VEX.128.66.0F DE /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.
        /// </summary>
        [Symbol("vpmaxub xmm, xmm, r8","VEX.128.66.0F DE /r")]
        vpmaxub_xmm_xmm_r8_vex = 3648,

        /// <summary>
        /// vpmaxub ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG DE /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG DE /r")]
        vpmaxub_ymm_k1z_ymm_m256 = 3649,

        /// <summary>
        /// vpmaxub ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG DE /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG DE /r")]
        vpmaxub_ymm_k1z_ymm_r16 = 3650,

        /// <summary>
        /// vpmaxub ymm, ymm, m256 | EVEX.256.66.0F.WIG DE /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub ymm, ymm, m256","EVEX.256.66.0F.WIG DE /r")]
        vpmaxub_ymm_ymm_m256 = 3651,

        /// <summary>
        /// vpmaxub ymm, ymm, m256 | VEX.256.66.0F DE /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.
        /// </summary>
        [Symbol("vpmaxub ymm, ymm, m256","VEX.256.66.0F DE /r")]
        vpmaxub_ymm_ymm_m256_vex = 3652,

        /// <summary>
        /// vpmaxub ymm, ymm, r16 | EVEX.256.66.0F.WIG DE /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub ymm, ymm, r16","EVEX.256.66.0F.WIG DE /r")]
        vpmaxub_ymm_ymm_r16 = 3653,

        /// <summary>
        /// vpmaxub ymm, ymm, r16 | VEX.256.66.0F DE /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.
        /// </summary>
        [Symbol("vpmaxub ymm, ymm, r16","VEX.256.66.0F DE /r")]
        vpmaxub_ymm_ymm_r16_vex = 3654,

        /// <summary>
        /// vpmaxub zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG DE /r | Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG DE /r")]
        vpmaxub_zmm_k1z_zmm_m512 = 3655,

        /// <summary>
        /// vpmaxub zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG DE /r | Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG DE /r")]
        vpmaxub_zmm_k1z_zmm_r32 = 3656,

        /// <summary>
        /// vpmaxub zmm, zmm, m512 | EVEX.512.66.0F.WIG DE /r | Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub zmm, zmm, m512","EVEX.512.66.0F.WIG DE /r")]
        vpmaxub_zmm_zmm_m512 = 3657,

        /// <summary>
        /// vpmaxub zmm, zmm, r32 | EVEX.512.66.0F.WIG DE /r | Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxub zmm, zmm, r32","EVEX.512.66.0F.WIG DE /r")]
        vpmaxub_zmm_zmm_r32 = 3658,

        /// <summary>
        /// vpmaxuw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.WIG 3E /r | Compare packed unsigned word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.WIG 3E /r")]
        vpmaxuw_xmm_k1z_xmm_m128 = 3659,

        /// <summary>
        /// vpmaxuw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.WIG 3E /r | Compare packed unsigned word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.WIG 3E /r")]
        vpmaxuw_xmm_k1z_xmm_r8 = 3660,

        /// <summary>
        /// vpmaxuw xmm, xmm, m128 | EVEX.128.66.0F38.WIG 3E /r | Compare packed unsigned word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw xmm, xmm, m128","EVEX.128.66.0F38.WIG 3E /r")]
        vpmaxuw_xmm_xmm_m128 = 3661,

        /// <summary>
        /// vpmaxuw xmm, xmm, m128 | VEX.128.66.0F38 3E /r | Compare packed unsigned word integers in xmm3/m128 and xmm2 and store maximum packed values in xmm1.
        /// </summary>
        [Symbol("vpmaxuw xmm, xmm, m128","VEX.128.66.0F38 3E /r")]
        vpmaxuw_xmm_xmm_m128_vex = 3662,

        /// <summary>
        /// vpmaxuw xmm, xmm, r8 | EVEX.128.66.0F38.WIG 3E /r | Compare packed unsigned word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw xmm, xmm, r8","EVEX.128.66.0F38.WIG 3E /r")]
        vpmaxuw_xmm_xmm_r8 = 3663,

        /// <summary>
        /// vpmaxuw xmm, xmm, r8 | VEX.128.66.0F38 3E /r | Compare packed unsigned word integers in xmm3/m128 and xmm2 and store maximum packed values in xmm1.
        /// </summary>
        [Symbol("vpmaxuw xmm, xmm, r8","VEX.128.66.0F38 3E /r")]
        vpmaxuw_xmm_xmm_r8_vex = 3664,

        /// <summary>
        /// vpmaxuw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.WIG 3E /r | Compare packed unsigned word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.WIG 3E /r")]
        vpmaxuw_ymm_k1z_ymm_m256 = 3665,

        /// <summary>
        /// vpmaxuw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.WIG 3E /r | Compare packed unsigned word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.WIG 3E /r")]
        vpmaxuw_ymm_k1z_ymm_r16 = 3666,

        /// <summary>
        /// vpmaxuw ymm, ymm, m256 | EVEX.256.66.0F38.WIG 3E /r | Compare packed unsigned word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw ymm, ymm, m256","EVEX.256.66.0F38.WIG 3E /r")]
        vpmaxuw_ymm_ymm_m256 = 3667,

        /// <summary>
        /// vpmaxuw ymm, ymm, m256 | VEX.256.66.0F38 3E /r | Compare packed unsigned word integers in ymm3/m256 and ymm2 and store maximum packed values in ymm1.
        /// </summary>
        [Symbol("vpmaxuw ymm, ymm, m256","VEX.256.66.0F38 3E /r")]
        vpmaxuw_ymm_ymm_m256_vex = 3668,

        /// <summary>
        /// vpmaxuw ymm, ymm, r16 | EVEX.256.66.0F38.WIG 3E /r | Compare packed unsigned word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw ymm, ymm, r16","EVEX.256.66.0F38.WIG 3E /r")]
        vpmaxuw_ymm_ymm_r16 = 3669,

        /// <summary>
        /// vpmaxuw ymm, ymm, r16 | VEX.256.66.0F38 3E /r | Compare packed unsigned word integers in ymm3/m256 and ymm2 and store maximum packed values in ymm1.
        /// </summary>
        [Symbol("vpmaxuw ymm, ymm, r16","VEX.256.66.0F38 3E /r")]
        vpmaxuw_ymm_ymm_r16_vex = 3670,

        /// <summary>
        /// vpmaxuw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.WIG 3E /r | Compare packed unsigned word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.WIG 3E /r")]
        vpmaxuw_zmm_k1z_zmm_m512 = 3671,

        /// <summary>
        /// vpmaxuw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.WIG 3E /r | Compare packed unsigned word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.WIG 3E /r")]
        vpmaxuw_zmm_k1z_zmm_r32 = 3672,

        /// <summary>
        /// vpmaxuw zmm, zmm, m512 | EVEX.512.66.0F38.WIG 3E /r | Compare packed unsigned word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw zmm, zmm, m512","EVEX.512.66.0F38.WIG 3E /r")]
        vpmaxuw_zmm_zmm_m512 = 3673,

        /// <summary>
        /// vpmaxuw zmm, zmm, r32 | EVEX.512.66.0F38.WIG 3E /r | Compare packed unsigned word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmaxuw zmm, zmm, r32","EVEX.512.66.0F38.WIG 3E /r")]
        vpmaxuw_zmm_zmm_r32 = 3674,

        /// <summary>
        /// vpminsb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.WIG 38 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.WIG 38 /r")]
        vpminsb_xmm_k1z_xmm_m128 = 3675,

        /// <summary>
        /// vpminsb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.WIG 38 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.WIG 38 /r")]
        vpminsb_xmm_k1z_xmm_r8 = 3676,

        /// <summary>
        /// vpminsb xmm, xmm, m128 | EVEX.128.66.0F38.WIG 38 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb xmm, xmm, m128","EVEX.128.66.0F38.WIG 38 /r")]
        vpminsb_xmm_xmm_m128 = 3677,

        /// <summary>
        /// vpminsb xmm, xmm, m128 | VEX.128.66.0F38 38 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("vpminsb xmm, xmm, m128","VEX.128.66.0F38 38 /r")]
        vpminsb_xmm_xmm_m128_vex = 3678,

        /// <summary>
        /// vpminsb xmm, xmm, r8 | EVEX.128.66.0F38.WIG 38 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb xmm, xmm, r8","EVEX.128.66.0F38.WIG 38 /r")]
        vpminsb_xmm_xmm_r8 = 3679,

        /// <summary>
        /// vpminsb xmm, xmm, r8 | VEX.128.66.0F38 38 /r | Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("vpminsb xmm, xmm, r8","VEX.128.66.0F38 38 /r")]
        vpminsb_xmm_xmm_r8_vex = 3680,

        /// <summary>
        /// vpminsb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.WIG 38 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.WIG 38 /r")]
        vpminsb_ymm_k1z_ymm_m256 = 3681,

        /// <summary>
        /// vpminsb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.WIG 38 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.WIG 38 /r")]
        vpminsb_ymm_k1z_ymm_r16 = 3682,

        /// <summary>
        /// vpminsb ymm, ymm, m256 | EVEX.256.66.0F38.WIG 38 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb ymm, ymm, m256","EVEX.256.66.0F38.WIG 38 /r")]
        vpminsb_ymm_ymm_m256 = 3683,

        /// <summary>
        /// vpminsb ymm, ymm, m256 | VEX.256.66.0F38 38 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.
        /// </summary>
        [Symbol("vpminsb ymm, ymm, m256","VEX.256.66.0F38 38 /r")]
        vpminsb_ymm_ymm_m256_vex = 3684,

        /// <summary>
        /// vpminsb ymm, ymm, r16 | EVEX.256.66.0F38.WIG 38 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb ymm, ymm, r16","EVEX.256.66.0F38.WIG 38 /r")]
        vpminsb_ymm_ymm_r16 = 3685,

        /// <summary>
        /// vpminsb ymm, ymm, r16 | VEX.256.66.0F38 38 /r | Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.
        /// </summary>
        [Symbol("vpminsb ymm, ymm, r16","VEX.256.66.0F38 38 /r")]
        vpminsb_ymm_ymm_r16_vex = 3686,

        /// <summary>
        /// vpminsb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.WIG 38 /r | Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.WIG 38 /r")]
        vpminsb_zmm_k1z_zmm_m512 = 3687,

        /// <summary>
        /// vpminsb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.WIG 38 /r | Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.WIG 38 /r")]
        vpminsb_zmm_k1z_zmm_r32 = 3688,

        /// <summary>
        /// vpminsb zmm, zmm, m512 | EVEX.512.66.0F38.WIG 38 /r | Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb zmm, zmm, m512","EVEX.512.66.0F38.WIG 38 /r")]
        vpminsb_zmm_zmm_m512 = 3689,

        /// <summary>
        /// vpminsb zmm, zmm, r32 | EVEX.512.66.0F38.WIG 38 /r | Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsb zmm, zmm, r32","EVEX.512.66.0F38.WIG 38 /r")]
        vpminsb_zmm_zmm_r32 = 3690,

        /// <summary>
        /// vpminsw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG EA /r | Compare packed signed word integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG EA /r")]
        vpminsw_xmm_k1z_xmm_m128 = 3691,

        /// <summary>
        /// vpminsw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG EA /r | Compare packed signed word integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG EA /r")]
        vpminsw_xmm_k1z_xmm_r8 = 3692,

        /// <summary>
        /// vpminsw xmm, xmm, m128 | EVEX.128.66.0F.WIG EA /r | Compare packed signed word integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw xmm, xmm, m128","EVEX.128.66.0F.WIG EA /r")]
        vpminsw_xmm_xmm_m128 = 3693,

        /// <summary>
        /// vpminsw xmm, xmm, m128 | VEX.128.66.0F EA /r | Compare packed signed word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.
        /// </summary>
        [Symbol("vpminsw xmm, xmm, m128","VEX.128.66.0F EA /r")]
        vpminsw_xmm_xmm_m128_vex = 3694,

        /// <summary>
        /// vpminsw xmm, xmm, r8 | EVEX.128.66.0F.WIG EA /r | Compare packed signed word integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw xmm, xmm, r8","EVEX.128.66.0F.WIG EA /r")]
        vpminsw_xmm_xmm_r8 = 3695,

        /// <summary>
        /// vpminsw xmm, xmm, r8 | VEX.128.66.0F EA /r | Compare packed signed word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.
        /// </summary>
        [Symbol("vpminsw xmm, xmm, r8","VEX.128.66.0F EA /r")]
        vpminsw_xmm_xmm_r8_vex = 3696,

        /// <summary>
        /// vpminsw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG EA /r | Compare packed signed word integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG EA /r")]
        vpminsw_ymm_k1z_ymm_m256 = 3697,

        /// <summary>
        /// vpminsw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG EA /r | Compare packed signed word integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG EA /r")]
        vpminsw_ymm_k1z_ymm_r16 = 3698,

        /// <summary>
        /// vpminsw ymm, ymm, m256 | EVEX.256.66.0F.WIG EA /r | Compare packed signed word integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw ymm, ymm, m256","EVEX.256.66.0F.WIG EA /r")]
        vpminsw_ymm_ymm_m256 = 3699,

        /// <summary>
        /// vpminsw ymm, ymm, m256 | VEX.256.66.0F EA /r | Compare packed signed word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.
        /// </summary>
        [Symbol("vpminsw ymm, ymm, m256","VEX.256.66.0F EA /r")]
        vpminsw_ymm_ymm_m256_vex = 3700,

        /// <summary>
        /// vpminsw ymm, ymm, r16 | EVEX.256.66.0F.WIG EA /r | Compare packed signed word integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw ymm, ymm, r16","EVEX.256.66.0F.WIG EA /r")]
        vpminsw_ymm_ymm_r16 = 3701,

        /// <summary>
        /// vpminsw ymm, ymm, r16 | VEX.256.66.0F EA /r | Compare packed signed word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.
        /// </summary>
        [Symbol("vpminsw ymm, ymm, r16","VEX.256.66.0F EA /r")]
        vpminsw_ymm_ymm_r16_vex = 3702,

        /// <summary>
        /// vpminsw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG EA /r | Compare packed signed word integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG EA /r")]
        vpminsw_zmm_k1z_zmm_m512 = 3703,

        /// <summary>
        /// vpminsw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG EA /r | Compare packed signed word integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG EA /r")]
        vpminsw_zmm_k1z_zmm_r32 = 3704,

        /// <summary>
        /// vpminsw zmm, zmm, m512 | EVEX.512.66.0F.WIG EA /r | Compare packed signed word integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw zmm, zmm, m512","EVEX.512.66.0F.WIG EA /r")]
        vpminsw_zmm_zmm_m512 = 3705,

        /// <summary>
        /// vpminsw zmm, zmm, r32 | EVEX.512.66.0F.WIG EA /r | Compare packed signed word integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminsw zmm, zmm, r32","EVEX.512.66.0F.WIG EA /r")]
        vpminsw_zmm_zmm_r32 = 3706,

        /// <summary>
        /// vpminub xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F DA /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub xmm {k1}{z}, xmm, m128","EVEX.128.66.0F DA /r")]
        vpminub_xmm_k1z_xmm_m128 = 3707,

        /// <summary>
        /// vpminub xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F DA /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub xmm {k1}{z}, xmm, r8","EVEX.128.66.0F DA /r")]
        vpminub_xmm_k1z_xmm_r8 = 3708,

        /// <summary>
        /// vpminub xmm, xmm, m128 | EVEX.128.66.0F DA /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub xmm, xmm, m128","EVEX.128.66.0F DA /r")]
        vpminub_xmm_xmm_m128 = 3709,

        /// <summary>
        /// vpminub xmm, xmm, m128 | VEX.128.66.0F DA /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("vpminub xmm, xmm, m128","VEX.128.66.0F DA /r")]
        vpminub_xmm_xmm_m128_vex = 3710,

        /// <summary>
        /// vpminub xmm, xmm, r8 | EVEX.128.66.0F DA /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub xmm, xmm, r8","EVEX.128.66.0F DA /r")]
        vpminub_xmm_xmm_r8 = 3711,

        /// <summary>
        /// vpminub xmm, xmm, r8 | VEX.128.66.0F DA /r | Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.
        /// </summary>
        [Symbol("vpminub xmm, xmm, r8","VEX.128.66.0F DA /r")]
        vpminub_xmm_xmm_r8_vex = 3712,

        /// <summary>
        /// vpminub ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F DA /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub ymm {k1}{z}, ymm, m256","EVEX.256.66.0F DA /r")]
        vpminub_ymm_k1z_ymm_m256 = 3713,

        /// <summary>
        /// vpminub ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F DA /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub ymm {k1}{z}, ymm, r16","EVEX.256.66.0F DA /r")]
        vpminub_ymm_k1z_ymm_r16 = 3714,

        /// <summary>
        /// vpminub ymm, ymm, m256 | EVEX.256.66.0F DA /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub ymm, ymm, m256","EVEX.256.66.0F DA /r")]
        vpminub_ymm_ymm_m256 = 3715,

        /// <summary>
        /// vpminub ymm, ymm, m256 | VEX.256.66.0F DA /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.
        /// </summary>
        [Symbol("vpminub ymm, ymm, m256","VEX.256.66.0F DA /r")]
        vpminub_ymm_ymm_m256_vex = 3716,

        /// <summary>
        /// vpminub ymm, ymm, r16 | EVEX.256.66.0F DA /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub ymm, ymm, r16","EVEX.256.66.0F DA /r")]
        vpminub_ymm_ymm_r16 = 3717,

        /// <summary>
        /// vpminub ymm, ymm, r16 | VEX.256.66.0F DA /r | Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.
        /// </summary>
        [Symbol("vpminub ymm, ymm, r16","VEX.256.66.0F DA /r")]
        vpminub_ymm_ymm_r16_vex = 3718,

        /// <summary>
        /// vpminub zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F DA /r | Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub zmm {k1}{z}, zmm, m512","EVEX.512.66.0F DA /r")]
        vpminub_zmm_k1z_zmm_m512 = 3719,

        /// <summary>
        /// vpminub zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F DA /r | Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub zmm {k1}{z}, zmm, r32","EVEX.512.66.0F DA /r")]
        vpminub_zmm_k1z_zmm_r32 = 3720,

        /// <summary>
        /// vpminub zmm, zmm, m512 | EVEX.512.66.0F DA /r | Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub zmm, zmm, m512","EVEX.512.66.0F DA /r")]
        vpminub_zmm_zmm_m512 = 3721,

        /// <summary>
        /// vpminub zmm, zmm, r32 | EVEX.512.66.0F DA /r | Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminub zmm, zmm, r32","EVEX.512.66.0F DA /r")]
        vpminub_zmm_zmm_r32 = 3722,

        /// <summary>
        /// vpminuw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38 3A /r | Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38 3A /r")]
        vpminuw_xmm_k1z_xmm_m128 = 3723,

        /// <summary>
        /// vpminuw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38 3A /r | Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38 3A /r")]
        vpminuw_xmm_k1z_xmm_r8 = 3724,

        /// <summary>
        /// vpminuw xmm, xmm, m128 | EVEX.128.66.0F38 3A /r | Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw xmm, xmm, m128","EVEX.128.66.0F38 3A /r")]
        vpminuw_xmm_xmm_m128 = 3725,

        /// <summary>
        /// vpminuw xmm, xmm, m128 | VEX.128.66.0F38 3A /r | Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.
        /// </summary>
        [Symbol("vpminuw xmm, xmm, m128","VEX.128.66.0F38 3A /r")]
        vpminuw_xmm_xmm_m128_vex = 3726,

        /// <summary>
        /// vpminuw xmm, xmm, r8 | EVEX.128.66.0F38 3A /r | Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw xmm, xmm, r8","EVEX.128.66.0F38 3A /r")]
        vpminuw_xmm_xmm_r8 = 3727,

        /// <summary>
        /// vpminuw xmm, xmm, r8 | VEX.128.66.0F38 3A /r | Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.
        /// </summary>
        [Symbol("vpminuw xmm, xmm, r8","VEX.128.66.0F38 3A /r")]
        vpminuw_xmm_xmm_r8_vex = 3728,

        /// <summary>
        /// vpminuw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38 3A /r | Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38 3A /r")]
        vpminuw_ymm_k1z_ymm_m256 = 3729,

        /// <summary>
        /// vpminuw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38 3A /r | Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38 3A /r")]
        vpminuw_ymm_k1z_ymm_r16 = 3730,

        /// <summary>
        /// vpminuw ymm, ymm, m256 | EVEX.256.66.0F38 3A /r | Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw ymm, ymm, m256","EVEX.256.66.0F38 3A /r")]
        vpminuw_ymm_ymm_m256 = 3731,

        /// <summary>
        /// vpminuw ymm, ymm, m256 | VEX.256.66.0F38 3A /r | Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.
        /// </summary>
        [Symbol("vpminuw ymm, ymm, m256","VEX.256.66.0F38 3A /r")]
        vpminuw_ymm_ymm_m256_vex = 3732,

        /// <summary>
        /// vpminuw ymm, ymm, r16 | EVEX.256.66.0F38 3A /r | Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw ymm, ymm, r16","EVEX.256.66.0F38 3A /r")]
        vpminuw_ymm_ymm_r16 = 3733,

        /// <summary>
        /// vpminuw ymm, ymm, r16 | VEX.256.66.0F38 3A /r | Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.
        /// </summary>
        [Symbol("vpminuw ymm, ymm, r16","VEX.256.66.0F38 3A /r")]
        vpminuw_ymm_ymm_r16_vex = 3734,

        /// <summary>
        /// vpminuw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38 3A /r | Compare packed unsigned word integers in zmm3/m512 and zmm2 and return packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38 3A /r")]
        vpminuw_zmm_k1z_zmm_m512 = 3735,

        /// <summary>
        /// vpminuw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38 3A /r | Compare packed unsigned word integers in zmm3/m512 and zmm2 and return packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38 3A /r")]
        vpminuw_zmm_k1z_zmm_r32 = 3736,

        /// <summary>
        /// vpminuw zmm, zmm, m512 | EVEX.512.66.0F38 3A /r | Compare packed unsigned word integers in zmm3/m512 and zmm2 and return packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw zmm, zmm, m512","EVEX.512.66.0F38 3A /r")]
        vpminuw_zmm_zmm_m512 = 3737,

        /// <summary>
        /// vpminuw zmm, zmm, r32 | EVEX.512.66.0F38 3A /r | Compare packed unsigned word integers in zmm3/m512 and zmm2 and return packed minimum values in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpminuw zmm, zmm, r32","EVEX.512.66.0F38 3A /r")]
        vpminuw_zmm_zmm_r32 = 3738,

        /// <summary>
        /// vpmovb2m k, xmm | EVEX.128.F3.0F38.W0 29 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in XMM1.
        /// </summary>
        [Symbol("vpmovb2m k, xmm","EVEX.128.F3.0F38.W0 29 /r")]
        vpmovb2m_k_xmm = 3739,

        /// <summary>
        /// vpmovb2m k, ymm | EVEX.256.F3.0F38.W0 29 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in YMM1.
        /// </summary>
        [Symbol("vpmovb2m k, ymm","EVEX.256.F3.0F38.W0 29 /r")]
        vpmovb2m_k_ymm = 3740,

        /// <summary>
        /// vpmovb2m k, zmm | EVEX.512.F3.0F38.W0 29 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in ZMM1.
        /// </summary>
        [Symbol("vpmovb2m k, zmm","EVEX.512.F3.0F38.W0 29 /r")]
        vpmovb2m_k_zmm = 3741,

        /// <summary>
        /// vpmovd2m k, xmm | EVEX.128.F3.0F38.W0 39 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in XMM1.
        /// </summary>
        [Symbol("vpmovd2m k, xmm","EVEX.128.F3.0F38.W0 39 /r")]
        vpmovd2m_k_xmm = 3742,

        /// <summary>
        /// vpmovd2m k, ymm | EVEX.256.F3.0F38.W0 39 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in YMM1.
        /// </summary>
        [Symbol("vpmovd2m k, ymm","EVEX.256.F3.0F38.W0 39 /r")]
        vpmovd2m_k_ymm = 3743,

        /// <summary>
        /// vpmovd2m k, zmm | EVEX.512.F3.0F38.W0 39 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in ZMM1.
        /// </summary>
        [Symbol("vpmovd2m k, zmm","EVEX.512.F3.0F38.W0 39 /r")]
        vpmovd2m_k_zmm = 3744,

        /// <summary>
        /// vpmovdb m128 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 31 /r | Converts 16 packed double-word integers from zmm2 into 16 packed byte integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb m128 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 31 /r")]
        vpmovdb_m128_k1z_zmm = 3745,

        /// <summary>
        /// vpmovdb m128, zmm | EVEX.512.F3.0F38.W0 31 /r | Converts 16 packed double-word integers from zmm2 into 16 packed byte integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb m128, zmm","EVEX.512.F3.0F38.W0 31 /r")]
        vpmovdb_m128_zmm = 3746,

        /// <summary>
        /// vpmovdb m32 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 31 /r | Converts 4 packed double-word integers from xmm2 into 4 packed byte integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb m32 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 31 /r")]
        vpmovdb_m32_k1z_xmm = 3747,

        /// <summary>
        /// vpmovdb m32, xmm | EVEX.128.F3.0F38.W0 31 /r | Converts 4 packed double-word integers from xmm2 into 4 packed byte integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb m32, xmm","EVEX.128.F3.0F38.W0 31 /r")]
        vpmovdb_m32_xmm = 3748,

        /// <summary>
        /// vpmovdb m64 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 31 /r | Converts 8 packed double-word integers from ymm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb m64 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 31 /r")]
        vpmovdb_m64_k1z_ymm = 3749,

        /// <summary>
        /// vpmovdb m64, ymm | EVEX.256.F3.0F38.W0 31 /r | Converts 8 packed double-word integers from ymm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb m64, ymm","EVEX.256.F3.0F38.W0 31 /r")]
        vpmovdb_m64_ymm = 3750,

        /// <summary>
        /// vpmovdb r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 31 /r | Converts 4 packed double-word integers from xmm2 into 4 packed byte integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 31 /r")]
        vpmovdb_r8_k1z_xmm = 3751,

        /// <summary>
        /// vpmovdb r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 31 /r | Converts 8 packed double-word integers from ymm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 31 /r")]
        vpmovdb_r8_k1z_ymm = 3752,

        /// <summary>
        /// vpmovdb r8 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 31 /r | Converts 16 packed double-word integers from zmm2 into 16 packed byte integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb r8 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 31 /r")]
        vpmovdb_r8_k1z_zmm = 3753,

        /// <summary>
        /// vpmovdb r8, xmm | EVEX.128.F3.0F38.W0 31 /r | Converts 4 packed double-word integers from xmm2 into 4 packed byte integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb r8, xmm","EVEX.128.F3.0F38.W0 31 /r")]
        vpmovdb_r8_xmm = 3754,

        /// <summary>
        /// vpmovdb r8, ymm | EVEX.256.F3.0F38.W0 31 /r | Converts 8 packed double-word integers from ymm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb r8, ymm","EVEX.256.F3.0F38.W0 31 /r")]
        vpmovdb_r8_ymm = 3755,

        /// <summary>
        /// vpmovdb r8, zmm | EVEX.512.F3.0F38.W0 31 /r | Converts 16 packed double-word integers from zmm2 into 16 packed byte integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdb r8, zmm","EVEX.512.F3.0F38.W0 31 /r")]
        vpmovdb_r8_zmm = 3756,

        /// <summary>
        /// vpmovdw m128 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 33 /r | Converts 8 packed double-word integers from ymm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw m128 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 33 /r")]
        vpmovdw_m128_k1z_ymm = 3757,

        /// <summary>
        /// vpmovdw m128, ymm | EVEX.256.F3.0F38.W0 33 /r | Converts 8 packed double-word integers from ymm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw m128, ymm","EVEX.256.F3.0F38.W0 33 /r")]
        vpmovdw_m128_ymm = 3758,

        /// <summary>
        /// vpmovdw m256 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 33 /r | Converts 16 packed double-word integers from zmm2 into 16 packed word integers in ymm1/m256 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw m256 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 33 /r")]
        vpmovdw_m256_k1z_zmm = 3759,

        /// <summary>
        /// vpmovdw m256, zmm | EVEX.512.F3.0F38.W0 33 /r | Converts 16 packed double-word integers from zmm2 into 16 packed word integers in ymm1/m256 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw m256, zmm","EVEX.512.F3.0F38.W0 33 /r")]
        vpmovdw_m256_zmm = 3760,

        /// <summary>
        /// vpmovdw m64 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 33 /r | Converts 4 packed double-word integers from xmm2 into 4 packed word integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw m64 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 33 /r")]
        vpmovdw_m64_k1z_xmm = 3761,

        /// <summary>
        /// vpmovdw m64, xmm | EVEX.128.F3.0F38.W0 33 /r | Converts 4 packed double-word integers from xmm2 into 4 packed word integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw m64, xmm","EVEX.128.F3.0F38.W0 33 /r")]
        vpmovdw_m64_xmm = 3762,

        /// <summary>
        /// vpmovdw r16 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 33 /r | Converts 16 packed double-word integers from zmm2 into 16 packed word integers in ymm1/m256 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw r16 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 33 /r")]
        vpmovdw_r16_k1z_zmm = 3763,

        /// <summary>
        /// vpmovdw r16, zmm | EVEX.512.F3.0F38.W0 33 /r | Converts 16 packed double-word integers from zmm2 into 16 packed word integers in ymm1/m256 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw r16, zmm","EVEX.512.F3.0F38.W0 33 /r")]
        vpmovdw_r16_zmm = 3764,

        /// <summary>
        /// vpmovdw r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 33 /r | Converts 4 packed double-word integers from xmm2 into 4 packed word integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 33 /r")]
        vpmovdw_r8_k1z_xmm = 3765,

        /// <summary>
        /// vpmovdw r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 33 /r | Converts 8 packed double-word integers from ymm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 33 /r")]
        vpmovdw_r8_k1z_ymm = 3766,

        /// <summary>
        /// vpmovdw r8, xmm | EVEX.128.F3.0F38.W0 33 /r | Converts 4 packed double-word integers from xmm2 into 4 packed word integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw r8, xmm","EVEX.128.F3.0F38.W0 33 /r")]
        vpmovdw_r8_xmm = 3767,

        /// <summary>
        /// vpmovdw r8, ymm | EVEX.256.F3.0F38.W0 33 /r | Converts 8 packed double-word integers from ymm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovdw r8, ymm","EVEX.256.F3.0F38.W0 33 /r")]
        vpmovdw_r8_ymm = 3768,

        /// <summary>
        /// vpmovm2b xmm, k | EVEX.128.F3.0F38.W0 28 /r | Sets each byte in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2b xmm, k","EVEX.128.F3.0F38.W0 28 /r")]
        vpmovm2b_xmm_k = 3769,

        /// <summary>
        /// vpmovm2b ymm, k | EVEX.256.F3.0F38.W0 28 /r | Sets each byte in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2b ymm, k","EVEX.256.F3.0F38.W0 28 /r")]
        vpmovm2b_ymm_k = 3770,

        /// <summary>
        /// vpmovm2b zmm, k | EVEX.512.F3.0F38.W0 28 /r | Sets each byte in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2b zmm, k","EVEX.512.F3.0F38.W0 28 /r")]
        vpmovm2b_zmm_k = 3771,

        /// <summary>
        /// vpmovm2d xmm, k | EVEX.128.F3.0F38.W0 38 /r | Sets each doubleword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2d xmm, k","EVEX.128.F3.0F38.W0 38 /r")]
        vpmovm2d_xmm_k = 3772,

        /// <summary>
        /// vpmovm2d ymm, k | EVEX.256.F3.0F38.W0 38 /r | Sets each doubleword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2d ymm, k","EVEX.256.F3.0F38.W0 38 /r")]
        vpmovm2d_ymm_k = 3773,

        /// <summary>
        /// vpmovm2d zmm, k | EVEX.512.F3.0F38.W0 38 /r | Sets each doubleword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2d zmm, k","EVEX.512.F3.0F38.W0 38 /r")]
        vpmovm2d_zmm_k = 3774,

        /// <summary>
        /// vpmovm2q xmm, k | EVEX.128.F3.0F38.W1 38 /r | Sets each quadword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2q xmm, k","EVEX.128.F3.0F38.W1 38 /r")]
        vpmovm2q_xmm_k = 3775,

        /// <summary>
        /// vpmovm2q ymm, k | EVEX.256.F3.0F38.W1 38 /r | Sets each quadword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2q ymm, k","EVEX.256.F3.0F38.W1 38 /r")]
        vpmovm2q_ymm_k = 3776,

        /// <summary>
        /// vpmovm2q zmm, k | EVEX.512.F3.0F38.W1 38 /r | Sets each quadword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2q zmm, k","EVEX.512.F3.0F38.W1 38 /r")]
        vpmovm2q_zmm_k = 3777,

        /// <summary>
        /// vpmovm2w xmm, k | EVEX.128.F3.0F38.W1 28 /r | Sets each word in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2w xmm, k","EVEX.128.F3.0F38.W1 28 /r")]
        vpmovm2w_xmm_k = 3778,

        /// <summary>
        /// vpmovm2w ymm, k | EVEX.256.F3.0F38.W1 28 /r | Sets each word in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2w ymm, k","EVEX.256.F3.0F38.W1 28 /r")]
        vpmovm2w_ymm_k = 3779,

        /// <summary>
        /// vpmovm2w zmm, k | EVEX.512.F3.0F38.W1 28 /r | Sets each word in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.
        /// </summary>
        [Symbol("vpmovm2w zmm, k","EVEX.512.F3.0F38.W1 28 /r")]
        vpmovm2w_zmm_k = 3780,

        /// <summary>
        /// vpmovmskb reg, xmm | VEX.128.66.0F.WIG D7 /r | Move a byte mask of xmm1 to reg. The upper bits of r32 or r64 are filled with zeros.
        /// </summary>
        [Symbol("vpmovmskb reg, xmm","VEX.128.66.0F.WIG D7 /r")]
        vpmovmskb_reg_xmm = 3781,

        /// <summary>
        /// vpmovmskb reg, ymm | VEX.256.66.0F.WIG D7 /r | Move a 32-bit mask of ymm1 to reg. The upper bits of r64 are filled with zeros.
        /// </summary>
        [Symbol("vpmovmskb reg, ymm","VEX.256.66.0F.WIG D7 /r")]
        vpmovmskb_reg_ymm = 3782,

        /// <summary>
        /// vpmovq2m k, xmm | EVEX.128.F3.0F38.W1 39 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in XMM1.
        /// </summary>
        [Symbol("vpmovq2m k, xmm","EVEX.128.F3.0F38.W1 39 /r")]
        vpmovq2m_k_xmm = 3783,

        /// <summary>
        /// vpmovq2m k, ymm | EVEX.256.F3.0F38.W1 39 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in YMM1.
        /// </summary>
        [Symbol("vpmovq2m k, ymm","EVEX.256.F3.0F38.W1 39 /r")]
        vpmovq2m_k_ymm = 3784,

        /// <summary>
        /// vpmovq2m k, zmm | EVEX.512.F3.0F38.W1 39 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in ZMM1.
        /// </summary>
        [Symbol("vpmovq2m k, zmm","EVEX.512.F3.0F38.W1 39 /r")]
        vpmovq2m_k_zmm = 3785,

        /// <summary>
        /// vpmovqb m16 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 32 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed byte integers in xmm1/m16 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb m16 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 32 /r")]
        vpmovqb_m16_k1z_xmm = 3786,

        /// <summary>
        /// vpmovqb m16, xmm | EVEX.128.F3.0F38.W0 32 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed byte integers in xmm1/m16 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb m16, xmm","EVEX.128.F3.0F38.W0 32 /r")]
        vpmovqb_m16_xmm = 3787,

        /// <summary>
        /// vpmovqb m32 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 32 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed byte integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb m32 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 32 /r")]
        vpmovqb_m32_k1z_ymm = 3788,

        /// <summary>
        /// vpmovqb m32, ymm | EVEX.256.F3.0F38.W0 32 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed byte integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb m32, ymm","EVEX.256.F3.0F38.W0 32 /r")]
        vpmovqb_m32_ymm = 3789,

        /// <summary>
        /// vpmovqb m64 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 32 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb m64 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 32 /r")]
        vpmovqb_m64_k1z_zmm = 3790,

        /// <summary>
        /// vpmovqb m64, zmm | EVEX.512.F3.0F38.W0 32 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb m64, zmm","EVEX.512.F3.0F38.W0 32 /r")]
        vpmovqb_m64_zmm = 3791,

        /// <summary>
        /// vpmovqb r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 32 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed byte integers in xmm1/m16 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 32 /r")]
        vpmovqb_r8_k1z_xmm = 3792,

        /// <summary>
        /// vpmovqb r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 32 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed byte integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 32 /r")]
        vpmovqb_r8_k1z_ymm = 3793,

        /// <summary>
        /// vpmovqb r8 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 32 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb r8 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 32 /r")]
        vpmovqb_r8_k1z_zmm = 3794,

        /// <summary>
        /// vpmovqb r8, xmm | EVEX.128.F3.0F38.W0 32 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed byte integers in xmm1/m16 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb r8, xmm","EVEX.128.F3.0F38.W0 32 /r")]
        vpmovqb_r8_xmm = 3795,

        /// <summary>
        /// vpmovqb r8, ymm | EVEX.256.F3.0F38.W0 32 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed byte integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb r8, ymm","EVEX.256.F3.0F38.W0 32 /r")]
        vpmovqb_r8_ymm = 3796,

        /// <summary>
        /// vpmovqb r8, zmm | EVEX.512.F3.0F38.W0 32 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqb r8, zmm","EVEX.512.F3.0F38.W0 32 /r")]
        vpmovqb_r8_zmm = 3797,

        /// <summary>
        /// vpmovqd m128 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 35 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed double-word integers in xmm1/m128 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd m128 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 35 /r")]
        vpmovqd_m128_k1z_xmm = 3798,

        /// <summary>
        /// vpmovqd m128 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 35 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed double-word integers in xmm1/m128 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd m128 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 35 /r")]
        vpmovqd_m128_k1z_ymm = 3799,

        /// <summary>
        /// vpmovqd m128, xmm | EVEX.128.F3.0F38.W0 35 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed double-word integers in xmm1/m128 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd m128, xmm","EVEX.128.F3.0F38.W0 35 /r")]
        vpmovqd_m128_xmm = 3800,

        /// <summary>
        /// vpmovqd m128, ymm | EVEX.256.F3.0F38.W0 35 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed double-word integers in xmm1/m128 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd m128, ymm","EVEX.256.F3.0F38.W0 35 /r")]
        vpmovqd_m128_ymm = 3801,

        /// <summary>
        /// vpmovqd m256 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 35 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed double-word integers in ymm1/m256 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd m256 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 35 /r")]
        vpmovqd_m256_k1z_zmm = 3802,

        /// <summary>
        /// vpmovqd m256, zmm | EVEX.512.F3.0F38.W0 35 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed double-word integers in ymm1/m256 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd m256, zmm","EVEX.512.F3.0F38.W0 35 /r")]
        vpmovqd_m256_zmm = 3803,

        /// <summary>
        /// vpmovqd r16 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 35 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed double-word integers in ymm1/m256 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd r16 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 35 /r")]
        vpmovqd_r16_k1z_zmm = 3804,

        /// <summary>
        /// vpmovqd r16, zmm | EVEX.512.F3.0F38.W0 35 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed double-word integers in ymm1/m256 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd r16, zmm","EVEX.512.F3.0F38.W0 35 /r")]
        vpmovqd_r16_zmm = 3805,

        /// <summary>
        /// vpmovqd r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 35 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed double-word integers in xmm1/m128 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 35 /r")]
        vpmovqd_r8_k1z_xmm = 3806,

        /// <summary>
        /// vpmovqd r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 35 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed double-word integers in xmm1/m128 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 35 /r")]
        vpmovqd_r8_k1z_ymm = 3807,

        /// <summary>
        /// vpmovqd r8, xmm | EVEX.128.F3.0F38.W0 35 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed double-word integers in xmm1/m128 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd r8, xmm","EVEX.128.F3.0F38.W0 35 /r")]
        vpmovqd_r8_xmm = 3808,

        /// <summary>
        /// vpmovqd r8, ymm | EVEX.256.F3.0F38.W0 35 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed double-word integers in xmm1/m128 with truncation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovqd r8, ymm","EVEX.256.F3.0F38.W0 35 /r")]
        vpmovqd_r8_ymm = 3809,

        /// <summary>
        /// vpmovqw m128 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 34 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw m128 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 34 /r")]
        vpmovqw_m128_k1z_zmm = 3810,

        /// <summary>
        /// vpmovqw m128, zmm | EVEX.512.F3.0F38.W0 34 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw m128, zmm","EVEX.512.F3.0F38.W0 34 /r")]
        vpmovqw_m128_zmm = 3811,

        /// <summary>
        /// vpmovqw m32 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 34 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed word integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw m32 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 34 /r")]
        vpmovqw_m32_k1z_xmm = 3812,

        /// <summary>
        /// vpmovqw m32, xmm | EVEX.128.F3.0F38.W0 34 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed word integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw m32, xmm","EVEX.128.F3.0F38.W0 34 /r")]
        vpmovqw_m32_xmm = 3813,

        /// <summary>
        /// vpmovqw m64 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 34 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed word integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw m64 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 34 /r")]
        vpmovqw_m64_k1z_ymm = 3814,

        /// <summary>
        /// vpmovqw m64, ymm | EVEX.256.F3.0F38.W0 34 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed word integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw m64, ymm","EVEX.256.F3.0F38.W0 34 /r")]
        vpmovqw_m64_ymm = 3815,

        /// <summary>
        /// vpmovqw r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 34 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed word integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 34 /r")]
        vpmovqw_r8_k1z_xmm = 3816,

        /// <summary>
        /// vpmovqw r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 34 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed word integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 34 /r")]
        vpmovqw_r8_k1z_ymm = 3817,

        /// <summary>
        /// vpmovqw r8 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 34 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw r8 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 34 /r")]
        vpmovqw_r8_k1z_zmm = 3818,

        /// <summary>
        /// vpmovqw r8, xmm | EVEX.128.F3.0F38.W0 34 /r | Converts 2 packed quad-word integers from xmm2 into 2 packed word integers in xmm1/m32 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw r8, xmm","EVEX.128.F3.0F38.W0 34 /r")]
        vpmovqw_r8_xmm = 3819,

        /// <summary>
        /// vpmovqw r8, ymm | EVEX.256.F3.0F38.W0 34 /r | Converts 4 packed quad-word integers from ymm2 into 4 packed word integers in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw r8, ymm","EVEX.256.F3.0F38.W0 34 /r")]
        vpmovqw_r8_ymm = 3820,

        /// <summary>
        /// vpmovqw r8, zmm | EVEX.512.F3.0F38.W0 34 /r | Converts 8 packed quad-word integers from zmm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovqw r8, zmm","EVEX.512.F3.0F38.W0 34 /r")]
        vpmovqw_r8_zmm = 3821,

        /// <summary>
        /// vpmovsdb m128 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 21 /r | Converts 16 packed signed double-word integers from zmm2 into 16 packed signed byte integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb m128 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 21 /r")]
        vpmovsdb_m128_k1z_zmm = 3822,

        /// <summary>
        /// vpmovsdb m128, zmm | EVEX.512.F3.0F38.W0 21 /r | Converts 16 packed signed double-word integers from zmm2 into 16 packed signed byte integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb m128, zmm","EVEX.512.F3.0F38.W0 21 /r")]
        vpmovsdb_m128_zmm = 3823,

        /// <summary>
        /// vpmovsdb m32 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 21 /r | Converts 4 packed signed double-word integers from xmm2 into 4 packed signed byte integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb m32 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 21 /r")]
        vpmovsdb_m32_k1z_xmm = 3824,

        /// <summary>
        /// vpmovsdb m32, xmm | EVEX.128.F3.0F38.W0 21 /r | Converts 4 packed signed double-word integers from xmm2 into 4 packed signed byte integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb m32, xmm","EVEX.128.F3.0F38.W0 21 /r")]
        vpmovsdb_m32_xmm = 3825,

        /// <summary>
        /// vpmovsdb m64 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 21 /r | Converts 8 packed signed double-word integers from ymm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb m64 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 21 /r")]
        vpmovsdb_m64_k1z_ymm = 3826,

        /// <summary>
        /// vpmovsdb m64, ymm | EVEX.256.F3.0F38.W0 21 /r | Converts 8 packed signed double-word integers from ymm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb m64, ymm","EVEX.256.F3.0F38.W0 21 /r")]
        vpmovsdb_m64_ymm = 3827,

        /// <summary>
        /// vpmovsdb r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 21 /r | Converts 4 packed signed double-word integers from xmm2 into 4 packed signed byte integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 21 /r")]
        vpmovsdb_r8_k1z_xmm = 3828,

        /// <summary>
        /// vpmovsdb r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 21 /r | Converts 8 packed signed double-word integers from ymm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 21 /r")]
        vpmovsdb_r8_k1z_ymm = 3829,

        /// <summary>
        /// vpmovsdb r8 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 21 /r | Converts 16 packed signed double-word integers from zmm2 into 16 packed signed byte integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb r8 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 21 /r")]
        vpmovsdb_r8_k1z_zmm = 3830,

        /// <summary>
        /// vpmovsdb r8, xmm | EVEX.128.F3.0F38.W0 21 /r | Converts 4 packed signed double-word integers from xmm2 into 4 packed signed byte integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb r8, xmm","EVEX.128.F3.0F38.W0 21 /r")]
        vpmovsdb_r8_xmm = 3831,

        /// <summary>
        /// vpmovsdb r8, ymm | EVEX.256.F3.0F38.W0 21 /r | Converts 8 packed signed double-word integers from ymm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb r8, ymm","EVEX.256.F3.0F38.W0 21 /r")]
        vpmovsdb_r8_ymm = 3832,

        /// <summary>
        /// vpmovsdb r8, zmm | EVEX.512.F3.0F38.W0 21 /r | Converts 16 packed signed double-word integers from zmm2 into 16 packed signed byte integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdb r8, zmm","EVEX.512.F3.0F38.W0 21 /r")]
        vpmovsdb_r8_zmm = 3833,

        /// <summary>
        /// vpmovsdw m128 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 23 /r | Converts 8 packed signed double-word integers from ymm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw m128 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 23 /r")]
        vpmovsdw_m128_k1z_ymm = 3834,

        /// <summary>
        /// vpmovsdw m128, ymm | EVEX.256.F3.0F38.W0 23 /r | Converts 8 packed signed double-word integers from ymm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw m128, ymm","EVEX.256.F3.0F38.W0 23 /r")]
        vpmovsdw_m128_ymm = 3835,

        /// <summary>
        /// vpmovsdw m256 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 23 /r | Converts 16 packed signed double-word integers from zmm2 into 16 packed signed word integers in ymm1/m256 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw m256 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 23 /r")]
        vpmovsdw_m256_k1z_zmm = 3836,

        /// <summary>
        /// vpmovsdw m256, zmm | EVEX.512.F3.0F38.W0 23 /r | Converts 16 packed signed double-word integers from zmm2 into 16 packed signed word integers in ymm1/m256 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw m256, zmm","EVEX.512.F3.0F38.W0 23 /r")]
        vpmovsdw_m256_zmm = 3837,

        /// <summary>
        /// vpmovsdw m64 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 23 /r | Converts 4 packed signed double-word integers from xmm2 into 4 packed signed word integers in ymm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw m64 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 23 /r")]
        vpmovsdw_m64_k1z_xmm = 3838,

        /// <summary>
        /// vpmovsdw m64, xmm | EVEX.128.F3.0F38.W0 23 /r | Converts 4 packed signed double-word integers from xmm2 into 4 packed signed word integers in ymm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw m64, xmm","EVEX.128.F3.0F38.W0 23 /r")]
        vpmovsdw_m64_xmm = 3839,

        /// <summary>
        /// vpmovsdw r16 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 23 /r | Converts 16 packed signed double-word integers from zmm2 into 16 packed signed word integers in ymm1/m256 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw r16 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 23 /r")]
        vpmovsdw_r16_k1z_zmm = 3840,

        /// <summary>
        /// vpmovsdw r16, zmm | EVEX.512.F3.0F38.W0 23 /r | Converts 16 packed signed double-word integers from zmm2 into 16 packed signed word integers in ymm1/m256 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw r16, zmm","EVEX.512.F3.0F38.W0 23 /r")]
        vpmovsdw_r16_zmm = 3841,

        /// <summary>
        /// vpmovsdw r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 23 /r | Converts 4 packed signed double-word integers from xmm2 into 4 packed signed word integers in ymm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 23 /r")]
        vpmovsdw_r8_k1z_xmm = 3842,

        /// <summary>
        /// vpmovsdw r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 23 /r | Converts 8 packed signed double-word integers from ymm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 23 /r")]
        vpmovsdw_r8_k1z_ymm = 3843,

        /// <summary>
        /// vpmovsdw r8, xmm | EVEX.128.F3.0F38.W0 23 /r | Converts 4 packed signed double-word integers from xmm2 into 4 packed signed word integers in ymm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw r8, xmm","EVEX.128.F3.0F38.W0 23 /r")]
        vpmovsdw_r8_xmm = 3844,

        /// <summary>
        /// vpmovsdw r8, ymm | EVEX.256.F3.0F38.W0 23 /r | Converts 8 packed signed double-word integers from ymm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsdw r8, ymm","EVEX.256.F3.0F38.W0 23 /r")]
        vpmovsdw_r8_ymm = 3845,

        /// <summary>
        /// vpmovsqb m16 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 22 /r | Converts 2 packed signed quad-word integers from xmm2 into 2 packed signed byte integers in xmm1/m16 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb m16 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 22 /r")]
        vpmovsqb_m16_k1z_xmm = 3846,

        /// <summary>
        /// vpmovsqb m16, xmm | EVEX.128.F3.0F38.W0 22 /r | Converts 2 packed signed quad-word integers from xmm2 into 2 packed signed byte integers in xmm1/m16 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb m16, xmm","EVEX.128.F3.0F38.W0 22 /r")]
        vpmovsqb_m16_xmm = 3847,

        /// <summary>
        /// vpmovsqb m32 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 22 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed byte integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb m32 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 22 /r")]
        vpmovsqb_m32_k1z_ymm = 3848,

        /// <summary>
        /// vpmovsqb m32, ymm | EVEX.256.F3.0F38.W0 22 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed byte integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb m32, ymm","EVEX.256.F3.0F38.W0 22 /r")]
        vpmovsqb_m32_ymm = 3849,

        /// <summary>
        /// vpmovsqb m64 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 22 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb m64 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 22 /r")]
        vpmovsqb_m64_k1z_zmm = 3850,

        /// <summary>
        /// vpmovsqb m64, zmm | EVEX.512.F3.0F38.W0 22 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb m64, zmm","EVEX.512.F3.0F38.W0 22 /r")]
        vpmovsqb_m64_zmm = 3851,

        /// <summary>
        /// vpmovsqb r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 22 /r | Converts 2 packed signed quad-word integers from xmm2 into 2 packed signed byte integers in xmm1/m16 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 22 /r")]
        vpmovsqb_r8_k1z_xmm = 3852,

        /// <summary>
        /// vpmovsqb r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 22 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed byte integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 22 /r")]
        vpmovsqb_r8_k1z_ymm = 3853,

        /// <summary>
        /// vpmovsqb r8 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 22 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb r8 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 22 /r")]
        vpmovsqb_r8_k1z_zmm = 3854,

        /// <summary>
        /// vpmovsqb r8, xmm | EVEX.128.F3.0F38.W0 22 /r | Converts 2 packed signed quad-word integers from xmm2 into 2 packed signed byte integers in xmm1/m16 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb r8, xmm","EVEX.128.F3.0F38.W0 22 /r")]
        vpmovsqb_r8_xmm = 3855,

        /// <summary>
        /// vpmovsqb r8, ymm | EVEX.256.F3.0F38.W0 22 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed byte integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb r8, ymm","EVEX.256.F3.0F38.W0 22 /r")]
        vpmovsqb_r8_ymm = 3856,

        /// <summary>
        /// vpmovsqb r8, zmm | EVEX.512.F3.0F38.W0 22 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqb r8, zmm","EVEX.512.F3.0F38.W0 22 /r")]
        vpmovsqb_r8_zmm = 3857,

        /// <summary>
        /// vpmovsqd m128 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 25 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed double-word integers in xmm1/m128 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd m128 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 25 /r")]
        vpmovsqd_m128_k1z_ymm = 3858,

        /// <summary>
        /// vpmovsqd m128, ymm | EVEX.256.F3.0F38.W0 25 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed double-word integers in xmm1/m128 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd m128, ymm","EVEX.256.F3.0F38.W0 25 /r")]
        vpmovsqd_m128_ymm = 3859,

        /// <summary>
        /// vpmovsqd m256 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 25 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed double-word integers in ymm1/m256 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd m256 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 25 /r")]
        vpmovsqd_m256_k1z_zmm = 3860,

        /// <summary>
        /// vpmovsqd m256, zmm | EVEX.512.F3.0F38.W0 25 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed double-word integers in ymm1/m256 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd m256, zmm","EVEX.512.F3.0F38.W0 25 /r")]
        vpmovsqd_m256_zmm = 3861,

        /// <summary>
        /// vpmovsqd m64 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 25 /r | Converts 2 packed signed quad-word integers from xmm2 into 2 packed signed double-word integers in xmm1/m64 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd m64 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 25 /r")]
        vpmovsqd_m64_k1z_xmm = 3862,

        /// <summary>
        /// vpmovsqd m64, xmm | EVEX.128.F3.0F38.W0 25 /r | Converts 2 packed signed quad-word integers from xmm2 into 2 packed signed double-word integers in xmm1/m64 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd m64, xmm","EVEX.128.F3.0F38.W0 25 /r")]
        vpmovsqd_m64_xmm = 3863,

        /// <summary>
        /// vpmovsqd r16 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 25 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed double-word integers in ymm1/m256 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd r16 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 25 /r")]
        vpmovsqd_r16_k1z_zmm = 3864,

        /// <summary>
        /// vpmovsqd r16, zmm | EVEX.512.F3.0F38.W0 25 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed double-word integers in ymm1/m256 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd r16, zmm","EVEX.512.F3.0F38.W0 25 /r")]
        vpmovsqd_r16_zmm = 3865,

        /// <summary>
        /// vpmovsqd r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 25 /r | Converts 2 packed signed quad-word integers from xmm2 into 2 packed signed double-word integers in xmm1/m64 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 25 /r")]
        vpmovsqd_r8_k1z_xmm = 3866,

        /// <summary>
        /// vpmovsqd r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 25 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed double-word integers in xmm1/m128 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 25 /r")]
        vpmovsqd_r8_k1z_ymm = 3867,

        /// <summary>
        /// vpmovsqd r8, xmm | EVEX.128.F3.0F38.W0 25 /r | Converts 2 packed signed quad-word integers from xmm2 into 2 packed signed double-word integers in xmm1/m64 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd r8, xmm","EVEX.128.F3.0F38.W0 25 /r")]
        vpmovsqd_r8_xmm = 3868,

        /// <summary>
        /// vpmovsqd r8, ymm | EVEX.256.F3.0F38.W0 25 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed double-word integers in xmm1/m128 using signed saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsqd r8, ymm","EVEX.256.F3.0F38.W0 25 /r")]
        vpmovsqd_r8_ymm = 3869,

        /// <summary>
        /// vpmovsqw m128 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 24 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw m128 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 24 /r")]
        vpmovsqw_m128_k1z_zmm = 3870,

        /// <summary>
        /// vpmovsqw m128, zmm | EVEX.512.F3.0F38.W0 24 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw m128, zmm","EVEX.512.F3.0F38.W0 24 /r")]
        vpmovsqw_m128_zmm = 3871,

        /// <summary>
        /// vpmovsqw m32 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 24 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw m32 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 24 /r")]
        vpmovsqw_m32_k1z_xmm = 3872,

        /// <summary>
        /// vpmovsqw m32, xmm | EVEX.128.F3.0F38.W0 24 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw m32, xmm","EVEX.128.F3.0F38.W0 24 /r")]
        vpmovsqw_m32_xmm = 3873,

        /// <summary>
        /// vpmovsqw m64 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 24 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed word integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw m64 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 24 /r")]
        vpmovsqw_m64_k1z_ymm = 3874,

        /// <summary>
        /// vpmovsqw m64, ymm | EVEX.256.F3.0F38.W0 24 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed word integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw m64, ymm","EVEX.256.F3.0F38.W0 24 /r")]
        vpmovsqw_m64_ymm = 3875,

        /// <summary>
        /// vpmovsqw r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 24 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 24 /r")]
        vpmovsqw_r8_k1z_xmm = 3876,

        /// <summary>
        /// vpmovsqw r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 24 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed word integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 24 /r")]
        vpmovsqw_r8_k1z_ymm = 3877,

        /// <summary>
        /// vpmovsqw r8 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 24 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw r8 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 24 /r")]
        vpmovsqw_r8_k1z_zmm = 3878,

        /// <summary>
        /// vpmovsqw r8, xmm | EVEX.128.F3.0F38.W0 24 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m32 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw r8, xmm","EVEX.128.F3.0F38.W0 24 /r")]
        vpmovsqw_r8_xmm = 3879,

        /// <summary>
        /// vpmovsqw r8, ymm | EVEX.256.F3.0F38.W0 24 /r | Converts 4 packed signed quad-word integers from ymm2 into 4 packed signed word integers in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw r8, ymm","EVEX.256.F3.0F38.W0 24 /r")]
        vpmovsqw_r8_ymm = 3880,

        /// <summary>
        /// vpmovsqw r8, zmm | EVEX.512.F3.0F38.W0 24 /r | Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovsqw r8, zmm","EVEX.512.F3.0F38.W0 24 /r")]
        vpmovsqw_r8_zmm = 3881,

        /// <summary>
        /// vpmovswb m128 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 20 /r | Converts 16 packed signed word integers from ymm2 into 16 packed signed bytes in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb m128 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 20 /r")]
        vpmovswb_m128_k1z_ymm = 3882,

        /// <summary>
        /// vpmovswb m128, ymm | EVEX.256.F3.0F38.W0 20 /r | Converts 16 packed signed word integers from ymm2 into 16 packed signed bytes in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb m128, ymm","EVEX.256.F3.0F38.W0 20 /r")]
        vpmovswb_m128_ymm = 3883,

        /// <summary>
        /// vpmovswb m256 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 20 /r | Converts 32 packed signed word integers from zmm2 into 32 packed signed bytes in ymm1/m256 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb m256 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 20 /r")]
        vpmovswb_m256_k1z_zmm = 3884,

        /// <summary>
        /// vpmovswb m256, zmm | EVEX.512.F3.0F38.W0 20 /r | Converts 32 packed signed word integers from zmm2 into 32 packed signed bytes in ymm1/m256 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb m256, zmm","EVEX.512.F3.0F38.W0 20 /r")]
        vpmovswb_m256_zmm = 3885,

        /// <summary>
        /// vpmovswb m64 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 20 /r | Converts 8 packed signed word integers from xmm2 into 8 packed signed bytes in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb m64 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 20 /r")]
        vpmovswb_m64_k1z_xmm = 3886,

        /// <summary>
        /// vpmovswb m64, xmm | EVEX.128.F3.0F38.W0 20 /r | Converts 8 packed signed word integers from xmm2 into 8 packed signed bytes in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb m64, xmm","EVEX.128.F3.0F38.W0 20 /r")]
        vpmovswb_m64_xmm = 3887,

        /// <summary>
        /// vpmovswb r16 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 20 /r | Converts 32 packed signed word integers from zmm2 into 32 packed signed bytes in ymm1/m256 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb r16 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 20 /r")]
        vpmovswb_r16_k1z_zmm = 3888,

        /// <summary>
        /// vpmovswb r16, zmm | EVEX.512.F3.0F38.W0 20 /r | Converts 32 packed signed word integers from zmm2 into 32 packed signed bytes in ymm1/m256 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb r16, zmm","EVEX.512.F3.0F38.W0 20 /r")]
        vpmovswb_r16_zmm = 3889,

        /// <summary>
        /// vpmovswb r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 20 /r | Converts 8 packed signed word integers from xmm2 into 8 packed signed bytes in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 20 /r")]
        vpmovswb_r8_k1z_xmm = 3890,

        /// <summary>
        /// vpmovswb r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 20 /r | Converts 16 packed signed word integers from ymm2 into 16 packed signed bytes in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 20 /r")]
        vpmovswb_r8_k1z_ymm = 3891,

        /// <summary>
        /// vpmovswb r8, xmm | EVEX.128.F3.0F38.W0 20 /r | Converts 8 packed signed word integers from xmm2 into 8 packed signed bytes in xmm1/m64 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb r8, xmm","EVEX.128.F3.0F38.W0 20 /r")]
        vpmovswb_r8_xmm = 3892,

        /// <summary>
        /// vpmovswb r8, ymm | EVEX.256.F3.0F38.W0 20 /r | Converts 16 packed signed word integers from ymm2 into 16 packed signed bytes in xmm1/m128 using signed saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovswb r8, ymm","EVEX.256.F3.0F38.W0 20 /r")]
        vpmovswb_r8_ymm = 3893,

        /// <summary>
        /// vpmovsxbd xmm {k1}{z}, m32 | EVEX.128.66.0F38.WIG 21 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd xmm {k1}{z}, m32","EVEX.128.66.0F38.WIG 21 /r")]
        vpmovsxbd_xmm_k1z_m32 = 3894,

        /// <summary>
        /// vpmovsxbd xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 21 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 21 /r")]
        vpmovsxbd_xmm_k1z_r8 = 3895,

        /// <summary>
        /// vpmovsxbd xmm, m32 | EVEX.128.66.0F38.WIG 21 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd xmm, m32","EVEX.128.66.0F38.WIG 21 /r")]
        vpmovsxbd_xmm_m32 = 3896,

        /// <summary>
        /// vpmovsxbd xmm, m32 | VEX.128.66.0F38.WIG 21 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxbd xmm, m32","VEX.128.66.0F38.WIG 21 /r")]
        vpmovsxbd_xmm_m32_vex = 3897,

        /// <summary>
        /// vpmovsxbd xmm, r8 | EVEX.128.66.0F38.WIG 21 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd xmm, r8","EVEX.128.66.0F38.WIG 21 /r")]
        vpmovsxbd_xmm_r8 = 3898,

        /// <summary>
        /// vpmovsxbd xmm, r8 | VEX.128.66.0F38.WIG 21 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxbd xmm, r8","VEX.128.66.0F38.WIG 21 /r")]
        vpmovsxbd_xmm_r8_vex = 3899,

        /// <summary>
        /// vpmovsxbd ymm {k1}{z}, m64 | EVEX.256.66.0F38.WIG 21 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd ymm {k1}{z}, m64","EVEX.256.66.0F38.WIG 21 /r")]
        vpmovsxbd_ymm_k1z_m64 = 3900,

        /// <summary>
        /// vpmovsxbd ymm {k1}{z}, r8 | EVEX.256.66.0F38.WIG 21 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd ymm {k1}{z}, r8","EVEX.256.66.0F38.WIG 21 /r")]
        vpmovsxbd_ymm_k1z_r8 = 3901,

        /// <summary>
        /// vpmovsxbd ymm, m64 | EVEX.256.66.0F38.WIG 21 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd ymm, m64","EVEX.256.66.0F38.WIG 21 /r")]
        vpmovsxbd_ymm_m64 = 3902,

        /// <summary>
        /// vpmovsxbd ymm, m64 | VEX.256.66.0F38.WIG 21 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxbd ymm, m64","VEX.256.66.0F38.WIG 21 /r")]
        vpmovsxbd_ymm_m64_vex = 3903,

        /// <summary>
        /// vpmovsxbd ymm, r8 | EVEX.256.66.0F38.WIG 21 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd ymm, r8","EVEX.256.66.0F38.WIG 21 /r")]
        vpmovsxbd_ymm_r8 = 3904,

        /// <summary>
        /// vpmovsxbd ymm, r8 | VEX.256.66.0F38.WIG 21 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxbd ymm, r8","VEX.256.66.0F38.WIG 21 /r")]
        vpmovsxbd_ymm_r8_vex = 3905,

        /// <summary>
        /// vpmovsxbd zmm {k1}{z}, m128 | EVEX.512.66.0F38.WIG 21 /r | Sign extend 16 packed 8-bit integers in the low 16 bytes of xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd zmm {k1}{z}, m128","EVEX.512.66.0F38.WIG 21 /r")]
        vpmovsxbd_zmm_k1z_m128 = 3906,

        /// <summary>
        /// vpmovsxbd zmm {k1}{z}, r8 | EVEX.512.66.0F38.WIG 21 /r | Sign extend 16 packed 8-bit integers in the low 16 bytes of xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd zmm {k1}{z}, r8","EVEX.512.66.0F38.WIG 21 /r")]
        vpmovsxbd_zmm_k1z_r8 = 3907,

        /// <summary>
        /// vpmovsxbd zmm, m128 | EVEX.512.66.0F38.WIG 21 /r | Sign extend 16 packed 8-bit integers in the low 16 bytes of xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd zmm, m128","EVEX.512.66.0F38.WIG 21 /r")]
        vpmovsxbd_zmm_m128 = 3908,

        /// <summary>
        /// vpmovsxbd zmm, r8 | EVEX.512.66.0F38.WIG 21 /r | Sign extend 16 packed 8-bit integers in the low 16 bytes of xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbd zmm, r8","EVEX.512.66.0F38.WIG 21 /r")]
        vpmovsxbd_zmm_r8 = 3909,

        /// <summary>
        /// vpmovsxbq xmm {k1}{z}, m16 | EVEX.128.66.0F38.WIG 22 /r | Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq xmm {k1}{z}, m16","EVEX.128.66.0F38.WIG 22 /r")]
        vpmovsxbq_xmm_k1z_m16 = 3910,

        /// <summary>
        /// vpmovsxbq xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 22 /r | Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 22 /r")]
        vpmovsxbq_xmm_k1z_r8 = 3911,

        /// <summary>
        /// vpmovsxbq xmm, m16 | EVEX.128.66.0F38.WIG 22 /r | Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq xmm, m16","EVEX.128.66.0F38.WIG 22 /r")]
        vpmovsxbq_xmm_m16 = 3912,

        /// <summary>
        /// vpmovsxbq xmm, m16 | VEX.128.66.0F38.WIG 22 /r | Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxbq xmm, m16","VEX.128.66.0F38.WIG 22 /r")]
        vpmovsxbq_xmm_m16_vex = 3913,

        /// <summary>
        /// vpmovsxbq xmm, r8 | EVEX.128.66.0F38.WIG 22 /r | Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq xmm, r8","EVEX.128.66.0F38.WIG 22 /r")]
        vpmovsxbq_xmm_r8 = 3914,

        /// <summary>
        /// vpmovsxbq xmm, r8 | VEX.128.66.0F38.WIG 22 /r | Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxbq xmm, r8","VEX.128.66.0F38.WIG 22 /r")]
        vpmovsxbq_xmm_r8_vex = 3915,

        /// <summary>
        /// vpmovsxbq ymm {k1}{z}, m32 | EVEX.256.66.0F38.WIG 22 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq ymm {k1}{z}, m32","EVEX.256.66.0F38.WIG 22 /r")]
        vpmovsxbq_ymm_k1z_m32 = 3916,

        /// <summary>
        /// vpmovsxbq ymm {k1}{z}, r8 | EVEX.256.66.0F38.WIG 22 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq ymm {k1}{z}, r8","EVEX.256.66.0F38.WIG 22 /r")]
        vpmovsxbq_ymm_k1z_r8 = 3917,

        /// <summary>
        /// vpmovsxbq ymm, m32 | EVEX.256.66.0F38.WIG 22 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq ymm, m32","EVEX.256.66.0F38.WIG 22 /r")]
        vpmovsxbq_ymm_m32 = 3918,

        /// <summary>
        /// vpmovsxbq ymm, m32 | VEX.256.66.0F38.WIG 22 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxbq ymm, m32","VEX.256.66.0F38.WIG 22 /r")]
        vpmovsxbq_ymm_m32_vex = 3919,

        /// <summary>
        /// vpmovsxbq ymm, r8 | EVEX.256.66.0F38.WIG 22 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq ymm, r8","EVEX.256.66.0F38.WIG 22 /r")]
        vpmovsxbq_ymm_r8 = 3920,

        /// <summary>
        /// vpmovsxbq ymm, r8 | VEX.256.66.0F38.WIG 22 /r | Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxbq ymm, r8","VEX.256.66.0F38.WIG 22 /r")]
        vpmovsxbq_ymm_r8_vex = 3921,

        /// <summary>
        /// vpmovsxbq zmm {k1}{z}, m64 | EVEX.512.66.0F38.WIG 22 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq zmm {k1}{z}, m64","EVEX.512.66.0F38.WIG 22 /r")]
        vpmovsxbq_zmm_k1z_m64 = 3922,

        /// <summary>
        /// vpmovsxbq zmm {k1}{z}, r8 | EVEX.512.66.0F38.WIG 22 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq zmm {k1}{z}, r8","EVEX.512.66.0F38.WIG 22 /r")]
        vpmovsxbq_zmm_k1z_r8 = 3923,

        /// <summary>
        /// vpmovsxbq zmm, m64 | EVEX.512.66.0F38.WIG 22 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq zmm, m64","EVEX.512.66.0F38.WIG 22 /r")]
        vpmovsxbq_zmm_m64 = 3924,

        /// <summary>
        /// vpmovsxbq zmm, r8 | EVEX.512.66.0F38.WIG 22 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxbq zmm, r8","EVEX.512.66.0F38.WIG 22 /r")]
        vpmovsxbq_zmm_r8 = 3925,

        /// <summary>
        /// vpmovsxbw xmm {k1}{z}, m64 | EVEX.128.66.0F38.WIG 20 /r | Sign extend 8 packed 8-bit integers in xmm2/m64 to 8 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovsxbw xmm {k1}{z}, m64","EVEX.128.66.0F38.WIG 20 /r")]
        vpmovsxbw_xmm_k1z_m64 = 3926,

        /// <summary>
        /// vpmovsxbw xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 20 /r | Sign extend 8 packed 8-bit integers in xmm2/m64 to 8 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovsxbw xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 20 /r")]
        vpmovsxbw_xmm_k1z_r8 = 3927,

        /// <summary>
        /// vpmovsxbw xmm, m64 | EVEX.128.66.0F38.WIG 20 /r | Sign extend 8 packed 8-bit integers in xmm2/m64 to 8 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovsxbw xmm, m64","EVEX.128.66.0F38.WIG 20 /r")]
        vpmovsxbw_xmm_m64 = 3928,

        /// <summary>
        /// vpmovsxbw xmm, m64 | VEX.128.66.0F38.WIG 20 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxbw xmm, m64","VEX.128.66.0F38.WIG 20 /r")]
        vpmovsxbw_xmm_m64_vex = 3929,

        /// <summary>
        /// vpmovsxbw xmm, r8 | EVEX.128.66.0F38.WIG 20 /r | Sign extend 8 packed 8-bit integers in xmm2/m64 to 8 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovsxbw xmm, r8","EVEX.128.66.0F38.WIG 20 /r")]
        vpmovsxbw_xmm_r8 = 3930,

        /// <summary>
        /// vpmovsxbw xmm, r8 | VEX.128.66.0F38.WIG 20 /r | Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxbw xmm, r8","VEX.128.66.0F38.WIG 20 /r")]
        vpmovsxbw_xmm_r8_vex = 3931,

        /// <summary>
        /// vpmovsxbw ymm {k1}{z}, m128 | EVEX.256.66.0F38.WIG 20 /r | Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxbw ymm {k1}{z}, m128","EVEX.256.66.0F38.WIG 20 /r")]
        vpmovsxbw_ymm_k1z_m128 = 3932,

        /// <summary>
        /// vpmovsxbw ymm {k1}{z}, r8 | EVEX.256.66.0F38.WIG 20 /r | Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxbw ymm {k1}{z}, r8","EVEX.256.66.0F38.WIG 20 /r")]
        vpmovsxbw_ymm_k1z_r8 = 3933,

        /// <summary>
        /// vpmovsxbw ymm, m128 | EVEX.256.66.0F38.WIG 20 /r | Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxbw ymm, m128","EVEX.256.66.0F38.WIG 20 /r")]
        vpmovsxbw_ymm_m128 = 3934,

        /// <summary>
        /// vpmovsxbw ymm, m128 | VEX.256.66.0F38.WIG 20 /r | Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxbw ymm, m128","VEX.256.66.0F38.WIG 20 /r")]
        vpmovsxbw_ymm_m128_vex = 3935,

        /// <summary>
        /// vpmovsxbw ymm, r8 | EVEX.256.66.0F38.WIG 20 /r | Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxbw ymm, r8","EVEX.256.66.0F38.WIG 20 /r")]
        vpmovsxbw_ymm_r8 = 3936,

        /// <summary>
        /// vpmovsxbw ymm, r8 | VEX.256.66.0F38.WIG 20 /r | Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxbw ymm, r8","VEX.256.66.0F38.WIG 20 /r")]
        vpmovsxbw_ymm_r8_vex = 3937,

        /// <summary>
        /// vpmovsxbw zmm {k1}{z}, m256 | EVEX.512.66.0F38.WIG 20 /r | Sign extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovsxbw zmm {k1}{z}, m256","EVEX.512.66.0F38.WIG 20 /r")]
        vpmovsxbw_zmm_k1z_m256 = 3938,

        /// <summary>
        /// vpmovsxbw zmm {k1}{z}, r16 | EVEX.512.66.0F38.WIG 20 /r | Sign extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovsxbw zmm {k1}{z}, r16","EVEX.512.66.0F38.WIG 20 /r")]
        vpmovsxbw_zmm_k1z_r16 = 3939,

        /// <summary>
        /// vpmovsxbw zmm, m256 | EVEX.512.66.0F38.WIG 20 /r | Sign extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovsxbw zmm, m256","EVEX.512.66.0F38.WIG 20 /r")]
        vpmovsxbw_zmm_m256 = 3940,

        /// <summary>
        /// vpmovsxbw zmm, r16 | EVEX.512.66.0F38.WIG 20 /r | Sign extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovsxbw zmm, r16","EVEX.512.66.0F38.WIG 20 /r")]
        vpmovsxbw_zmm_r16 = 3941,

        /// <summary>
        /// vpmovsxdq xmm {k1}{z}, m64 | EVEX.128.66.0F38.W0 25 /r | Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq xmm {k1}{z}, m64","EVEX.128.66.0F38.W0 25 /r")]
        vpmovsxdq_xmm_k1z_m64 = 3942,

        /// <summary>
        /// vpmovsxdq xmm {k1}{z}, r8 | EVEX.128.66.0F38.W0 25 /r | Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq xmm {k1}{z}, r8","EVEX.128.66.0F38.W0 25 /r")]
        vpmovsxdq_xmm_k1z_r8 = 3943,

        /// <summary>
        /// vpmovsxdq xmm, m64 | EVEX.128.66.0F38.W0 25 /r | Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq xmm, m64","EVEX.128.66.0F38.W0 25 /r")]
        vpmovsxdq_xmm_m64 = 3944,

        /// <summary>
        /// vpmovsxdq xmm, m64 | VEX.128.66.0F38.WIG 25 /r | Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxdq xmm, m64","VEX.128.66.0F38.WIG 25 /r")]
        vpmovsxdq_xmm_m64_vex = 3945,

        /// <summary>
        /// vpmovsxdq xmm, r8 | EVEX.128.66.0F38.W0 25 /r | Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq xmm, r8","EVEX.128.66.0F38.W0 25 /r")]
        vpmovsxdq_xmm_r8 = 3946,

        /// <summary>
        /// vpmovsxdq xmm, r8 | VEX.128.66.0F38.WIG 25 /r | Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxdq xmm, r8","VEX.128.66.0F38.WIG 25 /r")]
        vpmovsxdq_xmm_r8_vex = 3947,

        /// <summary>
        /// vpmovsxdq ymm {k1}{z}, m128 | EVEX.256.66.0F38.W0 25 /r | Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq ymm {k1}{z}, m128","EVEX.256.66.0F38.W0 25 /r")]
        vpmovsxdq_ymm_k1z_m128 = 3948,

        /// <summary>
        /// vpmovsxdq ymm {k1}{z}, r8 | EVEX.256.66.0F38.W0 25 /r | Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq ymm {k1}{z}, r8","EVEX.256.66.0F38.W0 25 /r")]
        vpmovsxdq_ymm_k1z_r8 = 3949,

        /// <summary>
        /// vpmovsxdq ymm, m128 | EVEX.256.66.0F38.W0 25 /r | Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq ymm, m128","EVEX.256.66.0F38.W0 25 /r")]
        vpmovsxdq_ymm_m128 = 3950,

        /// <summary>
        /// vpmovsxdq ymm, m128 | VEX.256.66.0F38.WIG 25 /r | Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxdq ymm, m128","VEX.256.66.0F38.WIG 25 /r")]
        vpmovsxdq_ymm_m128_vex = 3951,

        /// <summary>
        /// vpmovsxdq ymm, r8 | EVEX.256.66.0F38.W0 25 /r | Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq ymm, r8","EVEX.256.66.0F38.W0 25 /r")]
        vpmovsxdq_ymm_r8 = 3952,

        /// <summary>
        /// vpmovsxdq ymm, r8 | VEX.256.66.0F38.WIG 25 /r | Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxdq ymm, r8","VEX.256.66.0F38.WIG 25 /r")]
        vpmovsxdq_ymm_r8_vex = 3953,

        /// <summary>
        /// vpmovsxdq zmm {k1}{z}, m256 | EVEX.512.66.0F38.W0 25 /r | Sign extend 8 packed 32-bit integers in the low 32 bytes of ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq zmm {k1}{z}, m256","EVEX.512.66.0F38.W0 25 /r")]
        vpmovsxdq_zmm_k1z_m256 = 3954,

        /// <summary>
        /// vpmovsxdq zmm {k1}{z}, r16 | EVEX.512.66.0F38.W0 25 /r | Sign extend 8 packed 32-bit integers in the low 32 bytes of ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq zmm {k1}{z}, r16","EVEX.512.66.0F38.W0 25 /r")]
        vpmovsxdq_zmm_k1z_r16 = 3955,

        /// <summary>
        /// vpmovsxdq zmm, m256 | EVEX.512.66.0F38.W0 25 /r | Sign extend 8 packed 32-bit integers in the low 32 bytes of ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq zmm, m256","EVEX.512.66.0F38.W0 25 /r")]
        vpmovsxdq_zmm_m256 = 3956,

        /// <summary>
        /// vpmovsxdq zmm, r16 | EVEX.512.66.0F38.W0 25 /r | Sign extend 8 packed 32-bit integers in the low 32 bytes of ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovsxdq zmm, r16","EVEX.512.66.0F38.W0 25 /r")]
        vpmovsxdq_zmm_r16 = 3957,

        /// <summary>
        /// vpmovsxwd xmm {k1}{z}, m64 | EVEX.128.66.0F38.WIG 23 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of ymm2/mem to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd xmm {k1}{z}, m64","EVEX.128.66.0F38.WIG 23 /r")]
        vpmovsxwd_xmm_k1z_m64 = 3958,

        /// <summary>
        /// vpmovsxwd xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 23 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of ymm2/mem to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 23 /r")]
        vpmovsxwd_xmm_k1z_r8 = 3959,

        /// <summary>
        /// vpmovsxwd xmm, m64 | EVEX.128.66.0F38.WIG 23 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of ymm2/mem to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd xmm, m64","EVEX.128.66.0F38.WIG 23 /r")]
        vpmovsxwd_xmm_m64 = 3960,

        /// <summary>
        /// vpmovsxwd xmm, m64 | VEX.128.66.0F38.WIG 23 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxwd xmm, m64","VEX.128.66.0F38.WIG 23 /r")]
        vpmovsxwd_xmm_m64_vex = 3961,

        /// <summary>
        /// vpmovsxwd xmm, r8 | EVEX.128.66.0F38.WIG 23 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of ymm2/mem to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd xmm, r8","EVEX.128.66.0F38.WIG 23 /r")]
        vpmovsxwd_xmm_r8 = 3962,

        /// <summary>
        /// vpmovsxwd xmm, r8 | VEX.128.66.0F38.WIG 23 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxwd xmm, r8","VEX.128.66.0F38.WIG 23 /r")]
        vpmovsxwd_xmm_r8_vex = 3963,

        /// <summary>
        /// vpmovsxwd ymm {k1}{z}, m128 | EVEX.256.66.0F38.WIG 23 /r | Sign extend 8 packed 16-bit integers in the low 16 bytes of ymm2/m128 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd ymm {k1}{z}, m128","EVEX.256.66.0F38.WIG 23 /r")]
        vpmovsxwd_ymm_k1z_m128 = 3964,

        /// <summary>
        /// vpmovsxwd ymm {k1}{z}, r8 | EVEX.256.66.0F38.WIG 23 /r | Sign extend 8 packed 16-bit integers in the low 16 bytes of ymm2/m128 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd ymm {k1}{z}, r8","EVEX.256.66.0F38.WIG 23 /r")]
        vpmovsxwd_ymm_k1z_r8 = 3965,

        /// <summary>
        /// vpmovsxwd ymm, m128 | EVEX.256.66.0F38.WIG 23 /r | Sign extend 8 packed 16-bit integers in the low 16 bytes of ymm2/m128 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd ymm, m128","EVEX.256.66.0F38.WIG 23 /r")]
        vpmovsxwd_ymm_m128 = 3966,

        /// <summary>
        /// vpmovsxwd ymm, m128 | VEX.256.66.0F38.WIG 23 /r | Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 32-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxwd ymm, m128","VEX.256.66.0F38.WIG 23 /r")]
        vpmovsxwd_ymm_m128_vex = 3967,

        /// <summary>
        /// vpmovsxwd ymm, r8 | EVEX.256.66.0F38.WIG 23 /r | Sign extend 8 packed 16-bit integers in the low 16 bytes of ymm2/m128 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd ymm, r8","EVEX.256.66.0F38.WIG 23 /r")]
        vpmovsxwd_ymm_r8 = 3968,

        /// <summary>
        /// vpmovsxwd ymm, r8 | VEX.256.66.0F38.WIG 23 /r | Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 32-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxwd ymm, r8","VEX.256.66.0F38.WIG 23 /r")]
        vpmovsxwd_ymm_r8_vex = 3969,

        /// <summary>
        /// vpmovsxwd zmm {k1}{z}, m256 | EVEX.512.66.0F38.WIG 23 /r | Sign extend 16 packed 16-bit integers in the low 32 bytes of ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd zmm {k1}{z}, m256","EVEX.512.66.0F38.WIG 23 /r")]
        vpmovsxwd_zmm_k1z_m256 = 3970,

        /// <summary>
        /// vpmovsxwd zmm {k1}{z}, r16 | EVEX.512.66.0F38.WIG 23 /r | Sign extend 16 packed 16-bit integers in the low 32 bytes of ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd zmm {k1}{z}, r16","EVEX.512.66.0F38.WIG 23 /r")]
        vpmovsxwd_zmm_k1z_r16 = 3971,

        /// <summary>
        /// vpmovsxwd zmm, m256 | EVEX.512.66.0F38.WIG 23 /r | Sign extend 16 packed 16-bit integers in the low 32 bytes of ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd zmm, m256","EVEX.512.66.0F38.WIG 23 /r")]
        vpmovsxwd_zmm_m256 = 3972,

        /// <summary>
        /// vpmovsxwd zmm, r16 | EVEX.512.66.0F38.WIG 23 /r | Sign extend 16 packed 16-bit integers in the low 32 bytes of ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwd zmm, r16","EVEX.512.66.0F38.WIG 23 /r")]
        vpmovsxwd_zmm_r16 = 3973,

        /// <summary>
        /// vpmovsxwq xmm {k1}{z}, m32 | EVEX.128.66.0F38.WIG 24 /r | Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq xmm {k1}{z}, m32","EVEX.128.66.0F38.WIG 24 /r")]
        vpmovsxwq_xmm_k1z_m32 = 3974,

        /// <summary>
        /// vpmovsxwq xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 24 /r | Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 24 /r")]
        vpmovsxwq_xmm_k1z_r8 = 3975,

        /// <summary>
        /// vpmovsxwq xmm, m32 | EVEX.128.66.0F38.WIG 24 /r | Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq xmm, m32","EVEX.128.66.0F38.WIG 24 /r")]
        vpmovsxwq_xmm_m32 = 3976,

        /// <summary>
        /// vpmovsxwq xmm, m32 | VEX.128.66.0F38.WIG 24 /r | Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxwq xmm, m32","VEX.128.66.0F38.WIG 24 /r")]
        vpmovsxwq_xmm_m32_vex = 3977,

        /// <summary>
        /// vpmovsxwq xmm, r8 | EVEX.128.66.0F38.WIG 24 /r | Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq xmm, r8","EVEX.128.66.0F38.WIG 24 /r")]
        vpmovsxwq_xmm_r8 = 3978,

        /// <summary>
        /// vpmovsxwq xmm, r8 | VEX.128.66.0F38.WIG 24 /r | Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovsxwq xmm, r8","VEX.128.66.0F38.WIG 24 /r")]
        vpmovsxwq_xmm_r8_vex = 3979,

        /// <summary>
        /// vpmovsxwq ymm {k1}{z}, m64 | EVEX.256.66.0F38.WIG 24 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq ymm {k1}{z}, m64","EVEX.256.66.0F38.WIG 24 /r")]
        vpmovsxwq_ymm_k1z_m64 = 3980,

        /// <summary>
        /// vpmovsxwq ymm {k1}{z}, r8 | EVEX.256.66.0F38.WIG 24 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq ymm {k1}{z}, r8","EVEX.256.66.0F38.WIG 24 /r")]
        vpmovsxwq_ymm_k1z_r8 = 3981,

        /// <summary>
        /// vpmovsxwq ymm, m64 | EVEX.256.66.0F38.WIG 24 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq ymm, m64","EVEX.256.66.0F38.WIG 24 /r")]
        vpmovsxwq_ymm_m64 = 3982,

        /// <summary>
        /// vpmovsxwq ymm, m64 | VEX.256.66.0F38.WIG 24 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxwq ymm, m64","VEX.256.66.0F38.WIG 24 /r")]
        vpmovsxwq_ymm_m64_vex = 3983,

        /// <summary>
        /// vpmovsxwq ymm, r8 | EVEX.256.66.0F38.WIG 24 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq ymm, r8","EVEX.256.66.0F38.WIG 24 /r")]
        vpmovsxwq_ymm_r8 = 3984,

        /// <summary>
        /// vpmovsxwq ymm, r8 | VEX.256.66.0F38.WIG 24 /r | Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovsxwq ymm, r8","VEX.256.66.0F38.WIG 24 /r")]
        vpmovsxwq_ymm_r8_vex = 3985,

        /// <summary>
        /// vpmovsxwq zmm {k1}{z}, m128 | EVEX.512.66.0F38.WIG 24 /r | Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq zmm {k1}{z}, m128","EVEX.512.66.0F38.WIG 24 /r")]
        vpmovsxwq_zmm_k1z_m128 = 3986,

        /// <summary>
        /// vpmovsxwq zmm {k1}{z}, r8 | EVEX.512.66.0F38.WIG 24 /r | Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq zmm {k1}{z}, r8","EVEX.512.66.0F38.WIG 24 /r")]
        vpmovsxwq_zmm_k1z_r8 = 3987,

        /// <summary>
        /// vpmovsxwq zmm, m128 | EVEX.512.66.0F38.WIG 24 /r | Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq zmm, m128","EVEX.512.66.0F38.WIG 24 /r")]
        vpmovsxwq_zmm_m128 = 3988,

        /// <summary>
        /// vpmovsxwq zmm, r8 | EVEX.512.66.0F38.WIG 24 /r | Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovsxwq zmm, r8","EVEX.512.66.0F38.WIG 24 /r")]
        vpmovsxwq_zmm_r8 = 3989,

        /// <summary>
        /// vpmovusdb m128 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 11 /r | Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned byte integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb m128 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 11 /r")]
        vpmovusdb_m128_k1z_zmm = 3990,

        /// <summary>
        /// vpmovusdb m128, zmm | EVEX.512.F3.0F38.W0 11 /r | Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned byte integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb m128, zmm","EVEX.512.F3.0F38.W0 11 /r")]
        vpmovusdb_m128_zmm = 3991,

        /// <summary>
        /// vpmovusdb m32 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 11 /r | Converts 4 packed unsigned double-word integers from xmm2 into 4 packed unsigned byte integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb m32 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 11 /r")]
        vpmovusdb_m32_k1z_xmm = 3992,

        /// <summary>
        /// vpmovusdb m32, xmm | EVEX.128.F3.0F38.W0 11 /r | Converts 4 packed unsigned double-word integers from xmm2 into 4 packed unsigned byte integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb m32, xmm","EVEX.128.F3.0F38.W0 11 /r")]
        vpmovusdb_m32_xmm = 3993,

        /// <summary>
        /// vpmovusdb m64 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 11 /r | Converts 8 packed unsigned double-word integers from ymm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb m64 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 11 /r")]
        vpmovusdb_m64_k1z_ymm = 3994,

        /// <summary>
        /// vpmovusdb m64, ymm | EVEX.256.F3.0F38.W0 11 /r | Converts 8 packed unsigned double-word integers from ymm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb m64, ymm","EVEX.256.F3.0F38.W0 11 /r")]
        vpmovusdb_m64_ymm = 3995,

        /// <summary>
        /// vpmovusdb r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 11 /r | Converts 4 packed unsigned double-word integers from xmm2 into 4 packed unsigned byte integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 11 /r")]
        vpmovusdb_r8_k1z_xmm = 3996,

        /// <summary>
        /// vpmovusdb r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 11 /r | Converts 8 packed unsigned double-word integers from ymm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 11 /r")]
        vpmovusdb_r8_k1z_ymm = 3997,

        /// <summary>
        /// vpmovusdb r8 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 11 /r | Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned byte integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb r8 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 11 /r")]
        vpmovusdb_r8_k1z_zmm = 3998,

        /// <summary>
        /// vpmovusdb r8, xmm | EVEX.128.F3.0F38.W0 11 /r | Converts 4 packed unsigned double-word integers from xmm2 into 4 packed unsigned byte integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb r8, xmm","EVEX.128.F3.0F38.W0 11 /r")]
        vpmovusdb_r8_xmm = 3999,

        /// <summary>
        /// vpmovusdb r8, ymm | EVEX.256.F3.0F38.W0 11 /r | Converts 8 packed unsigned double-word integers from ymm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb r8, ymm","EVEX.256.F3.0F38.W0 11 /r")]
        vpmovusdb_r8_ymm = 4000,

        /// <summary>
        /// vpmovusdb r8, zmm | EVEX.512.F3.0F38.W0 11 /r | Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned byte integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdb r8, zmm","EVEX.512.F3.0F38.W0 11 /r")]
        vpmovusdb_r8_zmm = 4001,

        /// <summary>
        /// vpmovusdw m128 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 13 /r | Converts 8 packed unsigned double-word integers from ymm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw m128 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 13 /r")]
        vpmovusdw_m128_k1z_ymm = 4002,

        /// <summary>
        /// vpmovusdw m128, ymm | EVEX.256.F3.0F38.W0 13 /r | Converts 8 packed unsigned double-word integers from ymm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw m128, ymm","EVEX.256.F3.0F38.W0 13 /r")]
        vpmovusdw_m128_ymm = 4003,

        /// <summary>
        /// vpmovusdw m256 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 13 /r | Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned word integers in ymm1/m256 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw m256 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 13 /r")]
        vpmovusdw_m256_k1z_zmm = 4004,

        /// <summary>
        /// vpmovusdw m256, zmm | EVEX.512.F3.0F38.W0 13 /r | Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned word integers in ymm1/m256 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw m256, zmm","EVEX.512.F3.0F38.W0 13 /r")]
        vpmovusdw_m256_zmm = 4005,

        /// <summary>
        /// vpmovusdw m64 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 13 /r | Converts 4 packed unsigned double-word integers from xmm2 into 4 packed unsigned word integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw m64 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 13 /r")]
        vpmovusdw_m64_k1z_xmm = 4006,

        /// <summary>
        /// vpmovusdw m64, xmm | EVEX.128.F3.0F38.W0 13 /r | Converts 4 packed unsigned double-word integers from xmm2 into 4 packed unsigned word integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw m64, xmm","EVEX.128.F3.0F38.W0 13 /r")]
        vpmovusdw_m64_xmm = 4007,

        /// <summary>
        /// vpmovusdw r16 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 13 /r | Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned word integers in ymm1/m256 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw r16 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 13 /r")]
        vpmovusdw_r16_k1z_zmm = 4008,

        /// <summary>
        /// vpmovusdw r16, zmm | EVEX.512.F3.0F38.W0 13 /r | Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned word integers in ymm1/m256 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw r16, zmm","EVEX.512.F3.0F38.W0 13 /r")]
        vpmovusdw_r16_zmm = 4009,

        /// <summary>
        /// vpmovusdw r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 13 /r | Converts 4 packed unsigned double-word integers from xmm2 into 4 packed unsigned word integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 13 /r")]
        vpmovusdw_r8_k1z_xmm = 4010,

        /// <summary>
        /// vpmovusdw r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 13 /r | Converts 8 packed unsigned double-word integers from ymm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 13 /r")]
        vpmovusdw_r8_k1z_ymm = 4011,

        /// <summary>
        /// vpmovusdw r8, xmm | EVEX.128.F3.0F38.W0 13 /r | Converts 4 packed unsigned double-word integers from xmm2 into 4 packed unsigned word integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw r8, xmm","EVEX.128.F3.0F38.W0 13 /r")]
        vpmovusdw_r8_xmm = 4012,

        /// <summary>
        /// vpmovusdw r8, ymm | EVEX.256.F3.0F38.W0 13 /r | Converts 8 packed unsigned double-word integers from ymm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusdw r8, ymm","EVEX.256.F3.0F38.W0 13 /r")]
        vpmovusdw_r8_ymm = 4013,

        /// <summary>
        /// vpmovusqb m16 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 12 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned byte integers in xmm1/m16 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb m16 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 12 /r")]
        vpmovusqb_m16_k1z_xmm = 4014,

        /// <summary>
        /// vpmovusqb m16, xmm | EVEX.128.F3.0F38.W0 12 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned byte integers in xmm1/m16 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb m16, xmm","EVEX.128.F3.0F38.W0 12 /r")]
        vpmovusqb_m16_xmm = 4015,

        /// <summary>
        /// vpmovusqb m32 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 12 /r | Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned byte integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb m32 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 12 /r")]
        vpmovusqb_m32_k1z_ymm = 4016,

        /// <summary>
        /// vpmovusqb m32, ymm | EVEX.256.F3.0F38.W0 12 /r | Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned byte integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb m32, ymm","EVEX.256.F3.0F38.W0 12 /r")]
        vpmovusqb_m32_ymm = 4017,

        /// <summary>
        /// vpmovusqb m64 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 12 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb m64 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 12 /r")]
        vpmovusqb_m64_k1z_zmm = 4018,

        /// <summary>
        /// vpmovusqb m64, zmm | EVEX.512.F3.0F38.W0 12 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb m64, zmm","EVEX.512.F3.0F38.W0 12 /r")]
        vpmovusqb_m64_zmm = 4019,

        /// <summary>
        /// vpmovusqb r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 12 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned byte integers in xmm1/m16 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 12 /r")]
        vpmovusqb_r8_k1z_xmm = 4020,

        /// <summary>
        /// vpmovusqb r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 12 /r | Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned byte integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 12 /r")]
        vpmovusqb_r8_k1z_ymm = 4021,

        /// <summary>
        /// vpmovusqb r8 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 12 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb r8 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 12 /r")]
        vpmovusqb_r8_k1z_zmm = 4022,

        /// <summary>
        /// vpmovusqb r8, xmm | EVEX.128.F3.0F38.W0 12 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned byte integers in xmm1/m16 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb r8, xmm","EVEX.128.F3.0F38.W0 12 /r")]
        vpmovusqb_r8_xmm = 4023,

        /// <summary>
        /// vpmovusqb r8, ymm | EVEX.256.F3.0F38.W0 12 /r | Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned byte integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb r8, ymm","EVEX.256.F3.0F38.W0 12 /r")]
        vpmovusqb_r8_ymm = 4024,

        /// <summary>
        /// vpmovusqb r8, zmm | EVEX.512.F3.0F38.W0 12 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqb r8, zmm","EVEX.512.F3.0F38.W0 12 /r")]
        vpmovusqb_r8_zmm = 4025,

        /// <summary>
        /// vpmovusqd m128 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 15 /r | Converts 4 packed unsigned quad-word integers from y mm2 into 4 packed unsigned double-word integers in xmm1/m128 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd m128 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 15 /r")]
        vpmovusqd_m128_k1z_ymm = 4026,

        /// <summary>
        /// vpmovusqd m128, ymm | EVEX.256.F3.0F38.W0 15 /r | Converts 4 packed unsigned quad-word integers from y mm2 into 4 packed unsigned double-word integers in xmm1/m128 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd m128, ymm","EVEX.256.F3.0F38.W0 15 /r")]
        vpmovusqd_m128_ymm = 4027,

        /// <summary>
        /// vpmovusqd m256 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 15 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned double-word integers in ymm1/m256 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd m256 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 15 /r")]
        vpmovusqd_m256_k1z_zmm = 4028,

        /// <summary>
        /// vpmovusqd m256, zmm | EVEX.512.F3.0F38.W0 15 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned double-word integers in ymm1/m256 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd m256, zmm","EVEX.512.F3.0F38.W0 15 /r")]
        vpmovusqd_m256_zmm = 4029,

        /// <summary>
        /// vpmovusqd m64 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 15 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned double-word integers in xmm1/m64 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd m64 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 15 /r")]
        vpmovusqd_m64_k1z_xmm = 4030,

        /// <summary>
        /// vpmovusqd m64, xmm | EVEX.128.F3.0F38.W0 15 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned double-word integers in xmm1/m64 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd m64, xmm","EVEX.128.F3.0F38.W0 15 /r")]
        vpmovusqd_m64_xmm = 4031,

        /// <summary>
        /// vpmovusqd r16 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 15 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned double-word integers in ymm1/m256 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd r16 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 15 /r")]
        vpmovusqd_r16_k1z_zmm = 4032,

        /// <summary>
        /// vpmovusqd r16, zmm | EVEX.512.F3.0F38.W0 15 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned double-word integers in ymm1/m256 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd r16, zmm","EVEX.512.F3.0F38.W0 15 /r")]
        vpmovusqd_r16_zmm = 4033,

        /// <summary>
        /// vpmovusqd r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 15 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned double-word integers in xmm1/m64 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 15 /r")]
        vpmovusqd_r8_k1z_xmm = 4034,

        /// <summary>
        /// vpmovusqd r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 15 /r | Converts 4 packed unsigned quad-word integers from y mm2 into 4 packed unsigned double-word integers in xmm1/m128 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 15 /r")]
        vpmovusqd_r8_k1z_ymm = 4035,

        /// <summary>
        /// vpmovusqd r8, xmm | EVEX.128.F3.0F38.W0 15 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned double-word integers in xmm1/m64 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd r8, xmm","EVEX.128.F3.0F38.W0 15 /r")]
        vpmovusqd_r8_xmm = 4036,

        /// <summary>
        /// vpmovusqd r8, ymm | EVEX.256.F3.0F38.W0 15 /r | Converts 4 packed unsigned quad-word integers from y mm2 into 4 packed unsigned double-word integers in xmm1/m128 using unsigned saturation subject to writemask k1.
        /// </summary>
        [Symbol("vpmovusqd r8, ymm","EVEX.256.F3.0F38.W0 15 /r")]
        vpmovusqd_r8_ymm = 4037,

        /// <summary>
        /// vpmovusqw m128 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 14 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw m128 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 14 /r")]
        vpmovusqw_m128_k1z_zmm = 4038,

        /// <summary>
        /// vpmovusqw m128, zmm | EVEX.512.F3.0F38.W0 14 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw m128, zmm","EVEX.512.F3.0F38.W0 14 /r")]
        vpmovusqw_m128_zmm = 4039,

        /// <summary>
        /// vpmovusqw m32 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 14 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned word integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw m32 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 14 /r")]
        vpmovusqw_m32_k1z_xmm = 4040,

        /// <summary>
        /// vpmovusqw m32, xmm | EVEX.128.F3.0F38.W0 14 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned word integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw m32, xmm","EVEX.128.F3.0F38.W0 14 /r")]
        vpmovusqw_m32_xmm = 4041,

        /// <summary>
        /// vpmovusqw m64 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 14 /r | Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned word integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw m64 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 14 /r")]
        vpmovusqw_m64_k1z_ymm = 4042,

        /// <summary>
        /// vpmovusqw m64, ymm | EVEX.256.F3.0F38.W0 14 /r | Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned word integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw m64, ymm","EVEX.256.F3.0F38.W0 14 /r")]
        vpmovusqw_m64_ymm = 4043,

        /// <summary>
        /// vpmovusqw r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 14 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned word integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 14 /r")]
        vpmovusqw_r8_k1z_xmm = 4044,

        /// <summary>
        /// vpmovusqw r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 14 /r | Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned word integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 14 /r")]
        vpmovusqw_r8_k1z_ymm = 4045,

        /// <summary>
        /// vpmovusqw r8 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 14 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw r8 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 14 /r")]
        vpmovusqw_r8_k1z_zmm = 4046,

        /// <summary>
        /// vpmovusqw r8, xmm | EVEX.128.F3.0F38.W0 14 /r | Converts 2 packed unsigned quad-word integers from xmm2 into 2 packed unsigned word integers in xmm1/m32 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw r8, xmm","EVEX.128.F3.0F38.W0 14 /r")]
        vpmovusqw_r8_xmm = 4047,

        /// <summary>
        /// vpmovusqw r8, ymm | EVEX.256.F3.0F38.W0 14 /r | Converts 4 packed unsigned quad-word integers from ymm2 into 4 packed unsigned word integers in xmm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw r8, ymm","EVEX.256.F3.0F38.W0 14 /r")]
        vpmovusqw_r8_ymm = 4048,

        /// <summary>
        /// vpmovusqw r8, zmm | EVEX.512.F3.0F38.W0 14 /r | Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovusqw r8, zmm","EVEX.512.F3.0F38.W0 14 /r")]
        vpmovusqw_r8_zmm = 4049,

        /// <summary>
        /// vpmovuswb m128 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 10 /r | Converts 16 packed unsigned word integers from ymm2 into 16 packed unsigned bytes in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb m128 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 10 /r")]
        vpmovuswb_m128_k1z_ymm = 4050,

        /// <summary>
        /// vpmovuswb m128, ymm | EVEX.256.F3.0F38.W0 10 /r | Converts 16 packed unsigned word integers from ymm2 into 16 packed unsigned bytes in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb m128, ymm","EVEX.256.F3.0F38.W0 10 /r")]
        vpmovuswb_m128_ymm = 4051,

        /// <summary>
        /// vpmovuswb m256 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 10 /r | Converts 32 packed unsigned word integers from zmm2 into 32 packed unsigned bytes in ymm1/m256 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb m256 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 10 /r")]
        vpmovuswb_m256_k1z_zmm = 4052,

        /// <summary>
        /// vpmovuswb m256, zmm | EVEX.512.F3.0F38.W0 10 /r | Converts 32 packed unsigned word integers from zmm2 into 32 packed unsigned bytes in ymm1/m256 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb m256, zmm","EVEX.512.F3.0F38.W0 10 /r")]
        vpmovuswb_m256_zmm = 4053,

        /// <summary>
        /// vpmovuswb m64 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 10 /r | Converts 8 packed unsigned word integers from xmm2 into 8 packed unsigned bytes in 8mm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb m64 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 10 /r")]
        vpmovuswb_m64_k1z_xmm = 4054,

        /// <summary>
        /// vpmovuswb m64, xmm | EVEX.128.F3.0F38.W0 10 /r | Converts 8 packed unsigned word integers from xmm2 into 8 packed unsigned bytes in 8mm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb m64, xmm","EVEX.128.F3.0F38.W0 10 /r")]
        vpmovuswb_m64_xmm = 4055,

        /// <summary>
        /// vpmovuswb r16 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 10 /r | Converts 32 packed unsigned word integers from zmm2 into 32 packed unsigned bytes in ymm1/m256 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb r16 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 10 /r")]
        vpmovuswb_r16_k1z_zmm = 4056,

        /// <summary>
        /// vpmovuswb r16, zmm | EVEX.512.F3.0F38.W0 10 /r | Converts 32 packed unsigned word integers from zmm2 into 32 packed unsigned bytes in ymm1/m256 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb r16, zmm","EVEX.512.F3.0F38.W0 10 /r")]
        vpmovuswb_r16_zmm = 4057,

        /// <summary>
        /// vpmovuswb r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 10 /r | Converts 8 packed unsigned word integers from xmm2 into 8 packed unsigned bytes in 8mm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 10 /r")]
        vpmovuswb_r8_k1z_xmm = 4058,

        /// <summary>
        /// vpmovuswb r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 10 /r | Converts 16 packed unsigned word integers from ymm2 into 16 packed unsigned bytes in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 10 /r")]
        vpmovuswb_r8_k1z_ymm = 4059,

        /// <summary>
        /// vpmovuswb r8, xmm | EVEX.128.F3.0F38.W0 10 /r | Converts 8 packed unsigned word integers from xmm2 into 8 packed unsigned bytes in 8mm1/m64 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb r8, xmm","EVEX.128.F3.0F38.W0 10 /r")]
        vpmovuswb_r8_xmm = 4060,

        /// <summary>
        /// vpmovuswb r8, ymm | EVEX.256.F3.0F38.W0 10 /r | Converts 16 packed unsigned word integers from ymm2 into 16 packed unsigned bytes in xmm1/m128 using unsigned saturation under writemask k1.
        /// </summary>
        [Symbol("vpmovuswb r8, ymm","EVEX.256.F3.0F38.W0 10 /r")]
        vpmovuswb_r8_ymm = 4061,

        /// <summary>
        /// vpmovw2m k, xmm | EVEX.128.F3.0F38.W1 29 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in XMM1.
        /// </summary>
        [Symbol("vpmovw2m k, xmm","EVEX.128.F3.0F38.W1 29 /r")]
        vpmovw2m_k_xmm = 4062,

        /// <summary>
        /// vpmovw2m k, ymm | EVEX.256.F3.0F38.W1 29 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in YMM1.
        /// </summary>
        [Symbol("vpmovw2m k, ymm","EVEX.256.F3.0F38.W1 29 /r")]
        vpmovw2m_k_ymm = 4063,

        /// <summary>
        /// vpmovw2m k, zmm | EVEX.512.F3.0F38.W1 29 /r | Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in ZMM1.
        /// </summary>
        [Symbol("vpmovw2m k, zmm","EVEX.512.F3.0F38.W1 29 /r")]
        vpmovw2m_k_zmm = 4064,

        /// <summary>
        /// vpmovwb m128 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 30 /r | Converts 16 packed word integers from ymm2 into 16 packed bytes in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb m128 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 30 /r")]
        vpmovwb_m128_k1z_ymm = 4065,

        /// <summary>
        /// vpmovwb m128, ymm | EVEX.256.F3.0F38.W0 30 /r | Converts 16 packed word integers from ymm2 into 16 packed bytes in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb m128, ymm","EVEX.256.F3.0F38.W0 30 /r")]
        vpmovwb_m128_ymm = 4066,

        /// <summary>
        /// vpmovwb m256 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 30 /r | Converts 32 packed word integers from zmm2 into 32 packed bytes in ymm1/m256 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb m256 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 30 /r")]
        vpmovwb_m256_k1z_zmm = 4067,

        /// <summary>
        /// vpmovwb m256, zmm | EVEX.512.F3.0F38.W0 30 /r | Converts 32 packed word integers from zmm2 into 32 packed bytes in ymm1/m256 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb m256, zmm","EVEX.512.F3.0F38.W0 30 /r")]
        vpmovwb_m256_zmm = 4068,

        /// <summary>
        /// vpmovwb m64 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 30 /r | Converts 8 packed word integers from xmm2 into 8 packed bytes in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb m64 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 30 /r")]
        vpmovwb_m64_k1z_xmm = 4069,

        /// <summary>
        /// vpmovwb m64, xmm | EVEX.128.F3.0F38.W0 30 /r | Converts 8 packed word integers from xmm2 into 8 packed bytes in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb m64, xmm","EVEX.128.F3.0F38.W0 30 /r")]
        vpmovwb_m64_xmm = 4070,

        /// <summary>
        /// vpmovwb r16 {k1}{z}, zmm | EVEX.512.F3.0F38.W0 30 /r | Converts 32 packed word integers from zmm2 into 32 packed bytes in ymm1/m256 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb r16 {k1}{z}, zmm","EVEX.512.F3.0F38.W0 30 /r")]
        vpmovwb_r16_k1z_zmm = 4071,

        /// <summary>
        /// vpmovwb r16, zmm | EVEX.512.F3.0F38.W0 30 /r | Converts 32 packed word integers from zmm2 into 32 packed bytes in ymm1/m256 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb r16, zmm","EVEX.512.F3.0F38.W0 30 /r")]
        vpmovwb_r16_zmm = 4072,

        /// <summary>
        /// vpmovwb r8 {k1}{z}, xmm | EVEX.128.F3.0F38.W0 30 /r | Converts 8 packed word integers from xmm2 into 8 packed bytes in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb r8 {k1}{z}, xmm","EVEX.128.F3.0F38.W0 30 /r")]
        vpmovwb_r8_k1z_xmm = 4073,

        /// <summary>
        /// vpmovwb r8 {k1}{z}, ymm | EVEX.256.F3.0F38.W0 30 /r | Converts 16 packed word integers from ymm2 into 16 packed bytes in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb r8 {k1}{z}, ymm","EVEX.256.F3.0F38.W0 30 /r")]
        vpmovwb_r8_k1z_ymm = 4074,

        /// <summary>
        /// vpmovwb r8, xmm | EVEX.128.F3.0F38.W0 30 /r | Converts 8 packed word integers from xmm2 into 8 packed bytes in xmm1/m64 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb r8, xmm","EVEX.128.F3.0F38.W0 30 /r")]
        vpmovwb_r8_xmm = 4075,

        /// <summary>
        /// vpmovwb r8, ymm | EVEX.256.F3.0F38.W0 30 /r | Converts 16 packed word integers from ymm2 into 16 packed bytes in xmm1/m128 with truncation under writemask k1.
        /// </summary>
        [Symbol("vpmovwb r8, ymm","EVEX.256.F3.0F38.W0 30 /r")]
        vpmovwb_r8_ymm = 4076,

        /// <summary>
        /// vpmovzxbd xmm {k1}{z}, m32 | EVEX.128.66.0F38.WIG 31 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd xmm {k1}{z}, m32","EVEX.128.66.0F38.WIG 31 /r")]
        vpmovzxbd_xmm_k1z_m32 = 4077,

        /// <summary>
        /// vpmovzxbd xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 31 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 31 /r")]
        vpmovzxbd_xmm_k1z_r8 = 4078,

        /// <summary>
        /// vpmovzxbd xmm, m32 | EVEX.128.66.0F38.WIG 31 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd xmm, m32","EVEX.128.66.0F38.WIG 31 /r")]
        vpmovzxbd_xmm_m32 = 4079,

        /// <summary>
        /// vpmovzxbd xmm, m32 | VEX.128.66.0F38.WIG 31 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxbd xmm, m32","VEX.128.66.0F38.WIG 31 /r")]
        vpmovzxbd_xmm_m32_vex = 4080,

        /// <summary>
        /// vpmovzxbd xmm, r8 | EVEX.128.66.0F38.WIG 31 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd xmm, r8","EVEX.128.66.0F38.WIG 31 /r")]
        vpmovzxbd_xmm_r8 = 4081,

        /// <summary>
        /// vpmovzxbd xmm, r8 | VEX.128.66.0F38.WIG 31 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxbd xmm, r8","VEX.128.66.0F38.WIG 31 /r")]
        vpmovzxbd_xmm_r8_vex = 4082,

        /// <summary>
        /// vpmovzxbd ymm {k1}{z}, m64 | EVEX.256.66.0F38.WIG 31 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd ymm {k1}{z}, m64","EVEX.256.66.0F38.WIG 31 /r")]
        vpmovzxbd_ymm_k1z_m64 = 4083,

        /// <summary>
        /// vpmovzxbd ymm {k1}{z}, r8 | EVEX.256.66.0F38.WIG 31 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd ymm {k1}{z}, r8","EVEX.256.66.0F38.WIG 31 /r")]
        vpmovzxbd_ymm_k1z_r8 = 4084,

        /// <summary>
        /// vpmovzxbd ymm, m64 | EVEX.256.66.0F38.WIG 31 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd ymm, m64","EVEX.256.66.0F38.WIG 31 /r")]
        vpmovzxbd_ymm_m64 = 4085,

        /// <summary>
        /// vpmovzxbd ymm, m64 | VEX.256.66.0F38.WIG 31 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxbd ymm, m64","VEX.256.66.0F38.WIG 31 /r")]
        vpmovzxbd_ymm_m64_vex = 4086,

        /// <summary>
        /// vpmovzxbd ymm, r8 | EVEX.256.66.0F38.WIG 31 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd ymm, r8","EVEX.256.66.0F38.WIG 31 /r")]
        vpmovzxbd_ymm_r8 = 4087,

        /// <summary>
        /// vpmovzxbd ymm, r8 | VEX.256.66.0F38.WIG 31 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxbd ymm, r8","VEX.256.66.0F38.WIG 31 /r")]
        vpmovzxbd_ymm_r8_vex = 4088,

        /// <summary>
        /// vpmovzxbd zmm {k1}{z}, m128 | EVEX.512.66.0F38.WIG 31 /r | Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd zmm {k1}{z}, m128","EVEX.512.66.0F38.WIG 31 /r")]
        vpmovzxbd_zmm_k1z_m128 = 4089,

        /// <summary>
        /// vpmovzxbd zmm {k1}{z}, r8 | EVEX.512.66.0F38.WIG 31 /r | Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd zmm {k1}{z}, r8","EVEX.512.66.0F38.WIG 31 /r")]
        vpmovzxbd_zmm_k1z_r8 = 4090,

        /// <summary>
        /// vpmovzxbd zmm, m128 | EVEX.512.66.0F38.WIG 31 /r | Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd zmm, m128","EVEX.512.66.0F38.WIG 31 /r")]
        vpmovzxbd_zmm_m128 = 4091,

        /// <summary>
        /// vpmovzxbd zmm, r8 | EVEX.512.66.0F38.WIG 31 /r | Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbd zmm, r8","EVEX.512.66.0F38.WIG 31 /r")]
        vpmovzxbd_zmm_r8 = 4092,

        /// <summary>
        /// vpmovzxbq xmm {k1}{z}, m16 | EVEX.128.66.0F38.WIG 32 /r | Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq xmm {k1}{z}, m16","EVEX.128.66.0F38.WIG 32 /r")]
        vpmovzxbq_xmm_k1z_m16 = 4093,

        /// <summary>
        /// vpmovzxbq xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 32 /r | Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 32 /r")]
        vpmovzxbq_xmm_k1z_r8 = 4094,

        /// <summary>
        /// vpmovzxbq xmm, m16 | EVEX.128.66.0F38.WIG 32 /r | Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq xmm, m16","EVEX.128.66.0F38.WIG 32 /r")]
        vpmovzxbq_xmm_m16 = 4095,

        /// <summary>
        /// vpmovzxbq xmm, m16 | VEX.128.66.0F38.WIG 32 /r | Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxbq xmm, m16","VEX.128.66.0F38.WIG 32 /r")]
        vpmovzxbq_xmm_m16_vex = 4096,

        /// <summary>
        /// vpmovzxbq xmm, r8 | EVEX.128.66.0F38.WIG 32 /r | Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq xmm, r8","EVEX.128.66.0F38.WIG 32 /r")]
        vpmovzxbq_xmm_r8 = 4097,

        /// <summary>
        /// vpmovzxbq xmm, r8 | VEX.128.66.0F38.WIG 32 /r | Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxbq xmm, r8","VEX.128.66.0F38.WIG 32 /r")]
        vpmovzxbq_xmm_r8_vex = 4098,

        /// <summary>
        /// vpmovzxbq ymm {k1}{z}, m32 | EVEX.256.66.0F38.WIG 32 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq ymm {k1}{z}, m32","EVEX.256.66.0F38.WIG 32 /r")]
        vpmovzxbq_ymm_k1z_m32 = 4099,

        /// <summary>
        /// vpmovzxbq ymm {k1}{z}, r8 | EVEX.256.66.0F38.WIG 32 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq ymm {k1}{z}, r8","EVEX.256.66.0F38.WIG 32 /r")]
        vpmovzxbq_ymm_k1z_r8 = 4100,

        /// <summary>
        /// vpmovzxbq ymm, m32 | EVEX.256.66.0F38.WIG 32 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq ymm, m32","EVEX.256.66.0F38.WIG 32 /r")]
        vpmovzxbq_ymm_m32 = 4101,

        /// <summary>
        /// vpmovzxbq ymm, m32 | VEX.256.66.0F38.WIG 32 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxbq ymm, m32","VEX.256.66.0F38.WIG 32 /r")]
        vpmovzxbq_ymm_m32_vex = 4102,

        /// <summary>
        /// vpmovzxbq ymm, r8 | EVEX.256.66.0F38.WIG 32 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq ymm, r8","EVEX.256.66.0F38.WIG 32 /r")]
        vpmovzxbq_ymm_r8 = 4103,

        /// <summary>
        /// vpmovzxbq ymm, r8 | VEX.256.66.0F38.WIG 32 /r | Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxbq ymm, r8","VEX.256.66.0F38.WIG 32 /r")]
        vpmovzxbq_ymm_r8_vex = 4104,

        /// <summary>
        /// vpmovzxbq zmm {k1}{z}, m64 | EVEX.512.66.0F38.WIG 32 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq zmm {k1}{z}, m64","EVEX.512.66.0F38.WIG 32 /r")]
        vpmovzxbq_zmm_k1z_m64 = 4105,

        /// <summary>
        /// vpmovzxbq zmm {k1}{z}, r8 | EVEX.512.66.0F38.WIG 32 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq zmm {k1}{z}, r8","EVEX.512.66.0F38.WIG 32 /r")]
        vpmovzxbq_zmm_k1z_r8 = 4106,

        /// <summary>
        /// vpmovzxbq zmm, m64 | EVEX.512.66.0F38.WIG 32 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq zmm, m64","EVEX.512.66.0F38.WIG 32 /r")]
        vpmovzxbq_zmm_m64 = 4107,

        /// <summary>
        /// vpmovzxbq zmm, r8 | EVEX.512.66.0F38.WIG 32 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxbq zmm, r8","EVEX.512.66.0F38.WIG 32 /r")]
        vpmovzxbq_zmm_r8 = 4108,

        /// <summary>
        /// vpmovzxbw xmm {k1}{z}, m64 | EVEX.128.66.0F38.WIG 30 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxbw xmm {k1}{z}, m64","EVEX.128.66.0F38.WIG 30 /r")]
        vpmovzxbw_xmm_k1z_m64 = 4109,

        /// <summary>
        /// vpmovzxbw xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 30 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxbw xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 30 /r")]
        vpmovzxbw_xmm_k1z_r8 = 4110,

        /// <summary>
        /// vpmovzxbw xmm, m64 | EVEX.128.66.0F38.WIG 30 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxbw xmm, m64","EVEX.128.66.0F38.WIG 30 /r")]
        vpmovzxbw_xmm_m64 = 4111,

        /// <summary>
        /// vpmovzxbw xmm, m64 | VEX.128.66.0F38.WIG 30 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxbw xmm, m64","VEX.128.66.0F38.WIG 30 /r")]
        vpmovzxbw_xmm_m64_vex = 4112,

        /// <summary>
        /// vpmovzxbw xmm, r8 | EVEX.128.66.0F38.WIG 30 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxbw xmm, r8","EVEX.128.66.0F38.WIG 30 /r")]
        vpmovzxbw_xmm_r8 = 4113,

        /// <summary>
        /// vpmovzxbw xmm, r8 | VEX.128.66.0F38.WIG 30 /r | Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxbw xmm, r8","VEX.128.66.0F38.WIG 30 /r")]
        vpmovzxbw_xmm_r8_vex = 4114,

        /// <summary>
        /// vpmovzxbw ymm {k1}{z}, m128 | EVEX.256.66.0F38.WIG 30 /r | Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxbw ymm {k1}{z}, m128","EVEX.256.66.0F38.WIG 30 /r")]
        vpmovzxbw_ymm_k1z_m128 = 4115,

        /// <summary>
        /// vpmovzxbw ymm {k1}{z}, r8 | EVEX.256.66.0F38.WIG 30 /r | Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxbw ymm {k1}{z}, r8","EVEX.256.66.0F38.WIG 30 /r")]
        vpmovzxbw_ymm_k1z_r8 = 4116,

        /// <summary>
        /// vpmovzxbw ymm, m128 | EVEX.256.66.0F38.WIG 30 /r | Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxbw ymm, m128","EVEX.256.66.0F38.WIG 30 /r")]
        vpmovzxbw_ymm_m128 = 4117,

        /// <summary>
        /// vpmovzxbw ymm, m128 | VEX.256.66.0F38.WIG 30 /r | Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxbw ymm, m128","VEX.256.66.0F38.WIG 30 /r")]
        vpmovzxbw_ymm_m128_vex = 4118,

        /// <summary>
        /// vpmovzxbw ymm, r8 | EVEX.256.66.0F38.WIG 30 /r | Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxbw ymm, r8","EVEX.256.66.0F38.WIG 30 /r")]
        vpmovzxbw_ymm_r8 = 4119,

        /// <summary>
        /// vpmovzxbw ymm, r8 | VEX.256.66.0F38.WIG 30 /r | Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxbw ymm, r8","VEX.256.66.0F38.WIG 30 /r")]
        vpmovzxbw_ymm_r8_vex = 4120,

        /// <summary>
        /// vpmovzxbw zmm {k1}{z}, m256 | EVEX.512.66.0F38.WIG 30 /r | Zero extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovzxbw zmm {k1}{z}, m256","EVEX.512.66.0F38.WIG 30 /r")]
        vpmovzxbw_zmm_k1z_m256 = 4121,

        /// <summary>
        /// vpmovzxbw zmm {k1}{z}, r16 | EVEX.512.66.0F38.WIG 30 /r | Zero extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovzxbw zmm {k1}{z}, r16","EVEX.512.66.0F38.WIG 30 /r")]
        vpmovzxbw_zmm_k1z_r16 = 4122,

        /// <summary>
        /// vpmovzxbw zmm, m256 | EVEX.512.66.0F38.WIG 30 /r | Zero extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovzxbw zmm, m256","EVEX.512.66.0F38.WIG 30 /r")]
        vpmovzxbw_zmm_m256 = 4123,

        /// <summary>
        /// vpmovzxbw zmm, r16 | EVEX.512.66.0F38.WIG 30 /r | Zero extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.
        /// </summary>
        [Symbol("vpmovzxbw zmm, r16","EVEX.512.66.0F38.WIG 30 /r")]
        vpmovzxbw_zmm_r16 = 4124,

        /// <summary>
        /// vpmovzxdq xmm {k1}{z}, m64 | EVEX.128.66.0F38.W0 35 /r | Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq xmm {k1}{z}, m64","EVEX.128.66.0F38.W0 35 /r")]
        vpmovzxdq_xmm_k1z_m64 = 4125,

        /// <summary>
        /// vpmovzxdq xmm {k1}{z}, r8 | EVEX.128.66.0F38.W0 35 /r | Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq xmm {k1}{z}, r8","EVEX.128.66.0F38.W0 35 /r")]
        vpmovzxdq_xmm_k1z_r8 = 4126,

        /// <summary>
        /// vpmovzxdq xmm, m64 | EVEX.128.66.0F38.W0 35 /r | Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq xmm, m64","EVEX.128.66.0F38.W0 35 /r")]
        vpmovzxdq_xmm_m64 = 4127,

        /// <summary>
        /// vpmovzxdq xmm, m64 | VEX.128.66.0F38.WIG 35 /r | Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxdq xmm, m64","VEX.128.66.0F38.WIG 35 /r")]
        vpmovzxdq_xmm_m64_vex = 4128,

        /// <summary>
        /// vpmovzxdq xmm, r8 | EVEX.128.66.0F38.W0 35 /r | Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq xmm, r8","EVEX.128.66.0F38.W0 35 /r")]
        vpmovzxdq_xmm_r8 = 4129,

        /// <summary>
        /// vpmovzxdq xmm, r8 | VEX.128.66.0F38.WIG 35 /r | Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxdq xmm, r8","VEX.128.66.0F38.WIG 35 /r")]
        vpmovzxdq_xmm_r8_vex = 4130,

        /// <summary>
        /// vpmovzxdq ymm {k1}{z}, m128 | EVEX.256.66.0F38.W0 35 /r | Zero extend 4 packed 32-bit integers in xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq ymm {k1}{z}, m128","EVEX.256.66.0F38.W0 35 /r")]
        vpmovzxdq_ymm_k1z_m128 = 4131,

        /// <summary>
        /// vpmovzxdq ymm {k1}{z}, r8 | EVEX.256.66.0F38.W0 35 /r | Zero extend 4 packed 32-bit integers in xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq ymm {k1}{z}, r8","EVEX.256.66.0F38.W0 35 /r")]
        vpmovzxdq_ymm_k1z_r8 = 4132,

        /// <summary>
        /// vpmovzxdq ymm, m128 | EVEX.256.66.0F38.W0 35 /r | Zero extend 4 packed 32-bit integers in xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq ymm, m128","EVEX.256.66.0F38.W0 35 /r")]
        vpmovzxdq_ymm_m128 = 4133,

        /// <summary>
        /// vpmovzxdq ymm, m128 | VEX.256.66.0F38.WIG 35 /r | Zero extend 4 packed 32-bit integers in xmm2/m128 to 4 packed 64-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxdq ymm, m128","VEX.256.66.0F38.WIG 35 /r")]
        vpmovzxdq_ymm_m128_vex = 4134,

        /// <summary>
        /// vpmovzxdq ymm, r8 | EVEX.256.66.0F38.W0 35 /r | Zero extend 4 packed 32-bit integers in xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq ymm, r8","EVEX.256.66.0F38.W0 35 /r")]
        vpmovzxdq_ymm_r8 = 4135,

        /// <summary>
        /// vpmovzxdq ymm, r8 | VEX.256.66.0F38.WIG 35 /r | Zero extend 4 packed 32-bit integers in xmm2/m128 to 4 packed 64-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxdq ymm, r8","VEX.256.66.0F38.WIG 35 /r")]
        vpmovzxdq_ymm_r8_vex = 4136,

        /// <summary>
        /// vpmovzxdq zmm {k1}{z}, m256 | EVEX.512.66.0F38.W0 35 /r | Zero extend 8 packed 32-bit integers in ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq zmm {k1}{z}, m256","EVEX.512.66.0F38.W0 35 /r")]
        vpmovzxdq_zmm_k1z_m256 = 4137,

        /// <summary>
        /// vpmovzxdq zmm {k1}{z}, r16 | EVEX.512.66.0F38.W0 35 /r | Zero extend 8 packed 32-bit integers in ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq zmm {k1}{z}, r16","EVEX.512.66.0F38.W0 35 /r")]
        vpmovzxdq_zmm_k1z_r16 = 4138,

        /// <summary>
        /// vpmovzxdq zmm, m256 | EVEX.512.66.0F38.W0 35 /r | Zero extend 8 packed 32-bit integers in ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq zmm, m256","EVEX.512.66.0F38.W0 35 /r")]
        vpmovzxdq_zmm_m256 = 4139,

        /// <summary>
        /// vpmovzxdq zmm, r16 | EVEX.512.66.0F38.W0 35 /r | Zero extend 8 packed 32-bit integers in ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpmovzxdq zmm, r16","EVEX.512.66.0F38.W0 35 /r")]
        vpmovzxdq_zmm_r16 = 4140,

        /// <summary>
        /// vpmovzxwd xmm {k1}{z}, m64 | EVEX.128.66.0F38.WIG 33 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd xmm {k1}{z}, m64","EVEX.128.66.0F38.WIG 33 /r")]
        vpmovzxwd_xmm_k1z_m64 = 4141,

        /// <summary>
        /// vpmovzxwd xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 33 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 33 /r")]
        vpmovzxwd_xmm_k1z_r8 = 4142,

        /// <summary>
        /// vpmovzxwd xmm, m64 | EVEX.128.66.0F38.WIG 33 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd xmm, m64","EVEX.128.66.0F38.WIG 33 /r")]
        vpmovzxwd_xmm_m64 = 4143,

        /// <summary>
        /// vpmovzxwd xmm, m64 | VEX.128.66.0F38.WIG 33 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxwd xmm, m64","VEX.128.66.0F38.WIG 33 /r")]
        vpmovzxwd_xmm_m64_vex = 4144,

        /// <summary>
        /// vpmovzxwd xmm, r8 | EVEX.128.66.0F38.WIG 33 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd xmm, r8","EVEX.128.66.0F38.WIG 33 /r")]
        vpmovzxwd_xmm_r8 = 4145,

        /// <summary>
        /// vpmovzxwd xmm, r8 | VEX.128.66.0F38.WIG 33 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxwd xmm, r8","VEX.128.66.0F38.WIG 33 /r")]
        vpmovzxwd_xmm_r8_vex = 4146,

        /// <summary>
        /// vpmovzxwd ymm {k1}{z}, m128 | EVEX.256.66.0F38.WIG 33 /r | Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd ymm {k1}{z}, m128","EVEX.256.66.0F38.WIG 33 /r")]
        vpmovzxwd_ymm_k1z_m128 = 4147,

        /// <summary>
        /// vpmovzxwd ymm {k1}{z}, r8 | EVEX.256.66.0F38.WIG 33 /r | Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd ymm {k1}{z}, r8","EVEX.256.66.0F38.WIG 33 /r")]
        vpmovzxwd_ymm_k1z_r8 = 4148,

        /// <summary>
        /// vpmovzxwd ymm, m128 | EVEX.256.66.0F38.WIG 33 /r | Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd ymm, m128","EVEX.256.66.0F38.WIG 33 /r")]
        vpmovzxwd_ymm_m128 = 4149,

        /// <summary>
        /// vpmovzxwd ymm, m128 | VEX.256.66.0F38.WIG 33 /r | Zero extend 8 packed 16-bit integers xmm2/m128 to 8 packed 32-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxwd ymm, m128","VEX.256.66.0F38.WIG 33 /r")]
        vpmovzxwd_ymm_m128_vex = 4150,

        /// <summary>
        /// vpmovzxwd ymm, r8 | EVEX.256.66.0F38.WIG 33 /r | Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd ymm, r8","EVEX.256.66.0F38.WIG 33 /r")]
        vpmovzxwd_ymm_r8 = 4151,

        /// <summary>
        /// vpmovzxwd ymm, r8 | VEX.256.66.0F38.WIG 33 /r | Zero extend 8 packed 16-bit integers xmm2/m128 to 8 packed 32-bit integers in ymm1.
        /// </summary>
        [Symbol("vpmovzxwd ymm, r8","VEX.256.66.0F38.WIG 33 /r")]
        vpmovzxwd_ymm_r8_vex = 4152,

        /// <summary>
        /// vpmovzxwd zmm {k1}{z}, m256 | EVEX.512.66.0F38.WIG 33 /r | Zero extend 16 packed 16-bit integers in ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd zmm {k1}{z}, m256","EVEX.512.66.0F38.WIG 33 /r")]
        vpmovzxwd_zmm_k1z_m256 = 4153,

        /// <summary>
        /// vpmovzxwd zmm {k1}{z}, r16 | EVEX.512.66.0F38.WIG 33 /r | Zero extend 16 packed 16-bit integers in ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd zmm {k1}{z}, r16","EVEX.512.66.0F38.WIG 33 /r")]
        vpmovzxwd_zmm_k1z_r16 = 4154,

        /// <summary>
        /// vpmovzxwd zmm, m256 | EVEX.512.66.0F38.WIG 33 /r | Zero extend 16 packed 16-bit integers in ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd zmm, m256","EVEX.512.66.0F38.WIG 33 /r")]
        vpmovzxwd_zmm_m256 = 4155,

        /// <summary>
        /// vpmovzxwd zmm, r16 | EVEX.512.66.0F38.WIG 33 /r | Zero extend 16 packed 16-bit integers in ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwd zmm, r16","EVEX.512.66.0F38.WIG 33 /r")]
        vpmovzxwd_zmm_r16 = 4156,

        /// <summary>
        /// vpmovzxwq xmm {k1}{z}, m32 | EVEX.128.66.0F38.WIG 34 /r | Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq xmm {k1}{z}, m32","EVEX.128.66.0F38.WIG 34 /r")]
        vpmovzxwq_xmm_k1z_m32 = 4157,

        /// <summary>
        /// vpmovzxwq xmm {k1}{z}, r8 | EVEX.128.66.0F38.WIG 34 /r | Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq xmm {k1}{z}, r8","EVEX.128.66.0F38.WIG 34 /r")]
        vpmovzxwq_xmm_k1z_r8 = 4158,

        /// <summary>
        /// vpmovzxwq xmm, m32 | EVEX.128.66.0F38.WIG 34 /r | Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq xmm, m32","EVEX.128.66.0F38.WIG 34 /r")]
        vpmovzxwq_xmm_m32 = 4159,

        /// <summary>
        /// vpmovzxwq xmm, m32 | VEX.128.66.0F38.WIG 34 /r | Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxwq xmm, m32","VEX.128.66.0F38.WIG 34 /r")]
        vpmovzxwq_xmm_m32_vex = 4160,

        /// <summary>
        /// vpmovzxwq xmm, r8 | EVEX.128.66.0F38.WIG 34 /r | Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq xmm, r8","EVEX.128.66.0F38.WIG 34 /r")]
        vpmovzxwq_xmm_r8 = 4161,

        /// <summary>
        /// vpmovzxwq xmm, r8 | VEX.128.66.0F38.WIG 34 /r | Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxwq xmm, r8","VEX.128.66.0F38.WIG 34 /r")]
        vpmovzxwq_xmm_r8_vex = 4162,

        /// <summary>
        /// vpmovzxwq ymm {k1}{z}, m64 | EVEX.256.66.0F38.WIG 34 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq ymm {k1}{z}, m64","EVEX.256.66.0F38.WIG 34 /r")]
        vpmovzxwq_ymm_k1z_m64 = 4163,

        /// <summary>
        /// vpmovzxwq ymm {k1}{z}, r8 | EVEX.256.66.0F38.WIG 34 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq ymm {k1}{z}, r8","EVEX.256.66.0F38.WIG 34 /r")]
        vpmovzxwq_ymm_k1z_r8 = 4164,

        /// <summary>
        /// vpmovzxwq ymm, m64 | EVEX.256.66.0F38.WIG 34 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq ymm, m64","EVEX.256.66.0F38.WIG 34 /r")]
        vpmovzxwq_ymm_m64 = 4165,

        /// <summary>
        /// vpmovzxwq ymm, m64 | VEX.256.66.0F38.WIG 34 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxwq ymm, m64","VEX.256.66.0F38.WIG 34 /r")]
        vpmovzxwq_ymm_m64_vex = 4166,

        /// <summary>
        /// vpmovzxwq ymm, r8 | EVEX.256.66.0F38.WIG 34 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq ymm, r8","EVEX.256.66.0F38.WIG 34 /r")]
        vpmovzxwq_ymm_r8 = 4167,

        /// <summary>
        /// vpmovzxwq ymm, r8 | VEX.256.66.0F38.WIG 34 /r | Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in xmm1.
        /// </summary>
        [Symbol("vpmovzxwq ymm, r8","VEX.256.66.0F38.WIG 34 /r")]
        vpmovzxwq_ymm_r8_vex = 4168,

        /// <summary>
        /// vpmovzxwq zmm {k1}{z}, m128 | EVEX.512.66.0F38.WIG 34 /r | Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq zmm {k1}{z}, m128","EVEX.512.66.0F38.WIG 34 /r")]
        vpmovzxwq_zmm_k1z_m128 = 4169,

        /// <summary>
        /// vpmovzxwq zmm {k1}{z}, r8 | EVEX.512.66.0F38.WIG 34 /r | Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq zmm {k1}{z}, r8","EVEX.512.66.0F38.WIG 34 /r")]
        vpmovzxwq_zmm_k1z_r8 = 4170,

        /// <summary>
        /// vpmovzxwq zmm, m128 | EVEX.512.66.0F38.WIG 34 /r | Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq zmm, m128","EVEX.512.66.0F38.WIG 34 /r")]
        vpmovzxwq_zmm_m128 = 4171,

        /// <summary>
        /// vpmovzxwq zmm, r8 | EVEX.512.66.0F38.WIG 34 /r | Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.
        /// </summary>
        [Symbol("vpmovzxwq zmm, r8","EVEX.512.66.0F38.WIG 34 /r")]
        vpmovzxwq_zmm_r8 = 4172,

        /// <summary>
        /// vpmulhuw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG E4 /r")]
        vpmulhuw_xmm_k1z_xmm_m128 = 4173,

        /// <summary>
        /// vpmulhuw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG E4 /r")]
        vpmulhuw_xmm_k1z_xmm_r8 = 4174,

        /// <summary>
        /// vpmulhuw xmm, xmm, m128 | EVEX.128.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw xmm, xmm, m128","EVEX.128.66.0F.WIG E4 /r")]
        vpmulhuw_xmm_xmm_m128 = 4175,

        /// <summary>
        /// vpmulhuw xmm, xmm, m128 | VEX.128.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in xmm2 and xmm3/m128 , and store the high 16 bits of the results in xmm1.
        /// </summary>
        [Symbol("vpmulhuw xmm, xmm, m128","VEX.128.66.0F.WIG E4 /r")]
        vpmulhuw_xmm_xmm_m128_vex = 4176,

        /// <summary>
        /// vpmulhuw xmm, xmm, r8 | EVEX.128.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw xmm, xmm, r8","EVEX.128.66.0F.WIG E4 /r")]
        vpmulhuw_xmm_xmm_r8 = 4177,

        /// <summary>
        /// vpmulhuw xmm, xmm, r8 | VEX.128.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in xmm2 and xmm3/m128 , and store the high 16 bits of the results in xmm1.
        /// </summary>
        [Symbol("vpmulhuw xmm, xmm, r8","VEX.128.66.0F.WIG E4 /r")]
        vpmulhuw_xmm_xmm_r8_vex = 4178,

        /// <summary>
        /// vpmulhuw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG E4 /r")]
        vpmulhuw_ymm_k1z_ymm_m256 = 4179,

        /// <summary>
        /// vpmulhuw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG E4 /r")]
        vpmulhuw_ymm_k1z_ymm_r16 = 4180,

        /// <summary>
        /// vpmulhuw ymm, ymm, m256 | EVEX.256.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw ymm, ymm, m256","EVEX.256.66.0F.WIG E4 /r")]
        vpmulhuw_ymm_ymm_m256 = 4181,

        /// <summary>
        /// vpmulhuw ymm, ymm, m256 | VEX.256.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in ymm2 and ymm3/m256 , and store the high 16 bits of the results in ymm1.
        /// </summary>
        [Symbol("vpmulhuw ymm, ymm, m256","VEX.256.66.0F.WIG E4 /r")]
        vpmulhuw_ymm_ymm_m256_vex = 4182,

        /// <summary>
        /// vpmulhuw ymm, ymm, r16 | EVEX.256.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw ymm, ymm, r16","EVEX.256.66.0F.WIG E4 /r")]
        vpmulhuw_ymm_ymm_r16 = 4183,

        /// <summary>
        /// vpmulhuw ymm, ymm, r16 | VEX.256.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in ymm2 and ymm3/m256 , and store the high 16 bits of the results in ymm1.
        /// </summary>
        [Symbol("vpmulhuw ymm, ymm, r16","VEX.256.66.0F.WIG E4 /r")]
        vpmulhuw_ymm_ymm_r16_vex = 4184,

        /// <summary>
        /// vpmulhuw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in zmm2 and zmm3/m512, and store the high 16 bits of the results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG E4 /r")]
        vpmulhuw_zmm_k1z_zmm_m512 = 4185,

        /// <summary>
        /// vpmulhuw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in zmm2 and zmm3/m512, and store the high 16 bits of the results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG E4 /r")]
        vpmulhuw_zmm_k1z_zmm_r32 = 4186,

        /// <summary>
        /// vpmulhuw zmm, zmm, m512 | EVEX.512.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in zmm2 and zmm3/m512, and store the high 16 bits of the results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw zmm, zmm, m512","EVEX.512.66.0F.WIG E4 /r")]
        vpmulhuw_zmm_zmm_m512 = 4187,

        /// <summary>
        /// vpmulhuw zmm, zmm, r32 | EVEX.512.66.0F.WIG E4 /r | Multiply the packed unsigned word integers in zmm2 and zmm3/m512, and store the high 16 bits of the results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmulhuw zmm, zmm, r32","EVEX.512.66.0F.WIG E4 /r")]
        vpmulhuw_zmm_zmm_r32 = 4188,

        /// <summary>
        /// vpmullw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG D5 /r | Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the low 16 bits of the results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG D5 /r")]
        vpmullw_xmm_k1z_xmm_m128 = 4189,

        /// <summary>
        /// vpmullw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG D5 /r | Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the low 16 bits of the results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG D5 /r")]
        vpmullw_xmm_k1z_xmm_r8 = 4190,

        /// <summary>
        /// vpmullw xmm, xmm, m128 | EVEX.128.66.0F.WIG D5 /r | Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the low 16 bits of the results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw xmm, xmm, m128","EVEX.128.66.0F.WIG D5 /r")]
        vpmullw_xmm_xmm_m128 = 4191,

        /// <summary>
        /// vpmullw xmm, xmm, m128 | VEX.128.66.0F.WIG D5 /r | Multiply the packed dword signed integers in xmm2 and xmm3/m128 and store the low 32 bits of each product in xmm1.
        /// </summary>
        [Symbol("vpmullw xmm, xmm, m128","VEX.128.66.0F.WIG D5 /r")]
        vpmullw_xmm_xmm_m128_vex = 4192,

        /// <summary>
        /// vpmullw xmm, xmm, r8 | EVEX.128.66.0F.WIG D5 /r | Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the low 16 bits of the results in xmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw xmm, xmm, r8","EVEX.128.66.0F.WIG D5 /r")]
        vpmullw_xmm_xmm_r8 = 4193,

        /// <summary>
        /// vpmullw xmm, xmm, r8 | VEX.128.66.0F.WIG D5 /r | Multiply the packed dword signed integers in xmm2 and xmm3/m128 and store the low 32 bits of each product in xmm1.
        /// </summary>
        [Symbol("vpmullw xmm, xmm, r8","VEX.128.66.0F.WIG D5 /r")]
        vpmullw_xmm_xmm_r8_vex = 4194,

        /// <summary>
        /// vpmullw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG D5 /r | Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the low 16 bits of the results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG D5 /r")]
        vpmullw_ymm_k1z_ymm_m256 = 4195,

        /// <summary>
        /// vpmullw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG D5 /r | Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the low 16 bits of the results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG D5 /r")]
        vpmullw_ymm_k1z_ymm_r16 = 4196,

        /// <summary>
        /// vpmullw ymm, ymm, m256 | EVEX.256.66.0F.WIG D5 /r | Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the low 16 bits of the results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw ymm, ymm, m256","EVEX.256.66.0F.WIG D5 /r")]
        vpmullw_ymm_ymm_m256 = 4197,

        /// <summary>
        /// vpmullw ymm, ymm, m256 | VEX.256.66.0F.WIG D5 /r | Multiply the packed signed word integers in ymm2 and ymm3/m256 , and store the low 16 bits of the results in ymm1.
        /// </summary>
        [Symbol("vpmullw ymm, ymm, m256","VEX.256.66.0F.WIG D5 /r")]
        vpmullw_ymm_ymm_m256_vex = 4198,

        /// <summary>
        /// vpmullw ymm, ymm, r16 | EVEX.256.66.0F.WIG D5 /r | Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the low 16 bits of the results in ymm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw ymm, ymm, r16","EVEX.256.66.0F.WIG D5 /r")]
        vpmullw_ymm_ymm_r16 = 4199,

        /// <summary>
        /// vpmullw ymm, ymm, r16 | VEX.256.66.0F.WIG D5 /r | Multiply the packed signed word integers in ymm2 and ymm3/m256 , and store the low 16 bits of the results in ymm1.
        /// </summary>
        [Symbol("vpmullw ymm, ymm, r16","VEX.256.66.0F.WIG D5 /r")]
        vpmullw_ymm_ymm_r16_vex = 4200,

        /// <summary>
        /// vpmullw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG D5 /r | Multiply the packed signed word integers in zmm2 and zmm3/m512, and store the low 16 bits of the results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG D5 /r")]
        vpmullw_zmm_k1z_zmm_m512 = 4201,

        /// <summary>
        /// vpmullw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG D5 /r | Multiply the packed signed word integers in zmm2 and zmm3/m512, and store the low 16 bits of the results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG D5 /r")]
        vpmullw_zmm_k1z_zmm_r32 = 4202,

        /// <summary>
        /// vpmullw zmm, zmm, m512 | EVEX.512.66.0F.WIG D5 /r | Multiply the packed signed word integers in zmm2 and zmm3/m512, and store the low 16 bits of the results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw zmm, zmm, m512","EVEX.512.66.0F.WIG D5 /r")]
        vpmullw_zmm_zmm_m512 = 4203,

        /// <summary>
        /// vpmullw zmm, zmm, r32 | EVEX.512.66.0F.WIG D5 /r | Multiply the packed signed word integers in zmm2 and zmm3/m512, and store the low 16 bits of the results in zmm1 under writemask k1.
        /// </summary>
        [Symbol("vpmullw zmm, zmm, r32","EVEX.512.66.0F.WIG D5 /r")]
        vpmullw_zmm_zmm_r32 = 4204,

        /// <summary>
        /// vpor xmm, xmm, m128 | VEX.128.66.0F.WIG EB /r | Bitwise OR of xmm2/m128 and xmm3.
        /// </summary>
        [Symbol("vpor xmm, xmm, m128","VEX.128.66.0F.WIG EB /r")]
        vpor_xmm_xmm_m128 = 4205,

        /// <summary>
        /// vpor xmm, xmm, r8 | VEX.128.66.0F.WIG EB /r | Bitwise OR of xmm2/m128 and xmm3.
        /// </summary>
        [Symbol("vpor xmm, xmm, r8","VEX.128.66.0F.WIG EB /r")]
        vpor_xmm_xmm_r8 = 4206,

        /// <summary>
        /// vpor ymm, ymm, m256 | VEX.256.66.0F.WIG EB /r | Bitwise OR of ymm2/m256 and ymm3.
        /// </summary>
        [Symbol("vpor ymm, ymm, m256","VEX.256.66.0F.WIG EB /r")]
        vpor_ymm_ymm_m256 = 4207,

        /// <summary>
        /// vpor ymm, ymm, r16 | VEX.256.66.0F.WIG EB /r | Bitwise OR of ymm2/m256 and ymm3.
        /// </summary>
        [Symbol("vpor ymm, ymm, r16","VEX.256.66.0F.WIG EB /r")]
        vpor_ymm_ymm_r16 = 4208,

        /// <summary>
        /// vpord xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in xmm2 and xmm3/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 EB /r")]
        vpord_xmm_k1z_xmm_m128 = 4209,

        /// <summary>
        /// vpord xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in xmm2 and xmm3/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F.W0 EB /r")]
        vpord_xmm_k1z_xmm_m32bcst = 4210,

        /// <summary>
        /// vpord xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in xmm2 and xmm3/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W0 EB /r")]
        vpord_xmm_k1z_xmm_xmm = 4211,

        /// <summary>
        /// vpord xmm, xmm, m128 | EVEX.128.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in xmm2 and xmm3/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord xmm, xmm, m128","EVEX.128.66.0F.W0 EB /r")]
        vpord_xmm_xmm_m128 = 4212,

        /// <summary>
        /// vpord xmm, xmm, m32bcst | EVEX.128.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in xmm2 and xmm3/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord xmm, xmm, m32bcst","EVEX.128.66.0F.W0 EB /r")]
        vpord_xmm_xmm_m32bcst = 4213,

        /// <summary>
        /// vpord xmm, xmm, xmm | EVEX.128.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in xmm2 and xmm3/m128/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord xmm, xmm, xmm","EVEX.128.66.0F.W0 EB /r")]
        vpord_xmm_xmm_xmm = 4214,

        /// <summary>
        /// vpord ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in ymm2 and ymm3/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W0 EB /r")]
        vpord_ymm_k1z_ymm_m256 = 4215,

        /// <summary>
        /// vpord ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in ymm2 and ymm3/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F.W0 EB /r")]
        vpord_ymm_k1z_ymm_m32bcst = 4216,

        /// <summary>
        /// vpord ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in ymm2 and ymm3/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W0 EB /r")]
        vpord_ymm_k1z_ymm_ymm = 4217,

        /// <summary>
        /// vpord ymm, ymm, m256 | EVEX.256.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in ymm2 and ymm3/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord ymm, ymm, m256","EVEX.256.66.0F.W0 EB /r")]
        vpord_ymm_ymm_m256 = 4218,

        /// <summary>
        /// vpord ymm, ymm, m32bcst | EVEX.256.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in ymm2 and ymm3/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord ymm, ymm, m32bcst","EVEX.256.66.0F.W0 EB /r")]
        vpord_ymm_ymm_m32bcst = 4219,

        /// <summary>
        /// vpord ymm, ymm, ymm | EVEX.256.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in ymm2 and ymm3/m256/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord ymm, ymm, ymm","EVEX.256.66.0F.W0 EB /r")]
        vpord_ymm_ymm_ymm = 4220,

        /// <summary>
        /// vpord zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F.W0 EB /r")]
        vpord_zmm_k1z_zmm_m32bcst = 4221,

        /// <summary>
        /// vpord zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W0 EB /r")]
        vpord_zmm_k1z_zmm_m512 = 4222,

        /// <summary>
        /// vpord zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W0 EB /r")]
        vpord_zmm_k1z_zmm_zmm = 4223,

        /// <summary>
        /// vpord zmm, zmm, m32bcst | EVEX.512.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord zmm, zmm, m32bcst","EVEX.512.66.0F.W0 EB /r")]
        vpord_zmm_zmm_m32bcst = 4224,

        /// <summary>
        /// vpord zmm, zmm, m512 | EVEX.512.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord zmm, zmm, m512","EVEX.512.66.0F.W0 EB /r")]
        vpord_zmm_zmm_m512 = 4225,

        /// <summary>
        /// vpord zmm, zmm, zmm | EVEX.512.66.0F.W0 EB /r | Bitwise OR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpord zmm, zmm, zmm","EVEX.512.66.0F.W0 EB /r")]
        vpord_zmm_zmm_zmm = 4226,

        /// <summary>
        /// vporq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in xmm2 and xmm3/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 EB /r")]
        vporq_xmm_k1z_xmm_m128 = 4227,

        /// <summary>
        /// vporq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in xmm2 and xmm3/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F.W1 EB /r")]
        vporq_xmm_k1z_xmm_m64bcst = 4228,

        /// <summary>
        /// vporq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in xmm2 and xmm3/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W1 EB /r")]
        vporq_xmm_k1z_xmm_xmm = 4229,

        /// <summary>
        /// vporq xmm, xmm, m128 | EVEX.128.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in xmm2 and xmm3/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq xmm, xmm, m128","EVEX.128.66.0F.W1 EB /r")]
        vporq_xmm_xmm_m128 = 4230,

        /// <summary>
        /// vporq xmm, xmm, m64bcst | EVEX.128.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in xmm2 and xmm3/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq xmm, xmm, m64bcst","EVEX.128.66.0F.W1 EB /r")]
        vporq_xmm_xmm_m64bcst = 4231,

        /// <summary>
        /// vporq xmm, xmm, xmm | EVEX.128.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in xmm2 and xmm3/m128/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq xmm, xmm, xmm","EVEX.128.66.0F.W1 EB /r")]
        vporq_xmm_xmm_xmm = 4232,

        /// <summary>
        /// vporq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in ymm2 and ymm3/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W1 EB /r")]
        vporq_ymm_k1z_ymm_m256 = 4233,

        /// <summary>
        /// vporq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in ymm2 and ymm3/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F.W1 EB /r")]
        vporq_ymm_k1z_ymm_m64bcst = 4234,

        /// <summary>
        /// vporq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in ymm2 and ymm3/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W1 EB /r")]
        vporq_ymm_k1z_ymm_ymm = 4235,

        /// <summary>
        /// vporq ymm, ymm, m256 | EVEX.256.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in ymm2 and ymm3/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq ymm, ymm, m256","EVEX.256.66.0F.W1 EB /r")]
        vporq_ymm_ymm_m256 = 4236,

        /// <summary>
        /// vporq ymm, ymm, m64bcst | EVEX.256.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in ymm2 and ymm3/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq ymm, ymm, m64bcst","EVEX.256.66.0F.W1 EB /r")]
        vporq_ymm_ymm_m64bcst = 4237,

        /// <summary>
        /// vporq ymm, ymm, ymm | EVEX.256.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in ymm2 and ymm3/m256/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq ymm, ymm, ymm","EVEX.256.66.0F.W1 EB /r")]
        vporq_ymm_ymm_ymm = 4238,

        /// <summary>
        /// vporq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W1 EB /r")]
        vporq_zmm_k1z_zmm_m512 = 4239,

        /// <summary>
        /// vporq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F.W1 EB /r")]
        vporq_zmm_k1z_zmm_m64bcst = 4240,

        /// <summary>
        /// vporq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W1 EB /r")]
        vporq_zmm_k1z_zmm_zmm = 4241,

        /// <summary>
        /// vporq zmm, zmm, m512 | EVEX.512.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq zmm, zmm, m512","EVEX.512.66.0F.W1 EB /r")]
        vporq_zmm_zmm_m512 = 4242,

        /// <summary>
        /// vporq zmm, zmm, m64bcst | EVEX.512.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq zmm, zmm, m64bcst","EVEX.512.66.0F.W1 EB /r")]
        vporq_zmm_zmm_m64bcst = 4243,

        /// <summary>
        /// vporq zmm, zmm, zmm | EVEX.512.66.0F.W1 EB /r | Bitwise OR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vporq zmm, zmm, zmm","EVEX.512.66.0F.W1 EB /r")]
        vporq_zmm_zmm_zmm = 4244,

        /// <summary>
        /// vprold xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W0 72 /1 ib | Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W0 72 /1 ib")]
        vprold_xmm_k1z_m128_imm8 = 4245,

        /// <summary>
        /// vprold xmm {k1}{z}, m32bcst, imm8 | EVEX.128.66.0F.W0 72 /1 ib | Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold xmm {k1}{z}, m32bcst, imm8","EVEX.128.66.0F.W0 72 /1 ib")]
        vprold_xmm_k1z_m32bcst_imm8 = 4246,

        /// <summary>
        /// vprold xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W0 72 /1 ib | Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W0 72 /1 ib")]
        vprold_xmm_k1z_xmm_imm8 = 4247,

        /// <summary>
        /// vprold xmm, m128, imm8 | EVEX.128.66.0F.W0 72 /1 ib | Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold xmm, m128, imm8","EVEX.128.66.0F.W0 72 /1 ib")]
        vprold_xmm_m128_imm8 = 4248,

        /// <summary>
        /// vprold xmm, m32bcst, imm8 | EVEX.128.66.0F.W0 72 /1 ib | Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold xmm, m32bcst, imm8","EVEX.128.66.0F.W0 72 /1 ib")]
        vprold_xmm_m32bcst_imm8 = 4249,

        /// <summary>
        /// vprold xmm, xmm, imm8 | EVEX.128.66.0F.W0 72 /1 ib | Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold xmm, xmm, imm8","EVEX.128.66.0F.W0 72 /1 ib")]
        vprold_xmm_xmm_imm8 = 4250,

        /// <summary>
        /// vprold ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W0 72 /1 ib | Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprold ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W0 72 /1 ib")]
        vprold_ymm_k1z_m256_imm8 = 4251,

        /// <summary>
        /// vprold ymm {k1}{z}, m32bcst, imm8 | EVEX.256.66.0F.W0 72 /1 ib | Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprold ymm {k1}{z}, m32bcst, imm8","EVEX.256.66.0F.W0 72 /1 ib")]
        vprold_ymm_k1z_m32bcst_imm8 = 4252,

        /// <summary>
        /// vprold ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W0 72 /1 ib | Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprold ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W0 72 /1 ib")]
        vprold_ymm_k1z_ymm_imm8 = 4253,

        /// <summary>
        /// vprold ymm, m256, imm8 | EVEX.256.66.0F.W0 72 /1 ib | Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprold ymm, m256, imm8","EVEX.256.66.0F.W0 72 /1 ib")]
        vprold_ymm_m256_imm8 = 4254,

        /// <summary>
        /// vprold ymm, m32bcst, imm8 | EVEX.256.66.0F.W0 72 /1 ib | Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprold ymm, m32bcst, imm8","EVEX.256.66.0F.W0 72 /1 ib")]
        vprold_ymm_m32bcst_imm8 = 4255,

        /// <summary>
        /// vprold ymm, ymm, imm8 | EVEX.256.66.0F.W0 72 /1 ib | Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprold ymm, ymm, imm8","EVEX.256.66.0F.W0 72 /1 ib")]
        vprold_ymm_ymm_imm8 = 4256,

        /// <summary>
        /// vprold zmm {k1}{z}, m32bcst, imm8 | EVEX.512.66.0F.W0 72 /1 ib | Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold zmm {k1}{z}, m32bcst, imm8","EVEX.512.66.0F.W0 72 /1 ib")]
        vprold_zmm_k1z_m32bcst_imm8 = 4257,

        /// <summary>
        /// vprold zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W0 72 /1 ib | Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W0 72 /1 ib")]
        vprold_zmm_k1z_m512_imm8 = 4258,

        /// <summary>
        /// vprold zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W0 72 /1 ib | Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W0 72 /1 ib")]
        vprold_zmm_k1z_zmm_imm8 = 4259,

        /// <summary>
        /// vprold zmm, m32bcst, imm8 | EVEX.512.66.0F.W0 72 /1 ib | Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold zmm, m32bcst, imm8","EVEX.512.66.0F.W0 72 /1 ib")]
        vprold_zmm_m32bcst_imm8 = 4260,

        /// <summary>
        /// vprold zmm, m512, imm8 | EVEX.512.66.0F.W0 72 /1 ib | Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold zmm, m512, imm8","EVEX.512.66.0F.W0 72 /1 ib")]
        vprold_zmm_m512_imm8 = 4261,

        /// <summary>
        /// vprold zmm, zmm, imm8 | EVEX.512.66.0F.W0 72 /1 ib | Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprold zmm, zmm, imm8","EVEX.512.66.0F.W0 72 /1 ib")]
        vprold_zmm_zmm_imm8 = 4262,

        /// <summary>
        /// vprolq xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W1 72 /1 ib | Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W1 72 /1 ib")]
        vprolq_xmm_k1z_m128_imm8 = 4263,

        /// <summary>
        /// vprolq xmm {k1}{z}, m64bcst, imm8 | EVEX.128.66.0F.W1 72 /1 ib | Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq xmm {k1}{z}, m64bcst, imm8","EVEX.128.66.0F.W1 72 /1 ib")]
        vprolq_xmm_k1z_m64bcst_imm8 = 4264,

        /// <summary>
        /// vprolq xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W1 72 /1 ib | Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W1 72 /1 ib")]
        vprolq_xmm_k1z_xmm_imm8 = 4265,

        /// <summary>
        /// vprolq xmm, m128, imm8 | EVEX.128.66.0F.W1 72 /1 ib | Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq xmm, m128, imm8","EVEX.128.66.0F.W1 72 /1 ib")]
        vprolq_xmm_m128_imm8 = 4266,

        /// <summary>
        /// vprolq xmm, m64bcst, imm8 | EVEX.128.66.0F.W1 72 /1 ib | Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq xmm, m64bcst, imm8","EVEX.128.66.0F.W1 72 /1 ib")]
        vprolq_xmm_m64bcst_imm8 = 4267,

        /// <summary>
        /// vprolq xmm, xmm, imm8 | EVEX.128.66.0F.W1 72 /1 ib | Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq xmm, xmm, imm8","EVEX.128.66.0F.W1 72 /1 ib")]
        vprolq_xmm_xmm_imm8 = 4268,

        /// <summary>
        /// vprolq ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W1 72 /1 ib | Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W1 72 /1 ib")]
        vprolq_ymm_k1z_m256_imm8 = 4269,

        /// <summary>
        /// vprolq ymm {k1}{z}, m64bcst, imm8 | EVEX.256.66.0F.W1 72 /1 ib | Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq ymm {k1}{z}, m64bcst, imm8","EVEX.256.66.0F.W1 72 /1 ib")]
        vprolq_ymm_k1z_m64bcst_imm8 = 4270,

        /// <summary>
        /// vprolq ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W1 72 /1 ib | Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W1 72 /1 ib")]
        vprolq_ymm_k1z_ymm_imm8 = 4271,

        /// <summary>
        /// vprolq ymm, m256, imm8 | EVEX.256.66.0F.W1 72 /1 ib | Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq ymm, m256, imm8","EVEX.256.66.0F.W1 72 /1 ib")]
        vprolq_ymm_m256_imm8 = 4272,

        /// <summary>
        /// vprolq ymm, m64bcst, imm8 | EVEX.256.66.0F.W1 72 /1 ib | Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq ymm, m64bcst, imm8","EVEX.256.66.0F.W1 72 /1 ib")]
        vprolq_ymm_m64bcst_imm8 = 4273,

        /// <summary>
        /// vprolq ymm, ymm, imm8 | EVEX.256.66.0F.W1 72 /1 ib | Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq ymm, ymm, imm8","EVEX.256.66.0F.W1 72 /1 ib")]
        vprolq_ymm_ymm_imm8 = 4274,

        /// <summary>
        /// vprolq zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W1 72 /1 ib | Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W1 72 /1 ib")]
        vprolq_zmm_k1z_m512_imm8 = 4275,

        /// <summary>
        /// vprolq zmm {k1}{z}, m64bcst, imm8 | EVEX.512.66.0F.W1 72 /1 ib | Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq zmm {k1}{z}, m64bcst, imm8","EVEX.512.66.0F.W1 72 /1 ib")]
        vprolq_zmm_k1z_m64bcst_imm8 = 4276,

        /// <summary>
        /// vprolq zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W1 72 /1 ib | Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W1 72 /1 ib")]
        vprolq_zmm_k1z_zmm_imm8 = 4277,

        /// <summary>
        /// vprolq zmm, m512, imm8 | EVEX.512.66.0F.W1 72 /1 ib | Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq zmm, m512, imm8","EVEX.512.66.0F.W1 72 /1 ib")]
        vprolq_zmm_m512_imm8 = 4278,

        /// <summary>
        /// vprolq zmm, m64bcst, imm8 | EVEX.512.66.0F.W1 72 /1 ib | Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq zmm, m64bcst, imm8","EVEX.512.66.0F.W1 72 /1 ib")]
        vprolq_zmm_m64bcst_imm8 = 4279,

        /// <summary>
        /// vprolq zmm, zmm, imm8 | EVEX.512.66.0F.W1 72 /1 ib | Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolq zmm, zmm, imm8","EVEX.512.66.0F.W1 72 /1 ib")]
        vprolq_zmm_zmm_imm8 = 4280,

        /// <summary>
        /// vprolvd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 15 /r | Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 15 /r")]
        vprolvd_xmm_k1z_xmm_m128 = 4281,

        /// <summary>
        /// vprolvd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 15 /r | Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 15 /r")]
        vprolvd_xmm_k1z_xmm_m32bcst = 4282,

        /// <summary>
        /// vprolvd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 15 /r | Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 15 /r")]
        vprolvd_xmm_k1z_xmm_xmm = 4283,

        /// <summary>
        /// vprolvd xmm, xmm, m128 | EVEX.128.66.0F38.W0 15 /r | Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd xmm, xmm, m128","EVEX.128.66.0F38.W0 15 /r")]
        vprolvd_xmm_xmm_m128 = 4284,

        /// <summary>
        /// vprolvd xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 15 /r | Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 15 /r")]
        vprolvd_xmm_xmm_m32bcst = 4285,

        /// <summary>
        /// vprolvd xmm, xmm, xmm | EVEX.128.66.0F38.W0 15 /r | Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd xmm, xmm, xmm","EVEX.128.66.0F38.W0 15 /r")]
        vprolvd_xmm_xmm_xmm = 4286,

        /// <summary>
        /// vprolvd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 15 /r | Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 15 /r")]
        vprolvd_ymm_k1z_ymm_m256 = 4287,

        /// <summary>
        /// vprolvd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 15 /r | Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 15 /r")]
        vprolvd_ymm_k1z_ymm_m32bcst = 4288,

        /// <summary>
        /// vprolvd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 15 /r | Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 15 /r")]
        vprolvd_ymm_k1z_ymm_ymm = 4289,

        /// <summary>
        /// vprolvd ymm, ymm, m256 | EVEX.256.66.0F38.W0 15 /r | Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd ymm, ymm, m256","EVEX.256.66.0F38.W0 15 /r")]
        vprolvd_ymm_ymm_m256 = 4290,

        /// <summary>
        /// vprolvd ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 15 /r | Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 15 /r")]
        vprolvd_ymm_ymm_m32bcst = 4291,

        /// <summary>
        /// vprolvd ymm, ymm, ymm | EVEX.256.66.0F38.W0 15 /r | Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvd ymm, ymm, ymm","EVEX.256.66.0F38.W0 15 /r")]
        vprolvd_ymm_ymm_ymm = 4292,

        /// <summary>
        /// vprolvd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 15 /r | Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolvd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 15 /r")]
        vprolvd_zmm_k1z_zmm_m32bcst = 4293,

        /// <summary>
        /// vprolvd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 15 /r | Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolvd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 15 /r")]
        vprolvd_zmm_k1z_zmm_m512 = 4294,

        /// <summary>
        /// vprolvd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 15 /r | Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolvd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 15 /r")]
        vprolvd_zmm_k1z_zmm_zmm = 4295,

        /// <summary>
        /// vprolvd zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 15 /r | Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolvd zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 15 /r")]
        vprolvd_zmm_zmm_m32bcst = 4296,

        /// <summary>
        /// vprolvd zmm, zmm, m512 | EVEX.512.66.0F38.W0 15 /r | Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolvd zmm, zmm, m512","EVEX.512.66.0F38.W0 15 /r")]
        vprolvd_zmm_zmm_m512 = 4297,

        /// <summary>
        /// vprolvd zmm, zmm, zmm | EVEX.512.66.0F38.W0 15 /r | Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.
        /// </summary>
        [Symbol("vprolvd zmm, zmm, zmm","EVEX.512.66.0F38.W0 15 /r")]
        vprolvd_zmm_zmm_zmm = 4298,

        /// <summary>
        /// vprolvq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 15 /r | Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 15 /r")]
        vprolvq_xmm_k1z_xmm_m128 = 4299,

        /// <summary>
        /// vprolvq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 15 /r | Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 15 /r")]
        vprolvq_xmm_k1z_xmm_m64bcst = 4300,

        /// <summary>
        /// vprolvq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 15 /r | Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 15 /r")]
        vprolvq_xmm_k1z_xmm_xmm = 4301,

        /// <summary>
        /// vprolvq xmm, xmm, m128 | EVEX.128.66.0F38.W1 15 /r | Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq xmm, xmm, m128","EVEX.128.66.0F38.W1 15 /r")]
        vprolvq_xmm_xmm_m128 = 4302,

        /// <summary>
        /// vprolvq xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 15 /r | Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 15 /r")]
        vprolvq_xmm_xmm_m64bcst = 4303,

        /// <summary>
        /// vprolvq xmm, xmm, xmm | EVEX.128.66.0F38.W1 15 /r | Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq xmm, xmm, xmm","EVEX.128.66.0F38.W1 15 /r")]
        vprolvq_xmm_xmm_xmm = 4304,

        /// <summary>
        /// vprolvq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 15 /r | Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 15 /r")]
        vprolvq_ymm_k1z_ymm_m256 = 4305,

        /// <summary>
        /// vprolvq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 15 /r | Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 15 /r")]
        vprolvq_ymm_k1z_ymm_m64bcst = 4306,

        /// <summary>
        /// vprolvq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 15 /r | Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 15 /r")]
        vprolvq_ymm_k1z_ymm_ymm = 4307,

        /// <summary>
        /// vprolvq ymm, ymm, m256 | EVEX.256.66.0F38.W1 15 /r | Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq ymm, ymm, m256","EVEX.256.66.0F38.W1 15 /r")]
        vprolvq_ymm_ymm_m256 = 4308,

        /// <summary>
        /// vprolvq ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 15 /r | Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 15 /r")]
        vprolvq_ymm_ymm_m64bcst = 4309,

        /// <summary>
        /// vprolvq ymm, ymm, ymm | EVEX.256.66.0F38.W1 15 /r | Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.
        /// </summary>
        [Symbol("vprolvq ymm, ymm, ymm","EVEX.256.66.0F38.W1 15 /r")]
        vprolvq_ymm_ymm_ymm = 4310,

        /// <summary>
        /// vprolvq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 15 /r | Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.
        /// </summary>
        [Symbol("vprolvq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 15 /r")]
        vprolvq_zmm_k1z_zmm_m512 = 4311,

        /// <summary>
        /// vprolvq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 15 /r | Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.
        /// </summary>
        [Symbol("vprolvq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 15 /r")]
        vprolvq_zmm_k1z_zmm_m64bcst = 4312,

        /// <summary>
        /// vprolvq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 15 /r | Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.
        /// </summary>
        [Symbol("vprolvq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 15 /r")]
        vprolvq_zmm_k1z_zmm_zmm = 4313,

        /// <summary>
        /// vprolvq zmm, zmm, m512 | EVEX.512.66.0F38.W1 15 /r | Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.
        /// </summary>
        [Symbol("vprolvq zmm, zmm, m512","EVEX.512.66.0F38.W1 15 /r")]
        vprolvq_zmm_zmm_m512 = 4314,

        /// <summary>
        /// vprolvq zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 15 /r | Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.
        /// </summary>
        [Symbol("vprolvq zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 15 /r")]
        vprolvq_zmm_zmm_m64bcst = 4315,

        /// <summary>
        /// vprolvq zmm, zmm, zmm | EVEX.512.66.0F38.W1 15 /r | Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.
        /// </summary>
        [Symbol("vprolvq zmm, zmm, zmm","EVEX.512.66.0F38.W1 15 /r")]
        vprolvq_zmm_zmm_zmm = 4316,

        /// <summary>
        /// vprord xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W0 72 /0 ib | Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W0 72 /0 ib")]
        vprord_xmm_k1z_m128_imm8 = 4317,

        /// <summary>
        /// vprord xmm {k1}{z}, m32bcst, imm8 | EVEX.128.66.0F.W0 72 /0 ib | Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord xmm {k1}{z}, m32bcst, imm8","EVEX.128.66.0F.W0 72 /0 ib")]
        vprord_xmm_k1z_m32bcst_imm8 = 4318,

        /// <summary>
        /// vprord xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W0 72 /0 ib | Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W0 72 /0 ib")]
        vprord_xmm_k1z_xmm_imm8 = 4319,

        /// <summary>
        /// vprord xmm, m128, imm8 | EVEX.128.66.0F.W0 72 /0 ib | Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord xmm, m128, imm8","EVEX.128.66.0F.W0 72 /0 ib")]
        vprord_xmm_m128_imm8 = 4320,

        /// <summary>
        /// vprord xmm, m32bcst, imm8 | EVEX.128.66.0F.W0 72 /0 ib | Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord xmm, m32bcst, imm8","EVEX.128.66.0F.W0 72 /0 ib")]
        vprord_xmm_m32bcst_imm8 = 4321,

        /// <summary>
        /// vprord xmm, xmm, imm8 | EVEX.128.66.0F.W0 72 /0 ib | Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord xmm, xmm, imm8","EVEX.128.66.0F.W0 72 /0 ib")]
        vprord_xmm_xmm_imm8 = 4322,

        /// <summary>
        /// vprord ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W0 72 /0 ib | Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W0 72 /0 ib")]
        vprord_ymm_k1z_m256_imm8 = 4323,

        /// <summary>
        /// vprord ymm {k1}{z}, m32bcst, imm8 | EVEX.256.66.0F.W0 72 /0 ib | Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord ymm {k1}{z}, m32bcst, imm8","EVEX.256.66.0F.W0 72 /0 ib")]
        vprord_ymm_k1z_m32bcst_imm8 = 4324,

        /// <summary>
        /// vprord ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W0 72 /0 ib | Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W0 72 /0 ib")]
        vprord_ymm_k1z_ymm_imm8 = 4325,

        /// <summary>
        /// vprord ymm, m256, imm8 | EVEX.256.66.0F.W0 72 /0 ib | Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord ymm, m256, imm8","EVEX.256.66.0F.W0 72 /0 ib")]
        vprord_ymm_m256_imm8 = 4326,

        /// <summary>
        /// vprord ymm, m32bcst, imm8 | EVEX.256.66.0F.W0 72 /0 ib | Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord ymm, m32bcst, imm8","EVEX.256.66.0F.W0 72 /0 ib")]
        vprord_ymm_m32bcst_imm8 = 4327,

        /// <summary>
        /// vprord ymm, ymm, imm8 | EVEX.256.66.0F.W0 72 /0 ib | Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord ymm, ymm, imm8","EVEX.256.66.0F.W0 72 /0 ib")]
        vprord_ymm_ymm_imm8 = 4328,

        /// <summary>
        /// vprord zmm {k1}{z}, m32bcst, imm8 | EVEX.512.66.0F.W0 72 /0 ib | Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord zmm {k1}{z}, m32bcst, imm8","EVEX.512.66.0F.W0 72 /0 ib")]
        vprord_zmm_k1z_m32bcst_imm8 = 4329,

        /// <summary>
        /// vprord zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W0 72 /0 ib | Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W0 72 /0 ib")]
        vprord_zmm_k1z_m512_imm8 = 4330,

        /// <summary>
        /// vprord zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W0 72 /0 ib | Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W0 72 /0 ib")]
        vprord_zmm_k1z_zmm_imm8 = 4331,

        /// <summary>
        /// vprord zmm, m32bcst, imm8 | EVEX.512.66.0F.W0 72 /0 ib | Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord zmm, m32bcst, imm8","EVEX.512.66.0F.W0 72 /0 ib")]
        vprord_zmm_m32bcst_imm8 = 4332,

        /// <summary>
        /// vprord zmm, m512, imm8 | EVEX.512.66.0F.W0 72 /0 ib | Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord zmm, m512, imm8","EVEX.512.66.0F.W0 72 /0 ib")]
        vprord_zmm_m512_imm8 = 4333,

        /// <summary>
        /// vprord zmm, zmm, imm8 | EVEX.512.66.0F.W0 72 /0 ib | Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprord zmm, zmm, imm8","EVEX.512.66.0F.W0 72 /0 ib")]
        vprord_zmm_zmm_imm8 = 4334,

        /// <summary>
        /// vprorq xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W1 72 /0 ib | Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W1 72 /0 ib")]
        vprorq_xmm_k1z_m128_imm8 = 4335,

        /// <summary>
        /// vprorq xmm {k1}{z}, m64bcst, imm8 | EVEX.128.66.0F.W1 72 /0 ib | Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq xmm {k1}{z}, m64bcst, imm8","EVEX.128.66.0F.W1 72 /0 ib")]
        vprorq_xmm_k1z_m64bcst_imm8 = 4336,

        /// <summary>
        /// vprorq xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W1 72 /0 ib | Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W1 72 /0 ib")]
        vprorq_xmm_k1z_xmm_imm8 = 4337,

        /// <summary>
        /// vprorq xmm, m128, imm8 | EVEX.128.66.0F.W1 72 /0 ib | Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq xmm, m128, imm8","EVEX.128.66.0F.W1 72 /0 ib")]
        vprorq_xmm_m128_imm8 = 4338,

        /// <summary>
        /// vprorq xmm, m64bcst, imm8 | EVEX.128.66.0F.W1 72 /0 ib | Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq xmm, m64bcst, imm8","EVEX.128.66.0F.W1 72 /0 ib")]
        vprorq_xmm_m64bcst_imm8 = 4339,

        /// <summary>
        /// vprorq xmm, xmm, imm8 | EVEX.128.66.0F.W1 72 /0 ib | Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq xmm, xmm, imm8","EVEX.128.66.0F.W1 72 /0 ib")]
        vprorq_xmm_xmm_imm8 = 4340,

        /// <summary>
        /// vprorq ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W1 72 /0 ib | Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W1 72 /0 ib")]
        vprorq_ymm_k1z_m256_imm8 = 4341,

        /// <summary>
        /// vprorq ymm {k1}{z}, m64bcst, imm8 | EVEX.256.66.0F.W1 72 /0 ib | Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq ymm {k1}{z}, m64bcst, imm8","EVEX.256.66.0F.W1 72 /0 ib")]
        vprorq_ymm_k1z_m64bcst_imm8 = 4342,

        /// <summary>
        /// vprorq ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W1 72 /0 ib | Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W1 72 /0 ib")]
        vprorq_ymm_k1z_ymm_imm8 = 4343,

        /// <summary>
        /// vprorq ymm, m256, imm8 | EVEX.256.66.0F.W1 72 /0 ib | Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq ymm, m256, imm8","EVEX.256.66.0F.W1 72 /0 ib")]
        vprorq_ymm_m256_imm8 = 4344,

        /// <summary>
        /// vprorq ymm, m64bcst, imm8 | EVEX.256.66.0F.W1 72 /0 ib | Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq ymm, m64bcst, imm8","EVEX.256.66.0F.W1 72 /0 ib")]
        vprorq_ymm_m64bcst_imm8 = 4345,

        /// <summary>
        /// vprorq ymm, ymm, imm8 | EVEX.256.66.0F.W1 72 /0 ib | Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq ymm, ymm, imm8","EVEX.256.66.0F.W1 72 /0 ib")]
        vprorq_ymm_ymm_imm8 = 4346,

        /// <summary>
        /// vprorq zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W1 72 /0 ib | Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W1 72 /0 ib")]
        vprorq_zmm_k1z_m512_imm8 = 4347,

        /// <summary>
        /// vprorq zmm {k1}{z}, m64bcst, imm8 | EVEX.512.66.0F.W1 72 /0 ib | Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq zmm {k1}{z}, m64bcst, imm8","EVEX.512.66.0F.W1 72 /0 ib")]
        vprorq_zmm_k1z_m64bcst_imm8 = 4348,

        /// <summary>
        /// vprorq zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W1 72 /0 ib | Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W1 72 /0 ib")]
        vprorq_zmm_k1z_zmm_imm8 = 4349,

        /// <summary>
        /// vprorq zmm, m512, imm8 | EVEX.512.66.0F.W1 72 /0 ib | Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq zmm, m512, imm8","EVEX.512.66.0F.W1 72 /0 ib")]
        vprorq_zmm_m512_imm8 = 4350,

        /// <summary>
        /// vprorq zmm, m64bcst, imm8 | EVEX.512.66.0F.W1 72 /0 ib | Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq zmm, m64bcst, imm8","EVEX.512.66.0F.W1 72 /0 ib")]
        vprorq_zmm_m64bcst_imm8 = 4351,

        /// <summary>
        /// vprorq zmm, zmm, imm8 | EVEX.512.66.0F.W1 72 /0 ib | Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.
        /// </summary>
        [Symbol("vprorq zmm, zmm, imm8","EVEX.512.66.0F.W1 72 /0 ib")]
        vprorq_zmm_zmm_imm8 = 4352,

        /// <summary>
        /// vprorvd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 14 /r | Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 14 /r")]
        vprorvd_xmm_k1z_xmm_m128 = 4353,

        /// <summary>
        /// vprorvd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 14 /r | Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 14 /r")]
        vprorvd_xmm_k1z_xmm_m32bcst = 4354,

        /// <summary>
        /// vprorvd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 14 /r | Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 14 /r")]
        vprorvd_xmm_k1z_xmm_xmm = 4355,

        /// <summary>
        /// vprorvd xmm, xmm, m128 | EVEX.128.66.0F38.W0 14 /r | Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd xmm, xmm, m128","EVEX.128.66.0F38.W0 14 /r")]
        vprorvd_xmm_xmm_m128 = 4356,

        /// <summary>
        /// vprorvd xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 14 /r | Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 14 /r")]
        vprorvd_xmm_xmm_m32bcst = 4357,

        /// <summary>
        /// vprorvd xmm, xmm, xmm | EVEX.128.66.0F38.W0 14 /r | Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd xmm, xmm, xmm","EVEX.128.66.0F38.W0 14 /r")]
        vprorvd_xmm_xmm_xmm = 4358,

        /// <summary>
        /// vprorvd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 14 /r | Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.
        /// </summary>
        [Symbol("vprorvd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 14 /r")]
        vprorvd_ymm_k1z_ymm_m256 = 4359,

        /// <summary>
        /// vprorvd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 14 /r | Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.
        /// </summary>
        [Symbol("vprorvd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 14 /r")]
        vprorvd_ymm_k1z_ymm_m32bcst = 4360,

        /// <summary>
        /// vprorvd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 14 /r | Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.
        /// </summary>
        [Symbol("vprorvd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 14 /r")]
        vprorvd_ymm_k1z_ymm_ymm = 4361,

        /// <summary>
        /// vprorvd ymm, ymm, m256 | EVEX.256.66.0F38.W0 14 /r | Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.
        /// </summary>
        [Symbol("vprorvd ymm, ymm, m256","EVEX.256.66.0F38.W0 14 /r")]
        vprorvd_ymm_ymm_m256 = 4362,

        /// <summary>
        /// vprorvd ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 14 /r | Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.
        /// </summary>
        [Symbol("vprorvd ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 14 /r")]
        vprorvd_ymm_ymm_m32bcst = 4363,

        /// <summary>
        /// vprorvd ymm, ymm, ymm | EVEX.256.66.0F38.W0 14 /r | Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.
        /// </summary>
        [Symbol("vprorvd ymm, ymm, ymm","EVEX.256.66.0F38.W0 14 /r")]
        vprorvd_ymm_ymm_ymm = 4364,

        /// <summary>
        /// vprorvd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 14 /r | Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 14 /r")]
        vprorvd_zmm_k1z_zmm_m32bcst = 4365,

        /// <summary>
        /// vprorvd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 14 /r | Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 14 /r")]
        vprorvd_zmm_k1z_zmm_m512 = 4366,

        /// <summary>
        /// vprorvd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 14 /r | Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 14 /r")]
        vprorvd_zmm_k1z_zmm_zmm = 4367,

        /// <summary>
        /// vprorvd zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 14 /r | Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 14 /r")]
        vprorvd_zmm_zmm_m32bcst = 4368,

        /// <summary>
        /// vprorvd zmm, zmm, m512 | EVEX.512.66.0F38.W0 14 /r | Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd zmm, zmm, m512","EVEX.512.66.0F38.W0 14 /r")]
        vprorvd_zmm_zmm_m512 = 4369,

        /// <summary>
        /// vprorvd zmm, zmm, zmm | EVEX.512.66.0F38.W0 14 /r | Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvd zmm, zmm, zmm","EVEX.512.66.0F38.W0 14 /r")]
        vprorvd_zmm_zmm_zmm = 4370,

        /// <summary>
        /// vprorvq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 14 /r | Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 14 /r")]
        vprorvq_xmm_k1z_xmm_m128 = 4371,

        /// <summary>
        /// vprorvq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 14 /r | Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 14 /r")]
        vprorvq_xmm_k1z_xmm_m64bcst = 4372,

        /// <summary>
        /// vprorvq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 14 /r | Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 14 /r")]
        vprorvq_xmm_k1z_xmm_xmm = 4373,

        /// <summary>
        /// vprorvq xmm, xmm, m128 | EVEX.128.66.0F38.W1 14 /r | Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq xmm, xmm, m128","EVEX.128.66.0F38.W1 14 /r")]
        vprorvq_xmm_xmm_m128 = 4374,

        /// <summary>
        /// vprorvq xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 14 /r | Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 14 /r")]
        vprorvq_xmm_xmm_m64bcst = 4375,

        /// <summary>
        /// vprorvq xmm, xmm, xmm | EVEX.128.66.0F38.W1 14 /r | Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq xmm, xmm, xmm","EVEX.128.66.0F38.W1 14 /r")]
        vprorvq_xmm_xmm_xmm = 4376,

        /// <summary>
        /// vprorvq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 14 /r | Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 14 /r")]
        vprorvq_ymm_k1z_ymm_m256 = 4377,

        /// <summary>
        /// vprorvq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 14 /r | Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 14 /r")]
        vprorvq_ymm_k1z_ymm_m64bcst = 4378,

        /// <summary>
        /// vprorvq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 14 /r | Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 14 /r")]
        vprorvq_ymm_k1z_ymm_ymm = 4379,

        /// <summary>
        /// vprorvq ymm, ymm, m256 | EVEX.256.66.0F38.W1 14 /r | Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq ymm, ymm, m256","EVEX.256.66.0F38.W1 14 /r")]
        vprorvq_ymm_ymm_m256 = 4380,

        /// <summary>
        /// vprorvq ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 14 /r | Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 14 /r")]
        vprorvq_ymm_ymm_m64bcst = 4381,

        /// <summary>
        /// vprorvq ymm, ymm, ymm | EVEX.256.66.0F38.W1 14 /r | Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq ymm, ymm, ymm","EVEX.256.66.0F38.W1 14 /r")]
        vprorvq_ymm_ymm_ymm = 4382,

        /// <summary>
        /// vprorvq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 14 /r | Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 14 /r")]
        vprorvq_zmm_k1z_zmm_m512 = 4383,

        /// <summary>
        /// vprorvq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 14 /r | Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 14 /r")]
        vprorvq_zmm_k1z_zmm_m64bcst = 4384,

        /// <summary>
        /// vprorvq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 14 /r | Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 14 /r")]
        vprorvq_zmm_k1z_zmm_zmm = 4385,

        /// <summary>
        /// vprorvq zmm, zmm, m512 | EVEX.512.66.0F38.W1 14 /r | Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq zmm, zmm, m512","EVEX.512.66.0F38.W1 14 /r")]
        vprorvq_zmm_zmm_m512 = 4386,

        /// <summary>
        /// vprorvq zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 14 /r | Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 14 /r")]
        vprorvq_zmm_zmm_m64bcst = 4387,

        /// <summary>
        /// vprorvq zmm, zmm, zmm | EVEX.512.66.0F38.W1 14 /r | Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.
        /// </summary>
        [Symbol("vprorvq zmm, zmm, zmm","EVEX.512.66.0F38.W1 14 /r")]
        vprorvq_zmm_zmm_zmm = 4388,

        /// <summary>
        /// vpscatterdd vm32x {k1}, xmm | EVEX.128.66.0F38.W0 A0 /vsib | Using signed dword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdd vm32x {k1}, xmm","EVEX.128.66.0F38.W0 A0 /vsib")]
        vpscatterdd_vm32x_k1_xmm = 4389,

        /// <summary>
        /// vpscatterdd vm32x, xmm | EVEX.128.66.0F38.W0 A0 /vsib | Using signed dword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdd vm32x, xmm","EVEX.128.66.0F38.W0 A0 /vsib")]
        vpscatterdd_vm32x_xmm = 4390,

        /// <summary>
        /// vpscatterdd vm32y {k1}, ymm | EVEX.256.66.0F38.W0 A0 /vsib | Using signed dword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdd vm32y {k1}, ymm","EVEX.256.66.0F38.W0 A0 /vsib")]
        vpscatterdd_vm32y_k1_ymm = 4391,

        /// <summary>
        /// vpscatterdd vm32y, ymm | EVEX.256.66.0F38.W0 A0 /vsib | Using signed dword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdd vm32y, ymm","EVEX.256.66.0F38.W0 A0 /vsib")]
        vpscatterdd_vm32y_ymm = 4392,

        /// <summary>
        /// vpscatterdd vm32z {k1}, zmm | EVEX.512.66.0F38.W0 A0 /vsib | Using signed dword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdd vm32z {k1}, zmm","EVEX.512.66.0F38.W0 A0 /vsib")]
        vpscatterdd_vm32z_k1_zmm = 4393,

        /// <summary>
        /// vpscatterdd vm32z, zmm | EVEX.512.66.0F38.W0 A0 /vsib | Using signed dword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdd vm32z, zmm","EVEX.512.66.0F38.W0 A0 /vsib")]
        vpscatterdd_vm32z_zmm = 4394,

        /// <summary>
        /// vpscatterdq vm32x {k1}, xmm | EVEX.128.66.0F38.W1 A0 /vsib | Using signed dword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdq vm32x {k1}, xmm","EVEX.128.66.0F38.W1 A0 /vsib")]
        vpscatterdq_vm32x_k1_xmm = 4395,

        /// <summary>
        /// vpscatterdq vm32x {k1}, ymm | EVEX.256.66.0F38.W1 A0 /vsib | Using signed dword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdq vm32x {k1}, ymm","EVEX.256.66.0F38.W1 A0 /vsib")]
        vpscatterdq_vm32x_k1_ymm = 4396,

        /// <summary>
        /// vpscatterdq vm32x, xmm | EVEX.128.66.0F38.W1 A0 /vsib | Using signed dword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdq vm32x, xmm","EVEX.128.66.0F38.W1 A0 /vsib")]
        vpscatterdq_vm32x_xmm = 4397,

        /// <summary>
        /// vpscatterdq vm32x, ymm | EVEX.256.66.0F38.W1 A0 /vsib | Using signed dword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdq vm32x, ymm","EVEX.256.66.0F38.W1 A0 /vsib")]
        vpscatterdq_vm32x_ymm = 4398,

        /// <summary>
        /// vpscatterdq vm32y {k1}, zmm | EVEX.512.66.0F38.W1 A0 /vsib | Using signed dword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdq vm32y {k1}, zmm","EVEX.512.66.0F38.W1 A0 /vsib")]
        vpscatterdq_vm32y_k1_zmm = 4399,

        /// <summary>
        /// vpscatterdq vm32y, zmm | EVEX.512.66.0F38.W1 A0 /vsib | Using signed dword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterdq vm32y, zmm","EVEX.512.66.0F38.W1 A0 /vsib")]
        vpscatterdq_vm32y_zmm = 4400,

        /// <summary>
        /// vpscatterqd vm64x {k1}, xmm | EVEX.128.66.0F38.W0 A1 /vsib | Using signed qword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqd vm64x {k1}, xmm","EVEX.128.66.0F38.W0 A1 /vsib")]
        vpscatterqd_vm64x_k1_xmm = 4401,

        /// <summary>
        /// vpscatterqd vm64x, xmm | EVEX.128.66.0F38.W0 A1 /vsib | Using signed qword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqd vm64x, xmm","EVEX.128.66.0F38.W0 A1 /vsib")]
        vpscatterqd_vm64x_xmm = 4402,

        /// <summary>
        /// vpscatterqd vm64y {k1}, xmm | EVEX.256.66.0F38.W0 A1 /vsib | Using signed qword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqd vm64y {k1}, xmm","EVEX.256.66.0F38.W0 A1 /vsib")]
        vpscatterqd_vm64y_k1_xmm = 4403,

        /// <summary>
        /// vpscatterqd vm64y, xmm | EVEX.256.66.0F38.W0 A1 /vsib | Using signed qword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqd vm64y, xmm","EVEX.256.66.0F38.W0 A1 /vsib")]
        vpscatterqd_vm64y_xmm = 4404,

        /// <summary>
        /// vpscatterqd vm64z {k1}, ymm | EVEX.512.66.0F38.W0 A1 /vsib | Using signed qword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqd vm64z {k1}, ymm","EVEX.512.66.0F38.W0 A1 /vsib")]
        vpscatterqd_vm64z_k1_ymm = 4405,

        /// <summary>
        /// vpscatterqd vm64z, ymm | EVEX.512.66.0F38.W0 A1 /vsib | Using signed qword indices, scatter dword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqd vm64z, ymm","EVEX.512.66.0F38.W0 A1 /vsib")]
        vpscatterqd_vm64z_ymm = 4406,

        /// <summary>
        /// vpscatterqq vm64x {k1}, xmm | EVEX.128.66.0F38.W1 A1 /vsib | Using signed qword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqq vm64x {k1}, xmm","EVEX.128.66.0F38.W1 A1 /vsib")]
        vpscatterqq_vm64x_k1_xmm = 4407,

        /// <summary>
        /// vpscatterqq vm64x, xmm | EVEX.128.66.0F38.W1 A1 /vsib | Using signed qword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqq vm64x, xmm","EVEX.128.66.0F38.W1 A1 /vsib")]
        vpscatterqq_vm64x_xmm = 4408,

        /// <summary>
        /// vpscatterqq vm64y {k1}, ymm | EVEX.256.66.0F38.W1 A1 /vsib | Using signed qword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqq vm64y {k1}, ymm","EVEX.256.66.0F38.W1 A1 /vsib")]
        vpscatterqq_vm64y_k1_ymm = 4409,

        /// <summary>
        /// vpscatterqq vm64y, ymm | EVEX.256.66.0F38.W1 A1 /vsib | Using signed qword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqq vm64y, ymm","EVEX.256.66.0F38.W1 A1 /vsib")]
        vpscatterqq_vm64y_ymm = 4410,

        /// <summary>
        /// vpscatterqq vm64z {k1}, zmm | EVEX.512.66.0F38.W1 A1 /vsib | Using signed qword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqq vm64z {k1}, zmm","EVEX.512.66.0F38.W1 A1 /vsib")]
        vpscatterqq_vm64z_k1_zmm = 4411,

        /// <summary>
        /// vpscatterqq vm64z, zmm | EVEX.512.66.0F38.W1 A1 /vsib | Using signed qword indices, scatter qword values to memory using writemask k1.
        /// </summary>
        [Symbol("vpscatterqq vm64z, zmm","EVEX.512.66.0F38.W1 A1 /vsib")]
        vpscatterqq_vm64z_zmm = 4412,

        /// <summary>
        /// vpshufb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.WIG 00 /r | Shuffle bytes in xmm2 according to contents of xmm3/m128 under write mask k1.
        /// </summary>
        [Symbol("vpshufb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.WIG 00 /r")]
        vpshufb_xmm_k1z_xmm_m128 = 4413,

        /// <summary>
        /// vpshufb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.WIG 00 /r | Shuffle bytes in xmm2 according to contents of xmm3/m128 under write mask k1.
        /// </summary>
        [Symbol("vpshufb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.WIG 00 /r")]
        vpshufb_xmm_k1z_xmm_r8 = 4414,

        /// <summary>
        /// vpshufb xmm, xmm, m128 | EVEX.128.66.0F38.WIG 00 /r | Shuffle bytes in xmm2 according to contents of xmm3/m128 under write mask k1.
        /// </summary>
        [Symbol("vpshufb xmm, xmm, m128","EVEX.128.66.0F38.WIG 00 /r")]
        vpshufb_xmm_xmm_m128 = 4415,

        /// <summary>
        /// vpshufb xmm, xmm, m128 | VEX.128.66.0F38.WIG 00 /r | Shuffle bytes in xmm2 according to contents of xmm3/m128.
        /// </summary>
        [Symbol("vpshufb xmm, xmm, m128","VEX.128.66.0F38.WIG 00 /r")]
        vpshufb_xmm_xmm_m128_vex = 4416,

        /// <summary>
        /// vpshufb xmm, xmm, r8 | EVEX.128.66.0F38.WIG 00 /r | Shuffle bytes in xmm2 according to contents of xmm3/m128 under write mask k1.
        /// </summary>
        [Symbol("vpshufb xmm, xmm, r8","EVEX.128.66.0F38.WIG 00 /r")]
        vpshufb_xmm_xmm_r8 = 4417,

        /// <summary>
        /// vpshufb xmm, xmm, r8 | VEX.128.66.0F38.WIG 00 /r | Shuffle bytes in xmm2 according to contents of xmm3/m128.
        /// </summary>
        [Symbol("vpshufb xmm, xmm, r8","VEX.128.66.0F38.WIG 00 /r")]
        vpshufb_xmm_xmm_r8_vex = 4418,

        /// <summary>
        /// vpshufb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.WIG 00 /r | Shuffle bytes in ymm2 according to contents of ymm3/m256 under write mask k1.
        /// </summary>
        [Symbol("vpshufb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.WIG 00 /r")]
        vpshufb_ymm_k1z_ymm_m256 = 4419,

        /// <summary>
        /// vpshufb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.WIG 00 /r | Shuffle bytes in ymm2 according to contents of ymm3/m256 under write mask k1.
        /// </summary>
        [Symbol("vpshufb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.WIG 00 /r")]
        vpshufb_ymm_k1z_ymm_r16 = 4420,

        /// <summary>
        /// vpshufb ymm, ymm, m256 | EVEX.256.66.0F38.WIG 00 /r | Shuffle bytes in ymm2 according to contents of ymm3/m256 under write mask k1.
        /// </summary>
        [Symbol("vpshufb ymm, ymm, m256","EVEX.256.66.0F38.WIG 00 /r")]
        vpshufb_ymm_ymm_m256 = 4421,

        /// <summary>
        /// vpshufb ymm, ymm, m256 | VEX.256.66.0F38.WIG 00 /r | Shuffle bytes in ymm2 according to contents of ymm3/m256.
        /// </summary>
        [Symbol("vpshufb ymm, ymm, m256","VEX.256.66.0F38.WIG 00 /r")]
        vpshufb_ymm_ymm_m256_vex = 4422,

        /// <summary>
        /// vpshufb ymm, ymm, r16 | EVEX.256.66.0F38.WIG 00 /r | Shuffle bytes in ymm2 according to contents of ymm3/m256 under write mask k1.
        /// </summary>
        [Symbol("vpshufb ymm, ymm, r16","EVEX.256.66.0F38.WIG 00 /r")]
        vpshufb_ymm_ymm_r16 = 4423,

        /// <summary>
        /// vpshufb ymm, ymm, r16 | VEX.256.66.0F38.WIG 00 /r | Shuffle bytes in ymm2 according to contents of ymm3/m256.
        /// </summary>
        [Symbol("vpshufb ymm, ymm, r16","VEX.256.66.0F38.WIG 00 /r")]
        vpshufb_ymm_ymm_r16_vex = 4424,

        /// <summary>
        /// vpshufb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.WIG 00 /r | Shuffle bytes in zmm2 according to contents of zmm3/m512 under write mask k1.
        /// </summary>
        [Symbol("vpshufb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.WIG 00 /r")]
        vpshufb_zmm_k1z_zmm_m512 = 4425,

        /// <summary>
        /// vpshufb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.WIG 00 /r | Shuffle bytes in zmm2 according to contents of zmm3/m512 under write mask k1.
        /// </summary>
        [Symbol("vpshufb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.WIG 00 /r")]
        vpshufb_zmm_k1z_zmm_r32 = 4426,

        /// <summary>
        /// vpshufb zmm, zmm, m512 | EVEX.512.66.0F38.WIG 00 /r | Shuffle bytes in zmm2 according to contents of zmm3/m512 under write mask k1.
        /// </summary>
        [Symbol("vpshufb zmm, zmm, m512","EVEX.512.66.0F38.WIG 00 /r")]
        vpshufb_zmm_zmm_m512 = 4427,

        /// <summary>
        /// vpshufb zmm, zmm, r32 | EVEX.512.66.0F38.WIG 00 /r | Shuffle bytes in zmm2 according to contents of zmm3/m512 under write mask k1.
        /// </summary>
        [Symbol("vpshufb zmm, zmm, r32","EVEX.512.66.0F38.WIG 00 /r")]
        vpshufb_zmm_zmm_r32 = 4428,

        /// <summary>
        /// vpshufd xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W0 70 /r ib | Shuffle the doublewords in xmm2/m128/m32bcst based on the encoding in imm8 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W0 70 /r ib")]
        vpshufd_xmm_k1z_m128_imm8 = 4429,

        /// <summary>
        /// vpshufd xmm {k1}{z}, m32bcst, imm8 | EVEX.128.66.0F.W0 70 /r ib | Shuffle the doublewords in xmm2/m128/m32bcst based on the encoding in imm8 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd xmm {k1}{z}, m32bcst, imm8","EVEX.128.66.0F.W0 70 /r ib")]
        vpshufd_xmm_k1z_m32bcst_imm8 = 4430,

        /// <summary>
        /// vpshufd xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W0 70 /r ib | Shuffle the doublewords in xmm2/m128/m32bcst based on the encoding in imm8 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W0 70 /r ib")]
        vpshufd_xmm_k1z_xmm_imm8 = 4431,

        /// <summary>
        /// vpshufd xmm, m128, imm8 | EVEX.128.66.0F.W0 70 /r ib | Shuffle the doublewords in xmm2/m128/m32bcst based on the encoding in imm8 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd xmm, m128, imm8","EVEX.128.66.0F.W0 70 /r ib")]
        vpshufd_xmm_m128_imm8 = 4432,

        /// <summary>
        /// vpshufd xmm, m128, imm8 | VEX.128.66.0F.WIG 70 /r ib | Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
        /// </summary>
        [Symbol("vpshufd xmm, m128, imm8","VEX.128.66.0F.WIG 70 /r ib")]
        vpshufd_xmm_m128_imm8_vex = 4433,

        /// <summary>
        /// vpshufd xmm, m32bcst, imm8 | EVEX.128.66.0F.W0 70 /r ib | Shuffle the doublewords in xmm2/m128/m32bcst based on the encoding in imm8 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd xmm, m32bcst, imm8","EVEX.128.66.0F.W0 70 /r ib")]
        vpshufd_xmm_m32bcst_imm8 = 4434,

        /// <summary>
        /// vpshufd xmm, r8, imm8 | VEX.128.66.0F.WIG 70 /r ib | Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
        /// </summary>
        [Symbol("vpshufd xmm, r8, imm8","VEX.128.66.0F.WIG 70 /r ib")]
        vpshufd_xmm_r8_imm8 = 4435,

        /// <summary>
        /// vpshufd xmm, xmm, imm8 | EVEX.128.66.0F.W0 70 /r ib | Shuffle the doublewords in xmm2/m128/m32bcst based on the encoding in imm8 and store the result in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd xmm, xmm, imm8","EVEX.128.66.0F.W0 70 /r ib")]
        vpshufd_xmm_xmm_imm8 = 4436,

        /// <summary>
        /// vpshufd ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W0 70 /r ib | Shuffle the doublewords in ymm2/m256/m32bcst based on the encoding in imm8 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W0 70 /r ib")]
        vpshufd_ymm_k1z_m256_imm8 = 4437,

        /// <summary>
        /// vpshufd ymm {k1}{z}, m32bcst, imm8 | EVEX.256.66.0F.W0 70 /r ib | Shuffle the doublewords in ymm2/m256/m32bcst based on the encoding in imm8 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd ymm {k1}{z}, m32bcst, imm8","EVEX.256.66.0F.W0 70 /r ib")]
        vpshufd_ymm_k1z_m32bcst_imm8 = 4438,

        /// <summary>
        /// vpshufd ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W0 70 /r ib | Shuffle the doublewords in ymm2/m256/m32bcst based on the encoding in imm8 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W0 70 /r ib")]
        vpshufd_ymm_k1z_ymm_imm8 = 4439,

        /// <summary>
        /// vpshufd ymm, m256, imm8 | EVEX.256.66.0F.W0 70 /r ib | Shuffle the doublewords in ymm2/m256/m32bcst based on the encoding in imm8 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd ymm, m256, imm8","EVEX.256.66.0F.W0 70 /r ib")]
        vpshufd_ymm_m256_imm8 = 4440,

        /// <summary>
        /// vpshufd ymm, m256, imm8 | VEX.256.66.0F.WIG 70 /r ib | Shuffle the doublewords in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpshufd ymm, m256, imm8","VEX.256.66.0F.WIG 70 /r ib")]
        vpshufd_ymm_m256_imm8_vex = 4441,

        /// <summary>
        /// vpshufd ymm, m32bcst, imm8 | EVEX.256.66.0F.W0 70 /r ib | Shuffle the doublewords in ymm2/m256/m32bcst based on the encoding in imm8 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd ymm, m32bcst, imm8","EVEX.256.66.0F.W0 70 /r ib")]
        vpshufd_ymm_m32bcst_imm8 = 4442,

        /// <summary>
        /// vpshufd ymm, r16, imm8 | VEX.256.66.0F.WIG 70 /r ib | Shuffle the doublewords in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpshufd ymm, r16, imm8","VEX.256.66.0F.WIG 70 /r ib")]
        vpshufd_ymm_r16_imm8 = 4443,

        /// <summary>
        /// vpshufd ymm, ymm, imm8 | EVEX.256.66.0F.W0 70 /r ib | Shuffle the doublewords in ymm2/m256/m32bcst based on the encoding in imm8 and store the result in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd ymm, ymm, imm8","EVEX.256.66.0F.W0 70 /r ib")]
        vpshufd_ymm_ymm_imm8 = 4444,

        /// <summary>
        /// vpshufd zmm {k1}{z}, m32bcst, imm8 | EVEX.512.66.0F.W0 70 /r ib | Shuffle the doublewords in zmm2/m512/m32bcst based on the encoding in imm8 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd zmm {k1}{z}, m32bcst, imm8","EVEX.512.66.0F.W0 70 /r ib")]
        vpshufd_zmm_k1z_m32bcst_imm8 = 4445,

        /// <summary>
        /// vpshufd zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W0 70 /r ib | Shuffle the doublewords in zmm2/m512/m32bcst based on the encoding in imm8 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W0 70 /r ib")]
        vpshufd_zmm_k1z_m512_imm8 = 4446,

        /// <summary>
        /// vpshufd zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W0 70 /r ib | Shuffle the doublewords in zmm2/m512/m32bcst based on the encoding in imm8 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W0 70 /r ib")]
        vpshufd_zmm_k1z_zmm_imm8 = 4447,

        /// <summary>
        /// vpshufd zmm, m32bcst, imm8 | EVEX.512.66.0F.W0 70 /r ib | Shuffle the doublewords in zmm2/m512/m32bcst based on the encoding in imm8 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd zmm, m32bcst, imm8","EVEX.512.66.0F.W0 70 /r ib")]
        vpshufd_zmm_m32bcst_imm8 = 4448,

        /// <summary>
        /// vpshufd zmm, m512, imm8 | EVEX.512.66.0F.W0 70 /r ib | Shuffle the doublewords in zmm2/m512/m32bcst based on the encoding in imm8 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd zmm, m512, imm8","EVEX.512.66.0F.W0 70 /r ib")]
        vpshufd_zmm_m512_imm8 = 4449,

        /// <summary>
        /// vpshufd zmm, zmm, imm8 | EVEX.512.66.0F.W0 70 /r ib | Shuffle the doublewords in zmm2/m512/m32bcst based on the encoding in imm8 and store the result in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpshufd zmm, zmm, imm8","EVEX.512.66.0F.W0 70 /r ib")]
        vpshufd_zmm_zmm_imm8 = 4450,

        /// <summary>
        /// vpshuflw xmm {k1}{z}, m128, imm8 | EVEX.128.F2.0F.WIG 70 /r ib | Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw xmm {k1}{z}, m128, imm8","EVEX.128.F2.0F.WIG 70 /r ib")]
        vpshuflw_xmm_k1z_m128_imm8 = 4451,

        /// <summary>
        /// vpshuflw xmm {k1}{z}, r8, imm8 | EVEX.128.F2.0F.WIG 70 /r ib | Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw xmm {k1}{z}, r8, imm8","EVEX.128.F2.0F.WIG 70 /r ib")]
        vpshuflw_xmm_k1z_r8_imm8 = 4452,

        /// <summary>
        /// vpshuflw xmm, m128, imm8 | EVEX.128.F2.0F.WIG 70 /r ib | Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw xmm, m128, imm8","EVEX.128.F2.0F.WIG 70 /r ib")]
        vpshuflw_xmm_m128_imm8 = 4453,

        /// <summary>
        /// vpshuflw xmm, m128, imm8 | VEX.128.F2.0F.WIG 70 /r ib | Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
        /// </summary>
        [Symbol("vpshuflw xmm, m128, imm8","VEX.128.F2.0F.WIG 70 /r ib")]
        vpshuflw_xmm_m128_imm8_vex = 4454,

        /// <summary>
        /// vpshuflw xmm, r8, imm8 | EVEX.128.F2.0F.WIG 70 /r ib | Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw xmm, r8, imm8","EVEX.128.F2.0F.WIG 70 /r ib")]
        vpshuflw_xmm_r8_imm8 = 4455,

        /// <summary>
        /// vpshuflw xmm, r8, imm8 | VEX.128.F2.0F.WIG 70 /r ib | Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1.
        /// </summary>
        [Symbol("vpshuflw xmm, r8, imm8","VEX.128.F2.0F.WIG 70 /r ib")]
        vpshuflw_xmm_r8_imm8_vex = 4456,

        /// <summary>
        /// vpshuflw ymm {k1}{z}, m256, imm8 | EVEX.256.F2.0F.WIG 70 /r ib | Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw ymm {k1}{z}, m256, imm8","EVEX.256.F2.0F.WIG 70 /r ib")]
        vpshuflw_ymm_k1z_m256_imm8 = 4457,

        /// <summary>
        /// vpshuflw ymm {k1}{z}, r16, imm8 | EVEX.256.F2.0F.WIG 70 /r ib | Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw ymm {k1}{z}, r16, imm8","EVEX.256.F2.0F.WIG 70 /r ib")]
        vpshuflw_ymm_k1z_r16_imm8 = 4458,

        /// <summary>
        /// vpshuflw ymm, m256, imm8 | EVEX.256.F2.0F.WIG 70 /r ib | Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw ymm, m256, imm8","EVEX.256.F2.0F.WIG 70 /r ib")]
        vpshuflw_ymm_m256_imm8 = 4459,

        /// <summary>
        /// vpshuflw ymm, m256, imm8 | VEX.256.F2.0F.WIG 70 /r ib | Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpshuflw ymm, m256, imm8","VEX.256.F2.0F.WIG 70 /r ib")]
        vpshuflw_ymm_m256_imm8_vex = 4460,

        /// <summary>
        /// vpshuflw ymm, r16, imm8 | EVEX.256.F2.0F.WIG 70 /r ib | Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw ymm, r16, imm8","EVEX.256.F2.0F.WIG 70 /r ib")]
        vpshuflw_ymm_r16_imm8 = 4461,

        /// <summary>
        /// vpshuflw ymm, r16, imm8 | VEX.256.F2.0F.WIG 70 /r ib | Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1.
        /// </summary>
        [Symbol("vpshuflw ymm, r16, imm8","VEX.256.F2.0F.WIG 70 /r ib")]
        vpshuflw_ymm_r16_imm8_vex = 4462,

        /// <summary>
        /// vpshuflw zmm {k1}{z}, m512, imm8 | EVEX.512.F2.0F.WIG 70 /r ib | Shuffle the low words in zmm2/m512 based on the encoding in imm8 and store the result in zmm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw zmm {k1}{z}, m512, imm8","EVEX.512.F2.0F.WIG 70 /r ib")]
        vpshuflw_zmm_k1z_m512_imm8 = 4463,

        /// <summary>
        /// vpshuflw zmm {k1}{z}, r32, imm8 | EVEX.512.F2.0F.WIG 70 /r ib | Shuffle the low words in zmm2/m512 based on the encoding in imm8 and store the result in zmm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw zmm {k1}{z}, r32, imm8","EVEX.512.F2.0F.WIG 70 /r ib")]
        vpshuflw_zmm_k1z_r32_imm8 = 4464,

        /// <summary>
        /// vpshuflw zmm, m512, imm8 | EVEX.512.F2.0F.WIG 70 /r ib | Shuffle the low words in zmm2/m512 based on the encoding in imm8 and store the result in zmm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw zmm, m512, imm8","EVEX.512.F2.0F.WIG 70 /r ib")]
        vpshuflw_zmm_m512_imm8 = 4465,

        /// <summary>
        /// vpshuflw zmm, r32, imm8 | EVEX.512.F2.0F.WIG 70 /r ib | Shuffle the low words in zmm2/m512 based on the encoding in imm8 and store the result in zmm1 under write mask k1.
        /// </summary>
        [Symbol("vpshuflw zmm, r32, imm8","EVEX.512.F2.0F.WIG 70 /r ib")]
        vpshuflw_zmm_r32_imm8 = 4466,

        /// <summary>
        /// vpsignb xmm, xmm, m128 | VEX.128.66.0F38.WIG 08 /r | Negate/zero/preserve packed byte integers in xmm2 depending on the corresponding sign in xmm3/m128.
        /// </summary>
        [Symbol("vpsignb xmm, xmm, m128","VEX.128.66.0F38.WIG 08 /r")]
        vpsignb_xmm_xmm_m128 = 4467,

        /// <summary>
        /// vpsignb xmm, xmm, r8 | VEX.128.66.0F38.WIG 08 /r | Negate/zero/preserve packed byte integers in xmm2 depending on the corresponding sign in xmm3/m128.
        /// </summary>
        [Symbol("vpsignb xmm, xmm, r8","VEX.128.66.0F38.WIG 08 /r")]
        vpsignb_xmm_xmm_r8 = 4468,

        /// <summary>
        /// vpsignb ymm, ymm, m256 | VEX.256.66.0F38.WIG 08 /r | Negate packed byte integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero.
        /// </summary>
        [Symbol("vpsignb ymm, ymm, m256","VEX.256.66.0F38.WIG 08 /r")]
        vpsignb_ymm_ymm_m256 = 4469,

        /// <summary>
        /// vpsignb ymm, ymm, r16 | VEX.256.66.0F38.WIG 08 /r | Negate packed byte integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero.
        /// </summary>
        [Symbol("vpsignb ymm, ymm, r16","VEX.256.66.0F38.WIG 08 /r")]
        vpsignb_ymm_ymm_r16 = 4470,

        /// <summary>
        /// vpsignd xmm, xmm, m128 | VEX.128.66.0F38.WIG 0A /r | Negate/zero/preserve packed doubleword integers in xmm2 depending on the corresponding sign in xmm3/m128.
        /// </summary>
        [Symbol("vpsignd xmm, xmm, m128","VEX.128.66.0F38.WIG 0A /r")]
        vpsignd_xmm_xmm_m128 = 4471,

        /// <summary>
        /// vpsignd xmm, xmm, r8 | VEX.128.66.0F38.WIG 0A /r | Negate/zero/preserve packed doubleword integers in xmm2 depending on the corresponding sign in xmm3/m128.
        /// </summary>
        [Symbol("vpsignd xmm, xmm, r8","VEX.128.66.0F38.WIG 0A /r")]
        vpsignd_xmm_xmm_r8 = 4472,

        /// <summary>
        /// vpsignd ymm, ymm, m256 | VEX.256.66.0F38.WIG 0A /r | Negate packed doubleword integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero.
        /// </summary>
        [Symbol("vpsignd ymm, ymm, m256","VEX.256.66.0F38.WIG 0A /r")]
        vpsignd_ymm_ymm_m256 = 4473,

        /// <summary>
        /// vpsignd ymm, ymm, r16 | VEX.256.66.0F38.WIG 0A /r | Negate packed doubleword integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero.
        /// </summary>
        [Symbol("vpsignd ymm, ymm, r16","VEX.256.66.0F38.WIG 0A /r")]
        vpsignd_ymm_ymm_r16 = 4474,

        /// <summary>
        /// vpsignw xmm, xmm, m128 | VEX.128.66.0F38.WIG 09 /r | Negate/zero/preserve packed word integers in xmm2 depending on the corresponding sign in xmm3/m128.
        /// </summary>
        [Symbol("vpsignw xmm, xmm, m128","VEX.128.66.0F38.WIG 09 /r")]
        vpsignw_xmm_xmm_m128 = 4475,

        /// <summary>
        /// vpsignw xmm, xmm, r8 | VEX.128.66.0F38.WIG 09 /r | Negate/zero/preserve packed word integers in xmm2 depending on the corresponding sign in xmm3/m128.
        /// </summary>
        [Symbol("vpsignw xmm, xmm, r8","VEX.128.66.0F38.WIG 09 /r")]
        vpsignw_xmm_xmm_r8 = 4476,

        /// <summary>
        /// vpsignw ymm, ymm, m256 | VEX.256.66.0F38.WIG 09 /r | Negate packed 16-bit integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero.
        /// </summary>
        [Symbol("vpsignw ymm, ymm, m256","VEX.256.66.0F38.WIG 09 /r")]
        vpsignw_ymm_ymm_m256 = 4477,

        /// <summary>
        /// vpsignw ymm, ymm, r16 | VEX.256.66.0F38.WIG 09 /r | Negate packed 16-bit integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero.
        /// </summary>
        [Symbol("vpsignw ymm, ymm, r16","VEX.256.66.0F38.WIG 09 /r")]
        vpsignw_ymm_ymm_r16 = 4478,

        /// <summary>
        /// vpslld xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W0 72 /6 ib | Shift doublewords in xmm2/m128/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W0 72 /6 ib")]
        vpslld_xmm_k1z_m128_imm8 = 4479,

        /// <summary>
        /// vpslld xmm {k1}{z}, m32bcst, imm8 | EVEX.128.66.0F.W0 72 /6 ib | Shift doublewords in xmm2/m128/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld xmm {k1}{z}, m32bcst, imm8","EVEX.128.66.0F.W0 72 /6 ib")]
        vpslld_xmm_k1z_m32bcst_imm8 = 4480,

        /// <summary>
        /// vpslld xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W0 72 /6 ib | Shift doublewords in xmm2/m128/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W0 72 /6 ib")]
        vpslld_xmm_k1z_xmm_imm8 = 4481,

        /// <summary>
        /// vpslld xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 F2 /r | Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 F2 /r")]
        vpslld_xmm_k1z_xmm_m128 = 4482,

        /// <summary>
        /// vpslld xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.W0 F2 /r | Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.W0 F2 /r")]
        vpslld_xmm_k1z_xmm_r8 = 4483,

        /// <summary>
        /// vpslld xmm, m128, imm8 | EVEX.128.66.0F.W0 72 /6 ib | Shift doublewords in xmm2/m128/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld xmm, m128, imm8","EVEX.128.66.0F.W0 72 /6 ib")]
        vpslld_xmm_m128_imm8 = 4484,

        /// <summary>
        /// vpslld xmm, m32bcst, imm8 | EVEX.128.66.0F.W0 72 /6 ib | Shift doublewords in xmm2/m128/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld xmm, m32bcst, imm8","EVEX.128.66.0F.W0 72 /6 ib")]
        vpslld_xmm_m32bcst_imm8 = 4485,

        /// <summary>
        /// vpslld xmm, xmm, imm8 | EVEX.128.66.0F.W0 72 /6 ib | Shift doublewords in xmm2/m128/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld xmm, xmm, imm8","EVEX.128.66.0F.W0 72 /6 ib")]
        vpslld_xmm_xmm_imm8 = 4486,

        /// <summary>
        /// vpslld xmm, xmm, imm8 | VEX.128.66.0F.WIG 72 /6 ib | Shift doublewords in xmm2 left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpslld xmm, xmm, imm8","VEX.128.66.0F.WIG 72 /6 ib")]
        vpslld_xmm_xmm_imm8_vex = 4487,

        /// <summary>
        /// vpslld xmm, xmm, m128 | EVEX.128.66.0F.W0 F2 /r | Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld xmm, xmm, m128","EVEX.128.66.0F.W0 F2 /r")]
        vpslld_xmm_xmm_m128 = 4488,

        /// <summary>
        /// vpslld xmm, xmm, m128 | VEX.128.66.0F.WIG F2 /r | Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpslld xmm, xmm, m128","VEX.128.66.0F.WIG F2 /r")]
        vpslld_xmm_xmm_m128_vex = 4489,

        /// <summary>
        /// vpslld xmm, xmm, r8 | EVEX.128.66.0F.W0 F2 /r | Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld xmm, xmm, r8","EVEX.128.66.0F.W0 F2 /r")]
        vpslld_xmm_xmm_r8 = 4490,

        /// <summary>
        /// vpslld xmm, xmm, r8 | VEX.128.66.0F.WIG F2 /r | Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpslld xmm, xmm, r8","VEX.128.66.0F.WIG F2 /r")]
        vpslld_xmm_xmm_r8_vex = 4491,

        /// <summary>
        /// vpslld ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W0 72 /6 ib | Shift doublewords in ymm2/m256/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W0 72 /6 ib")]
        vpslld_ymm_k1z_m256_imm8 = 4492,

        /// <summary>
        /// vpslld ymm {k1}{z}, m32bcst, imm8 | EVEX.256.66.0F.W0 72 /6 ib | Shift doublewords in ymm2/m256/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld ymm {k1}{z}, m32bcst, imm8","EVEX.256.66.0F.W0 72 /6 ib")]
        vpslld_ymm_k1z_m32bcst_imm8 = 4493,

        /// <summary>
        /// vpslld ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W0 72 /6 ib | Shift doublewords in ymm2/m256/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W0 72 /6 ib")]
        vpslld_ymm_k1z_ymm_imm8 = 4494,

        /// <summary>
        /// vpslld ymm {k1}{z}, ymm, m128 | EVEX.256.66.0F.W0 F2 /r | Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld ymm {k1}{z}, ymm, m128","EVEX.256.66.0F.W0 F2 /r")]
        vpslld_ymm_k1z_ymm_m128 = 4495,

        /// <summary>
        /// vpslld ymm {k1}{z}, ymm, r8 | EVEX.256.66.0F.W0 F2 /r | Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld ymm {k1}{z}, ymm, r8","EVEX.256.66.0F.W0 F2 /r")]
        vpslld_ymm_k1z_ymm_r8 = 4496,

        /// <summary>
        /// vpslld ymm, m256, imm8 | EVEX.256.66.0F.W0 72 /6 ib | Shift doublewords in ymm2/m256/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld ymm, m256, imm8","EVEX.256.66.0F.W0 72 /6 ib")]
        vpslld_ymm_m256_imm8 = 4497,

        /// <summary>
        /// vpslld ymm, m32bcst, imm8 | EVEX.256.66.0F.W0 72 /6 ib | Shift doublewords in ymm2/m256/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld ymm, m32bcst, imm8","EVEX.256.66.0F.W0 72 /6 ib")]
        vpslld_ymm_m32bcst_imm8 = 4498,

        /// <summary>
        /// vpslld ymm, ymm, imm8 | EVEX.256.66.0F.W0 72 /6 ib | Shift doublewords in ymm2/m256/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld ymm, ymm, imm8","EVEX.256.66.0F.W0 72 /6 ib")]
        vpslld_ymm_ymm_imm8 = 4499,

        /// <summary>
        /// vpslld ymm, ymm, imm8 | VEX.256.66.0F.WIG 72 /6 ib | Shift doublewords in ymm2 left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpslld ymm, ymm, imm8","VEX.256.66.0F.WIG 72 /6 ib")]
        vpslld_ymm_ymm_imm8_vex = 4500,

        /// <summary>
        /// vpslld ymm, ymm, m128 | EVEX.256.66.0F.W0 F2 /r | Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld ymm, ymm, m128","EVEX.256.66.0F.W0 F2 /r")]
        vpslld_ymm_ymm_m128 = 4501,

        /// <summary>
        /// vpslld ymm, ymm, m128 | VEX.256.66.0F.WIG F2 /r | Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpslld ymm, ymm, m128","VEX.256.66.0F.WIG F2 /r")]
        vpslld_ymm_ymm_m128_vex = 4502,

        /// <summary>
        /// vpslld ymm, ymm, r8 | EVEX.256.66.0F.W0 F2 /r | Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld ymm, ymm, r8","EVEX.256.66.0F.W0 F2 /r")]
        vpslld_ymm_ymm_r8 = 4503,

        /// <summary>
        /// vpslld ymm, ymm, r8 | VEX.256.66.0F.WIG F2 /r | Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpslld ymm, ymm, r8","VEX.256.66.0F.WIG F2 /r")]
        vpslld_ymm_ymm_r8_vex = 4504,

        /// <summary>
        /// vpslld zmm {k1}{z}, m32bcst, imm8 | EVEX.512.66.0F.W0 72 /6 ib | Shift doublewords in zmm2/m512/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld zmm {k1}{z}, m32bcst, imm8","EVEX.512.66.0F.W0 72 /6 ib")]
        vpslld_zmm_k1z_m32bcst_imm8 = 4505,

        /// <summary>
        /// vpslld zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W0 72 /6 ib | Shift doublewords in zmm2/m512/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W0 72 /6 ib")]
        vpslld_zmm_k1z_m512_imm8 = 4506,

        /// <summary>
        /// vpslld zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W0 72 /6 ib | Shift doublewords in zmm2/m512/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W0 72 /6 ib")]
        vpslld_zmm_k1z_zmm_imm8 = 4507,

        /// <summary>
        /// vpslld zmm {k1}{z}, zmm, m128 | EVEX.512.66.0F.W0 F2 /r | Shift doublewords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld zmm {k1}{z}, zmm, m128","EVEX.512.66.0F.W0 F2 /r")]
        vpslld_zmm_k1z_zmm_m128 = 4508,

        /// <summary>
        /// vpslld zmm {k1}{z}, zmm, r8 | EVEX.512.66.0F.W0 F2 /r | Shift doublewords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld zmm {k1}{z}, zmm, r8","EVEX.512.66.0F.W0 F2 /r")]
        vpslld_zmm_k1z_zmm_r8 = 4509,

        /// <summary>
        /// vpslld zmm, m32bcst, imm8 | EVEX.512.66.0F.W0 72 /6 ib | Shift doublewords in zmm2/m512/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld zmm, m32bcst, imm8","EVEX.512.66.0F.W0 72 /6 ib")]
        vpslld_zmm_m32bcst_imm8 = 4510,

        /// <summary>
        /// vpslld zmm, m512, imm8 | EVEX.512.66.0F.W0 72 /6 ib | Shift doublewords in zmm2/m512/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld zmm, m512, imm8","EVEX.512.66.0F.W0 72 /6 ib")]
        vpslld_zmm_m512_imm8 = 4511,

        /// <summary>
        /// vpslld zmm, zmm, imm8 | EVEX.512.66.0F.W0 72 /6 ib | Shift doublewords in zmm2/m512/m32bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpslld zmm, zmm, imm8","EVEX.512.66.0F.W0 72 /6 ib")]
        vpslld_zmm_zmm_imm8 = 4512,

        /// <summary>
        /// vpslld zmm, zmm, m128 | EVEX.512.66.0F.W0 F2 /r | Shift doublewords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld zmm, zmm, m128","EVEX.512.66.0F.W0 F2 /r")]
        vpslld_zmm_zmm_m128 = 4513,

        /// <summary>
        /// vpslld zmm, zmm, r8 | EVEX.512.66.0F.W0 F2 /r | Shift doublewords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.
        /// </summary>
        [Symbol("vpslld zmm, zmm, r8","EVEX.512.66.0F.W0 F2 /r")]
        vpslld_zmm_zmm_r8 = 4514,

        /// <summary>
        /// vpslldq xmm, m128, imm8 | EVEX.128.66.0F.WIG 73 /7 ib | Shift xmm2/m128 left by imm8 bytes while shifting in 0s and store result in xmm1.
        /// </summary>
        [Symbol("vpslldq xmm, m128, imm8","EVEX.128.66.0F.WIG 73 /7 ib")]
        vpslldq_xmm_m128_imm8 = 4515,

        /// <summary>
        /// vpslldq xmm, r8, imm8 | EVEX.128.66.0F.WIG 73 /7 ib | Shift xmm2/m128 left by imm8 bytes while shifting in 0s and store result in xmm1.
        /// </summary>
        [Symbol("vpslldq xmm, r8, imm8","EVEX.128.66.0F.WIG 73 /7 ib")]
        vpslldq_xmm_r8_imm8 = 4516,

        /// <summary>
        /// vpslldq xmm, xmm, imm8 | VEX.128.66.0F.WIG 73 /7 ib | Shift xmm2 left by imm8 bytes while shifting in 0s and store result in xmm1.
        /// </summary>
        [Symbol("vpslldq xmm, xmm, imm8","VEX.128.66.0F.WIG 73 /7 ib")]
        vpslldq_xmm_xmm_imm8 = 4517,

        /// <summary>
        /// vpslldq ymm, m256, imm8 | EVEX.256.66.0F.WIG 73 /7 ib | Shift ymm2/m256 left by imm8 bytes while shifting in 0s and store result in ymm1.
        /// </summary>
        [Symbol("vpslldq ymm, m256, imm8","EVEX.256.66.0F.WIG 73 /7 ib")]
        vpslldq_ymm_m256_imm8 = 4518,

        /// <summary>
        /// vpslldq ymm, r16, imm8 | EVEX.256.66.0F.WIG 73 /7 ib | Shift ymm2/m256 left by imm8 bytes while shifting in 0s and store result in ymm1.
        /// </summary>
        [Symbol("vpslldq ymm, r16, imm8","EVEX.256.66.0F.WIG 73 /7 ib")]
        vpslldq_ymm_r16_imm8 = 4519,

        /// <summary>
        /// vpslldq ymm, ymm, imm8 | VEX.256.66.0F.WIG 73 /7 ib | Shift ymm2 left by imm8 bytes while shifting in 0s and store result in ymm1.
        /// </summary>
        [Symbol("vpslldq ymm, ymm, imm8","VEX.256.66.0F.WIG 73 /7 ib")]
        vpslldq_ymm_ymm_imm8 = 4520,

        /// <summary>
        /// vpslldq zmm, m512, imm8 | EVEX.512.66.0F.WIG 73 /7 ib | Shift zmm2/m512 left by imm8 bytes while shifting in 0s and store result in zmm1.
        /// </summary>
        [Symbol("vpslldq zmm, m512, imm8","EVEX.512.66.0F.WIG 73 /7 ib")]
        vpslldq_zmm_m512_imm8 = 4521,

        /// <summary>
        /// vpslldq zmm, r32, imm8 | EVEX.512.66.0F.WIG 73 /7 ib | Shift zmm2/m512 left by imm8 bytes while shifting in 0s and store result in zmm1.
        /// </summary>
        [Symbol("vpslldq zmm, r32, imm8","EVEX.512.66.0F.WIG 73 /7 ib")]
        vpslldq_zmm_r32_imm8 = 4522,

        /// <summary>
        /// vpsllq xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W1 73 /6 ib | Shift quadwords in xmm2/m128/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W1 73 /6 ib")]
        vpsllq_xmm_k1z_m128_imm8 = 4523,

        /// <summary>
        /// vpsllq xmm {k1}{z}, m64bcst, imm8 | EVEX.128.66.0F.W1 73 /6 ib | Shift quadwords in xmm2/m128/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq xmm {k1}{z}, m64bcst, imm8","EVEX.128.66.0F.W1 73 /6 ib")]
        vpsllq_xmm_k1z_m64bcst_imm8 = 4524,

        /// <summary>
        /// vpsllq xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W1 73 /6 ib | Shift quadwords in xmm2/m128/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W1 73 /6 ib")]
        vpsllq_xmm_k1z_xmm_imm8 = 4525,

        /// <summary>
        /// vpsllq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 F3 /r | Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 F3 /r")]
        vpsllq_xmm_k1z_xmm_m128 = 4526,

        /// <summary>
        /// vpsllq xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.W1 F3 /r | Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.W1 F3 /r")]
        vpsllq_xmm_k1z_xmm_r8 = 4527,

        /// <summary>
        /// vpsllq xmm, m128, imm8 | EVEX.128.66.0F.W1 73 /6 ib | Shift quadwords in xmm2/m128/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq xmm, m128, imm8","EVEX.128.66.0F.W1 73 /6 ib")]
        vpsllq_xmm_m128_imm8 = 4528,

        /// <summary>
        /// vpsllq xmm, m64bcst, imm8 | EVEX.128.66.0F.W1 73 /6 ib | Shift quadwords in xmm2/m128/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq xmm, m64bcst, imm8","EVEX.128.66.0F.W1 73 /6 ib")]
        vpsllq_xmm_m64bcst_imm8 = 4529,

        /// <summary>
        /// vpsllq xmm, xmm, imm8 | EVEX.128.66.0F.W1 73 /6 ib | Shift quadwords in xmm2/m128/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq xmm, xmm, imm8","EVEX.128.66.0F.W1 73 /6 ib")]
        vpsllq_xmm_xmm_imm8 = 4530,

        /// <summary>
        /// vpsllq xmm, xmm, imm8 | VEX.128.66.0F.WIG 73 /6 ib | Shift quadwords in xmm2 left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllq xmm, xmm, imm8","VEX.128.66.0F.WIG 73 /6 ib")]
        vpsllq_xmm_xmm_imm8_vex = 4531,

        /// <summary>
        /// vpsllq xmm, xmm, m128 | EVEX.128.66.0F.W1 F3 /r | Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq xmm, xmm, m128","EVEX.128.66.0F.W1 F3 /r")]
        vpsllq_xmm_xmm_m128 = 4532,

        /// <summary>
        /// vpsllq xmm, xmm, m128 | VEX.128.66.0F.WIG F3 /r | Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllq xmm, xmm, m128","VEX.128.66.0F.WIG F3 /r")]
        vpsllq_xmm_xmm_m128_vex = 4533,

        /// <summary>
        /// vpsllq xmm, xmm, r8 | EVEX.128.66.0F.W1 F3 /r | Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq xmm, xmm, r8","EVEX.128.66.0F.W1 F3 /r")]
        vpsllq_xmm_xmm_r8 = 4534,

        /// <summary>
        /// vpsllq xmm, xmm, r8 | VEX.128.66.0F.WIG F3 /r | Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllq xmm, xmm, r8","VEX.128.66.0F.WIG F3 /r")]
        vpsllq_xmm_xmm_r8_vex = 4535,

        /// <summary>
        /// vpsllq ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W1 73 /6 ib | Shift quadwords in ymm2/m256/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W1 73 /6 ib")]
        vpsllq_ymm_k1z_m256_imm8 = 4536,

        /// <summary>
        /// vpsllq ymm {k1}{z}, m64bcst, imm8 | EVEX.256.66.0F.W1 73 /6 ib | Shift quadwords in ymm2/m256/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq ymm {k1}{z}, m64bcst, imm8","EVEX.256.66.0F.W1 73 /6 ib")]
        vpsllq_ymm_k1z_m64bcst_imm8 = 4537,

        /// <summary>
        /// vpsllq ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W1 73 /6 ib | Shift quadwords in ymm2/m256/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W1 73 /6 ib")]
        vpsllq_ymm_k1z_ymm_imm8 = 4538,

        /// <summary>
        /// vpsllq ymm {k1}{z}, ymm, m128 | EVEX.256.66.0F.W1 F3 /r | Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq ymm {k1}{z}, ymm, m128","EVEX.256.66.0F.W1 F3 /r")]
        vpsllq_ymm_k1z_ymm_m128 = 4539,

        /// <summary>
        /// vpsllq ymm {k1}{z}, ymm, r8 | EVEX.256.66.0F.W1 F3 /r | Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq ymm {k1}{z}, ymm, r8","EVEX.256.66.0F.W1 F3 /r")]
        vpsllq_ymm_k1z_ymm_r8 = 4540,

        /// <summary>
        /// vpsllq ymm, m256, imm8 | EVEX.256.66.0F.W1 73 /6 ib | Shift quadwords in ymm2/m256/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq ymm, m256, imm8","EVEX.256.66.0F.W1 73 /6 ib")]
        vpsllq_ymm_m256_imm8 = 4541,

        /// <summary>
        /// vpsllq ymm, m64bcst, imm8 | EVEX.256.66.0F.W1 73 /6 ib | Shift quadwords in ymm2/m256/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq ymm, m64bcst, imm8","EVEX.256.66.0F.W1 73 /6 ib")]
        vpsllq_ymm_m64bcst_imm8 = 4542,

        /// <summary>
        /// vpsllq ymm, ymm, imm8 | EVEX.256.66.0F.W1 73 /6 ib | Shift quadwords in ymm2/m256/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq ymm, ymm, imm8","EVEX.256.66.0F.W1 73 /6 ib")]
        vpsllq_ymm_ymm_imm8 = 4543,

        /// <summary>
        /// vpsllq ymm, ymm, imm8 | VEX.256.66.0F.WIG 73 /6 ib | Shift quadwords in ymm2 left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllq ymm, ymm, imm8","VEX.256.66.0F.WIG 73 /6 ib")]
        vpsllq_ymm_ymm_imm8_vex = 4544,

        /// <summary>
        /// vpsllq ymm, ymm, m128 | EVEX.256.66.0F.W1 F3 /r | Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq ymm, ymm, m128","EVEX.256.66.0F.W1 F3 /r")]
        vpsllq_ymm_ymm_m128 = 4545,

        /// <summary>
        /// vpsllq ymm, ymm, m128 | VEX.256.66.0F.WIG F3 /r | Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllq ymm, ymm, m128","VEX.256.66.0F.WIG F3 /r")]
        vpsllq_ymm_ymm_m128_vex = 4546,

        /// <summary>
        /// vpsllq ymm, ymm, r8 | EVEX.256.66.0F.W1 F3 /r | Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq ymm, ymm, r8","EVEX.256.66.0F.W1 F3 /r")]
        vpsllq_ymm_ymm_r8 = 4547,

        /// <summary>
        /// vpsllq ymm, ymm, r8 | VEX.256.66.0F.WIG F3 /r | Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllq ymm, ymm, r8","VEX.256.66.0F.WIG F3 /r")]
        vpsllq_ymm_ymm_r8_vex = 4548,

        /// <summary>
        /// vpsllq zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W1 73 /6 ib | Shift quadwords in zmm2/m512/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W1 73 /6 ib")]
        vpsllq_zmm_k1z_m512_imm8 = 4549,

        /// <summary>
        /// vpsllq zmm {k1}{z}, m64bcst, imm8 | EVEX.512.66.0F.W1 73 /6 ib | Shift quadwords in zmm2/m512/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq zmm {k1}{z}, m64bcst, imm8","EVEX.512.66.0F.W1 73 /6 ib")]
        vpsllq_zmm_k1z_m64bcst_imm8 = 4550,

        /// <summary>
        /// vpsllq zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W1 73 /6 ib | Shift quadwords in zmm2/m512/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W1 73 /6 ib")]
        vpsllq_zmm_k1z_zmm_imm8 = 4551,

        /// <summary>
        /// vpsllq zmm {k1}{z}, zmm, m128 | EVEX.512.66.0F.W1 F3 /r | Shift quadwords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq zmm {k1}{z}, zmm, m128","EVEX.512.66.0F.W1 F3 /r")]
        vpsllq_zmm_k1z_zmm_m128 = 4552,

        /// <summary>
        /// vpsllq zmm {k1}{z}, zmm, r8 | EVEX.512.66.0F.W1 F3 /r | Shift quadwords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq zmm {k1}{z}, zmm, r8","EVEX.512.66.0F.W1 F3 /r")]
        vpsllq_zmm_k1z_zmm_r8 = 4553,

        /// <summary>
        /// vpsllq zmm, m512, imm8 | EVEX.512.66.0F.W1 73 /6 ib | Shift quadwords in zmm2/m512/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq zmm, m512, imm8","EVEX.512.66.0F.W1 73 /6 ib")]
        vpsllq_zmm_m512_imm8 = 4554,

        /// <summary>
        /// vpsllq zmm, m64bcst, imm8 | EVEX.512.66.0F.W1 73 /6 ib | Shift quadwords in zmm2/m512/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq zmm, m64bcst, imm8","EVEX.512.66.0F.W1 73 /6 ib")]
        vpsllq_zmm_m64bcst_imm8 = 4555,

        /// <summary>
        /// vpsllq zmm, zmm, imm8 | EVEX.512.66.0F.W1 73 /6 ib | Shift quadwords in zmm2/m512/m64bcst left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq zmm, zmm, imm8","EVEX.512.66.0F.W1 73 /6 ib")]
        vpsllq_zmm_zmm_imm8 = 4556,

        /// <summary>
        /// vpsllq zmm, zmm, m128 | EVEX.512.66.0F.W1 F3 /r | Shift quadwords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq zmm, zmm, m128","EVEX.512.66.0F.W1 F3 /r")]
        vpsllq_zmm_zmm_m128 = 4557,

        /// <summary>
        /// vpsllq zmm, zmm, r8 | EVEX.512.66.0F.W1 F3 /r | Shift quadwords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllq zmm, zmm, r8","EVEX.512.66.0F.W1 F3 /r")]
        vpsllq_zmm_zmm_r8 = 4558,

        /// <summary>
        /// vpsllvd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 47 /r | Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 47 /r")]
        vpsllvd_xmm_k1z_xmm_m128 = 4559,

        /// <summary>
        /// vpsllvd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 47 /r | Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 47 /r")]
        vpsllvd_xmm_k1z_xmm_m32bcst = 4560,

        /// <summary>
        /// vpsllvd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 47 /r | Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 47 /r")]
        vpsllvd_xmm_k1z_xmm_xmm = 4561,

        /// <summary>
        /// vpsllvd xmm, xmm, m128 | EVEX.128.66.0F38.W0 47 /r | Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd xmm, xmm, m128","EVEX.128.66.0F38.W0 47 /r")]
        vpsllvd_xmm_xmm_m128 = 4562,

        /// <summary>
        /// vpsllvd xmm, xmm, m128 | VEX.128.66.0F38.W0 47 /r | Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllvd xmm, xmm, m128","VEX.128.66.0F38.W0 47 /r")]
        vpsllvd_xmm_xmm_m128_vex = 4563,

        /// <summary>
        /// vpsllvd xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 47 /r | Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 47 /r")]
        vpsllvd_xmm_xmm_m32bcst = 4564,

        /// <summary>
        /// vpsllvd xmm, xmm, r8 | VEX.128.66.0F38.W0 47 /r | Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllvd xmm, xmm, r8","VEX.128.66.0F38.W0 47 /r")]
        vpsllvd_xmm_xmm_r8 = 4565,

        /// <summary>
        /// vpsllvd xmm, xmm, xmm | EVEX.128.66.0F38.W0 47 /r | Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd xmm, xmm, xmm","EVEX.128.66.0F38.W0 47 /r")]
        vpsllvd_xmm_xmm_xmm = 4566,

        /// <summary>
        /// vpsllvd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 47 /r | Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 47 /r")]
        vpsllvd_ymm_k1z_ymm_m256 = 4567,

        /// <summary>
        /// vpsllvd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 47 /r | Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 47 /r")]
        vpsllvd_ymm_k1z_ymm_m32bcst = 4568,

        /// <summary>
        /// vpsllvd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 47 /r | Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 47 /r")]
        vpsllvd_ymm_k1z_ymm_ymm = 4569,

        /// <summary>
        /// vpsllvd ymm, ymm, m256 | EVEX.256.66.0F38.W0 47 /r | Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd ymm, ymm, m256","EVEX.256.66.0F38.W0 47 /r")]
        vpsllvd_ymm_ymm_m256 = 4570,

        /// <summary>
        /// vpsllvd ymm, ymm, m256 | VEX.256.66.0F38.W0 47 /r | Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllvd ymm, ymm, m256","VEX.256.66.0F38.W0 47 /r")]
        vpsllvd_ymm_ymm_m256_vex = 4571,

        /// <summary>
        /// vpsllvd ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 47 /r | Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 47 /r")]
        vpsllvd_ymm_ymm_m32bcst = 4572,

        /// <summary>
        /// vpsllvd ymm, ymm, r16 | VEX.256.66.0F38.W0 47 /r | Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllvd ymm, ymm, r16","VEX.256.66.0F38.W0 47 /r")]
        vpsllvd_ymm_ymm_r16 = 4573,

        /// <summary>
        /// vpsllvd ymm, ymm, ymm | EVEX.256.66.0F38.W0 47 /r | Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd ymm, ymm, ymm","EVEX.256.66.0F38.W0 47 /r")]
        vpsllvd_ymm_ymm_ymm = 4574,

        /// <summary>
        /// vpsllvd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 47 /r | Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 47 /r")]
        vpsllvd_zmm_k1z_zmm_m32bcst = 4575,

        /// <summary>
        /// vpsllvd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 47 /r | Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 47 /r")]
        vpsllvd_zmm_k1z_zmm_m512 = 4576,

        /// <summary>
        /// vpsllvd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 47 /r | Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 47 /r")]
        vpsllvd_zmm_k1z_zmm_zmm = 4577,

        /// <summary>
        /// vpsllvd zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 47 /r | Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 47 /r")]
        vpsllvd_zmm_zmm_m32bcst = 4578,

        /// <summary>
        /// vpsllvd zmm, zmm, m512 | EVEX.512.66.0F38.W0 47 /r | Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd zmm, zmm, m512","EVEX.512.66.0F38.W0 47 /r")]
        vpsllvd_zmm_zmm_m512 = 4579,

        /// <summary>
        /// vpsllvd zmm, zmm, zmm | EVEX.512.66.0F38.W0 47 /r | Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvd zmm, zmm, zmm","EVEX.512.66.0F38.W0 47 /r")]
        vpsllvd_zmm_zmm_zmm = 4580,

        /// <summary>
        /// vpsllvq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 47 /r | Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 47 /r")]
        vpsllvq_xmm_k1z_xmm_m128 = 4581,

        /// <summary>
        /// vpsllvq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 47 /r | Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 47 /r")]
        vpsllvq_xmm_k1z_xmm_m64bcst = 4582,

        /// <summary>
        /// vpsllvq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 47 /r | Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 47 /r")]
        vpsllvq_xmm_k1z_xmm_xmm = 4583,

        /// <summary>
        /// vpsllvq xmm, xmm, m128 | EVEX.128.66.0F38.W1 47 /r | Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq xmm, xmm, m128","EVEX.128.66.0F38.W1 47 /r")]
        vpsllvq_xmm_xmm_m128 = 4584,

        /// <summary>
        /// vpsllvq xmm, xmm, m128 | VEX.128.66.0F38.W1 47 /r | Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllvq xmm, xmm, m128","VEX.128.66.0F38.W1 47 /r")]
        vpsllvq_xmm_xmm_m128_vex = 4585,

        /// <summary>
        /// vpsllvq xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 47 /r | Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 47 /r")]
        vpsllvq_xmm_xmm_m64bcst = 4586,

        /// <summary>
        /// vpsllvq xmm, xmm, r8 | VEX.128.66.0F38.W1 47 /r | Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllvq xmm, xmm, r8","VEX.128.66.0F38.W1 47 /r")]
        vpsllvq_xmm_xmm_r8 = 4587,

        /// <summary>
        /// vpsllvq xmm, xmm, xmm | EVEX.128.66.0F38.W1 47 /r | Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq xmm, xmm, xmm","EVEX.128.66.0F38.W1 47 /r")]
        vpsllvq_xmm_xmm_xmm = 4588,

        /// <summary>
        /// vpsllvq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 47 /r | Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 47 /r")]
        vpsllvq_ymm_k1z_ymm_m256 = 4589,

        /// <summary>
        /// vpsllvq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 47 /r | Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 47 /r")]
        vpsllvq_ymm_k1z_ymm_m64bcst = 4590,

        /// <summary>
        /// vpsllvq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 47 /r | Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 47 /r")]
        vpsllvq_ymm_k1z_ymm_ymm = 4591,

        /// <summary>
        /// vpsllvq ymm, ymm, m256 | EVEX.256.66.0F38.W1 47 /r | Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq ymm, ymm, m256","EVEX.256.66.0F38.W1 47 /r")]
        vpsllvq_ymm_ymm_m256 = 4592,

        /// <summary>
        /// vpsllvq ymm, ymm, m256 | VEX.256.66.0F38.W1 47 /r | Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllvq ymm, ymm, m256","VEX.256.66.0F38.W1 47 /r")]
        vpsllvq_ymm_ymm_m256_vex = 4593,

        /// <summary>
        /// vpsllvq ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 47 /r | Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 47 /r")]
        vpsllvq_ymm_ymm_m64bcst = 4594,

        /// <summary>
        /// vpsllvq ymm, ymm, r16 | VEX.256.66.0F38.W1 47 /r | Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllvq ymm, ymm, r16","VEX.256.66.0F38.W1 47 /r")]
        vpsllvq_ymm_ymm_r16 = 4595,

        /// <summary>
        /// vpsllvq ymm, ymm, ymm | EVEX.256.66.0F38.W1 47 /r | Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq ymm, ymm, ymm","EVEX.256.66.0F38.W1 47 /r")]
        vpsllvq_ymm_ymm_ymm = 4596,

        /// <summary>
        /// vpsllvq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 47 /r | Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 47 /r")]
        vpsllvq_zmm_k1z_zmm_m512 = 4597,

        /// <summary>
        /// vpsllvq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 47 /r | Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 47 /r")]
        vpsllvq_zmm_k1z_zmm_m64bcst = 4598,

        /// <summary>
        /// vpsllvq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 47 /r | Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 47 /r")]
        vpsllvq_zmm_k1z_zmm_zmm = 4599,

        /// <summary>
        /// vpsllvq zmm, zmm, m512 | EVEX.512.66.0F38.W1 47 /r | Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq zmm, zmm, m512","EVEX.512.66.0F38.W1 47 /r")]
        vpsllvq_zmm_zmm_m512 = 4600,

        /// <summary>
        /// vpsllvq zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 47 /r | Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 47 /r")]
        vpsllvq_zmm_zmm_m64bcst = 4601,

        /// <summary>
        /// vpsllvq zmm, zmm, zmm | EVEX.512.66.0F38.W1 47 /r | Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvq zmm, zmm, zmm","EVEX.512.66.0F38.W1 47 /r")]
        vpsllvq_zmm_zmm_zmm = 4602,

        /// <summary>
        /// vpsllvw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 12 /r | Shift words in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 12 /r")]
        vpsllvw_xmm_k1z_xmm_m128 = 4603,

        /// <summary>
        /// vpsllvw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.W1 12 /r | Shift words in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.W1 12 /r")]
        vpsllvw_xmm_k1z_xmm_r8 = 4604,

        /// <summary>
        /// vpsllvw xmm, xmm, m128 | EVEX.128.66.0F38.W1 12 /r | Shift words in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw xmm, xmm, m128","EVEX.128.66.0F38.W1 12 /r")]
        vpsllvw_xmm_xmm_m128 = 4605,

        /// <summary>
        /// vpsllvw xmm, xmm, r8 | EVEX.128.66.0F38.W1 12 /r | Shift words in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw xmm, xmm, r8","EVEX.128.66.0F38.W1 12 /r")]
        vpsllvw_xmm_xmm_r8 = 4606,

        /// <summary>
        /// vpsllvw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 12 /r | Shift words in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 12 /r")]
        vpsllvw_ymm_k1z_ymm_m256 = 4607,

        /// <summary>
        /// vpsllvw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.W1 12 /r | Shift words in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.W1 12 /r")]
        vpsllvw_ymm_k1z_ymm_r16 = 4608,

        /// <summary>
        /// vpsllvw ymm, ymm, m256 | EVEX.256.66.0F38.W1 12 /r | Shift words in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw ymm, ymm, m256","EVEX.256.66.0F38.W1 12 /r")]
        vpsllvw_ymm_ymm_m256 = 4609,

        /// <summary>
        /// vpsllvw ymm, ymm, r16 | EVEX.256.66.0F38.W1 12 /r | Shift words in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw ymm, ymm, r16","EVEX.256.66.0F38.W1 12 /r")]
        vpsllvw_ymm_ymm_r16 = 4610,

        /// <summary>
        /// vpsllvw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 12 /r | Shift words in zmm2 left by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 12 /r")]
        vpsllvw_zmm_k1z_zmm_m512 = 4611,

        /// <summary>
        /// vpsllvw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.W1 12 /r | Shift words in zmm2 left by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.W1 12 /r")]
        vpsllvw_zmm_k1z_zmm_r32 = 4612,

        /// <summary>
        /// vpsllvw zmm, zmm, m512 | EVEX.512.66.0F38.W1 12 /r | Shift words in zmm2 left by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw zmm, zmm, m512","EVEX.512.66.0F38.W1 12 /r")]
        vpsllvw_zmm_zmm_m512 = 4613,

        /// <summary>
        /// vpsllvw zmm, zmm, r32 | EVEX.512.66.0F38.W1 12 /r | Shift words in zmm2 left by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllvw zmm, zmm, r32","EVEX.512.66.0F38.W1 12 /r")]
        vpsllvw_zmm_zmm_r32 = 4614,

        /// <summary>
        /// vpsllw xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.WIG 71 /6 ib | Shift words in xmm2/m128 left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.WIG 71 /6 ib")]
        vpsllw_xmm_k1z_m128_imm8 = 4615,

        /// <summary>
        /// vpsllw xmm {k1}{z}, r8, imm8 | EVEX.128.66.0F.WIG 71 /6 ib | Shift words in xmm2/m128 left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw xmm {k1}{z}, r8, imm8","EVEX.128.66.0F.WIG 71 /6 ib")]
        vpsllw_xmm_k1z_r8_imm8 = 4616,

        /// <summary>
        /// vpsllw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG F1 /r | Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG F1 /r")]
        vpsllw_xmm_k1z_xmm_m128 = 4617,

        /// <summary>
        /// vpsllw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG F1 /r | Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG F1 /r")]
        vpsllw_xmm_k1z_xmm_r8 = 4618,

        /// <summary>
        /// vpsllw xmm, m128, imm8 | EVEX.128.66.0F.WIG 71 /6 ib | Shift words in xmm2/m128 left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw xmm, m128, imm8","EVEX.128.66.0F.WIG 71 /6 ib")]
        vpsllw_xmm_m128_imm8 = 4619,

        /// <summary>
        /// vpsllw xmm, r8, imm8 | EVEX.128.66.0F.WIG 71 /6 ib | Shift words in xmm2/m128 left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw xmm, r8, imm8","EVEX.128.66.0F.WIG 71 /6 ib")]
        vpsllw_xmm_r8_imm8 = 4620,

        /// <summary>
        /// vpsllw xmm, xmm, imm8 | VEX.128.66.0F.WIG 71 /6 ib | Shift words in xmm2 left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllw xmm, xmm, imm8","VEX.128.66.0F.WIG 71 /6 ib")]
        vpsllw_xmm_xmm_imm8 = 4621,

        /// <summary>
        /// vpsllw xmm, xmm, m128 | EVEX.128.66.0F.WIG F1 /r | Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw xmm, xmm, m128","EVEX.128.66.0F.WIG F1 /r")]
        vpsllw_xmm_xmm_m128 = 4622,

        /// <summary>
        /// vpsllw xmm, xmm, m128 | VEX.128.66.0F.WIG F1 /r | Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllw xmm, xmm, m128","VEX.128.66.0F.WIG F1 /r")]
        vpsllw_xmm_xmm_m128_vex = 4623,

        /// <summary>
        /// vpsllw xmm, xmm, r8 | EVEX.128.66.0F.WIG F1 /r | Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw xmm, xmm, r8","EVEX.128.66.0F.WIG F1 /r")]
        vpsllw_xmm_xmm_r8 = 4624,

        /// <summary>
        /// vpsllw xmm, xmm, r8 | VEX.128.66.0F.WIG F1 /r | Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllw xmm, xmm, r8","VEX.128.66.0F.WIG F1 /r")]
        vpsllw_xmm_xmm_r8_vex = 4625,

        /// <summary>
        /// vpsllw ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.WIG 71 /6 ib | Shift words in ymm2/m256 left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.WIG 71 /6 ib")]
        vpsllw_ymm_k1z_m256_imm8 = 4626,

        /// <summary>
        /// vpsllw ymm {k1}{z}, r16, imm8 | EVEX.256.66.0F.WIG 71 /6 ib | Shift words in ymm2/m256 left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw ymm {k1}{z}, r16, imm8","EVEX.256.66.0F.WIG 71 /6 ib")]
        vpsllw_ymm_k1z_r16_imm8 = 4627,

        /// <summary>
        /// vpsllw ymm {k1}{z}, ymm, m128 | EVEX.256.66.0F.WIG F1 /r | Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw ymm {k1}{z}, ymm, m128","EVEX.256.66.0F.WIG F1 /r")]
        vpsllw_ymm_k1z_ymm_m128 = 4628,

        /// <summary>
        /// vpsllw ymm {k1}{z}, ymm, r8 | EVEX.256.66.0F.WIG F1 /r | Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw ymm {k1}{z}, ymm, r8","EVEX.256.66.0F.WIG F1 /r")]
        vpsllw_ymm_k1z_ymm_r8 = 4629,

        /// <summary>
        /// vpsllw ymm, m256, imm8 | EVEX.256.66.0F.WIG 71 /6 ib | Shift words in ymm2/m256 left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw ymm, m256, imm8","EVEX.256.66.0F.WIG 71 /6 ib")]
        vpsllw_ymm_m256_imm8 = 4630,

        /// <summary>
        /// vpsllw ymm, r16, imm8 | EVEX.256.66.0F.WIG 71 /6 ib | Shift words in ymm2/m256 left by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw ymm, r16, imm8","EVEX.256.66.0F.WIG 71 /6 ib")]
        vpsllw_ymm_r16_imm8 = 4631,

        /// <summary>
        /// vpsllw ymm, ymm, imm8 | VEX.256.66.0F.WIG 71 /6 ib | Shift words in ymm2 left by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllw ymm, ymm, imm8","VEX.256.66.0F.WIG 71 /6 ib")]
        vpsllw_ymm_ymm_imm8 = 4632,

        /// <summary>
        /// vpsllw ymm, ymm, m128 | EVEX.256.66.0F.WIG F1 /r | Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw ymm, ymm, m128","EVEX.256.66.0F.WIG F1 /r")]
        vpsllw_ymm_ymm_m128 = 4633,

        /// <summary>
        /// vpsllw ymm, ymm, m128 | VEX.256.66.0F.WIG F1 /r | Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllw ymm, ymm, m128","VEX.256.66.0F.WIG F1 /r")]
        vpsllw_ymm_ymm_m128_vex = 4634,

        /// <summary>
        /// vpsllw ymm, ymm, r8 | EVEX.256.66.0F.WIG F1 /r | Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw ymm, ymm, r8","EVEX.256.66.0F.WIG F1 /r")]
        vpsllw_ymm_ymm_r8 = 4635,

        /// <summary>
        /// vpsllw ymm, ymm, r8 | VEX.256.66.0F.WIG F1 /r | Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsllw ymm, ymm, r8","VEX.256.66.0F.WIG F1 /r")]
        vpsllw_ymm_ymm_r8_vex = 4636,

        /// <summary>
        /// vpsllw zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.WIG 71 /6 ib | Shift words in zmm2/m512 left by imm8 while shifting in 0 using writemask k1.
        /// </summary>
        [Symbol("vpsllw zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.WIG 71 /6 ib")]
        vpsllw_zmm_k1z_m512_imm8 = 4637,

        /// <summary>
        /// vpsllw zmm {k1}{z}, r32, imm8 | EVEX.512.66.0F.WIG 71 /6 ib | Shift words in zmm2/m512 left by imm8 while shifting in 0 using writemask k1.
        /// </summary>
        [Symbol("vpsllw zmm {k1}{z}, r32, imm8","EVEX.512.66.0F.WIG 71 /6 ib")]
        vpsllw_zmm_k1z_r32_imm8 = 4638,

        /// <summary>
        /// vpsllw zmm {k1}{z}, zmm, m128 | EVEX.512.66.0F.WIG F1 /r | Shift words in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw zmm {k1}{z}, zmm, m128","EVEX.512.66.0F.WIG F1 /r")]
        vpsllw_zmm_k1z_zmm_m128 = 4639,

        /// <summary>
        /// vpsllw zmm {k1}{z}, zmm, r8 | EVEX.512.66.0F.WIG F1 /r | Shift words in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw zmm {k1}{z}, zmm, r8","EVEX.512.66.0F.WIG F1 /r")]
        vpsllw_zmm_k1z_zmm_r8 = 4640,

        /// <summary>
        /// vpsllw zmm, m512, imm8 | EVEX.512.66.0F.WIG 71 /6 ib | Shift words in zmm2/m512 left by imm8 while shifting in 0 using writemask k1.
        /// </summary>
        [Symbol("vpsllw zmm, m512, imm8","EVEX.512.66.0F.WIG 71 /6 ib")]
        vpsllw_zmm_m512_imm8 = 4641,

        /// <summary>
        /// vpsllw zmm, r32, imm8 | EVEX.512.66.0F.WIG 71 /6 ib | Shift words in zmm2/m512 left by imm8 while shifting in 0 using writemask k1.
        /// </summary>
        [Symbol("vpsllw zmm, r32, imm8","EVEX.512.66.0F.WIG 71 /6 ib")]
        vpsllw_zmm_r32_imm8 = 4642,

        /// <summary>
        /// vpsllw zmm, zmm, m128 | EVEX.512.66.0F.WIG F1 /r | Shift words in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw zmm, zmm, m128","EVEX.512.66.0F.WIG F1 /r")]
        vpsllw_zmm_zmm_m128 = 4643,

        /// <summary>
        /// vpsllw zmm, zmm, r8 | EVEX.512.66.0F.WIG F1 /r | Shift words in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsllw zmm, zmm, r8","EVEX.512.66.0F.WIG F1 /r")]
        vpsllw_zmm_zmm_r8 = 4644,

        /// <summary>
        /// vpsrad xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W0 72 /4 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W0 72 /4 ib")]
        vpsrad_xmm_k1z_m128_imm8 = 4645,

        /// <summary>
        /// vpsrad xmm {k1}{z}, m32bcst, imm8 | EVEX.128.66.0F.W0 72 /4 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad xmm {k1}{z}, m32bcst, imm8","EVEX.128.66.0F.W0 72 /4 ib")]
        vpsrad_xmm_k1z_m32bcst_imm8 = 4646,

        /// <summary>
        /// vpsrad xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W0 72 /4 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W0 72 /4 ib")]
        vpsrad_xmm_k1z_xmm_imm8 = 4647,

        /// <summary>
        /// vpsrad xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 E2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 E2 /r")]
        vpsrad_xmm_k1z_xmm_m128 = 4648,

        /// <summary>
        /// vpsrad xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.W0 E2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.W0 E2 /r")]
        vpsrad_xmm_k1z_xmm_r8 = 4649,

        /// <summary>
        /// vpsrad xmm, m128, imm8 | EVEX.128.66.0F.W0 72 /4 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad xmm, m128, imm8","EVEX.128.66.0F.W0 72 /4 ib")]
        vpsrad_xmm_m128_imm8 = 4650,

        /// <summary>
        /// vpsrad xmm, m32bcst, imm8 | EVEX.128.66.0F.W0 72 /4 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad xmm, m32bcst, imm8","EVEX.128.66.0F.W0 72 /4 ib")]
        vpsrad_xmm_m32bcst_imm8 = 4651,

        /// <summary>
        /// vpsrad xmm, xmm, imm8 | EVEX.128.66.0F.W0 72 /4 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad xmm, xmm, imm8","EVEX.128.66.0F.W0 72 /4 ib")]
        vpsrad_xmm_xmm_imm8 = 4652,

        /// <summary>
        /// vpsrad xmm, xmm, imm8 | VEX.128.66.0F.WIG 72 /4 ib | Shift doublewords in xmm2 right by imm8 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsrad xmm, xmm, imm8","VEX.128.66.0F.WIG 72 /4 ib")]
        vpsrad_xmm_xmm_imm8_vex = 4653,

        /// <summary>
        /// vpsrad xmm, xmm, m128 | EVEX.128.66.0F.W0 E2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad xmm, xmm, m128","EVEX.128.66.0F.W0 E2 /r")]
        vpsrad_xmm_xmm_m128 = 4654,

        /// <summary>
        /// vpsrad xmm, xmm, m128 | VEX.128.66.0F.WIG E2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsrad xmm, xmm, m128","VEX.128.66.0F.WIG E2 /r")]
        vpsrad_xmm_xmm_m128_vex = 4655,

        /// <summary>
        /// vpsrad xmm, xmm, r8 | EVEX.128.66.0F.W0 E2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad xmm, xmm, r8","EVEX.128.66.0F.W0 E2 /r")]
        vpsrad_xmm_xmm_r8 = 4656,

        /// <summary>
        /// vpsrad xmm, xmm, r8 | VEX.128.66.0F.WIG E2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsrad xmm, xmm, r8","VEX.128.66.0F.WIG E2 /r")]
        vpsrad_xmm_xmm_r8_vex = 4657,

        /// <summary>
        /// vpsrad ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W0 72 /4 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W0 72 /4 ib")]
        vpsrad_ymm_k1z_m256_imm8 = 4658,

        /// <summary>
        /// vpsrad ymm {k1}{z}, m32bcst, imm8 | EVEX.256.66.0F.W0 72 /4 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad ymm {k1}{z}, m32bcst, imm8","EVEX.256.66.0F.W0 72 /4 ib")]
        vpsrad_ymm_k1z_m32bcst_imm8 = 4659,

        /// <summary>
        /// vpsrad ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W0 72 /4 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W0 72 /4 ib")]
        vpsrad_ymm_k1z_ymm_imm8 = 4660,

        /// <summary>
        /// vpsrad ymm {k1}{z}, ymm, m128 | EVEX.256.66.0F.W0 E2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad ymm {k1}{z}, ymm, m128","EVEX.256.66.0F.W0 E2 /r")]
        vpsrad_ymm_k1z_ymm_m128 = 4661,

        /// <summary>
        /// vpsrad ymm {k1}{z}, ymm, r8 | EVEX.256.66.0F.W0 E2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad ymm {k1}{z}, ymm, r8","EVEX.256.66.0F.W0 E2 /r")]
        vpsrad_ymm_k1z_ymm_r8 = 4662,

        /// <summary>
        /// vpsrad ymm, m256, imm8 | EVEX.256.66.0F.W0 72 /4 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad ymm, m256, imm8","EVEX.256.66.0F.W0 72 /4 ib")]
        vpsrad_ymm_m256_imm8 = 4663,

        /// <summary>
        /// vpsrad ymm, m32bcst, imm8 | EVEX.256.66.0F.W0 72 /4 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad ymm, m32bcst, imm8","EVEX.256.66.0F.W0 72 /4 ib")]
        vpsrad_ymm_m32bcst_imm8 = 4664,

        /// <summary>
        /// vpsrad ymm, ymm, imm8 | EVEX.256.66.0F.W0 72 /4 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad ymm, ymm, imm8","EVEX.256.66.0F.W0 72 /4 ib")]
        vpsrad_ymm_ymm_imm8 = 4665,

        /// <summary>
        /// vpsrad ymm, ymm, imm8 | VEX.256.66.0F.WIG 72 /4 ib | Shift doublewords in ymm2 right by imm8 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsrad ymm, ymm, imm8","VEX.256.66.0F.WIG 72 /4 ib")]
        vpsrad_ymm_ymm_imm8_vex = 4666,

        /// <summary>
        /// vpsrad ymm, ymm, m128 | EVEX.256.66.0F.W0 E2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad ymm, ymm, m128","EVEX.256.66.0F.W0 E2 /r")]
        vpsrad_ymm_ymm_m128 = 4667,

        /// <summary>
        /// vpsrad ymm, ymm, m128 | VEX.256.66.0F.WIG E2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsrad ymm, ymm, m128","VEX.256.66.0F.WIG E2 /r")]
        vpsrad_ymm_ymm_m128_vex = 4668,

        /// <summary>
        /// vpsrad ymm, ymm, r8 | EVEX.256.66.0F.W0 E2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad ymm, ymm, r8","EVEX.256.66.0F.W0 E2 /r")]
        vpsrad_ymm_ymm_r8 = 4669,

        /// <summary>
        /// vpsrad ymm, ymm, r8 | VEX.256.66.0F.WIG E2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsrad ymm, ymm, r8","VEX.256.66.0F.WIG E2 /r")]
        vpsrad_ymm_ymm_r8_vex = 4670,

        /// <summary>
        /// vpsrad zmm {k1}{z}, m32bcst, imm8 | EVEX.512.66.0F.W0 72 /4 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad zmm {k1}{z}, m32bcst, imm8","EVEX.512.66.0F.W0 72 /4 ib")]
        vpsrad_zmm_k1z_m32bcst_imm8 = 4671,

        /// <summary>
        /// vpsrad zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W0 72 /4 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W0 72 /4 ib")]
        vpsrad_zmm_k1z_m512_imm8 = 4672,

        /// <summary>
        /// vpsrad zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W0 72 /4 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W0 72 /4 ib")]
        vpsrad_zmm_k1z_zmm_imm8 = 4673,

        /// <summary>
        /// vpsrad zmm {k1}{z}, zmm, m128 | EVEX.512.66.0F.W0 E2 /r | Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad zmm {k1}{z}, zmm, m128","EVEX.512.66.0F.W0 E2 /r")]
        vpsrad_zmm_k1z_zmm_m128 = 4674,

        /// <summary>
        /// vpsrad zmm {k1}{z}, zmm, r8 | EVEX.512.66.0F.W0 E2 /r | Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad zmm {k1}{z}, zmm, r8","EVEX.512.66.0F.W0 E2 /r")]
        vpsrad_zmm_k1z_zmm_r8 = 4675,

        /// <summary>
        /// vpsrad zmm, m32bcst, imm8 | EVEX.512.66.0F.W0 72 /4 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad zmm, m32bcst, imm8","EVEX.512.66.0F.W0 72 /4 ib")]
        vpsrad_zmm_m32bcst_imm8 = 4676,

        /// <summary>
        /// vpsrad zmm, m512, imm8 | EVEX.512.66.0F.W0 72 /4 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad zmm, m512, imm8","EVEX.512.66.0F.W0 72 /4 ib")]
        vpsrad_zmm_m512_imm8 = 4677,

        /// <summary>
        /// vpsrad zmm, zmm, imm8 | EVEX.512.66.0F.W0 72 /4 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad zmm, zmm, imm8","EVEX.512.66.0F.W0 72 /4 ib")]
        vpsrad_zmm_zmm_imm8 = 4678,

        /// <summary>
        /// vpsrad zmm, zmm, m128 | EVEX.512.66.0F.W0 E2 /r | Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad zmm, zmm, m128","EVEX.512.66.0F.W0 E2 /r")]
        vpsrad_zmm_zmm_m128 = 4679,

        /// <summary>
        /// vpsrad zmm, zmm, r8 | EVEX.512.66.0F.W0 E2 /r | Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsrad zmm, zmm, r8","EVEX.512.66.0F.W0 E2 /r")]
        vpsrad_zmm_zmm_r8 = 4680,

        /// <summary>
        /// vpsraq xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W1 72 /4 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W1 72 /4 ib")]
        vpsraq_xmm_k1z_m128_imm8 = 4681,

        /// <summary>
        /// vpsraq xmm {k1}{z}, m64bcst, imm8 | EVEX.128.66.0F.W1 72 /4 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq xmm {k1}{z}, m64bcst, imm8","EVEX.128.66.0F.W1 72 /4 ib")]
        vpsraq_xmm_k1z_m64bcst_imm8 = 4682,

        /// <summary>
        /// vpsraq xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W1 72 /4 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W1 72 /4 ib")]
        vpsraq_xmm_k1z_xmm_imm8 = 4683,

        /// <summary>
        /// vpsraq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 E2 /r | Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 E2 /r")]
        vpsraq_xmm_k1z_xmm_m128 = 4684,

        /// <summary>
        /// vpsraq xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.W1 E2 /r | Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.W1 E2 /r")]
        vpsraq_xmm_k1z_xmm_r8 = 4685,

        /// <summary>
        /// vpsraq xmm, m128, imm8 | EVEX.128.66.0F.W1 72 /4 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq xmm, m128, imm8","EVEX.128.66.0F.W1 72 /4 ib")]
        vpsraq_xmm_m128_imm8 = 4686,

        /// <summary>
        /// vpsraq xmm, m64bcst, imm8 | EVEX.128.66.0F.W1 72 /4 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq xmm, m64bcst, imm8","EVEX.128.66.0F.W1 72 /4 ib")]
        vpsraq_xmm_m64bcst_imm8 = 4687,

        /// <summary>
        /// vpsraq xmm, xmm, imm8 | EVEX.128.66.0F.W1 72 /4 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq xmm, xmm, imm8","EVEX.128.66.0F.W1 72 /4 ib")]
        vpsraq_xmm_xmm_imm8 = 4688,

        /// <summary>
        /// vpsraq xmm, xmm, m128 | EVEX.128.66.0F.W1 E2 /r | Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq xmm, xmm, m128","EVEX.128.66.0F.W1 E2 /r")]
        vpsraq_xmm_xmm_m128 = 4689,

        /// <summary>
        /// vpsraq xmm, xmm, r8 | EVEX.128.66.0F.W1 E2 /r | Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq xmm, xmm, r8","EVEX.128.66.0F.W1 E2 /r")]
        vpsraq_xmm_xmm_r8 = 4690,

        /// <summary>
        /// vpsraq ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W1 72 /4 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W1 72 /4 ib")]
        vpsraq_ymm_k1z_m256_imm8 = 4691,

        /// <summary>
        /// vpsraq ymm {k1}{z}, m64bcst, imm8 | EVEX.256.66.0F.W1 72 /4 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq ymm {k1}{z}, m64bcst, imm8","EVEX.256.66.0F.W1 72 /4 ib")]
        vpsraq_ymm_k1z_m64bcst_imm8 = 4692,

        /// <summary>
        /// vpsraq ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W1 72 /4 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W1 72 /4 ib")]
        vpsraq_ymm_k1z_ymm_imm8 = 4693,

        /// <summary>
        /// vpsraq ymm {k1}{z}, ymm, m128 | EVEX.256.66.0F.W1 E2 /r | Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq ymm {k1}{z}, ymm, m128","EVEX.256.66.0F.W1 E2 /r")]
        vpsraq_ymm_k1z_ymm_m128 = 4694,

        /// <summary>
        /// vpsraq ymm {k1}{z}, ymm, r8 | EVEX.256.66.0F.W1 E2 /r | Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq ymm {k1}{z}, ymm, r8","EVEX.256.66.0F.W1 E2 /r")]
        vpsraq_ymm_k1z_ymm_r8 = 4695,

        /// <summary>
        /// vpsraq ymm, m256, imm8 | EVEX.256.66.0F.W1 72 /4 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq ymm, m256, imm8","EVEX.256.66.0F.W1 72 /4 ib")]
        vpsraq_ymm_m256_imm8 = 4696,

        /// <summary>
        /// vpsraq ymm, m64bcst, imm8 | EVEX.256.66.0F.W1 72 /4 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq ymm, m64bcst, imm8","EVEX.256.66.0F.W1 72 /4 ib")]
        vpsraq_ymm_m64bcst_imm8 = 4697,

        /// <summary>
        /// vpsraq ymm, ymm, imm8 | EVEX.256.66.0F.W1 72 /4 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq ymm, ymm, imm8","EVEX.256.66.0F.W1 72 /4 ib")]
        vpsraq_ymm_ymm_imm8 = 4698,

        /// <summary>
        /// vpsraq ymm, ymm, m128 | EVEX.256.66.0F.W1 E2 /r | Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq ymm, ymm, m128","EVEX.256.66.0F.W1 E2 /r")]
        vpsraq_ymm_ymm_m128 = 4699,

        /// <summary>
        /// vpsraq ymm, ymm, r8 | EVEX.256.66.0F.W1 E2 /r | Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq ymm, ymm, r8","EVEX.256.66.0F.W1 E2 /r")]
        vpsraq_ymm_ymm_r8 = 4700,

        /// <summary>
        /// vpsraq zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W1 72 /4 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W1 72 /4 ib")]
        vpsraq_zmm_k1z_m512_imm8 = 4701,

        /// <summary>
        /// vpsraq zmm {k1}{z}, m64bcst, imm8 | EVEX.512.66.0F.W1 72 /4 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq zmm {k1}{z}, m64bcst, imm8","EVEX.512.66.0F.W1 72 /4 ib")]
        vpsraq_zmm_k1z_m64bcst_imm8 = 4702,

        /// <summary>
        /// vpsraq zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W1 72 /4 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W1 72 /4 ib")]
        vpsraq_zmm_k1z_zmm_imm8 = 4703,

        /// <summary>
        /// vpsraq zmm {k1}{z}, zmm, m128 | EVEX.512.66.0F.W1 E2 /r | Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq zmm {k1}{z}, zmm, m128","EVEX.512.66.0F.W1 E2 /r")]
        vpsraq_zmm_k1z_zmm_m128 = 4704,

        /// <summary>
        /// vpsraq zmm {k1}{z}, zmm, r8 | EVEX.512.66.0F.W1 E2 /r | Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq zmm {k1}{z}, zmm, r8","EVEX.512.66.0F.W1 E2 /r")]
        vpsraq_zmm_k1z_zmm_r8 = 4705,

        /// <summary>
        /// vpsraq zmm, m512, imm8 | EVEX.512.66.0F.W1 72 /4 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq zmm, m512, imm8","EVEX.512.66.0F.W1 72 /4 ib")]
        vpsraq_zmm_m512_imm8 = 4706,

        /// <summary>
        /// vpsraq zmm, m64bcst, imm8 | EVEX.512.66.0F.W1 72 /4 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq zmm, m64bcst, imm8","EVEX.512.66.0F.W1 72 /4 ib")]
        vpsraq_zmm_m64bcst_imm8 = 4707,

        /// <summary>
        /// vpsraq zmm, zmm, imm8 | EVEX.512.66.0F.W1 72 /4 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq zmm, zmm, imm8","EVEX.512.66.0F.W1 72 /4 ib")]
        vpsraq_zmm_zmm_imm8 = 4708,

        /// <summary>
        /// vpsraq zmm, zmm, m128 | EVEX.512.66.0F.W1 E2 /r | Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq zmm, zmm, m128","EVEX.512.66.0F.W1 E2 /r")]
        vpsraq_zmm_zmm_m128 = 4709,

        /// <summary>
        /// vpsraq zmm, zmm, r8 | EVEX.512.66.0F.W1 E2 /r | Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraq zmm, zmm, r8","EVEX.512.66.0F.W1 E2 /r")]
        vpsraq_zmm_zmm_r8 = 4710,

        /// <summary>
        /// vpsravd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 46 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 46 /r")]
        vpsravd_xmm_k1z_xmm_m128 = 4711,

        /// <summary>
        /// vpsravd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 46 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 46 /r")]
        vpsravd_xmm_k1z_xmm_m32bcst = 4712,

        /// <summary>
        /// vpsravd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 46 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 46 /r")]
        vpsravd_xmm_k1z_xmm_xmm = 4713,

        /// <summary>
        /// vpsravd xmm, xmm, m128 | EVEX.128.66.0F38.W0 46 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd xmm, xmm, m128","EVEX.128.66.0F38.W0 46 /r")]
        vpsravd_xmm_xmm_m128 = 4714,

        /// <summary>
        /// vpsravd xmm, xmm, m128 | VEX.128.66.0F38.W0 46 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsravd xmm, xmm, m128","VEX.128.66.0F38.W0 46 /r")]
        vpsravd_xmm_xmm_m128_vex = 4715,

        /// <summary>
        /// vpsravd xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 46 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 46 /r")]
        vpsravd_xmm_xmm_m32bcst = 4716,

        /// <summary>
        /// vpsravd xmm, xmm, r8 | VEX.128.66.0F38.W0 46 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsravd xmm, xmm, r8","VEX.128.66.0F38.W0 46 /r")]
        vpsravd_xmm_xmm_r8 = 4717,

        /// <summary>
        /// vpsravd xmm, xmm, xmm | EVEX.128.66.0F38.W0 46 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd xmm, xmm, xmm","EVEX.128.66.0F38.W0 46 /r")]
        vpsravd_xmm_xmm_xmm = 4718,

        /// <summary>
        /// vpsravd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 46 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 46 /r")]
        vpsravd_ymm_k1z_ymm_m256 = 4719,

        /// <summary>
        /// vpsravd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 46 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 46 /r")]
        vpsravd_ymm_k1z_ymm_m32bcst = 4720,

        /// <summary>
        /// vpsravd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 46 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 46 /r")]
        vpsravd_ymm_k1z_ymm_ymm = 4721,

        /// <summary>
        /// vpsravd ymm, ymm, m256 | EVEX.256.66.0F38.W0 46 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd ymm, ymm, m256","EVEX.256.66.0F38.W0 46 /r")]
        vpsravd_ymm_ymm_m256 = 4722,

        /// <summary>
        /// vpsravd ymm, ymm, m256 | VEX.256.66.0F38.W0 46 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsravd ymm, ymm, m256","VEX.256.66.0F38.W0 46 /r")]
        vpsravd_ymm_ymm_m256_vex = 4723,

        /// <summary>
        /// vpsravd ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 46 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 46 /r")]
        vpsravd_ymm_ymm_m32bcst = 4724,

        /// <summary>
        /// vpsravd ymm, ymm, r16 | VEX.256.66.0F38.W0 46 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsravd ymm, ymm, r16","VEX.256.66.0F38.W0 46 /r")]
        vpsravd_ymm_ymm_r16 = 4725,

        /// <summary>
        /// vpsravd ymm, ymm, ymm | EVEX.256.66.0F38.W0 46 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd ymm, ymm, ymm","EVEX.256.66.0F38.W0 46 /r")]
        vpsravd_ymm_ymm_ymm = 4726,

        /// <summary>
        /// vpsravd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 46 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 46 /r")]
        vpsravd_zmm_k1z_zmm_m32bcst = 4727,

        /// <summary>
        /// vpsravd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 46 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 46 /r")]
        vpsravd_zmm_k1z_zmm_m512 = 4728,

        /// <summary>
        /// vpsravd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 46 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 46 /r")]
        vpsravd_zmm_k1z_zmm_zmm = 4729,

        /// <summary>
        /// vpsravd zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 46 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 46 /r")]
        vpsravd_zmm_zmm_m32bcst = 4730,

        /// <summary>
        /// vpsravd zmm, zmm, m512 | EVEX.512.66.0F38.W0 46 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd zmm, zmm, m512","EVEX.512.66.0F38.W0 46 /r")]
        vpsravd_zmm_zmm_m512 = 4731,

        /// <summary>
        /// vpsravd zmm, zmm, zmm | EVEX.512.66.0F38.W0 46 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravd zmm, zmm, zmm","EVEX.512.66.0F38.W0 46 /r")]
        vpsravd_zmm_zmm_zmm = 4732,

        /// <summary>
        /// vpsravq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 46 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 46 /r")]
        vpsravq_xmm_k1z_xmm_m128 = 4733,

        /// <summary>
        /// vpsravq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 46 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 46 /r")]
        vpsravq_xmm_k1z_xmm_m64bcst = 4734,

        /// <summary>
        /// vpsravq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 46 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 46 /r")]
        vpsravq_xmm_k1z_xmm_xmm = 4735,

        /// <summary>
        /// vpsravq xmm, xmm, m128 | EVEX.128.66.0F38.W1 46 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq xmm, xmm, m128","EVEX.128.66.0F38.W1 46 /r")]
        vpsravq_xmm_xmm_m128 = 4736,

        /// <summary>
        /// vpsravq xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 46 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 46 /r")]
        vpsravq_xmm_xmm_m64bcst = 4737,

        /// <summary>
        /// vpsravq xmm, xmm, xmm | EVEX.128.66.0F38.W1 46 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq xmm, xmm, xmm","EVEX.128.66.0F38.W1 46 /r")]
        vpsravq_xmm_xmm_xmm = 4738,

        /// <summary>
        /// vpsravq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 46 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 46 /r")]
        vpsravq_ymm_k1z_ymm_m256 = 4739,

        /// <summary>
        /// vpsravq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 46 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 46 /r")]
        vpsravq_ymm_k1z_ymm_m64bcst = 4740,

        /// <summary>
        /// vpsravq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 46 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 46 /r")]
        vpsravq_ymm_k1z_ymm_ymm = 4741,

        /// <summary>
        /// vpsravq ymm, ymm, m256 | EVEX.256.66.0F38.W1 46 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq ymm, ymm, m256","EVEX.256.66.0F38.W1 46 /r")]
        vpsravq_ymm_ymm_m256 = 4742,

        /// <summary>
        /// vpsravq ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 46 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 46 /r")]
        vpsravq_ymm_ymm_m64bcst = 4743,

        /// <summary>
        /// vpsravq ymm, ymm, ymm | EVEX.256.66.0F38.W1 46 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq ymm, ymm, ymm","EVEX.256.66.0F38.W1 46 /r")]
        vpsravq_ymm_ymm_ymm = 4744,

        /// <summary>
        /// vpsravq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 46 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 46 /r")]
        vpsravq_zmm_k1z_zmm_m512 = 4745,

        /// <summary>
        /// vpsravq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 46 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 46 /r")]
        vpsravq_zmm_k1z_zmm_m64bcst = 4746,

        /// <summary>
        /// vpsravq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 46 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 46 /r")]
        vpsravq_zmm_k1z_zmm_zmm = 4747,

        /// <summary>
        /// vpsravq zmm, zmm, m512 | EVEX.512.66.0F38.W1 46 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq zmm, zmm, m512","EVEX.512.66.0F38.W1 46 /r")]
        vpsravq_zmm_zmm_m512 = 4748,

        /// <summary>
        /// vpsravq zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 46 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 46 /r")]
        vpsravq_zmm_zmm_m64bcst = 4749,

        /// <summary>
        /// vpsravq zmm, zmm, zmm | EVEX.512.66.0F38.W1 46 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravq zmm, zmm, zmm","EVEX.512.66.0F38.W1 46 /r")]
        vpsravq_zmm_zmm_zmm = 4750,

        /// <summary>
        /// vpsravw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 11 /r | Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 11 /r")]
        vpsravw_xmm_k1z_xmm_m128 = 4751,

        /// <summary>
        /// vpsravw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.W1 11 /r | Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.W1 11 /r")]
        vpsravw_xmm_k1z_xmm_r8 = 4752,

        /// <summary>
        /// vpsravw xmm, xmm, m128 | EVEX.128.66.0F38.W1 11 /r | Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw xmm, xmm, m128","EVEX.128.66.0F38.W1 11 /r")]
        vpsravw_xmm_xmm_m128 = 4753,

        /// <summary>
        /// vpsravw xmm, xmm, r8 | EVEX.128.66.0F38.W1 11 /r | Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw xmm, xmm, r8","EVEX.128.66.0F38.W1 11 /r")]
        vpsravw_xmm_xmm_r8 = 4754,

        /// <summary>
        /// vpsravw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 11 /r | Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 11 /r")]
        vpsravw_ymm_k1z_ymm_m256 = 4755,

        /// <summary>
        /// vpsravw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.W1 11 /r | Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.W1 11 /r")]
        vpsravw_ymm_k1z_ymm_r16 = 4756,

        /// <summary>
        /// vpsravw ymm, ymm, m256 | EVEX.256.66.0F38.W1 11 /r | Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw ymm, ymm, m256","EVEX.256.66.0F38.W1 11 /r")]
        vpsravw_ymm_ymm_m256 = 4757,

        /// <summary>
        /// vpsravw ymm, ymm, r16 | EVEX.256.66.0F38.W1 11 /r | Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw ymm, ymm, r16","EVEX.256.66.0F38.W1 11 /r")]
        vpsravw_ymm_ymm_r16 = 4758,

        /// <summary>
        /// vpsravw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 11 /r | Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 11 /r")]
        vpsravw_zmm_k1z_zmm_m512 = 4759,

        /// <summary>
        /// vpsravw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.W1 11 /r | Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.W1 11 /r")]
        vpsravw_zmm_k1z_zmm_r32 = 4760,

        /// <summary>
        /// vpsravw zmm, zmm, m512 | EVEX.512.66.0F38.W1 11 /r | Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw zmm, zmm, m512","EVEX.512.66.0F38.W1 11 /r")]
        vpsravw_zmm_zmm_m512 = 4761,

        /// <summary>
        /// vpsravw zmm, zmm, r32 | EVEX.512.66.0F38.W1 11 /r | Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsravw zmm, zmm, r32","EVEX.512.66.0F38.W1 11 /r")]
        vpsravw_zmm_zmm_r32 = 4762,

        /// <summary>
        /// vpsraw xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.WIG 71 /4 ib | Shift words in xmm2/m128 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.WIG 71 /4 ib")]
        vpsraw_xmm_k1z_m128_imm8 = 4763,

        /// <summary>
        /// vpsraw xmm {k1}{z}, r8, imm8 | EVEX.128.66.0F.WIG 71 /4 ib | Shift words in xmm2/m128 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw xmm {k1}{z}, r8, imm8","EVEX.128.66.0F.WIG 71 /4 ib")]
        vpsraw_xmm_k1z_r8_imm8 = 4764,

        /// <summary>
        /// vpsraw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG E1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG E1 /r")]
        vpsraw_xmm_k1z_xmm_m128 = 4765,

        /// <summary>
        /// vpsraw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG E1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG E1 /r")]
        vpsraw_xmm_k1z_xmm_r8 = 4766,

        /// <summary>
        /// vpsraw xmm, m128, imm8 | EVEX.128.66.0F.WIG 71 /4 ib | Shift words in xmm2/m128 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw xmm, m128, imm8","EVEX.128.66.0F.WIG 71 /4 ib")]
        vpsraw_xmm_m128_imm8 = 4767,

        /// <summary>
        /// vpsraw xmm, r8, imm8 | EVEX.128.66.0F.WIG 71 /4 ib | Shift words in xmm2/m128 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw xmm, r8, imm8","EVEX.128.66.0F.WIG 71 /4 ib")]
        vpsraw_xmm_r8_imm8 = 4768,

        /// <summary>
        /// vpsraw xmm, xmm, imm8 | VEX.128.66.0F.WIG 71 /4 ib | Shift words in xmm2 right by imm8 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsraw xmm, xmm, imm8","VEX.128.66.0F.WIG 71 /4 ib")]
        vpsraw_xmm_xmm_imm8 = 4769,

        /// <summary>
        /// vpsraw xmm, xmm, m128 | EVEX.128.66.0F.WIG E1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw xmm, xmm, m128","EVEX.128.66.0F.WIG E1 /r")]
        vpsraw_xmm_xmm_m128 = 4770,

        /// <summary>
        /// vpsraw xmm, xmm, m128 | VEX.128.66.0F.WIG E1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsraw xmm, xmm, m128","VEX.128.66.0F.WIG E1 /r")]
        vpsraw_xmm_xmm_m128_vex = 4771,

        /// <summary>
        /// vpsraw xmm, xmm, r8 | EVEX.128.66.0F.WIG E1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw xmm, xmm, r8","EVEX.128.66.0F.WIG E1 /r")]
        vpsraw_xmm_xmm_r8 = 4772,

        /// <summary>
        /// vpsraw xmm, xmm, r8 | VEX.128.66.0F.WIG E1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsraw xmm, xmm, r8","VEX.128.66.0F.WIG E1 /r")]
        vpsraw_xmm_xmm_r8_vex = 4773,

        /// <summary>
        /// vpsraw ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.WIG 71 /4 ib | Shift words in ymm2/m256 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.WIG 71 /4 ib")]
        vpsraw_ymm_k1z_m256_imm8 = 4774,

        /// <summary>
        /// vpsraw ymm {k1}{z}, r16, imm8 | EVEX.256.66.0F.WIG 71 /4 ib | Shift words in ymm2/m256 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw ymm {k1}{z}, r16, imm8","EVEX.256.66.0F.WIG 71 /4 ib")]
        vpsraw_ymm_k1z_r16_imm8 = 4775,

        /// <summary>
        /// vpsraw ymm {k1}{z}, ymm, m128 | EVEX.256.66.0F.WIG E1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw ymm {k1}{z}, ymm, m128","EVEX.256.66.0F.WIG E1 /r")]
        vpsraw_ymm_k1z_ymm_m128 = 4776,

        /// <summary>
        /// vpsraw ymm {k1}{z}, ymm, r8 | EVEX.256.66.0F.WIG E1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw ymm {k1}{z}, ymm, r8","EVEX.256.66.0F.WIG E1 /r")]
        vpsraw_ymm_k1z_ymm_r8 = 4777,

        /// <summary>
        /// vpsraw ymm, m256, imm8 | EVEX.256.66.0F.WIG 71 /4 ib | Shift words in ymm2/m256 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw ymm, m256, imm8","EVEX.256.66.0F.WIG 71 /4 ib")]
        vpsraw_ymm_m256_imm8 = 4778,

        /// <summary>
        /// vpsraw ymm, r16, imm8 | EVEX.256.66.0F.WIG 71 /4 ib | Shift words in ymm2/m256 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw ymm, r16, imm8","EVEX.256.66.0F.WIG 71 /4 ib")]
        vpsraw_ymm_r16_imm8 = 4779,

        /// <summary>
        /// vpsraw ymm, ymm, imm8 | VEX.256.66.0F.WIG 71 /4 ib | Shift words in ymm2 right by imm8 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsraw ymm, ymm, imm8","VEX.256.66.0F.WIG 71 /4 ib")]
        vpsraw_ymm_ymm_imm8 = 4780,

        /// <summary>
        /// vpsraw ymm, ymm, m128 | EVEX.256.66.0F.WIG E1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw ymm, ymm, m128","EVEX.256.66.0F.WIG E1 /r")]
        vpsraw_ymm_ymm_m128 = 4781,

        /// <summary>
        /// vpsraw ymm, ymm, m128 | VEX.256.66.0F.WIG E1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsraw ymm, ymm, m128","VEX.256.66.0F.WIG E1 /r")]
        vpsraw_ymm_ymm_m128_vex = 4782,

        /// <summary>
        /// vpsraw ymm, ymm, r8 | EVEX.256.66.0F.WIG E1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw ymm, ymm, r8","EVEX.256.66.0F.WIG E1 /r")]
        vpsraw_ymm_ymm_r8 = 4783,

        /// <summary>
        /// vpsraw ymm, ymm, r8 | VEX.256.66.0F.WIG E1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits.
        /// </summary>
        [Symbol("vpsraw ymm, ymm, r8","VEX.256.66.0F.WIG E1 /r")]
        vpsraw_ymm_ymm_r8_vex = 4784,

        /// <summary>
        /// vpsraw zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.WIG 71 /4 ib | Shift words in zmm2/m512 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.WIG 71 /4 ib")]
        vpsraw_zmm_k1z_m512_imm8 = 4785,

        /// <summary>
        /// vpsraw zmm {k1}{z}, r32, imm8 | EVEX.512.66.0F.WIG 71 /4 ib | Shift words in zmm2/m512 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw zmm {k1}{z}, r32, imm8","EVEX.512.66.0F.WIG 71 /4 ib")]
        vpsraw_zmm_k1z_r32_imm8 = 4786,

        /// <summary>
        /// vpsraw zmm {k1}{z}, zmm, m128 | EVEX.512.66.0F.WIG E1 /r | Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw zmm {k1}{z}, zmm, m128","EVEX.512.66.0F.WIG E1 /r")]
        vpsraw_zmm_k1z_zmm_m128 = 4787,

        /// <summary>
        /// vpsraw zmm {k1}{z}, zmm, r8 | EVEX.512.66.0F.WIG E1 /r | Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw zmm {k1}{z}, zmm, r8","EVEX.512.66.0F.WIG E1 /r")]
        vpsraw_zmm_k1z_zmm_r8 = 4788,

        /// <summary>
        /// vpsraw zmm, m512, imm8 | EVEX.512.66.0F.WIG 71 /4 ib | Shift words in zmm2/m512 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw zmm, m512, imm8","EVEX.512.66.0F.WIG 71 /4 ib")]
        vpsraw_zmm_m512_imm8 = 4789,

        /// <summary>
        /// vpsraw zmm, r32, imm8 | EVEX.512.66.0F.WIG 71 /4 ib | Shift words in zmm2/m512 right by imm8 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw zmm, r32, imm8","EVEX.512.66.0F.WIG 71 /4 ib")]
        vpsraw_zmm_r32_imm8 = 4790,

        /// <summary>
        /// vpsraw zmm, zmm, m128 | EVEX.512.66.0F.WIG E1 /r | Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw zmm, zmm, m128","EVEX.512.66.0F.WIG E1 /r")]
        vpsraw_zmm_zmm_m128 = 4791,

        /// <summary>
        /// vpsraw zmm, zmm, r8 | EVEX.512.66.0F.WIG E1 /r | Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.
        /// </summary>
        [Symbol("vpsraw zmm, zmm, r8","EVEX.512.66.0F.WIG E1 /r")]
        vpsraw_zmm_zmm_r8 = 4792,

        /// <summary>
        /// vpsrld xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W0 72 /2 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W0 72 /2 ib")]
        vpsrld_xmm_k1z_m128_imm8 = 4793,

        /// <summary>
        /// vpsrld xmm {k1}{z}, m32bcst, imm8 | EVEX.128.66.0F.W0 72 /2 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld xmm {k1}{z}, m32bcst, imm8","EVEX.128.66.0F.W0 72 /2 ib")]
        vpsrld_xmm_k1z_m32bcst_imm8 = 4794,

        /// <summary>
        /// vpsrld xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W0 72 /2 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W0 72 /2 ib")]
        vpsrld_xmm_k1z_xmm_imm8 = 4795,

        /// <summary>
        /// vpsrld xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 D2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 D2 /r")]
        vpsrld_xmm_k1z_xmm_m128 = 4796,

        /// <summary>
        /// vpsrld xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.W0 D2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.W0 D2 /r")]
        vpsrld_xmm_k1z_xmm_r8 = 4797,

        /// <summary>
        /// vpsrld xmm, m128, imm8 | EVEX.128.66.0F.W0 72 /2 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld xmm, m128, imm8","EVEX.128.66.0F.W0 72 /2 ib")]
        vpsrld_xmm_m128_imm8 = 4798,

        /// <summary>
        /// vpsrld xmm, m32bcst, imm8 | EVEX.128.66.0F.W0 72 /2 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld xmm, m32bcst, imm8","EVEX.128.66.0F.W0 72 /2 ib")]
        vpsrld_xmm_m32bcst_imm8 = 4799,

        /// <summary>
        /// vpsrld xmm, xmm, imm8 | EVEX.128.66.0F.W0 72 /2 ib | Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld xmm, xmm, imm8","EVEX.128.66.0F.W0 72 /2 ib")]
        vpsrld_xmm_xmm_imm8 = 4800,

        /// <summary>
        /// vpsrld xmm, xmm, imm8 | VEX.128.66.0F.WIG 72 /2 ib | Shift doublewords in xmm2 right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrld xmm, xmm, imm8","VEX.128.66.0F.WIG 72 /2 ib")]
        vpsrld_xmm_xmm_imm8_vex = 4801,

        /// <summary>
        /// vpsrld xmm, xmm, m128 | EVEX.128.66.0F.W0 D2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld xmm, xmm, m128","EVEX.128.66.0F.W0 D2 /r")]
        vpsrld_xmm_xmm_m128 = 4802,

        /// <summary>
        /// vpsrld xmm, xmm, m128 | VEX.128.66.0F.WIG D2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrld xmm, xmm, m128","VEX.128.66.0F.WIG D2 /r")]
        vpsrld_xmm_xmm_m128_vex = 4803,

        /// <summary>
        /// vpsrld xmm, xmm, r8 | EVEX.128.66.0F.W0 D2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld xmm, xmm, r8","EVEX.128.66.0F.W0 D2 /r")]
        vpsrld_xmm_xmm_r8 = 4804,

        /// <summary>
        /// vpsrld xmm, xmm, r8 | VEX.128.66.0F.WIG D2 /r | Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrld xmm, xmm, r8","VEX.128.66.0F.WIG D2 /r")]
        vpsrld_xmm_xmm_r8_vex = 4805,

        /// <summary>
        /// vpsrld ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W0 72 /2 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W0 72 /2 ib")]
        vpsrld_ymm_k1z_m256_imm8 = 4806,

        /// <summary>
        /// vpsrld ymm {k1}{z}, m32bcst, imm8 | EVEX.256.66.0F.W0 72 /2 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld ymm {k1}{z}, m32bcst, imm8","EVEX.256.66.0F.W0 72 /2 ib")]
        vpsrld_ymm_k1z_m32bcst_imm8 = 4807,

        /// <summary>
        /// vpsrld ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W0 72 /2 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W0 72 /2 ib")]
        vpsrld_ymm_k1z_ymm_imm8 = 4808,

        /// <summary>
        /// vpsrld ymm {k1}{z}, ymm, m128 | EVEX.256.66.0F.W0 D2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld ymm {k1}{z}, ymm, m128","EVEX.256.66.0F.W0 D2 /r")]
        vpsrld_ymm_k1z_ymm_m128 = 4809,

        /// <summary>
        /// vpsrld ymm {k1}{z}, ymm, r8 | EVEX.256.66.0F.W0 D2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld ymm {k1}{z}, ymm, r8","EVEX.256.66.0F.W0 D2 /r")]
        vpsrld_ymm_k1z_ymm_r8 = 4810,

        /// <summary>
        /// vpsrld ymm, m256, imm8 | EVEX.256.66.0F.W0 72 /2 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld ymm, m256, imm8","EVEX.256.66.0F.W0 72 /2 ib")]
        vpsrld_ymm_m256_imm8 = 4811,

        /// <summary>
        /// vpsrld ymm, m32bcst, imm8 | EVEX.256.66.0F.W0 72 /2 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld ymm, m32bcst, imm8","EVEX.256.66.0F.W0 72 /2 ib")]
        vpsrld_ymm_m32bcst_imm8 = 4812,

        /// <summary>
        /// vpsrld ymm, ymm, imm8 | EVEX.256.66.0F.W0 72 /2 ib | Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld ymm, ymm, imm8","EVEX.256.66.0F.W0 72 /2 ib")]
        vpsrld_ymm_ymm_imm8 = 4813,

        /// <summary>
        /// vpsrld ymm, ymm, imm8 | VEX.256.66.0F.WIG 72 /2 ib | Shift doublewords in ymm2 right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrld ymm, ymm, imm8","VEX.256.66.0F.WIG 72 /2 ib")]
        vpsrld_ymm_ymm_imm8_vex = 4814,

        /// <summary>
        /// vpsrld ymm, ymm, m128 | EVEX.256.66.0F.W0 D2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld ymm, ymm, m128","EVEX.256.66.0F.W0 D2 /r")]
        vpsrld_ymm_ymm_m128 = 4815,

        /// <summary>
        /// vpsrld ymm, ymm, m128 | VEX.256.66.0F.WIG D2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrld ymm, ymm, m128","VEX.256.66.0F.WIG D2 /r")]
        vpsrld_ymm_ymm_m128_vex = 4816,

        /// <summary>
        /// vpsrld ymm, ymm, r8 | EVEX.256.66.0F.W0 D2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld ymm, ymm, r8","EVEX.256.66.0F.W0 D2 /r")]
        vpsrld_ymm_ymm_r8 = 4817,

        /// <summary>
        /// vpsrld ymm, ymm, r8 | VEX.256.66.0F.WIG D2 /r | Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrld ymm, ymm, r8","VEX.256.66.0F.WIG D2 /r")]
        vpsrld_ymm_ymm_r8_vex = 4818,

        /// <summary>
        /// vpsrld zmm {k1}{z}, m32bcst, imm8 | EVEX.512.66.0F.W0 72 /2 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld zmm {k1}{z}, m32bcst, imm8","EVEX.512.66.0F.W0 72 /2 ib")]
        vpsrld_zmm_k1z_m32bcst_imm8 = 4819,

        /// <summary>
        /// vpsrld zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W0 72 /2 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W0 72 /2 ib")]
        vpsrld_zmm_k1z_m512_imm8 = 4820,

        /// <summary>
        /// vpsrld zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W0 72 /2 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W0 72 /2 ib")]
        vpsrld_zmm_k1z_zmm_imm8 = 4821,

        /// <summary>
        /// vpsrld zmm {k1}{z}, zmm, m128 | EVEX.512.66.0F.W0 D2 /r | Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld zmm {k1}{z}, zmm, m128","EVEX.512.66.0F.W0 D2 /r")]
        vpsrld_zmm_k1z_zmm_m128 = 4822,

        /// <summary>
        /// vpsrld zmm {k1}{z}, zmm, r8 | EVEX.512.66.0F.W0 D2 /r | Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld zmm {k1}{z}, zmm, r8","EVEX.512.66.0F.W0 D2 /r")]
        vpsrld_zmm_k1z_zmm_r8 = 4823,

        /// <summary>
        /// vpsrld zmm, m32bcst, imm8 | EVEX.512.66.0F.W0 72 /2 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld zmm, m32bcst, imm8","EVEX.512.66.0F.W0 72 /2 ib")]
        vpsrld_zmm_m32bcst_imm8 = 4824,

        /// <summary>
        /// vpsrld zmm, m512, imm8 | EVEX.512.66.0F.W0 72 /2 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld zmm, m512, imm8","EVEX.512.66.0F.W0 72 /2 ib")]
        vpsrld_zmm_m512_imm8 = 4825,

        /// <summary>
        /// vpsrld zmm, zmm, imm8 | EVEX.512.66.0F.W0 72 /2 ib | Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld zmm, zmm, imm8","EVEX.512.66.0F.W0 72 /2 ib")]
        vpsrld_zmm_zmm_imm8 = 4826,

        /// <summary>
        /// vpsrld zmm, zmm, m128 | EVEX.512.66.0F.W0 D2 /r | Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld zmm, zmm, m128","EVEX.512.66.0F.W0 D2 /r")]
        vpsrld_zmm_zmm_m128 = 4827,

        /// <summary>
        /// vpsrld zmm, zmm, r8 | EVEX.512.66.0F.W0 D2 /r | Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrld zmm, zmm, r8","EVEX.512.66.0F.W0 D2 /r")]
        vpsrld_zmm_zmm_r8 = 4828,

        /// <summary>
        /// vpsrlq xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.W1 73 /2 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.W1 73 /2 ib")]
        vpsrlq_xmm_k1z_m128_imm8 = 4829,

        /// <summary>
        /// vpsrlq xmm {k1}{z}, m64bcst, imm8 | EVEX.128.66.0F.W1 73 /2 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq xmm {k1}{z}, m64bcst, imm8","EVEX.128.66.0F.W1 73 /2 ib")]
        vpsrlq_xmm_k1z_m64bcst_imm8 = 4830,

        /// <summary>
        /// vpsrlq xmm {k1}{z}, xmm, imm8 | EVEX.128.66.0F.W1 73 /2 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq xmm {k1}{z}, xmm, imm8","EVEX.128.66.0F.W1 73 /2 ib")]
        vpsrlq_xmm_k1z_xmm_imm8 = 4831,

        /// <summary>
        /// vpsrlq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 D3 /r | Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 D3 /r")]
        vpsrlq_xmm_k1z_xmm_m128 = 4832,

        /// <summary>
        /// vpsrlq xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.W1 D3 /r | Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.W1 D3 /r")]
        vpsrlq_xmm_k1z_xmm_r8 = 4833,

        /// <summary>
        /// vpsrlq xmm, m128, imm8 | EVEX.128.66.0F.W1 73 /2 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq xmm, m128, imm8","EVEX.128.66.0F.W1 73 /2 ib")]
        vpsrlq_xmm_m128_imm8 = 4834,

        /// <summary>
        /// vpsrlq xmm, m64bcst, imm8 | EVEX.128.66.0F.W1 73 /2 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq xmm, m64bcst, imm8","EVEX.128.66.0F.W1 73 /2 ib")]
        vpsrlq_xmm_m64bcst_imm8 = 4835,

        /// <summary>
        /// vpsrlq xmm, xmm, imm8 | EVEX.128.66.0F.W1 73 /2 ib | Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq xmm, xmm, imm8","EVEX.128.66.0F.W1 73 /2 ib")]
        vpsrlq_xmm_xmm_imm8 = 4836,

        /// <summary>
        /// vpsrlq xmm, xmm, imm8 | VEX.128.66.0F.WIG 73 /2 ib | Shift quadwords in xmm2 right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlq xmm, xmm, imm8","VEX.128.66.0F.WIG 73 /2 ib")]
        vpsrlq_xmm_xmm_imm8_vex = 4837,

        /// <summary>
        /// vpsrlq xmm, xmm, m128 | EVEX.128.66.0F.W1 D3 /r | Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq xmm, xmm, m128","EVEX.128.66.0F.W1 D3 /r")]
        vpsrlq_xmm_xmm_m128 = 4838,

        /// <summary>
        /// vpsrlq xmm, xmm, m128 | VEX.128.66.0F.WIG D3 /r | Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlq xmm, xmm, m128","VEX.128.66.0F.WIG D3 /r")]
        vpsrlq_xmm_xmm_m128_vex = 4839,

        /// <summary>
        /// vpsrlq xmm, xmm, r8 | EVEX.128.66.0F.W1 D3 /r | Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq xmm, xmm, r8","EVEX.128.66.0F.W1 D3 /r")]
        vpsrlq_xmm_xmm_r8 = 4840,

        /// <summary>
        /// vpsrlq xmm, xmm, r8 | VEX.128.66.0F.WIG D3 /r | Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlq xmm, xmm, r8","VEX.128.66.0F.WIG D3 /r")]
        vpsrlq_xmm_xmm_r8_vex = 4841,

        /// <summary>
        /// vpsrlq ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.W1 73 /2 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.W1 73 /2 ib")]
        vpsrlq_ymm_k1z_m256_imm8 = 4842,

        /// <summary>
        /// vpsrlq ymm {k1}{z}, m64bcst, imm8 | EVEX.256.66.0F.W1 73 /2 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq ymm {k1}{z}, m64bcst, imm8","EVEX.256.66.0F.W1 73 /2 ib")]
        vpsrlq_ymm_k1z_m64bcst_imm8 = 4843,

        /// <summary>
        /// vpsrlq ymm {k1}{z}, ymm, imm8 | EVEX.256.66.0F.W1 73 /2 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq ymm {k1}{z}, ymm, imm8","EVEX.256.66.0F.W1 73 /2 ib")]
        vpsrlq_ymm_k1z_ymm_imm8 = 4844,

        /// <summary>
        /// vpsrlq ymm {k1}{z}, ymm, m128 | EVEX.256.66.0F.W1 D3 /r | Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq ymm {k1}{z}, ymm, m128","EVEX.256.66.0F.W1 D3 /r")]
        vpsrlq_ymm_k1z_ymm_m128 = 4845,

        /// <summary>
        /// vpsrlq ymm {k1}{z}, ymm, r8 | EVEX.256.66.0F.W1 D3 /r | Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq ymm {k1}{z}, ymm, r8","EVEX.256.66.0F.W1 D3 /r")]
        vpsrlq_ymm_k1z_ymm_r8 = 4846,

        /// <summary>
        /// vpsrlq ymm, m256, imm8 | EVEX.256.66.0F.W1 73 /2 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq ymm, m256, imm8","EVEX.256.66.0F.W1 73 /2 ib")]
        vpsrlq_ymm_m256_imm8 = 4847,

        /// <summary>
        /// vpsrlq ymm, m64bcst, imm8 | EVEX.256.66.0F.W1 73 /2 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq ymm, m64bcst, imm8","EVEX.256.66.0F.W1 73 /2 ib")]
        vpsrlq_ymm_m64bcst_imm8 = 4848,

        /// <summary>
        /// vpsrlq ymm, ymm, imm8 | EVEX.256.66.0F.W1 73 /2 ib | Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq ymm, ymm, imm8","EVEX.256.66.0F.W1 73 /2 ib")]
        vpsrlq_ymm_ymm_imm8 = 4849,

        /// <summary>
        /// vpsrlq ymm, ymm, imm8 | VEX.256.66.0F.WIG 73 /2 ib | Shift quadwords in ymm2 right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlq ymm, ymm, imm8","VEX.256.66.0F.WIG 73 /2 ib")]
        vpsrlq_ymm_ymm_imm8_vex = 4850,

        /// <summary>
        /// vpsrlq ymm, ymm, m128 | EVEX.256.66.0F.W1 D3 /r | Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq ymm, ymm, m128","EVEX.256.66.0F.W1 D3 /r")]
        vpsrlq_ymm_ymm_m128 = 4851,

        /// <summary>
        /// vpsrlq ymm, ymm, m128 | VEX.256.66.0F.WIG D3 /r | Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlq ymm, ymm, m128","VEX.256.66.0F.WIG D3 /r")]
        vpsrlq_ymm_ymm_m128_vex = 4852,

        /// <summary>
        /// vpsrlq ymm, ymm, r8 | EVEX.256.66.0F.W1 D3 /r | Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq ymm, ymm, r8","EVEX.256.66.0F.W1 D3 /r")]
        vpsrlq_ymm_ymm_r8 = 4853,

        /// <summary>
        /// vpsrlq ymm, ymm, r8 | VEX.256.66.0F.WIG D3 /r | Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlq ymm, ymm, r8","VEX.256.66.0F.WIG D3 /r")]
        vpsrlq_ymm_ymm_r8_vex = 4854,

        /// <summary>
        /// vpsrlq zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.W1 73 /2 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.W1 73 /2 ib")]
        vpsrlq_zmm_k1z_m512_imm8 = 4855,

        /// <summary>
        /// vpsrlq zmm {k1}{z}, m64bcst, imm8 | EVEX.512.66.0F.W1 73 /2 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq zmm {k1}{z}, m64bcst, imm8","EVEX.512.66.0F.W1 73 /2 ib")]
        vpsrlq_zmm_k1z_m64bcst_imm8 = 4856,

        /// <summary>
        /// vpsrlq zmm {k1}{z}, zmm, imm8 | EVEX.512.66.0F.W1 73 /2 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq zmm {k1}{z}, zmm, imm8","EVEX.512.66.0F.W1 73 /2 ib")]
        vpsrlq_zmm_k1z_zmm_imm8 = 4857,

        /// <summary>
        /// vpsrlq zmm {k1}{z}, zmm, m128 | EVEX.512.66.0F.W1 D3 /r | Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq zmm {k1}{z}, zmm, m128","EVEX.512.66.0F.W1 D3 /r")]
        vpsrlq_zmm_k1z_zmm_m128 = 4858,

        /// <summary>
        /// vpsrlq zmm {k1}{z}, zmm, r8 | EVEX.512.66.0F.W1 D3 /r | Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq zmm {k1}{z}, zmm, r8","EVEX.512.66.0F.W1 D3 /r")]
        vpsrlq_zmm_k1z_zmm_r8 = 4859,

        /// <summary>
        /// vpsrlq zmm, m512, imm8 | EVEX.512.66.0F.W1 73 /2 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq zmm, m512, imm8","EVEX.512.66.0F.W1 73 /2 ib")]
        vpsrlq_zmm_m512_imm8 = 4860,

        /// <summary>
        /// vpsrlq zmm, m64bcst, imm8 | EVEX.512.66.0F.W1 73 /2 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq zmm, m64bcst, imm8","EVEX.512.66.0F.W1 73 /2 ib")]
        vpsrlq_zmm_m64bcst_imm8 = 4861,

        /// <summary>
        /// vpsrlq zmm, zmm, imm8 | EVEX.512.66.0F.W1 73 /2 ib | Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq zmm, zmm, imm8","EVEX.512.66.0F.W1 73 /2 ib")]
        vpsrlq_zmm_zmm_imm8 = 4862,

        /// <summary>
        /// vpsrlq zmm, zmm, m128 | EVEX.512.66.0F.W1 D3 /r | Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq zmm, zmm, m128","EVEX.512.66.0F.W1 D3 /r")]
        vpsrlq_zmm_zmm_m128 = 4863,

        /// <summary>
        /// vpsrlq zmm, zmm, r8 | EVEX.512.66.0F.W1 D3 /r | Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlq zmm, zmm, r8","EVEX.512.66.0F.W1 D3 /r")]
        vpsrlq_zmm_zmm_r8 = 4864,

        /// <summary>
        /// vpsrlvd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W0 45 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W0 45 /r")]
        vpsrlvd_xmm_k1z_xmm_m128 = 4865,

        /// <summary>
        /// vpsrlvd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F38.W0 45 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F38.W0 45 /r")]
        vpsrlvd_xmm_k1z_xmm_m32bcst = 4866,

        /// <summary>
        /// vpsrlvd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W0 45 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W0 45 /r")]
        vpsrlvd_xmm_k1z_xmm_xmm = 4867,

        /// <summary>
        /// vpsrlvd xmm, xmm, m128 | EVEX.128.66.0F38.W0 45 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd xmm, xmm, m128","EVEX.128.66.0F38.W0 45 /r")]
        vpsrlvd_xmm_xmm_m128 = 4868,

        /// <summary>
        /// vpsrlvd xmm, xmm, m128 | VEX.128.66.0F38.W0 45 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlvd xmm, xmm, m128","VEX.128.66.0F38.W0 45 /r")]
        vpsrlvd_xmm_xmm_m128_vex = 4869,

        /// <summary>
        /// vpsrlvd xmm, xmm, m32bcst | EVEX.128.66.0F38.W0 45 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd xmm, xmm, m32bcst","EVEX.128.66.0F38.W0 45 /r")]
        vpsrlvd_xmm_xmm_m32bcst = 4870,

        /// <summary>
        /// vpsrlvd xmm, xmm, r8 | VEX.128.66.0F38.W0 45 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlvd xmm, xmm, r8","VEX.128.66.0F38.W0 45 /r")]
        vpsrlvd_xmm_xmm_r8 = 4871,

        /// <summary>
        /// vpsrlvd xmm, xmm, xmm | EVEX.128.66.0F38.W0 45 /r | Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd xmm, xmm, xmm","EVEX.128.66.0F38.W0 45 /r")]
        vpsrlvd_xmm_xmm_xmm = 4872,

        /// <summary>
        /// vpsrlvd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W0 45 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W0 45 /r")]
        vpsrlvd_ymm_k1z_ymm_m256 = 4873,

        /// <summary>
        /// vpsrlvd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F38.W0 45 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F38.W0 45 /r")]
        vpsrlvd_ymm_k1z_ymm_m32bcst = 4874,

        /// <summary>
        /// vpsrlvd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W0 45 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W0 45 /r")]
        vpsrlvd_ymm_k1z_ymm_ymm = 4875,

        /// <summary>
        /// vpsrlvd ymm, ymm, m256 | EVEX.256.66.0F38.W0 45 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd ymm, ymm, m256","EVEX.256.66.0F38.W0 45 /r")]
        vpsrlvd_ymm_ymm_m256 = 4876,

        /// <summary>
        /// vpsrlvd ymm, ymm, m256 | VEX.256.66.0F38.W0 45 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlvd ymm, ymm, m256","VEX.256.66.0F38.W0 45 /r")]
        vpsrlvd_ymm_ymm_m256_vex = 4877,

        /// <summary>
        /// vpsrlvd ymm, ymm, m32bcst | EVEX.256.66.0F38.W0 45 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd ymm, ymm, m32bcst","EVEX.256.66.0F38.W0 45 /r")]
        vpsrlvd_ymm_ymm_m32bcst = 4878,

        /// <summary>
        /// vpsrlvd ymm, ymm, r16 | VEX.256.66.0F38.W0 45 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlvd ymm, ymm, r16","VEX.256.66.0F38.W0 45 /r")]
        vpsrlvd_ymm_ymm_r16 = 4879,

        /// <summary>
        /// vpsrlvd ymm, ymm, ymm | EVEX.256.66.0F38.W0 45 /r | Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd ymm, ymm, ymm","EVEX.256.66.0F38.W0 45 /r")]
        vpsrlvd_ymm_ymm_ymm = 4880,

        /// <summary>
        /// vpsrlvd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F38.W0 45 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F38.W0 45 /r")]
        vpsrlvd_zmm_k1z_zmm_m32bcst = 4881,

        /// <summary>
        /// vpsrlvd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W0 45 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W0 45 /r")]
        vpsrlvd_zmm_k1z_zmm_m512 = 4882,

        /// <summary>
        /// vpsrlvd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W0 45 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W0 45 /r")]
        vpsrlvd_zmm_k1z_zmm_zmm = 4883,

        /// <summary>
        /// vpsrlvd zmm, zmm, m32bcst | EVEX.512.66.0F38.W0 45 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd zmm, zmm, m32bcst","EVEX.512.66.0F38.W0 45 /r")]
        vpsrlvd_zmm_zmm_m32bcst = 4884,

        /// <summary>
        /// vpsrlvd zmm, zmm, m512 | EVEX.512.66.0F38.W0 45 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd zmm, zmm, m512","EVEX.512.66.0F38.W0 45 /r")]
        vpsrlvd_zmm_zmm_m512 = 4885,

        /// <summary>
        /// vpsrlvd zmm, zmm, zmm | EVEX.512.66.0F38.W0 45 /r | Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvd zmm, zmm, zmm","EVEX.512.66.0F38.W0 45 /r")]
        vpsrlvd_zmm_zmm_zmm = 4886,

        /// <summary>
        /// vpsrlvq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 45 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 45 /r")]
        vpsrlvq_xmm_k1z_xmm_m128 = 4887,

        /// <summary>
        /// vpsrlvq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F38.W1 45 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F38.W1 45 /r")]
        vpsrlvq_xmm_k1z_xmm_m64bcst = 4888,

        /// <summary>
        /// vpsrlvq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F38.W1 45 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F38.W1 45 /r")]
        vpsrlvq_xmm_k1z_xmm_xmm = 4889,

        /// <summary>
        /// vpsrlvq xmm, xmm, m128 | EVEX.128.66.0F38.W1 45 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq xmm, xmm, m128","EVEX.128.66.0F38.W1 45 /r")]
        vpsrlvq_xmm_xmm_m128 = 4890,

        /// <summary>
        /// vpsrlvq xmm, xmm, m128 | VEX.128.66.0F38.W1 45 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlvq xmm, xmm, m128","VEX.128.66.0F38.W1 45 /r")]
        vpsrlvq_xmm_xmm_m128_vex = 4891,

        /// <summary>
        /// vpsrlvq xmm, xmm, m64bcst | EVEX.128.66.0F38.W1 45 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq xmm, xmm, m64bcst","EVEX.128.66.0F38.W1 45 /r")]
        vpsrlvq_xmm_xmm_m64bcst = 4892,

        /// <summary>
        /// vpsrlvq xmm, xmm, r8 | VEX.128.66.0F38.W1 45 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlvq xmm, xmm, r8","VEX.128.66.0F38.W1 45 /r")]
        vpsrlvq_xmm_xmm_r8 = 4893,

        /// <summary>
        /// vpsrlvq xmm, xmm, xmm | EVEX.128.66.0F38.W1 45 /r | Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq xmm, xmm, xmm","EVEX.128.66.0F38.W1 45 /r")]
        vpsrlvq_xmm_xmm_xmm = 4894,

        /// <summary>
        /// vpsrlvq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 45 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 45 /r")]
        vpsrlvq_ymm_k1z_ymm_m256 = 4895,

        /// <summary>
        /// vpsrlvq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F38.W1 45 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F38.W1 45 /r")]
        vpsrlvq_ymm_k1z_ymm_m64bcst = 4896,

        /// <summary>
        /// vpsrlvq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F38.W1 45 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F38.W1 45 /r")]
        vpsrlvq_ymm_k1z_ymm_ymm = 4897,

        /// <summary>
        /// vpsrlvq ymm, ymm, m256 | EVEX.256.66.0F38.W1 45 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq ymm, ymm, m256","EVEX.256.66.0F38.W1 45 /r")]
        vpsrlvq_ymm_ymm_m256 = 4898,

        /// <summary>
        /// vpsrlvq ymm, ymm, m256 | VEX.256.66.0F38.W1 45 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlvq ymm, ymm, m256","VEX.256.66.0F38.W1 45 /r")]
        vpsrlvq_ymm_ymm_m256_vex = 4899,

        /// <summary>
        /// vpsrlvq ymm, ymm, m64bcst | EVEX.256.66.0F38.W1 45 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq ymm, ymm, m64bcst","EVEX.256.66.0F38.W1 45 /r")]
        vpsrlvq_ymm_ymm_m64bcst = 4900,

        /// <summary>
        /// vpsrlvq ymm, ymm, r16 | VEX.256.66.0F38.W1 45 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlvq ymm, ymm, r16","VEX.256.66.0F38.W1 45 /r")]
        vpsrlvq_ymm_ymm_r16 = 4901,

        /// <summary>
        /// vpsrlvq ymm, ymm, ymm | EVEX.256.66.0F38.W1 45 /r | Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq ymm, ymm, ymm","EVEX.256.66.0F38.W1 45 /r")]
        vpsrlvq_ymm_ymm_ymm = 4902,

        /// <summary>
        /// vpsrlvq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 45 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 45 /r")]
        vpsrlvq_zmm_k1z_zmm_m512 = 4903,

        /// <summary>
        /// vpsrlvq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F38.W1 45 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F38.W1 45 /r")]
        vpsrlvq_zmm_k1z_zmm_m64bcst = 4904,

        /// <summary>
        /// vpsrlvq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F38.W1 45 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F38.W1 45 /r")]
        vpsrlvq_zmm_k1z_zmm_zmm = 4905,

        /// <summary>
        /// vpsrlvq zmm, zmm, m512 | EVEX.512.66.0F38.W1 45 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq zmm, zmm, m512","EVEX.512.66.0F38.W1 45 /r")]
        vpsrlvq_zmm_zmm_m512 = 4906,

        /// <summary>
        /// vpsrlvq zmm, zmm, m64bcst | EVEX.512.66.0F38.W1 45 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq zmm, zmm, m64bcst","EVEX.512.66.0F38.W1 45 /r")]
        vpsrlvq_zmm_zmm_m64bcst = 4907,

        /// <summary>
        /// vpsrlvq zmm, zmm, zmm | EVEX.512.66.0F38.W1 45 /r | Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvq zmm, zmm, zmm","EVEX.512.66.0F38.W1 45 /r")]
        vpsrlvq_zmm_zmm_zmm = 4908,

        /// <summary>
        /// vpsrlvw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F38.W1 10 /r | Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F38.W1 10 /r")]
        vpsrlvw_xmm_k1z_xmm_m128 = 4909,

        /// <summary>
        /// vpsrlvw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F38.W1 10 /r | Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F38.W1 10 /r")]
        vpsrlvw_xmm_k1z_xmm_r8 = 4910,

        /// <summary>
        /// vpsrlvw xmm, xmm, m128 | EVEX.128.66.0F38.W1 10 /r | Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw xmm, xmm, m128","EVEX.128.66.0F38.W1 10 /r")]
        vpsrlvw_xmm_xmm_m128 = 4911,

        /// <summary>
        /// vpsrlvw xmm, xmm, r8 | EVEX.128.66.0F38.W1 10 /r | Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw xmm, xmm, r8","EVEX.128.66.0F38.W1 10 /r")]
        vpsrlvw_xmm_xmm_r8 = 4912,

        /// <summary>
        /// vpsrlvw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F38.W1 10 /r | Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F38.W1 10 /r")]
        vpsrlvw_ymm_k1z_ymm_m256 = 4913,

        /// <summary>
        /// vpsrlvw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F38.W1 10 /r | Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F38.W1 10 /r")]
        vpsrlvw_ymm_k1z_ymm_r16 = 4914,

        /// <summary>
        /// vpsrlvw ymm, ymm, m256 | EVEX.256.66.0F38.W1 10 /r | Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw ymm, ymm, m256","EVEX.256.66.0F38.W1 10 /r")]
        vpsrlvw_ymm_ymm_m256 = 4915,

        /// <summary>
        /// vpsrlvw ymm, ymm, r16 | EVEX.256.66.0F38.W1 10 /r | Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw ymm, ymm, r16","EVEX.256.66.0F38.W1 10 /r")]
        vpsrlvw_ymm_ymm_r16 = 4916,

        /// <summary>
        /// vpsrlvw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F38.W1 10 /r | Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F38.W1 10 /r")]
        vpsrlvw_zmm_k1z_zmm_m512 = 4917,

        /// <summary>
        /// vpsrlvw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F38.W1 10 /r | Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F38.W1 10 /r")]
        vpsrlvw_zmm_k1z_zmm_r32 = 4918,

        /// <summary>
        /// vpsrlvw zmm, zmm, m512 | EVEX.512.66.0F38.W1 10 /r | Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw zmm, zmm, m512","EVEX.512.66.0F38.W1 10 /r")]
        vpsrlvw_zmm_zmm_m512 = 4919,

        /// <summary>
        /// vpsrlvw zmm, zmm, r32 | EVEX.512.66.0F38.W1 10 /r | Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlvw zmm, zmm, r32","EVEX.512.66.0F38.W1 10 /r")]
        vpsrlvw_zmm_zmm_r32 = 4920,

        /// <summary>
        /// vpsrlw xmm {k1}{z}, m128, imm8 | EVEX.128.66.0F.WIG 71 /2 ib | Shift words in xmm2/m128 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw xmm {k1}{z}, m128, imm8","EVEX.128.66.0F.WIG 71 /2 ib")]
        vpsrlw_xmm_k1z_m128_imm8 = 4921,

        /// <summary>
        /// vpsrlw xmm {k1}{z}, r8, imm8 | EVEX.128.66.0F.WIG 71 /2 ib | Shift words in xmm2/m128 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw xmm {k1}{z}, r8, imm8","EVEX.128.66.0F.WIG 71 /2 ib")]
        vpsrlw_xmm_k1z_r8_imm8 = 4922,

        /// <summary>
        /// vpsrlw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG D1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG D1 /r")]
        vpsrlw_xmm_k1z_xmm_m128 = 4923,

        /// <summary>
        /// vpsrlw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG D1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG D1 /r")]
        vpsrlw_xmm_k1z_xmm_r8 = 4924,

        /// <summary>
        /// vpsrlw xmm, m128, imm8 | EVEX.128.66.0F.WIG 71 /2 ib | Shift words in xmm2/m128 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw xmm, m128, imm8","EVEX.128.66.0F.WIG 71 /2 ib")]
        vpsrlw_xmm_m128_imm8 = 4925,

        /// <summary>
        /// vpsrlw xmm, r8, imm8 | EVEX.128.66.0F.WIG 71 /2 ib | Shift words in xmm2/m128 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw xmm, r8, imm8","EVEX.128.66.0F.WIG 71 /2 ib")]
        vpsrlw_xmm_r8_imm8 = 4926,

        /// <summary>
        /// vpsrlw xmm, xmm, imm8 | VEX.128.66.0F.WIG 71 /2 ib | Shift words in xmm2 right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlw xmm, xmm, imm8","VEX.128.66.0F.WIG 71 /2 ib")]
        vpsrlw_xmm_xmm_imm8 = 4927,

        /// <summary>
        /// vpsrlw xmm, xmm, m128 | EVEX.128.66.0F.WIG D1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw xmm, xmm, m128","EVEX.128.66.0F.WIG D1 /r")]
        vpsrlw_xmm_xmm_m128 = 4928,

        /// <summary>
        /// vpsrlw xmm, xmm, m128 | VEX.128.66.0F.WIG D1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlw xmm, xmm, m128","VEX.128.66.0F.WIG D1 /r")]
        vpsrlw_xmm_xmm_m128_vex = 4929,

        /// <summary>
        /// vpsrlw xmm, xmm, r8 | EVEX.128.66.0F.WIG D1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw xmm, xmm, r8","EVEX.128.66.0F.WIG D1 /r")]
        vpsrlw_xmm_xmm_r8 = 4930,

        /// <summary>
        /// vpsrlw xmm, xmm, r8 | VEX.128.66.0F.WIG D1 /r | Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlw xmm, xmm, r8","VEX.128.66.0F.WIG D1 /r")]
        vpsrlw_xmm_xmm_r8_vex = 4931,

        /// <summary>
        /// vpsrlw ymm {k1}{z}, m256, imm8 | EVEX.256.66.0F.WIG 71 /2 ib | Shift words in ymm2/m256 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw ymm {k1}{z}, m256, imm8","EVEX.256.66.0F.WIG 71 /2 ib")]
        vpsrlw_ymm_k1z_m256_imm8 = 4932,

        /// <summary>
        /// vpsrlw ymm {k1}{z}, r16, imm8 | EVEX.256.66.0F.WIG 71 /2 ib | Shift words in ymm2/m256 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw ymm {k1}{z}, r16, imm8","EVEX.256.66.0F.WIG 71 /2 ib")]
        vpsrlw_ymm_k1z_r16_imm8 = 4933,

        /// <summary>
        /// vpsrlw ymm {k1}{z}, ymm, m128 | EVEX.256.66.0F.WIG D1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw ymm {k1}{z}, ymm, m128","EVEX.256.66.0F.WIG D1 /r")]
        vpsrlw_ymm_k1z_ymm_m128 = 4934,

        /// <summary>
        /// vpsrlw ymm {k1}{z}, ymm, r8 | EVEX.256.66.0F.WIG D1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw ymm {k1}{z}, ymm, r8","EVEX.256.66.0F.WIG D1 /r")]
        vpsrlw_ymm_k1z_ymm_r8 = 4935,

        /// <summary>
        /// vpsrlw ymm, m256, imm8 | EVEX.256.66.0F.WIG 71 /2 ib | Shift words in ymm2/m256 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw ymm, m256, imm8","EVEX.256.66.0F.WIG 71 /2 ib")]
        vpsrlw_ymm_m256_imm8 = 4936,

        /// <summary>
        /// vpsrlw ymm, r16, imm8 | EVEX.256.66.0F.WIG 71 /2 ib | Shift words in ymm2/m256 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw ymm, r16, imm8","EVEX.256.66.0F.WIG 71 /2 ib")]
        vpsrlw_ymm_r16_imm8 = 4937,

        /// <summary>
        /// vpsrlw ymm, ymm, imm8 | VEX.256.66.0F.WIG 71 /2 ib | Shift words in ymm2 right by imm8 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlw ymm, ymm, imm8","VEX.256.66.0F.WIG 71 /2 ib")]
        vpsrlw_ymm_ymm_imm8 = 4938,

        /// <summary>
        /// vpsrlw ymm, ymm, m128 | EVEX.256.66.0F.WIG D1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw ymm, ymm, m128","EVEX.256.66.0F.WIG D1 /r")]
        vpsrlw_ymm_ymm_m128 = 4939,

        /// <summary>
        /// vpsrlw ymm, ymm, m128 | VEX.256.66.0F.WIG D1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlw ymm, ymm, m128","VEX.256.66.0F.WIG D1 /r")]
        vpsrlw_ymm_ymm_m128_vex = 4940,

        /// <summary>
        /// vpsrlw ymm, ymm, r8 | EVEX.256.66.0F.WIG D1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw ymm, ymm, r8","EVEX.256.66.0F.WIG D1 /r")]
        vpsrlw_ymm_ymm_r8 = 4941,

        /// <summary>
        /// vpsrlw ymm, ymm, r8 | VEX.256.66.0F.WIG D1 /r | Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s.
        /// </summary>
        [Symbol("vpsrlw ymm, ymm, r8","VEX.256.66.0F.WIG D1 /r")]
        vpsrlw_ymm_ymm_r8_vex = 4942,

        /// <summary>
        /// vpsrlw zmm {k1}{z}, m512, imm8 | EVEX.512.66.0F.WIG 71 /2 ib | Shift words in zmm2/m512 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw zmm {k1}{z}, m512, imm8","EVEX.512.66.0F.WIG 71 /2 ib")]
        vpsrlw_zmm_k1z_m512_imm8 = 4943,

        /// <summary>
        /// vpsrlw zmm {k1}{z}, r32, imm8 | EVEX.512.66.0F.WIG 71 /2 ib | Shift words in zmm2/m512 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw zmm {k1}{z}, r32, imm8","EVEX.512.66.0F.WIG 71 /2 ib")]
        vpsrlw_zmm_k1z_r32_imm8 = 4944,

        /// <summary>
        /// vpsrlw zmm {k1}{z}, zmm, m128 | EVEX.512.66.0F.WIG D1 /r | Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw zmm {k1}{z}, zmm, m128","EVEX.512.66.0F.WIG D1 /r")]
        vpsrlw_zmm_k1z_zmm_m128 = 4945,

        /// <summary>
        /// vpsrlw zmm {k1}{z}, zmm, r8 | EVEX.512.66.0F.WIG D1 /r | Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw zmm {k1}{z}, zmm, r8","EVEX.512.66.0F.WIG D1 /r")]
        vpsrlw_zmm_k1z_zmm_r8 = 4946,

        /// <summary>
        /// vpsrlw zmm, m512, imm8 | EVEX.512.66.0F.WIG 71 /2 ib | Shift words in zmm2/m512 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw zmm, m512, imm8","EVEX.512.66.0F.WIG 71 /2 ib")]
        vpsrlw_zmm_m512_imm8 = 4947,

        /// <summary>
        /// vpsrlw zmm, r32, imm8 | EVEX.512.66.0F.WIG 71 /2 ib | Shift words in zmm2/m512 right by imm8 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw zmm, r32, imm8","EVEX.512.66.0F.WIG 71 /2 ib")]
        vpsrlw_zmm_r32_imm8 = 4948,

        /// <summary>
        /// vpsrlw zmm, zmm, m128 | EVEX.512.66.0F.WIG D1 /r | Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw zmm, zmm, m128","EVEX.512.66.0F.WIG D1 /r")]
        vpsrlw_zmm_zmm_m128 = 4949,

        /// <summary>
        /// vpsrlw zmm, zmm, r8 | EVEX.512.66.0F.WIG D1 /r | Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.
        /// </summary>
        [Symbol("vpsrlw zmm, zmm, r8","EVEX.512.66.0F.WIG D1 /r")]
        vpsrlw_zmm_zmm_r8 = 4950,

        /// <summary>
        /// vpsubb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG F8 /r | Subtract packed byte integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG F8 /r")]
        vpsubb_xmm_k1z_xmm_m128 = 4951,

        /// <summary>
        /// vpsubb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG F8 /r | Subtract packed byte integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG F8 /r")]
        vpsubb_xmm_k1z_xmm_r8 = 4952,

        /// <summary>
        /// vpsubb xmm, xmm, m128 | EVEX.128.66.0F.WIG F8 /r | Subtract packed byte integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb xmm, xmm, m128","EVEX.128.66.0F.WIG F8 /r")]
        vpsubb_xmm_xmm_m128 = 4953,

        /// <summary>
        /// vpsubb xmm, xmm, m128 | VEX.128.66.0F.WIG F8 /r | Subtract packed byte integers in xmm3/m128 from xmm2.
        /// </summary>
        [Symbol("vpsubb xmm, xmm, m128","VEX.128.66.0F.WIG F8 /r")]
        vpsubb_xmm_xmm_m128_vex = 4954,

        /// <summary>
        /// vpsubb xmm, xmm, r8 | EVEX.128.66.0F.WIG F8 /r | Subtract packed byte integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb xmm, xmm, r8","EVEX.128.66.0F.WIG F8 /r")]
        vpsubb_xmm_xmm_r8 = 4955,

        /// <summary>
        /// vpsubb xmm, xmm, r8 | VEX.128.66.0F.WIG F8 /r | Subtract packed byte integers in xmm3/m128 from xmm2.
        /// </summary>
        [Symbol("vpsubb xmm, xmm, r8","VEX.128.66.0F.WIG F8 /r")]
        vpsubb_xmm_xmm_r8_vex = 4956,

        /// <summary>
        /// vpsubb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG F8 /r | Subtract packed byte integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG F8 /r")]
        vpsubb_ymm_k1z_ymm_m256 = 4957,

        /// <summary>
        /// vpsubb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG F8 /r | Subtract packed byte integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG F8 /r")]
        vpsubb_ymm_k1z_ymm_r16 = 4958,

        /// <summary>
        /// vpsubb ymm, ymm, m256 | EVEX.256.66.0F.WIG F8 /r | Subtract packed byte integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb ymm, ymm, m256","EVEX.256.66.0F.WIG F8 /r")]
        vpsubb_ymm_ymm_m256 = 4959,

        /// <summary>
        /// vpsubb ymm, ymm, m256 | VEX.256.66.0F.WIG F8 /r | Subtract packed byte integers in ymm3/m256 from ymm2.
        /// </summary>
        [Symbol("vpsubb ymm, ymm, m256","VEX.256.66.0F.WIG F8 /r")]
        vpsubb_ymm_ymm_m256_vex = 4960,

        /// <summary>
        /// vpsubb ymm, ymm, r16 | EVEX.256.66.0F.WIG F8 /r | Subtract packed byte integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb ymm, ymm, r16","EVEX.256.66.0F.WIG F8 /r")]
        vpsubb_ymm_ymm_r16 = 4961,

        /// <summary>
        /// vpsubb ymm, ymm, r16 | VEX.256.66.0F.WIG F8 /r | Subtract packed byte integers in ymm3/m256 from ymm2.
        /// </summary>
        [Symbol("vpsubb ymm, ymm, r16","VEX.256.66.0F.WIG F8 /r")]
        vpsubb_ymm_ymm_r16_vex = 4962,

        /// <summary>
        /// vpsubb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG F8 /r | Subtract packed byte integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG F8 /r")]
        vpsubb_zmm_k1z_zmm_m512 = 4963,

        /// <summary>
        /// vpsubb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG F8 /r | Subtract packed byte integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG F8 /r")]
        vpsubb_zmm_k1z_zmm_r32 = 4964,

        /// <summary>
        /// vpsubb zmm, zmm, m512 | EVEX.512.66.0F.WIG F8 /r | Subtract packed byte integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb zmm, zmm, m512","EVEX.512.66.0F.WIG F8 /r")]
        vpsubb_zmm_zmm_m512 = 4965,

        /// <summary>
        /// vpsubb zmm, zmm, r32 | EVEX.512.66.0F.WIG F8 /r | Subtract packed byte integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubb zmm, zmm, r32","EVEX.512.66.0F.WIG F8 /r")]
        vpsubb_zmm_zmm_r32 = 4966,

        /// <summary>
        /// vpsubd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 FA /r | Subtract packed doubleword integers in xmm3/m128/m32bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 FA /r")]
        vpsubd_xmm_k1z_xmm_m128 = 4967,

        /// <summary>
        /// vpsubd xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F.W0 FA /r | Subtract packed doubleword integers in xmm3/m128/m32bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F.W0 FA /r")]
        vpsubd_xmm_k1z_xmm_m32bcst = 4968,

        /// <summary>
        /// vpsubd xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W0 FA /r | Subtract packed doubleword integers in xmm3/m128/m32bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W0 FA /r")]
        vpsubd_xmm_k1z_xmm_xmm = 4969,

        /// <summary>
        /// vpsubd xmm, xmm, m128 | EVEX.128.66.0F.W0 FA /r | Subtract packed doubleword integers in xmm3/m128/m32bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd xmm, xmm, m128","EVEX.128.66.0F.W0 FA /r")]
        vpsubd_xmm_xmm_m128 = 4970,

        /// <summary>
        /// vpsubd xmm, xmm, m128 | VEX.128.66.0F.WIG FA /r | Subtract packed doubleword integers in xmm3/m128 from xmm2.
        /// </summary>
        [Symbol("vpsubd xmm, xmm, m128","VEX.128.66.0F.WIG FA /r")]
        vpsubd_xmm_xmm_m128_vex = 4971,

        /// <summary>
        /// vpsubd xmm, xmm, m32bcst | EVEX.128.66.0F.W0 FA /r | Subtract packed doubleword integers in xmm3/m128/m32bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd xmm, xmm, m32bcst","EVEX.128.66.0F.W0 FA /r")]
        vpsubd_xmm_xmm_m32bcst = 4972,

        /// <summary>
        /// vpsubd xmm, xmm, r8 | VEX.128.66.0F.WIG FA /r | Subtract packed doubleword integers in xmm3/m128 from xmm2.
        /// </summary>
        [Symbol("vpsubd xmm, xmm, r8","VEX.128.66.0F.WIG FA /r")]
        vpsubd_xmm_xmm_r8 = 4973,

        /// <summary>
        /// vpsubd xmm, xmm, xmm | EVEX.128.66.0F.W0 FA /r | Subtract packed doubleword integers in xmm3/m128/m32bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd xmm, xmm, xmm","EVEX.128.66.0F.W0 FA /r")]
        vpsubd_xmm_xmm_xmm = 4974,

        /// <summary>
        /// vpsubd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W0 FA /r | Subtract packed doubleword integers in ymm3/m256/m32bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W0 FA /r")]
        vpsubd_ymm_k1z_ymm_m256 = 4975,

        /// <summary>
        /// vpsubd ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F.W0 FA /r | Subtract packed doubleword integers in ymm3/m256/m32bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F.W0 FA /r")]
        vpsubd_ymm_k1z_ymm_m32bcst = 4976,

        /// <summary>
        /// vpsubd ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W0 FA /r | Subtract packed doubleword integers in ymm3/m256/m32bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W0 FA /r")]
        vpsubd_ymm_k1z_ymm_ymm = 4977,

        /// <summary>
        /// vpsubd ymm, ymm, m256 | EVEX.256.66.0F.W0 FA /r | Subtract packed doubleword integers in ymm3/m256/m32bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd ymm, ymm, m256","EVEX.256.66.0F.W0 FA /r")]
        vpsubd_ymm_ymm_m256 = 4978,

        /// <summary>
        /// vpsubd ymm, ymm, m256 | VEX.256.66.0F.WIG FA /r | Subtract packed doubleword integers in ymm3/m256 from ymm2.
        /// </summary>
        [Symbol("vpsubd ymm, ymm, m256","VEX.256.66.0F.WIG FA /r")]
        vpsubd_ymm_ymm_m256_vex = 4979,

        /// <summary>
        /// vpsubd ymm, ymm, m32bcst | EVEX.256.66.0F.W0 FA /r | Subtract packed doubleword integers in ymm3/m256/m32bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd ymm, ymm, m32bcst","EVEX.256.66.0F.W0 FA /r")]
        vpsubd_ymm_ymm_m32bcst = 4980,

        /// <summary>
        /// vpsubd ymm, ymm, r16 | VEX.256.66.0F.WIG FA /r | Subtract packed doubleword integers in ymm3/m256 from ymm2.
        /// </summary>
        [Symbol("vpsubd ymm, ymm, r16","VEX.256.66.0F.WIG FA /r")]
        vpsubd_ymm_ymm_r16 = 4981,

        /// <summary>
        /// vpsubd ymm, ymm, ymm | EVEX.256.66.0F.W0 FA /r | Subtract packed doubleword integers in ymm3/m256/m32bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubd ymm, ymm, ymm","EVEX.256.66.0F.W0 FA /r")]
        vpsubd_ymm_ymm_ymm = 4982,

        /// <summary>
        /// vpsubd zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F.W0 FA /r | Subtract packed doubleword integers in zmm3/m512/m32bcst from zmm2 and store in zmm1 using writemask k1
        /// </summary>
        [Symbol("vpsubd zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F.W0 FA /r")]
        vpsubd_zmm_k1z_zmm_m32bcst = 4983,

        /// <summary>
        /// vpsubd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W0 FA /r | Subtract packed doubleword integers in zmm3/m512/m32bcst from zmm2 and store in zmm1 using writemask k1
        /// </summary>
        [Symbol("vpsubd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W0 FA /r")]
        vpsubd_zmm_k1z_zmm_m512 = 4984,

        /// <summary>
        /// vpsubd zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W0 FA /r | Subtract packed doubleword integers in zmm3/m512/m32bcst from zmm2 and store in zmm1 using writemask k1
        /// </summary>
        [Symbol("vpsubd zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W0 FA /r")]
        vpsubd_zmm_k1z_zmm_zmm = 4985,

        /// <summary>
        /// vpsubd zmm, zmm, m32bcst | EVEX.512.66.0F.W0 FA /r | Subtract packed doubleword integers in zmm3/m512/m32bcst from zmm2 and store in zmm1 using writemask k1
        /// </summary>
        [Symbol("vpsubd zmm, zmm, m32bcst","EVEX.512.66.0F.W0 FA /r")]
        vpsubd_zmm_zmm_m32bcst = 4986,

        /// <summary>
        /// vpsubd zmm, zmm, m512 | EVEX.512.66.0F.W0 FA /r | Subtract packed doubleword integers in zmm3/m512/m32bcst from zmm2 and store in zmm1 using writemask k1
        /// </summary>
        [Symbol("vpsubd zmm, zmm, m512","EVEX.512.66.0F.W0 FA /r")]
        vpsubd_zmm_zmm_m512 = 4987,

        /// <summary>
        /// vpsubd zmm, zmm, zmm | EVEX.512.66.0F.W0 FA /r | Subtract packed doubleword integers in zmm3/m512/m32bcst from zmm2 and store in zmm1 using writemask k1
        /// </summary>
        [Symbol("vpsubd zmm, zmm, zmm","EVEX.512.66.0F.W0 FA /r")]
        vpsubd_zmm_zmm_zmm = 4988,

        /// <summary>
        /// vpsubq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 FB /r | Subtract packed quadword integers in xmm3/m128/m64bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 FB /r")]
        vpsubq_xmm_k1z_xmm_m128 = 4989,

        /// <summary>
        /// vpsubq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F.W1 FB /r | Subtract packed quadword integers in xmm3/m128/m64bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F.W1 FB /r")]
        vpsubq_xmm_k1z_xmm_m64bcst = 4990,

        /// <summary>
        /// vpsubq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W1 FB /r | Subtract packed quadword integers in xmm3/m128/m64bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W1 FB /r")]
        vpsubq_xmm_k1z_xmm_xmm = 4991,

        /// <summary>
        /// vpsubq xmm, xmm, m128 | EVEX.128.66.0F.W1 FB /r | Subtract packed quadword integers in xmm3/m128/m64bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq xmm, xmm, m128","EVEX.128.66.0F.W1 FB /r")]
        vpsubq_xmm_xmm_m128 = 4992,

        /// <summary>
        /// vpsubq xmm, xmm, m128 | VEX.128.66.0F.WIG FB /r | Subtract packed quadword integers in xmm3/m128 from xmm2.
        /// </summary>
        [Symbol("vpsubq xmm, xmm, m128","VEX.128.66.0F.WIG FB /r")]
        vpsubq_xmm_xmm_m128_vex = 4993,

        /// <summary>
        /// vpsubq xmm, xmm, m64bcst | EVEX.128.66.0F.W1 FB /r | Subtract packed quadword integers in xmm3/m128/m64bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq xmm, xmm, m64bcst","EVEX.128.66.0F.W1 FB /r")]
        vpsubq_xmm_xmm_m64bcst = 4994,

        /// <summary>
        /// vpsubq xmm, xmm, r8 | VEX.128.66.0F.WIG FB /r | Subtract packed quadword integers in xmm3/m128 from xmm2.
        /// </summary>
        [Symbol("vpsubq xmm, xmm, r8","VEX.128.66.0F.WIG FB /r")]
        vpsubq_xmm_xmm_r8 = 4995,

        /// <summary>
        /// vpsubq xmm, xmm, xmm | EVEX.128.66.0F.W1 FB /r | Subtract packed quadword integers in xmm3/m128/m64bcst from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq xmm, xmm, xmm","EVEX.128.66.0F.W1 FB /r")]
        vpsubq_xmm_xmm_xmm = 4996,

        /// <summary>
        /// vpsubq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W1 FB /r | Subtract packed quadword integers in ymm3/m256/m64bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W1 FB /r")]
        vpsubq_ymm_k1z_ymm_m256 = 4997,

        /// <summary>
        /// vpsubq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F.W1 FB /r | Subtract packed quadword integers in ymm3/m256/m64bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F.W1 FB /r")]
        vpsubq_ymm_k1z_ymm_m64bcst = 4998,

        /// <summary>
        /// vpsubq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W1 FB /r | Subtract packed quadword integers in ymm3/m256/m64bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W1 FB /r")]
        vpsubq_ymm_k1z_ymm_ymm = 4999,

        /// <summary>
        /// vpsubq ymm, ymm, m256 | EVEX.256.66.0F.W1 FB /r | Subtract packed quadword integers in ymm3/m256/m64bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq ymm, ymm, m256","EVEX.256.66.0F.W1 FB /r")]
        vpsubq_ymm_ymm_m256 = 5000,

        /// <summary>
        /// vpsubq ymm, ymm, m256 | VEX.256.66.0F.WIG FB /r | Subtract packed quadword integers in ymm3/m256 from ymm2.
        /// </summary>
        [Symbol("vpsubq ymm, ymm, m256","VEX.256.66.0F.WIG FB /r")]
        vpsubq_ymm_ymm_m256_vex = 5001,

        /// <summary>
        /// vpsubq ymm, ymm, m64bcst | EVEX.256.66.0F.W1 FB /r | Subtract packed quadword integers in ymm3/m256/m64bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq ymm, ymm, m64bcst","EVEX.256.66.0F.W1 FB /r")]
        vpsubq_ymm_ymm_m64bcst = 5002,

        /// <summary>
        /// vpsubq ymm, ymm, r16 | VEX.256.66.0F.WIG FB /r | Subtract packed quadword integers in ymm3/m256 from ymm2.
        /// </summary>
        [Symbol("vpsubq ymm, ymm, r16","VEX.256.66.0F.WIG FB /r")]
        vpsubq_ymm_ymm_r16 = 5003,

        /// <summary>
        /// vpsubq ymm, ymm, ymm | EVEX.256.66.0F.W1 FB /r | Subtract packed quadword integers in ymm3/m256/m64bcst from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq ymm, ymm, ymm","EVEX.256.66.0F.W1 FB /r")]
        vpsubq_ymm_ymm_ymm = 5004,

        /// <summary>
        /// vpsubq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W1 FB /r | Subtract packed quadword integers in zmm3/m512/m64bcst from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W1 FB /r")]
        vpsubq_zmm_k1z_zmm_m512 = 5005,

        /// <summary>
        /// vpsubq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F.W1 FB /r | Subtract packed quadword integers in zmm3/m512/m64bcst from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F.W1 FB /r")]
        vpsubq_zmm_k1z_zmm_m64bcst = 5006,

        /// <summary>
        /// vpsubq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W1 FB /r | Subtract packed quadword integers in zmm3/m512/m64bcst from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W1 FB /r")]
        vpsubq_zmm_k1z_zmm_zmm = 5007,

        /// <summary>
        /// vpsubq zmm, zmm, m512 | EVEX.512.66.0F.W1 FB /r | Subtract packed quadword integers in zmm3/m512/m64bcst from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq zmm, zmm, m512","EVEX.512.66.0F.W1 FB /r")]
        vpsubq_zmm_zmm_m512 = 5008,

        /// <summary>
        /// vpsubq zmm, zmm, m64bcst | EVEX.512.66.0F.W1 FB /r | Subtract packed quadword integers in zmm3/m512/m64bcst from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq zmm, zmm, m64bcst","EVEX.512.66.0F.W1 FB /r")]
        vpsubq_zmm_zmm_m64bcst = 5009,

        /// <summary>
        /// vpsubq zmm, zmm, zmm | EVEX.512.66.0F.W1 FB /r | Subtract packed quadword integers in zmm3/m512/m64bcst from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubq zmm, zmm, zmm","EVEX.512.66.0F.W1 FB /r")]
        vpsubq_zmm_zmm_zmm = 5010,

        /// <summary>
        /// vpsubsb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG E8 /r | Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG E8 /r")]
        vpsubsb_xmm_k1z_xmm_m128 = 5011,

        /// <summary>
        /// vpsubsb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG E8 /r | Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG E8 /r")]
        vpsubsb_xmm_k1z_xmm_r8 = 5012,

        /// <summary>
        /// vpsubsb xmm, xmm, m128 | EVEX.128.66.0F.WIG E8 /r | Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb xmm, xmm, m128","EVEX.128.66.0F.WIG E8 /r")]
        vpsubsb_xmm_xmm_m128 = 5013,

        /// <summary>
        /// vpsubsb xmm, xmm, m128 | VEX.128.66.0F.WIG E8 /r | Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results.
        /// </summary>
        [Symbol("vpsubsb xmm, xmm, m128","VEX.128.66.0F.WIG E8 /r")]
        vpsubsb_xmm_xmm_m128_vex = 5014,

        /// <summary>
        /// vpsubsb xmm, xmm, r8 | EVEX.128.66.0F.WIG E8 /r | Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb xmm, xmm, r8","EVEX.128.66.0F.WIG E8 /r")]
        vpsubsb_xmm_xmm_r8 = 5015,

        /// <summary>
        /// vpsubsb xmm, xmm, r8 | VEX.128.66.0F.WIG E8 /r | Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results.
        /// </summary>
        [Symbol("vpsubsb xmm, xmm, r8","VEX.128.66.0F.WIG E8 /r")]
        vpsubsb_xmm_xmm_r8_vex = 5016,

        /// <summary>
        /// vpsubsb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG E8 /r | Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG E8 /r")]
        vpsubsb_ymm_k1z_ymm_m256 = 5017,

        /// <summary>
        /// vpsubsb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG E8 /r | Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG E8 /r")]
        vpsubsb_ymm_k1z_ymm_r16 = 5018,

        /// <summary>
        /// vpsubsb ymm, ymm, m256 | EVEX.256.66.0F.WIG E8 /r | Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb ymm, ymm, m256","EVEX.256.66.0F.WIG E8 /r")]
        vpsubsb_ymm_ymm_m256 = 5019,

        /// <summary>
        /// vpsubsb ymm, ymm, m256 | VEX.256.66.0F.WIG E8 /r | Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results.
        /// </summary>
        [Symbol("vpsubsb ymm, ymm, m256","VEX.256.66.0F.WIG E8 /r")]
        vpsubsb_ymm_ymm_m256_vex = 5020,

        /// <summary>
        /// vpsubsb ymm, ymm, r16 | EVEX.256.66.0F.WIG E8 /r | Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb ymm, ymm, r16","EVEX.256.66.0F.WIG E8 /r")]
        vpsubsb_ymm_ymm_r16 = 5021,

        /// <summary>
        /// vpsubsb ymm, ymm, r16 | VEX.256.66.0F.WIG E8 /r | Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results.
        /// </summary>
        [Symbol("vpsubsb ymm, ymm, r16","VEX.256.66.0F.WIG E8 /r")]
        vpsubsb_ymm_ymm_r16_vex = 5022,

        /// <summary>
        /// vpsubsb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG E8 /r | Subtract packed signed byte integers in zmm3/m512 from packed signed byte integers in zmm2 and saturate results and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG E8 /r")]
        vpsubsb_zmm_k1z_zmm_m512 = 5023,

        /// <summary>
        /// vpsubsb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG E8 /r | Subtract packed signed byte integers in zmm3/m512 from packed signed byte integers in zmm2 and saturate results and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG E8 /r")]
        vpsubsb_zmm_k1z_zmm_r32 = 5024,

        /// <summary>
        /// vpsubsb zmm, zmm, m512 | EVEX.512.66.0F.WIG E8 /r | Subtract packed signed byte integers in zmm3/m512 from packed signed byte integers in zmm2 and saturate results and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb zmm, zmm, m512","EVEX.512.66.0F.WIG E8 /r")]
        vpsubsb_zmm_zmm_m512 = 5025,

        /// <summary>
        /// vpsubsb zmm, zmm, r32 | EVEX.512.66.0F.WIG E8 /r | Subtract packed signed byte integers in zmm3/m512 from packed signed byte integers in zmm2 and saturate results and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsb zmm, zmm, r32","EVEX.512.66.0F.WIG E8 /r")]
        vpsubsb_zmm_zmm_r32 = 5026,

        /// <summary>
        /// vpsubsw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG E9 /r | Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG E9 /r")]
        vpsubsw_xmm_k1z_xmm_m128 = 5027,

        /// <summary>
        /// vpsubsw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG E9 /r | Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG E9 /r")]
        vpsubsw_xmm_k1z_xmm_r8 = 5028,

        /// <summary>
        /// vpsubsw xmm, xmm, m128 | EVEX.128.66.0F.WIG E9 /r | Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsw xmm, xmm, m128","EVEX.128.66.0F.WIG E9 /r")]
        vpsubsw_xmm_xmm_m128 = 5029,

        /// <summary>
        /// vpsubsw xmm, xmm, m128 | VEX.128.66.0F.WIG E9 /r | Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results.
        /// </summary>
        [Symbol("vpsubsw xmm, xmm, m128","VEX.128.66.0F.WIG E9 /r")]
        vpsubsw_xmm_xmm_m128_vex = 5030,

        /// <summary>
        /// vpsubsw xmm, xmm, r8 | EVEX.128.66.0F.WIG E9 /r | Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsw xmm, xmm, r8","EVEX.128.66.0F.WIG E9 /r")]
        vpsubsw_xmm_xmm_r8 = 5031,

        /// <summary>
        /// vpsubsw xmm, xmm, r8 | VEX.128.66.0F.WIG E9 /r | Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results.
        /// </summary>
        [Symbol("vpsubsw xmm, xmm, r8","VEX.128.66.0F.WIG E9 /r")]
        vpsubsw_xmm_xmm_r8_vex = 5032,

        /// <summary>
        /// vpsubsw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG E9 /r | Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG E9 /r")]
        vpsubsw_ymm_k1z_ymm_m256 = 5033,

        /// <summary>
        /// vpsubsw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG E9 /r | Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG E9 /r")]
        vpsubsw_ymm_k1z_ymm_r16 = 5034,

        /// <summary>
        /// vpsubsw ymm, ymm, m256 | EVEX.256.66.0F.WIG E9 /r | Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsw ymm, ymm, m256","EVEX.256.66.0F.WIG E9 /r")]
        vpsubsw_ymm_ymm_m256 = 5035,

        /// <summary>
        /// vpsubsw ymm, ymm, m256 | VEX.256.66.0F.WIG E9 /r | Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results.
        /// </summary>
        [Symbol("vpsubsw ymm, ymm, m256","VEX.256.66.0F.WIG E9 /r")]
        vpsubsw_ymm_ymm_m256_vex = 5036,

        /// <summary>
        /// vpsubsw ymm, ymm, r16 | EVEX.256.66.0F.WIG E9 /r | Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubsw ymm, ymm, r16","EVEX.256.66.0F.WIG E9 /r")]
        vpsubsw_ymm_ymm_r16 = 5037,

        /// <summary>
        /// vpsubsw ymm, ymm, r16 | VEX.256.66.0F.WIG E9 /r | Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results.
        /// </summary>
        [Symbol("vpsubsw ymm, ymm, r16","VEX.256.66.0F.WIG E9 /r")]
        vpsubsw_ymm_ymm_r16_vex = 5038,

        /// <summary>
        /// vpsubusb xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2, saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG D8 /r")]
        vpsubusb_xmm_k1z_xmm_m128 = 5039,

        /// <summary>
        /// vpsubusb xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2, saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG D8 /r")]
        vpsubusb_xmm_k1z_xmm_r8 = 5040,

        /// <summary>
        /// vpsubusb xmm, xmm, m128 | EVEX.128.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2, saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb xmm, xmm, m128","EVEX.128.66.0F.WIG D8 /r")]
        vpsubusb_xmm_xmm_m128 = 5041,

        /// <summary>
        /// vpsubusb xmm, xmm, m128 | VEX.128.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2 and saturate result.
        /// </summary>
        [Symbol("vpsubusb xmm, xmm, m128","VEX.128.66.0F.WIG D8 /r")]
        vpsubusb_xmm_xmm_m128_vex = 5042,

        /// <summary>
        /// vpsubusb xmm, xmm, r8 | EVEX.128.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2, saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb xmm, xmm, r8","EVEX.128.66.0F.WIG D8 /r")]
        vpsubusb_xmm_xmm_r8 = 5043,

        /// <summary>
        /// vpsubusb xmm, xmm, r8 | VEX.128.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2 and saturate result.
        /// </summary>
        [Symbol("vpsubusb xmm, xmm, r8","VEX.128.66.0F.WIG D8 /r")]
        vpsubusb_xmm_xmm_r8_vex = 5044,

        /// <summary>
        /// vpsubusb ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2, saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG D8 /r")]
        vpsubusb_ymm_k1z_ymm_m256 = 5045,

        /// <summary>
        /// vpsubusb ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2, saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG D8 /r")]
        vpsubusb_ymm_k1z_ymm_r16 = 5046,

        /// <summary>
        /// vpsubusb ymm, ymm, m256 | EVEX.256.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2, saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb ymm, ymm, m256","EVEX.256.66.0F.WIG D8 /r")]
        vpsubusb_ymm_ymm_m256 = 5047,

        /// <summary>
        /// vpsubusb ymm, ymm, m256 | VEX.256.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2 and saturate result.
        /// </summary>
        [Symbol("vpsubusb ymm, ymm, m256","VEX.256.66.0F.WIG D8 /r")]
        vpsubusb_ymm_ymm_m256_vex = 5048,

        /// <summary>
        /// vpsubusb ymm, ymm, r16 | EVEX.256.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2, saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb ymm, ymm, r16","EVEX.256.66.0F.WIG D8 /r")]
        vpsubusb_ymm_ymm_r16 = 5049,

        /// <summary>
        /// vpsubusb ymm, ymm, r16 | VEX.256.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2 and saturate result.
        /// </summary>
        [Symbol("vpsubusb ymm, ymm, r16","VEX.256.66.0F.WIG D8 /r")]
        vpsubusb_ymm_ymm_r16_vex = 5050,

        /// <summary>
        /// vpsubusb zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in zmm3/m512 from packed unsigned byte integers in zmm2, saturate results and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG D8 /r")]
        vpsubusb_zmm_k1z_zmm_m512 = 5051,

        /// <summary>
        /// vpsubusb zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in zmm3/m512 from packed unsigned byte integers in zmm2, saturate results and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG D8 /r")]
        vpsubusb_zmm_k1z_zmm_r32 = 5052,

        /// <summary>
        /// vpsubusb zmm, zmm, m512 | EVEX.512.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in zmm3/m512 from packed unsigned byte integers in zmm2, saturate results and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb zmm, zmm, m512","EVEX.512.66.0F.WIG D8 /r")]
        vpsubusb_zmm_zmm_m512 = 5053,

        /// <summary>
        /// vpsubusb zmm, zmm, r32 | EVEX.512.66.0F.WIG D8 /r | Subtract packed unsigned byte integers in zmm3/m512 from packed unsigned byte integers in zmm2, saturate results and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusb zmm, zmm, r32","EVEX.512.66.0F.WIG D8 /r")]
        vpsubusb_zmm_zmm_r32 = 5054,

        /// <summary>
        /// vpsubusw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG D9 /r | Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG D9 /r")]
        vpsubusw_xmm_k1z_xmm_m128 = 5055,

        /// <summary>
        /// vpsubusw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG D9 /r | Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG D9 /r")]
        vpsubusw_xmm_k1z_xmm_r8 = 5056,

        /// <summary>
        /// vpsubusw xmm, xmm, m128 | EVEX.128.66.0F.WIG D9 /r | Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusw xmm, xmm, m128","EVEX.128.66.0F.WIG D9 /r")]
        vpsubusw_xmm_xmm_m128 = 5057,

        /// <summary>
        /// vpsubusw xmm, xmm, m128 | VEX.128.66.0F.WIG D9 /r | Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate result.
        /// </summary>
        [Symbol("vpsubusw xmm, xmm, m128","VEX.128.66.0F.WIG D9 /r")]
        vpsubusw_xmm_xmm_m128_vex = 5058,

        /// <summary>
        /// vpsubusw xmm, xmm, r8 | EVEX.128.66.0F.WIG D9 /r | Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate results and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusw xmm, xmm, r8","EVEX.128.66.0F.WIG D9 /r")]
        vpsubusw_xmm_xmm_r8 = 5059,

        /// <summary>
        /// vpsubusw xmm, xmm, r8 | VEX.128.66.0F.WIG D9 /r | Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate result.
        /// </summary>
        [Symbol("vpsubusw xmm, xmm, r8","VEX.128.66.0F.WIG D9 /r")]
        vpsubusw_xmm_xmm_r8_vex = 5060,

        /// <summary>
        /// vpsubusw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG D9 /r | Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2, saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG D9 /r")]
        vpsubusw_ymm_k1z_ymm_m256 = 5061,

        /// <summary>
        /// vpsubusw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG D9 /r | Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2, saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG D9 /r")]
        vpsubusw_ymm_k1z_ymm_r16 = 5062,

        /// <summary>
        /// vpsubusw ymm, ymm, m256 | EVEX.256.66.0F.WIG D9 /r | Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2, saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusw ymm, ymm, m256","EVEX.256.66.0F.WIG D9 /r")]
        vpsubusw_ymm_ymm_m256 = 5063,

        /// <summary>
        /// vpsubusw ymm, ymm, m256 | VEX.256.66.0F.WIG D9 /r | Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2 and saturate result.
        /// </summary>
        [Symbol("vpsubusw ymm, ymm, m256","VEX.256.66.0F.WIG D9 /r")]
        vpsubusw_ymm_ymm_m256_vex = 5064,

        /// <summary>
        /// vpsubusw ymm, ymm, r16 | EVEX.256.66.0F.WIG D9 /r | Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2, saturate results and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubusw ymm, ymm, r16","EVEX.256.66.0F.WIG D9 /r")]
        vpsubusw_ymm_ymm_r16 = 5065,

        /// <summary>
        /// vpsubusw ymm, ymm, r16 | VEX.256.66.0F.WIG D9 /r | Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2 and saturate result.
        /// </summary>
        [Symbol("vpsubusw ymm, ymm, r16","VEX.256.66.0F.WIG D9 /r")]
        vpsubusw_ymm_ymm_r16_vex = 5066,

        /// <summary>
        /// vpsubw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG F9 /r | Subtract packed word integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG F9 /r")]
        vpsubw_xmm_k1z_xmm_m128 = 5067,

        /// <summary>
        /// vpsubw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG F9 /r | Subtract packed word integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG F9 /r")]
        vpsubw_xmm_k1z_xmm_r8 = 5068,

        /// <summary>
        /// vpsubw xmm, xmm, m128 | EVEX.128.66.0F.WIG F9 /r | Subtract packed word integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw xmm, xmm, m128","EVEX.128.66.0F.WIG F9 /r")]
        vpsubw_xmm_xmm_m128 = 5069,

        /// <summary>
        /// vpsubw xmm, xmm, m128 | VEX.128.66.0F.WIG F9 /r | Subtract packed word integers in xmm3/m128 from xmm2.
        /// </summary>
        [Symbol("vpsubw xmm, xmm, m128","VEX.128.66.0F.WIG F9 /r")]
        vpsubw_xmm_xmm_m128_vex = 5070,

        /// <summary>
        /// vpsubw xmm, xmm, r8 | EVEX.128.66.0F.WIG F9 /r | Subtract packed word integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw xmm, xmm, r8","EVEX.128.66.0F.WIG F9 /r")]
        vpsubw_xmm_xmm_r8 = 5071,

        /// <summary>
        /// vpsubw xmm, xmm, r8 | VEX.128.66.0F.WIG F9 /r | Subtract packed word integers in xmm3/m128 from xmm2.
        /// </summary>
        [Symbol("vpsubw xmm, xmm, r8","VEX.128.66.0F.WIG F9 /r")]
        vpsubw_xmm_xmm_r8_vex = 5072,

        /// <summary>
        /// vpsubw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG F9 /r | Subtract packed word integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG F9 /r")]
        vpsubw_ymm_k1z_ymm_m256 = 5073,

        /// <summary>
        /// vpsubw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG F9 /r | Subtract packed word integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG F9 /r")]
        vpsubw_ymm_k1z_ymm_r16 = 5074,

        /// <summary>
        /// vpsubw ymm, ymm, m256 | EVEX.256.66.0F.WIG F9 /r | Subtract packed word integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw ymm, ymm, m256","EVEX.256.66.0F.WIG F9 /r")]
        vpsubw_ymm_ymm_m256 = 5075,

        /// <summary>
        /// vpsubw ymm, ymm, m256 | VEX.256.66.0F.WIG F9 /r | Subtract packed word integers in ymm3/m256 from ymm2.
        /// </summary>
        [Symbol("vpsubw ymm, ymm, m256","VEX.256.66.0F.WIG F9 /r")]
        vpsubw_ymm_ymm_m256_vex = 5076,

        /// <summary>
        /// vpsubw ymm, ymm, r16 | EVEX.256.66.0F.WIG F9 /r | Subtract packed word integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw ymm, ymm, r16","EVEX.256.66.0F.WIG F9 /r")]
        vpsubw_ymm_ymm_r16 = 5077,

        /// <summary>
        /// vpsubw ymm, ymm, r16 | VEX.256.66.0F.WIG F9 /r | Subtract packed word integers in ymm3/m256 from ymm2.
        /// </summary>
        [Symbol("vpsubw ymm, ymm, r16","VEX.256.66.0F.WIG F9 /r")]
        vpsubw_ymm_ymm_r16_vex = 5078,

        /// <summary>
        /// vpsubw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG F9 /r | Subtract packed word integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG F9 /r")]
        vpsubw_zmm_k1z_zmm_m512 = 5079,

        /// <summary>
        /// vpsubw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG F9 /r | Subtract packed word integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG F9 /r")]
        vpsubw_zmm_k1z_zmm_r32 = 5080,

        /// <summary>
        /// vpsubw zmm, zmm, m512 | EVEX.512.66.0F.WIG F9 /r | Subtract packed word integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw zmm, zmm, m512","EVEX.512.66.0F.WIG F9 /r")]
        vpsubw_zmm_zmm_m512 = 5081,

        /// <summary>
        /// vpsubw zmm, zmm, r32 | EVEX.512.66.0F.WIG F9 /r | Subtract packed word integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.
        /// </summary>
        [Symbol("vpsubw zmm, zmm, r32","EVEX.512.66.0F.WIG F9 /r")]
        vpsubw_zmm_zmm_r32 = 5082,

        /// <summary>
        /// vpternlogd xmm {k1}{z}, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m32bcst as source operands and writing the result to xmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd xmm {k1}{z}, xmm, m128, imm8","EVEX.128.66.0F3A.W0 25 /r ib")]
        vpternlogd_xmm_k1z_xmm_m128_imm8 = 5083,

        /// <summary>
        /// vpternlogd xmm {k1}{z}, xmm, m32bcst, imm8 | EVEX.128.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m32bcst as source operands and writing the result to xmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd xmm {k1}{z}, xmm, m32bcst, imm8","EVEX.128.66.0F3A.W0 25 /r ib")]
        vpternlogd_xmm_k1z_xmm_m32bcst_imm8 = 5084,

        /// <summary>
        /// vpternlogd xmm {k1}{z}, xmm, xmm, imm8 | EVEX.128.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m32bcst as source operands and writing the result to xmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd xmm {k1}{z}, xmm, xmm, imm8","EVEX.128.66.0F3A.W0 25 /r ib")]
        vpternlogd_xmm_k1z_xmm_xmm_imm8 = 5085,

        /// <summary>
        /// vpternlogd xmm, xmm, m128, imm8 | EVEX.128.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m32bcst as source operands and writing the result to xmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd xmm, xmm, m128, imm8","EVEX.128.66.0F3A.W0 25 /r ib")]
        vpternlogd_xmm_xmm_m128_imm8 = 5086,

        /// <summary>
        /// vpternlogd xmm, xmm, m32bcst, imm8 | EVEX.128.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m32bcst as source operands and writing the result to xmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd xmm, xmm, m32bcst, imm8","EVEX.128.66.0F3A.W0 25 /r ib")]
        vpternlogd_xmm_xmm_m32bcst_imm8 = 5087,

        /// <summary>
        /// vpternlogd xmm, xmm, xmm, imm8 | EVEX.128.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m32bcst as source operands and writing the result to xmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd xmm, xmm, xmm, imm8","EVEX.128.66.0F3A.W0 25 /r ib")]
        vpternlogd_xmm_xmm_xmm_imm8 = 5088,

        /// <summary>
        /// vpternlogd ymm {k1}{z}, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m32bcst as source operands and writing the result to ymm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd ymm {k1}{z}, ymm, m256, imm8","EVEX.256.66.0F3A.W0 25 /r ib")]
        vpternlogd_ymm_k1z_ymm_m256_imm8 = 5089,

        /// <summary>
        /// vpternlogd ymm {k1}{z}, ymm, m32bcst, imm8 | EVEX.256.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m32bcst as source operands and writing the result to ymm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd ymm {k1}{z}, ymm, m32bcst, imm8","EVEX.256.66.0F3A.W0 25 /r ib")]
        vpternlogd_ymm_k1z_ymm_m32bcst_imm8 = 5090,

        /// <summary>
        /// vpternlogd ymm {k1}{z}, ymm, ymm, imm8 | EVEX.256.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m32bcst as source operands and writing the result to ymm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd ymm {k1}{z}, ymm, ymm, imm8","EVEX.256.66.0F3A.W0 25 /r ib")]
        vpternlogd_ymm_k1z_ymm_ymm_imm8 = 5091,

        /// <summary>
        /// vpternlogd ymm, ymm, m256, imm8 | EVEX.256.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m32bcst as source operands and writing the result to ymm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd ymm, ymm, m256, imm8","EVEX.256.66.0F3A.W0 25 /r ib")]
        vpternlogd_ymm_ymm_m256_imm8 = 5092,

        /// <summary>
        /// vpternlogd ymm, ymm, m32bcst, imm8 | EVEX.256.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m32bcst as source operands and writing the result to ymm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd ymm, ymm, m32bcst, imm8","EVEX.256.66.0F3A.W0 25 /r ib")]
        vpternlogd_ymm_ymm_m32bcst_imm8 = 5093,

        /// <summary>
        /// vpternlogd ymm, ymm, ymm, imm8 | EVEX.256.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m32bcst as source operands and writing the result to ymm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd ymm, ymm, ymm, imm8","EVEX.256.66.0F3A.W0 25 /r ib")]
        vpternlogd_ymm_ymm_ymm_imm8 = 5094,

        /// <summary>
        /// vpternlogd zmm {k1}{z}, zmm, m32bcst, imm8 | EVEX.512.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m32bcst as source operands and writing the result to zmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd zmm {k1}{z}, zmm, m32bcst, imm8","EVEX.512.66.0F3A.W0 25 /r ib")]
        vpternlogd_zmm_k1z_zmm_m32bcst_imm8 = 5095,

        /// <summary>
        /// vpternlogd zmm {k1}{z}, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m32bcst as source operands and writing the result to zmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd zmm {k1}{z}, zmm, m512, imm8","EVEX.512.66.0F3A.W0 25 /r ib")]
        vpternlogd_zmm_k1z_zmm_m512_imm8 = 5096,

        /// <summary>
        /// vpternlogd zmm {k1}{z}, zmm, zmm, imm8 | EVEX.512.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m32bcst as source operands and writing the result to zmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd zmm {k1}{z}, zmm, zmm, imm8","EVEX.512.66.0F3A.W0 25 /r ib")]
        vpternlogd_zmm_k1z_zmm_zmm_imm8 = 5097,

        /// <summary>
        /// vpternlogd zmm, zmm, m32bcst, imm8 | EVEX.512.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m32bcst as source operands and writing the result to zmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd zmm, zmm, m32bcst, imm8","EVEX.512.66.0F3A.W0 25 /r ib")]
        vpternlogd_zmm_zmm_m32bcst_imm8 = 5098,

        /// <summary>
        /// vpternlogd zmm, zmm, m512, imm8 | EVEX.512.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m32bcst as source operands and writing the result to zmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd zmm, zmm, m512, imm8","EVEX.512.66.0F3A.W0 25 /r ib")]
        vpternlogd_zmm_zmm_m512_imm8 = 5099,

        /// <summary>
        /// vpternlogd zmm, zmm, zmm, imm8 | EVEX.512.66.0F3A.W0 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m32bcst as source operands and writing the result to zmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogd zmm, zmm, zmm, imm8","EVEX.512.66.0F3A.W0 25 /r ib")]
        vpternlogd_zmm_zmm_zmm_imm8 = 5100,

        /// <summary>
        /// vpternlogq xmm {k1}{z}, xmm, m128, imm8 | EVEX.128.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m64bcst as source operands and writing the result to xmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq xmm {k1}{z}, xmm, m128, imm8","EVEX.128.66.0F3A.W1 25 /r ib")]
        vpternlogq_xmm_k1z_xmm_m128_imm8 = 5101,

        /// <summary>
        /// vpternlogq xmm {k1}{z}, xmm, m64bcst, imm8 | EVEX.128.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m64bcst as source operands and writing the result to xmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq xmm {k1}{z}, xmm, m64bcst, imm8","EVEX.128.66.0F3A.W1 25 /r ib")]
        vpternlogq_xmm_k1z_xmm_m64bcst_imm8 = 5102,

        /// <summary>
        /// vpternlogq xmm {k1}{z}, xmm, xmm, imm8 | EVEX.128.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m64bcst as source operands and writing the result to xmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq xmm {k1}{z}, xmm, xmm, imm8","EVEX.128.66.0F3A.W1 25 /r ib")]
        vpternlogq_xmm_k1z_xmm_xmm_imm8 = 5103,

        /// <summary>
        /// vpternlogq xmm, xmm, m128, imm8 | EVEX.128.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m64bcst as source operands and writing the result to xmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq xmm, xmm, m128, imm8","EVEX.128.66.0F3A.W1 25 /r ib")]
        vpternlogq_xmm_xmm_m128_imm8 = 5104,

        /// <summary>
        /// vpternlogq xmm, xmm, m64bcst, imm8 | EVEX.128.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m64bcst as source operands and writing the result to xmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq xmm, xmm, m64bcst, imm8","EVEX.128.66.0F3A.W1 25 /r ib")]
        vpternlogq_xmm_xmm_m64bcst_imm8 = 5105,

        /// <summary>
        /// vpternlogq xmm, xmm, xmm, imm8 | EVEX.128.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m64bcst as source operands and writing the result to xmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq xmm, xmm, xmm, imm8","EVEX.128.66.0F3A.W1 25 /r ib")]
        vpternlogq_xmm_xmm_xmm_imm8 = 5106,

        /// <summary>
        /// vpternlogq ymm {k1}{z}, ymm, m256, imm8 | EVEX.256.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m64bcst as source operands and writing the result to ymm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq ymm {k1}{z}, ymm, m256, imm8","EVEX.256.66.0F3A.W1 25 /r ib")]
        vpternlogq_ymm_k1z_ymm_m256_imm8 = 5107,

        /// <summary>
        /// vpternlogq ymm {k1}{z}, ymm, m64bcst, imm8 | EVEX.256.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m64bcst as source operands and writing the result to ymm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq ymm {k1}{z}, ymm, m64bcst, imm8","EVEX.256.66.0F3A.W1 25 /r ib")]
        vpternlogq_ymm_k1z_ymm_m64bcst_imm8 = 5108,

        /// <summary>
        /// vpternlogq ymm {k1}{z}, ymm, ymm, imm8 | EVEX.256.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m64bcst as source operands and writing the result to ymm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq ymm {k1}{z}, ymm, ymm, imm8","EVEX.256.66.0F3A.W1 25 /r ib")]
        vpternlogq_ymm_k1z_ymm_ymm_imm8 = 5109,

        /// <summary>
        /// vpternlogq ymm, ymm, m256, imm8 | EVEX.256.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m64bcst as source operands and writing the result to ymm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq ymm, ymm, m256, imm8","EVEX.256.66.0F3A.W1 25 /r ib")]
        vpternlogq_ymm_ymm_m256_imm8 = 5110,

        /// <summary>
        /// vpternlogq ymm, ymm, m64bcst, imm8 | EVEX.256.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m64bcst as source operands and writing the result to ymm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq ymm, ymm, m64bcst, imm8","EVEX.256.66.0F3A.W1 25 /r ib")]
        vpternlogq_ymm_ymm_m64bcst_imm8 = 5111,

        /// <summary>
        /// vpternlogq ymm, ymm, ymm, imm8 | EVEX.256.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m64bcst as source operands and writing the result to ymm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq ymm, ymm, ymm, imm8","EVEX.256.66.0F3A.W1 25 /r ib")]
        vpternlogq_ymm_ymm_ymm_imm8 = 5112,

        /// <summary>
        /// vpternlogq zmm {k1}{z}, zmm, m512, imm8 | EVEX.512.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m64bcst as source operands and writing the result to zmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq zmm {k1}{z}, zmm, m512, imm8","EVEX.512.66.0F3A.W1 25 /r ib")]
        vpternlogq_zmm_k1z_zmm_m512_imm8 = 5113,

        /// <summary>
        /// vpternlogq zmm {k1}{z}, zmm, m64bcst, imm8 | EVEX.512.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m64bcst as source operands and writing the result to zmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq zmm {k1}{z}, zmm, m64bcst, imm8","EVEX.512.66.0F3A.W1 25 /r ib")]
        vpternlogq_zmm_k1z_zmm_m64bcst_imm8 = 5114,

        /// <summary>
        /// vpternlogq zmm {k1}{z}, zmm, zmm, imm8 | EVEX.512.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m64bcst as source operands and writing the result to zmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq zmm {k1}{z}, zmm, zmm, imm8","EVEX.512.66.0F3A.W1 25 /r ib")]
        vpternlogq_zmm_k1z_zmm_zmm_imm8 = 5115,

        /// <summary>
        /// vpternlogq zmm, zmm, m512, imm8 | EVEX.512.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m64bcst as source operands and writing the result to zmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq zmm, zmm, m512, imm8","EVEX.512.66.0F3A.W1 25 /r ib")]
        vpternlogq_zmm_zmm_m512_imm8 = 5116,

        /// <summary>
        /// vpternlogq zmm, zmm, m64bcst, imm8 | EVEX.512.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m64bcst as source operands and writing the result to zmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq zmm, zmm, m64bcst, imm8","EVEX.512.66.0F3A.W1 25 /r ib")]
        vpternlogq_zmm_zmm_m64bcst_imm8 = 5117,

        /// <summary>
        /// vpternlogq zmm, zmm, zmm, imm8 | EVEX.512.66.0F3A.W1 25 /r ib | Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m64bcst as source operands and writing the result to zmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.
        /// </summary>
        [Symbol("vpternlogq zmm, zmm, zmm, imm8","EVEX.512.66.0F3A.W1 25 /r ib")]
        vpternlogq_zmm_zmm_zmm_imm8 = 5118,

        /// <summary>
        /// vptest xmm, m128 | VEX.128.66.0F38.WIG 17 /r | Set ZF and CF depending on bitwise AND and ANDN of sources.
        /// </summary>
        [Symbol("vptest xmm, m128","VEX.128.66.0F38.WIG 17 /r")]
        vptest_xmm_m128 = 5119,

        /// <summary>
        /// vptest xmm, r8 | VEX.128.66.0F38.WIG 17 /r | Set ZF and CF depending on bitwise AND and ANDN of sources.
        /// </summary>
        [Symbol("vptest xmm, r8","VEX.128.66.0F38.WIG 17 /r")]
        vptest_xmm_r8 = 5120,

        /// <summary>
        /// vptest ymm, m256 | VEX.256.66.0F38.WIG 17 /r | Set ZF and CF depending on bitwise AND and ANDN of sources.
        /// </summary>
        [Symbol("vptest ymm, m256","VEX.256.66.0F38.WIG 17 /r")]
        vptest_ymm_m256 = 5121,

        /// <summary>
        /// vptest ymm, r16 | VEX.256.66.0F38.WIG 17 /r | Set ZF and CF depending on bitwise AND and ANDN of sources.
        /// </summary>
        [Symbol("vptest ymm, r16","VEX.256.66.0F38.WIG 17 /r")]
        vptest_ymm_r16 = 5122,

        /// <summary>
        /// vptestmb k2 {k1}, xmm, m128 | EVEX.128.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2 {k1}, xmm, m128","EVEX.128.66.0F38.W0 26 /r")]
        vptestmb_k2_k1_xmm_m128 = 5123,

        /// <summary>
        /// vptestmb k2 {k1}, xmm, r8 | EVEX.128.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2 {k1}, xmm, r8","EVEX.128.66.0F38.W0 26 /r")]
        vptestmb_k2_k1_xmm_r8 = 5124,

        /// <summary>
        /// vptestmb k2 {k1}, ymm, m256 | EVEX.256.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2 {k1}, ymm, m256","EVEX.256.66.0F38.W0 26 /r")]
        vptestmb_k2_k1_ymm_m256 = 5125,

        /// <summary>
        /// vptestmb k2 {k1}, ymm, r16 | EVEX.256.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2 {k1}, ymm, r16","EVEX.256.66.0F38.W0 26 /r")]
        vptestmb_k2_k1_ymm_r16 = 5126,

        /// <summary>
        /// vptestmb k2 {k1}, zmm, m512 | EVEX.512.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2 {k1}, zmm, m512","EVEX.512.66.0F38.W0 26 /r")]
        vptestmb_k2_k1_zmm_m512 = 5127,

        /// <summary>
        /// vptestmb k2 {k1}, zmm, r32 | EVEX.512.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2 {k1}, zmm, r32","EVEX.512.66.0F38.W0 26 /r")]
        vptestmb_k2_k1_zmm_r32 = 5128,

        /// <summary>
        /// vptestmb k2, xmm, m128 | EVEX.128.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2, xmm, m128","EVEX.128.66.0F38.W0 26 /r")]
        vptestmb_k2_xmm_m128 = 5129,

        /// <summary>
        /// vptestmb k2, xmm, r8 | EVEX.128.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2, xmm, r8","EVEX.128.66.0F38.W0 26 /r")]
        vptestmb_k2_xmm_r8 = 5130,

        /// <summary>
        /// vptestmb k2, ymm, m256 | EVEX.256.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2, ymm, m256","EVEX.256.66.0F38.W0 26 /r")]
        vptestmb_k2_ymm_m256 = 5131,

        /// <summary>
        /// vptestmb k2, ymm, r16 | EVEX.256.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2, ymm, r16","EVEX.256.66.0F38.W0 26 /r")]
        vptestmb_k2_ymm_r16 = 5132,

        /// <summary>
        /// vptestmb k2, zmm, m512 | EVEX.512.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2, zmm, m512","EVEX.512.66.0F38.W0 26 /r")]
        vptestmb_k2_zmm_m512 = 5133,

        /// <summary>
        /// vptestmb k2, zmm, r32 | EVEX.512.66.0F38.W0 26 /r | Bitwise AND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmb k2, zmm, r32","EVEX.512.66.0F38.W0 26 /r")]
        vptestmb_k2_zmm_r32 = 5134,

        /// <summary>
        /// vptestmd k2 {k1}, xmm, m128 | EVEX.128.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2 {k1}, xmm, m128","EVEX.128.66.0F38.W0 27 /r")]
        vptestmd_k2_k1_xmm_m128 = 5135,

        /// <summary>
        /// vptestmd k2 {k1}, xmm, m32bcst | EVEX.128.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2 {k1}, xmm, m32bcst","EVEX.128.66.0F38.W0 27 /r")]
        vptestmd_k2_k1_xmm_m32bcst = 5136,

        /// <summary>
        /// vptestmd k2 {k1}, xmm, xmm | EVEX.128.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2 {k1}, xmm, xmm","EVEX.128.66.0F38.W0 27 /r")]
        vptestmd_k2_k1_xmm_xmm = 5137,

        /// <summary>
        /// vptestmd k2 {k1}, ymm, m256 | EVEX.256.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2 {k1}, ymm, m256","EVEX.256.66.0F38.W0 27 /r")]
        vptestmd_k2_k1_ymm_m256 = 5138,

        /// <summary>
        /// vptestmd k2 {k1}, ymm, m32bcst | EVEX.256.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2 {k1}, ymm, m32bcst","EVEX.256.66.0F38.W0 27 /r")]
        vptestmd_k2_k1_ymm_m32bcst = 5139,

        /// <summary>
        /// vptestmd k2 {k1}, ymm, ymm | EVEX.256.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2 {k1}, ymm, ymm","EVEX.256.66.0F38.W0 27 /r")]
        vptestmd_k2_k1_ymm_ymm = 5140,

        /// <summary>
        /// vptestmd k2 {k1}, zmm, m32bcst | EVEX.512.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2 {k1}, zmm, m32bcst","EVEX.512.66.0F38.W0 27 /r")]
        vptestmd_k2_k1_zmm_m32bcst = 5141,

        /// <summary>
        /// vptestmd k2 {k1}, zmm, m512 | EVEX.512.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2 {k1}, zmm, m512","EVEX.512.66.0F38.W0 27 /r")]
        vptestmd_k2_k1_zmm_m512 = 5142,

        /// <summary>
        /// vptestmd k2 {k1}, zmm, zmm | EVEX.512.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2 {k1}, zmm, zmm","EVEX.512.66.0F38.W0 27 /r")]
        vptestmd_k2_k1_zmm_zmm = 5143,

        /// <summary>
        /// vptestmd k2, xmm, m128 | EVEX.128.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2, xmm, m128","EVEX.128.66.0F38.W0 27 /r")]
        vptestmd_k2_xmm_m128 = 5144,

        /// <summary>
        /// vptestmd k2, xmm, m32bcst | EVEX.128.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2, xmm, m32bcst","EVEX.128.66.0F38.W0 27 /r")]
        vptestmd_k2_xmm_m32bcst = 5145,

        /// <summary>
        /// vptestmd k2, xmm, xmm | EVEX.128.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2, xmm, xmm","EVEX.128.66.0F38.W0 27 /r")]
        vptestmd_k2_xmm_xmm = 5146,

        /// <summary>
        /// vptestmd k2, ymm, m256 | EVEX.256.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2, ymm, m256","EVEX.256.66.0F38.W0 27 /r")]
        vptestmd_k2_ymm_m256 = 5147,

        /// <summary>
        /// vptestmd k2, ymm, m32bcst | EVEX.256.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2, ymm, m32bcst","EVEX.256.66.0F38.W0 27 /r")]
        vptestmd_k2_ymm_m32bcst = 5148,

        /// <summary>
        /// vptestmd k2, ymm, ymm | EVEX.256.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2, ymm, ymm","EVEX.256.66.0F38.W0 27 /r")]
        vptestmd_k2_ymm_ymm = 5149,

        /// <summary>
        /// vptestmd k2, zmm, m32bcst | EVEX.512.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2, zmm, m32bcst","EVEX.512.66.0F38.W0 27 /r")]
        vptestmd_k2_zmm_m32bcst = 5150,

        /// <summary>
        /// vptestmd k2, zmm, m512 | EVEX.512.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2, zmm, m512","EVEX.512.66.0F38.W0 27 /r")]
        vptestmd_k2_zmm_m512 = 5151,

        /// <summary>
        /// vptestmd k2, zmm, zmm | EVEX.512.66.0F38.W0 27 /r | Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmd k2, zmm, zmm","EVEX.512.66.0F38.W0 27 /r")]
        vptestmd_k2_zmm_zmm = 5152,

        /// <summary>
        /// vptestmq k2 {k1}, xmm, m128 | EVEX.128.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2 {k1}, xmm, m128","EVEX.128.66.0F38.W1 27 /r")]
        vptestmq_k2_k1_xmm_m128 = 5153,

        /// <summary>
        /// vptestmq k2 {k1}, xmm, m64bcst | EVEX.128.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2 {k1}, xmm, m64bcst","EVEX.128.66.0F38.W1 27 /r")]
        vptestmq_k2_k1_xmm_m64bcst = 5154,

        /// <summary>
        /// vptestmq k2 {k1}, xmm, xmm | EVEX.128.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2 {k1}, xmm, xmm","EVEX.128.66.0F38.W1 27 /r")]
        vptestmq_k2_k1_xmm_xmm = 5155,

        /// <summary>
        /// vptestmq k2 {k1}, ymm, m256 | EVEX.256.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2 {k1}, ymm, m256","EVEX.256.66.0F38.W1 27 /r")]
        vptestmq_k2_k1_ymm_m256 = 5156,

        /// <summary>
        /// vptestmq k2 {k1}, ymm, m64bcst | EVEX.256.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2 {k1}, ymm, m64bcst","EVEX.256.66.0F38.W1 27 /r")]
        vptestmq_k2_k1_ymm_m64bcst = 5157,

        /// <summary>
        /// vptestmq k2 {k1}, ymm, ymm | EVEX.256.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2 {k1}, ymm, ymm","EVEX.256.66.0F38.W1 27 /r")]
        vptestmq_k2_k1_ymm_ymm = 5158,

        /// <summary>
        /// vptestmq k2 {k1}, zmm, m512 | EVEX.512.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2 {k1}, zmm, m512","EVEX.512.66.0F38.W1 27 /r")]
        vptestmq_k2_k1_zmm_m512 = 5159,

        /// <summary>
        /// vptestmq k2 {k1}, zmm, m64bcst | EVEX.512.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2 {k1}, zmm, m64bcst","EVEX.512.66.0F38.W1 27 /r")]
        vptestmq_k2_k1_zmm_m64bcst = 5160,

        /// <summary>
        /// vptestmq k2 {k1}, zmm, zmm | EVEX.512.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2 {k1}, zmm, zmm","EVEX.512.66.0F38.W1 27 /r")]
        vptestmq_k2_k1_zmm_zmm = 5161,

        /// <summary>
        /// vptestmq k2, xmm, m128 | EVEX.128.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2, xmm, m128","EVEX.128.66.0F38.W1 27 /r")]
        vptestmq_k2_xmm_m128 = 5162,

        /// <summary>
        /// vptestmq k2, xmm, m64bcst | EVEX.128.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2, xmm, m64bcst","EVEX.128.66.0F38.W1 27 /r")]
        vptestmq_k2_xmm_m64bcst = 5163,

        /// <summary>
        /// vptestmq k2, xmm, xmm | EVEX.128.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2, xmm, xmm","EVEX.128.66.0F38.W1 27 /r")]
        vptestmq_k2_xmm_xmm = 5164,

        /// <summary>
        /// vptestmq k2, ymm, m256 | EVEX.256.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2, ymm, m256","EVEX.256.66.0F38.W1 27 /r")]
        vptestmq_k2_ymm_m256 = 5165,

        /// <summary>
        /// vptestmq k2, ymm, m64bcst | EVEX.256.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2, ymm, m64bcst","EVEX.256.66.0F38.W1 27 /r")]
        vptestmq_k2_ymm_m64bcst = 5166,

        /// <summary>
        /// vptestmq k2, ymm, ymm | EVEX.256.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2, ymm, ymm","EVEX.256.66.0F38.W1 27 /r")]
        vptestmq_k2_ymm_ymm = 5167,

        /// <summary>
        /// vptestmq k2, zmm, m512 | EVEX.512.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2, zmm, m512","EVEX.512.66.0F38.W1 27 /r")]
        vptestmq_k2_zmm_m512 = 5168,

        /// <summary>
        /// vptestmq k2, zmm, m64bcst | EVEX.512.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2, zmm, m64bcst","EVEX.512.66.0F38.W1 27 /r")]
        vptestmq_k2_zmm_m64bcst = 5169,

        /// <summary>
        /// vptestmq k2, zmm, zmm | EVEX.512.66.0F38.W1 27 /r | Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmq k2, zmm, zmm","EVEX.512.66.0F38.W1 27 /r")]
        vptestmq_k2_zmm_zmm = 5170,

        /// <summary>
        /// vptestmw k2 {k1}, xmm, m128 | EVEX.128.66.0F38.W1 26 /r | Bitwise AND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2 {k1}, xmm, m128","EVEX.128.66.0F38.W1 26 /r")]
        vptestmw_k2_k1_xmm_m128 = 5171,

        /// <summary>
        /// vptestmw k2 {k1}, xmm, r8 | EVEX.128.66.0F38.W1 26 /r | Bitwise AND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2 {k1}, xmm, r8","EVEX.128.66.0F38.W1 26 /r")]
        vptestmw_k2_k1_xmm_r8 = 5172,

        /// <summary>
        /// vptestmw k2 {k1}, ymm, m256 | EVEX.256.66.0F38.W1 26 /r | Bitwise AND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2 {k1}, ymm, m256","EVEX.256.66.0F38.W1 26 /r")]
        vptestmw_k2_k1_ymm_m256 = 5173,

        /// <summary>
        /// vptestmw k2 {k1}, ymm, r16 | EVEX.256.66.0F38.W1 26 /r | Bitwise AND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2 {k1}, ymm, r16","EVEX.256.66.0F38.W1 26 /r")]
        vptestmw_k2_k1_ymm_r16 = 5174,

        /// <summary>
        /// vptestmw k2 {k1}, zmm, m512 | EVEX.512.66.0F38.W1 26 /r | Bitwise AND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2 {k1}, zmm, m512","EVEX.512.66.0F38.W1 26 /r")]
        vptestmw_k2_k1_zmm_m512 = 5175,

        /// <summary>
        /// vptestmw k2 {k1}, zmm, r32 | EVEX.512.66.0F38.W1 26 /r | Bitwise AND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2 {k1}, zmm, r32","EVEX.512.66.0F38.W1 26 /r")]
        vptestmw_k2_k1_zmm_r32 = 5176,

        /// <summary>
        /// vptestmw k2, xmm, m128 | EVEX.128.66.0F38.W1 26 /r | Bitwise AND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2, xmm, m128","EVEX.128.66.0F38.W1 26 /r")]
        vptestmw_k2_xmm_m128 = 5177,

        /// <summary>
        /// vptestmw k2, xmm, r8 | EVEX.128.66.0F38.W1 26 /r | Bitwise AND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2, xmm, r8","EVEX.128.66.0F38.W1 26 /r")]
        vptestmw_k2_xmm_r8 = 5178,

        /// <summary>
        /// vptestmw k2, ymm, m256 | EVEX.256.66.0F38.W1 26 /r | Bitwise AND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2, ymm, m256","EVEX.256.66.0F38.W1 26 /r")]
        vptestmw_k2_ymm_m256 = 5179,

        /// <summary>
        /// vptestmw k2, ymm, r16 | EVEX.256.66.0F38.W1 26 /r | Bitwise AND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2, ymm, r16","EVEX.256.66.0F38.W1 26 /r")]
        vptestmw_k2_ymm_r16 = 5180,

        /// <summary>
        /// vptestmw k2, zmm, m512 | EVEX.512.66.0F38.W1 26 /r | Bitwise AND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2, zmm, m512","EVEX.512.66.0F38.W1 26 /r")]
        vptestmw_k2_zmm_m512 = 5181,

        /// <summary>
        /// vptestmw k2, zmm, r32 | EVEX.512.66.0F38.W1 26 /r | Bitwise AND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestmw k2, zmm, r32","EVEX.512.66.0F38.W1 26 /r")]
        vptestmw_k2_zmm_r32 = 5182,

        /// <summary>
        /// vptestnmb k2 {k1}, xmm, m128 | EVEX.128.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2 {k1}, xmm, m128","EVEX.128.F3.0F38.W0 26 /r")]
        vptestnmb_k2_k1_xmm_m128 = 5183,

        /// <summary>
        /// vptestnmb k2 {k1}, xmm, r8 | EVEX.128.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2 {k1}, xmm, r8","EVEX.128.F3.0F38.W0 26 /r")]
        vptestnmb_k2_k1_xmm_r8 = 5184,

        /// <summary>
        /// vptestnmb k2 {k1}, ymm, m256 | EVEX.256.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2 {k1}, ymm, m256","EVEX.256.F3.0F38.W0 26 /r")]
        vptestnmb_k2_k1_ymm_m256 = 5185,

        /// <summary>
        /// vptestnmb k2 {k1}, ymm, r16 | EVEX.256.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2 {k1}, ymm, r16","EVEX.256.F3.0F38.W0 26 /r")]
        vptestnmb_k2_k1_ymm_r16 = 5186,

        /// <summary>
        /// vptestnmb k2 {k1}, zmm, m512 | EVEX.512.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2 {k1}, zmm, m512","EVEX.512.F3.0F38.W0 26 /r")]
        vptestnmb_k2_k1_zmm_m512 = 5187,

        /// <summary>
        /// vptestnmb k2 {k1}, zmm, r32 | EVEX.512.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2 {k1}, zmm, r32","EVEX.512.F3.0F38.W0 26 /r")]
        vptestnmb_k2_k1_zmm_r32 = 5188,

        /// <summary>
        /// vptestnmb k2, xmm, m128 | EVEX.128.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2, xmm, m128","EVEX.128.F3.0F38.W0 26 /r")]
        vptestnmb_k2_xmm_m128 = 5189,

        /// <summary>
        /// vptestnmb k2, xmm, r8 | EVEX.128.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2, xmm, r8","EVEX.128.F3.0F38.W0 26 /r")]
        vptestnmb_k2_xmm_r8 = 5190,

        /// <summary>
        /// vptestnmb k2, ymm, m256 | EVEX.256.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2, ymm, m256","EVEX.256.F3.0F38.W0 26 /r")]
        vptestnmb_k2_ymm_m256 = 5191,

        /// <summary>
        /// vptestnmb k2, ymm, r16 | EVEX.256.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2, ymm, r16","EVEX.256.F3.0F38.W0 26 /r")]
        vptestnmb_k2_ymm_r16 = 5192,

        /// <summary>
        /// vptestnmb k2, zmm, m512 | EVEX.512.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2, zmm, m512","EVEX.512.F3.0F38.W0 26 /r")]
        vptestnmb_k2_zmm_m512 = 5193,

        /// <summary>
        /// vptestnmb k2, zmm, r32 | EVEX.512.F3.0F38.W0 26 /r | Bitwise NAND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmb k2, zmm, r32","EVEX.512.F3.0F38.W0 26 /r")]
        vptestnmb_k2_zmm_r32 = 5194,

        /// <summary>
        /// vptestnmd k2 {k1}, xmm, m128 | EVEX.128.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2 {k1}, xmm, m128","EVEX.128.F3.0F38.W0 27 /r")]
        vptestnmd_k2_k1_xmm_m128 = 5195,

        /// <summary>
        /// vptestnmd k2 {k1}, xmm, m32bcst | EVEX.128.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2 {k1}, xmm, m32bcst","EVEX.128.F3.0F38.W0 27 /r")]
        vptestnmd_k2_k1_xmm_m32bcst = 5196,

        /// <summary>
        /// vptestnmd k2 {k1}, xmm, xmm | EVEX.128.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2 {k1}, xmm, xmm","EVEX.128.F3.0F38.W0 27 /r")]
        vptestnmd_k2_k1_xmm_xmm = 5197,

        /// <summary>
        /// vptestnmd k2 {k1}, ymm, m256 | EVEX.256.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2 {k1}, ymm, m256","EVEX.256.F3.0F38.W0 27 /r")]
        vptestnmd_k2_k1_ymm_m256 = 5198,

        /// <summary>
        /// vptestnmd k2 {k1}, ymm, m32bcst | EVEX.256.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2 {k1}, ymm, m32bcst","EVEX.256.F3.0F38.W0 27 /r")]
        vptestnmd_k2_k1_ymm_m32bcst = 5199,

        /// <summary>
        /// vptestnmd k2 {k1}, ymm, ymm | EVEX.256.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2 {k1}, ymm, ymm","EVEX.256.F3.0F38.W0 27 /r")]
        vptestnmd_k2_k1_ymm_ymm = 5200,

        /// <summary>
        /// vptestnmd k2 {k1}, zmm, m32bcst | EVEX.512.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2 {k1}, zmm, m32bcst","EVEX.512.F3.0F38.W0 27 /r")]
        vptestnmd_k2_k1_zmm_m32bcst = 5201,

        /// <summary>
        /// vptestnmd k2 {k1}, zmm, m512 | EVEX.512.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2 {k1}, zmm, m512","EVEX.512.F3.0F38.W0 27 /r")]
        vptestnmd_k2_k1_zmm_m512 = 5202,

        /// <summary>
        /// vptestnmd k2 {k1}, zmm, zmm | EVEX.512.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2 {k1}, zmm, zmm","EVEX.512.F3.0F38.W0 27 /r")]
        vptestnmd_k2_k1_zmm_zmm = 5203,

        /// <summary>
        /// vptestnmd k2, xmm, m128 | EVEX.128.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2, xmm, m128","EVEX.128.F3.0F38.W0 27 /r")]
        vptestnmd_k2_xmm_m128 = 5204,

        /// <summary>
        /// vptestnmd k2, xmm, m32bcst | EVEX.128.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2, xmm, m32bcst","EVEX.128.F3.0F38.W0 27 /r")]
        vptestnmd_k2_xmm_m32bcst = 5205,

        /// <summary>
        /// vptestnmd k2, xmm, xmm | EVEX.128.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2, xmm, xmm","EVEX.128.F3.0F38.W0 27 /r")]
        vptestnmd_k2_xmm_xmm = 5206,

        /// <summary>
        /// vptestnmd k2, ymm, m256 | EVEX.256.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2, ymm, m256","EVEX.256.F3.0F38.W0 27 /r")]
        vptestnmd_k2_ymm_m256 = 5207,

        /// <summary>
        /// vptestnmd k2, ymm, m32bcst | EVEX.256.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2, ymm, m32bcst","EVEX.256.F3.0F38.W0 27 /r")]
        vptestnmd_k2_ymm_m32bcst = 5208,

        /// <summary>
        /// vptestnmd k2, ymm, ymm | EVEX.256.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2, ymm, ymm","EVEX.256.F3.0F38.W0 27 /r")]
        vptestnmd_k2_ymm_ymm = 5209,

        /// <summary>
        /// vptestnmd k2, zmm, m32bcst | EVEX.512.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2, zmm, m32bcst","EVEX.512.F3.0F38.W0 27 /r")]
        vptestnmd_k2_zmm_m32bcst = 5210,

        /// <summary>
        /// vptestnmd k2, zmm, m512 | EVEX.512.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2, zmm, m512","EVEX.512.F3.0F38.W0 27 /r")]
        vptestnmd_k2_zmm_m512 = 5211,

        /// <summary>
        /// vptestnmd k2, zmm, zmm | EVEX.512.F3.0F38.W0 27 /r | Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmd k2, zmm, zmm","EVEX.512.F3.0F38.W0 27 /r")]
        vptestnmd_k2_zmm_zmm = 5212,

        /// <summary>
        /// vptestnmq k2 {k1}, xmm, m128 | EVEX.128.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2 {k1}, xmm, m128","EVEX.128.F3.0F38.W1 27 /r")]
        vptestnmq_k2_k1_xmm_m128 = 5213,

        /// <summary>
        /// vptestnmq k2 {k1}, xmm, m64bcst | EVEX.128.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2 {k1}, xmm, m64bcst","EVEX.128.F3.0F38.W1 27 /r")]
        vptestnmq_k2_k1_xmm_m64bcst = 5214,

        /// <summary>
        /// vptestnmq k2 {k1}, xmm, xmm | EVEX.128.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2 {k1}, xmm, xmm","EVEX.128.F3.0F38.W1 27 /r")]
        vptestnmq_k2_k1_xmm_xmm = 5215,

        /// <summary>
        /// vptestnmq k2 {k1}, ymm, m256 | EVEX.256.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2 {k1}, ymm, m256","EVEX.256.F3.0F38.W1 27 /r")]
        vptestnmq_k2_k1_ymm_m256 = 5216,

        /// <summary>
        /// vptestnmq k2 {k1}, ymm, m64bcst | EVEX.256.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2 {k1}, ymm, m64bcst","EVEX.256.F3.0F38.W1 27 /r")]
        vptestnmq_k2_k1_ymm_m64bcst = 5217,

        /// <summary>
        /// vptestnmq k2 {k1}, ymm, ymm | EVEX.256.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2 {k1}, ymm, ymm","EVEX.256.F3.0F38.W1 27 /r")]
        vptestnmq_k2_k1_ymm_ymm = 5218,

        /// <summary>
        /// vptestnmq k2 {k1}, zmm, m512 | EVEX.512.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2 {k1}, zmm, m512","EVEX.512.F3.0F38.W1 27 /r")]
        vptestnmq_k2_k1_zmm_m512 = 5219,

        /// <summary>
        /// vptestnmq k2 {k1}, zmm, m64bcst | EVEX.512.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2 {k1}, zmm, m64bcst","EVEX.512.F3.0F38.W1 27 /r")]
        vptestnmq_k2_k1_zmm_m64bcst = 5220,

        /// <summary>
        /// vptestnmq k2 {k1}, zmm, zmm | EVEX.512.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2 {k1}, zmm, zmm","EVEX.512.F3.0F38.W1 27 /r")]
        vptestnmq_k2_k1_zmm_zmm = 5221,

        /// <summary>
        /// vptestnmq k2, xmm, m128 | EVEX.128.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2, xmm, m128","EVEX.128.F3.0F38.W1 27 /r")]
        vptestnmq_k2_xmm_m128 = 5222,

        /// <summary>
        /// vptestnmq k2, xmm, m64bcst | EVEX.128.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2, xmm, m64bcst","EVEX.128.F3.0F38.W1 27 /r")]
        vptestnmq_k2_xmm_m64bcst = 5223,

        /// <summary>
        /// vptestnmq k2, xmm, xmm | EVEX.128.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2, xmm, xmm","EVEX.128.F3.0F38.W1 27 /r")]
        vptestnmq_k2_xmm_xmm = 5224,

        /// <summary>
        /// vptestnmq k2, ymm, m256 | EVEX.256.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2, ymm, m256","EVEX.256.F3.0F38.W1 27 /r")]
        vptestnmq_k2_ymm_m256 = 5225,

        /// <summary>
        /// vptestnmq k2, ymm, m64bcst | EVEX.256.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2, ymm, m64bcst","EVEX.256.F3.0F38.W1 27 /r")]
        vptestnmq_k2_ymm_m64bcst = 5226,

        /// <summary>
        /// vptestnmq k2, ymm, ymm | EVEX.256.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2, ymm, ymm","EVEX.256.F3.0F38.W1 27 /r")]
        vptestnmq_k2_ymm_ymm = 5227,

        /// <summary>
        /// vptestnmq k2, zmm, m512 | EVEX.512.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2, zmm, m512","EVEX.512.F3.0F38.W1 27 /r")]
        vptestnmq_k2_zmm_m512 = 5228,

        /// <summary>
        /// vptestnmq k2, zmm, m64bcst | EVEX.512.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2, zmm, m64bcst","EVEX.512.F3.0F38.W1 27 /r")]
        vptestnmq_k2_zmm_m64bcst = 5229,

        /// <summary>
        /// vptestnmq k2, zmm, zmm | EVEX.512.F3.0F38.W1 27 /r | Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmq k2, zmm, zmm","EVEX.512.F3.0F38.W1 27 /r")]
        vptestnmq_k2_zmm_zmm = 5230,

        /// <summary>
        /// vptestnmw k2 {k1}, xmm, m128 | EVEX.128.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2 {k1}, xmm, m128","EVEX.128.F3.0F38.W1 26 /r")]
        vptestnmw_k2_k1_xmm_m128 = 5231,

        /// <summary>
        /// vptestnmw k2 {k1}, xmm, r8 | EVEX.128.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2 {k1}, xmm, r8","EVEX.128.F3.0F38.W1 26 /r")]
        vptestnmw_k2_k1_xmm_r8 = 5232,

        /// <summary>
        /// vptestnmw k2 {k1}, ymm, m256 | EVEX.256.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2 {k1}, ymm, m256","EVEX.256.F3.0F38.W1 26 /r")]
        vptestnmw_k2_k1_ymm_m256 = 5233,

        /// <summary>
        /// vptestnmw k2 {k1}, ymm, r16 | EVEX.256.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2 {k1}, ymm, r16","EVEX.256.F3.0F38.W1 26 /r")]
        vptestnmw_k2_k1_ymm_r16 = 5234,

        /// <summary>
        /// vptestnmw k2 {k1}, zmm, m512 | EVEX.512.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2 {k1}, zmm, m512","EVEX.512.F3.0F38.W1 26 /r")]
        vptestnmw_k2_k1_zmm_m512 = 5235,

        /// <summary>
        /// vptestnmw k2 {k1}, zmm, r32 | EVEX.512.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2 {k1}, zmm, r32","EVEX.512.F3.0F38.W1 26 /r")]
        vptestnmw_k2_k1_zmm_r32 = 5236,

        /// <summary>
        /// vptestnmw k2, xmm, m128 | EVEX.128.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2, xmm, m128","EVEX.128.F3.0F38.W1 26 /r")]
        vptestnmw_k2_xmm_m128 = 5237,

        /// <summary>
        /// vptestnmw k2, xmm, r8 | EVEX.128.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2, xmm, r8","EVEX.128.F3.0F38.W1 26 /r")]
        vptestnmw_k2_xmm_r8 = 5238,

        /// <summary>
        /// vptestnmw k2, ymm, m256 | EVEX.256.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2, ymm, m256","EVEX.256.F3.0F38.W1 26 /r")]
        vptestnmw_k2_ymm_m256 = 5239,

        /// <summary>
        /// vptestnmw k2, ymm, r16 | EVEX.256.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2, ymm, r16","EVEX.256.F3.0F38.W1 26 /r")]
        vptestnmw_k2_ymm_r16 = 5240,

        /// <summary>
        /// vptestnmw k2, zmm, m512 | EVEX.512.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2, zmm, m512","EVEX.512.F3.0F38.W1 26 /r")]
        vptestnmw_k2_zmm_m512 = 5241,

        /// <summary>
        /// vptestnmw k2, zmm, r32 | EVEX.512.F3.0F38.W1 26 /r | Bitwise NAND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.
        /// </summary>
        [Symbol("vptestnmw k2, zmm, r32","EVEX.512.F3.0F38.W1 26 /r")]
        vptestnmw_k2_zmm_r32 = 5242,

        /// <summary>
        /// vpunpckhbw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG 68 /r | Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhbw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG 68 /r")]
        vpunpckhbw_xmm_k1z_xmm_m128 = 5243,

        /// <summary>
        /// vpunpckhbw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG 68 /r | Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhbw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG 68 /r")]
        vpunpckhbw_xmm_k1z_xmm_r8 = 5244,

        /// <summary>
        /// vpunpckhbw xmm, xmm, m128 | EVEX.128.66.0F.WIG 68 /r | Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhbw xmm, xmm, m128","EVEX.128.66.0F.WIG 68 /r")]
        vpunpckhbw_xmm_xmm_m128 = 5245,

        /// <summary>
        /// vpunpckhbw xmm, xmm, m128 | VEX.128.66.0F.WIG 68 /r | Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpckhbw xmm, xmm, m128","VEX.128.66.0F.WIG 68 /r")]
        vpunpckhbw_xmm_xmm_m128_vex = 5246,

        /// <summary>
        /// vpunpckhbw xmm, xmm, r8 | EVEX.128.66.0F.WIG 68 /r | Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhbw xmm, xmm, r8","EVEX.128.66.0F.WIG 68 /r")]
        vpunpckhbw_xmm_xmm_r8 = 5247,

        /// <summary>
        /// vpunpckhbw xmm, xmm, r8 | VEX.128.66.0F.WIG 68 /r | Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpckhbw xmm, xmm, r8","VEX.128.66.0F.WIG 68 /r")]
        vpunpckhbw_xmm_xmm_r8_vex = 5248,

        /// <summary>
        /// vpunpckhbw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG 68 /r | Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhbw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG 68 /r")]
        vpunpckhbw_ymm_k1z_ymm_m256 = 5249,

        /// <summary>
        /// vpunpckhbw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG 68 /r | Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhbw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG 68 /r")]
        vpunpckhbw_ymm_k1z_ymm_r16 = 5250,

        /// <summary>
        /// vpunpckhbw ymm, ymm, m256 | EVEX.256.66.0F.WIG 68 /r | Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhbw ymm, ymm, m256","EVEX.256.66.0F.WIG 68 /r")]
        vpunpckhbw_ymm_ymm_m256 = 5251,

        /// <summary>
        /// vpunpckhbw ymm, ymm, m256 | VEX.256.66.0F.WIG 68 /r | Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpckhbw ymm, ymm, m256","VEX.256.66.0F.WIG 68 /r")]
        vpunpckhbw_ymm_ymm_m256_vex = 5252,

        /// <summary>
        /// vpunpckhbw ymm, ymm, r16 | EVEX.256.66.0F.WIG 68 /r | Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhbw ymm, ymm, r16","EVEX.256.66.0F.WIG 68 /r")]
        vpunpckhbw_ymm_ymm_r16 = 5253,

        /// <summary>
        /// vpunpckhbw ymm, ymm, r16 | VEX.256.66.0F.WIG 68 /r | Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpckhbw ymm, ymm, r16","VEX.256.66.0F.WIG 68 /r")]
        vpunpckhbw_ymm_ymm_r16_vex = 5254,

        /// <summary>
        /// vpunpckhbw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG 68 /r | Interleave high-order bytes from zmm2 and zmm3/m512 into zmm1 register.
        /// </summary>
        [Symbol("vpunpckhbw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG 68 /r")]
        vpunpckhbw_zmm_k1z_zmm_m512 = 5255,

        /// <summary>
        /// vpunpckhbw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG 68 /r | Interleave high-order bytes from zmm2 and zmm3/m512 into zmm1 register.
        /// </summary>
        [Symbol("vpunpckhbw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG 68 /r")]
        vpunpckhbw_zmm_k1z_zmm_r32 = 5256,

        /// <summary>
        /// vpunpckhbw zmm, zmm, m512 | EVEX.512.66.0F.WIG 68 /r | Interleave high-order bytes from zmm2 and zmm3/m512 into zmm1 register.
        /// </summary>
        [Symbol("vpunpckhbw zmm, zmm, m512","EVEX.512.66.0F.WIG 68 /r")]
        vpunpckhbw_zmm_zmm_m512 = 5257,

        /// <summary>
        /// vpunpckhbw zmm, zmm, r32 | EVEX.512.66.0F.WIG 68 /r | Interleave high-order bytes from zmm2 and zmm3/m512 into zmm1 register.
        /// </summary>
        [Symbol("vpunpckhbw zmm, zmm, r32","EVEX.512.66.0F.WIG 68 /r")]
        vpunpckhbw_zmm_zmm_r32 = 5258,

        /// <summary>
        /// vpunpckhdq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 6A /r | Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 6A /r")]
        vpunpckhdq_xmm_k1z_xmm_m128 = 5259,

        /// <summary>
        /// vpunpckhdq xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F.W0 6A /r | Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F.W0 6A /r")]
        vpunpckhdq_xmm_k1z_xmm_m32bcst = 5260,

        /// <summary>
        /// vpunpckhdq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W0 6A /r | Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W0 6A /r")]
        vpunpckhdq_xmm_k1z_xmm_xmm = 5261,

        /// <summary>
        /// vpunpckhdq xmm, xmm, m128 | EVEX.128.66.0F.W0 6A /r | Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq xmm, xmm, m128","EVEX.128.66.0F.W0 6A /r")]
        vpunpckhdq_xmm_xmm_m128 = 5262,

        /// <summary>
        /// vpunpckhdq xmm, xmm, m128 | VEX.128.66.0F.WIG 6A /r | Interleave high-order doublewords from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpckhdq xmm, xmm, m128","VEX.128.66.0F.WIG 6A /r")]
        vpunpckhdq_xmm_xmm_m128_vex = 5263,

        /// <summary>
        /// vpunpckhdq xmm, xmm, m32bcst | EVEX.128.66.0F.W0 6A /r | Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq xmm, xmm, m32bcst","EVEX.128.66.0F.W0 6A /r")]
        vpunpckhdq_xmm_xmm_m32bcst = 5264,

        /// <summary>
        /// vpunpckhdq xmm, xmm, r8 | VEX.128.66.0F.WIG 6A /r | Interleave high-order doublewords from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpckhdq xmm, xmm, r8","VEX.128.66.0F.WIG 6A /r")]
        vpunpckhdq_xmm_xmm_r8 = 5265,

        /// <summary>
        /// vpunpckhdq xmm, xmm, xmm | EVEX.128.66.0F.W0 6A /r | Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq xmm, xmm, xmm","EVEX.128.66.0F.W0 6A /r")]
        vpunpckhdq_xmm_xmm_xmm = 5266,

        /// <summary>
        /// vpunpckhdq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W0 6A /r | Interleave high-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W0 6A /r")]
        vpunpckhdq_ymm_k1z_ymm_m256 = 5267,

        /// <summary>
        /// vpunpckhdq ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F.W0 6A /r | Interleave high-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F.W0 6A /r")]
        vpunpckhdq_ymm_k1z_ymm_m32bcst = 5268,

        /// <summary>
        /// vpunpckhdq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W0 6A /r | Interleave high-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W0 6A /r")]
        vpunpckhdq_ymm_k1z_ymm_ymm = 5269,

        /// <summary>
        /// vpunpckhdq ymm, ymm, m256 | EVEX.256.66.0F.W0 6A /r | Interleave high-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq ymm, ymm, m256","EVEX.256.66.0F.W0 6A /r")]
        vpunpckhdq_ymm_ymm_m256 = 5270,

        /// <summary>
        /// vpunpckhdq ymm, ymm, m256 | VEX.256.66.0F.WIG 6A /r | Interleave high-order doublewords from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpckhdq ymm, ymm, m256","VEX.256.66.0F.WIG 6A /r")]
        vpunpckhdq_ymm_ymm_m256_vex = 5271,

        /// <summary>
        /// vpunpckhdq ymm, ymm, m32bcst | EVEX.256.66.0F.W0 6A /r | Interleave high-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq ymm, ymm, m32bcst","EVEX.256.66.0F.W0 6A /r")]
        vpunpckhdq_ymm_ymm_m32bcst = 5272,

        /// <summary>
        /// vpunpckhdq ymm, ymm, r16 | VEX.256.66.0F.WIG 6A /r | Interleave high-order doublewords from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpckhdq ymm, ymm, r16","VEX.256.66.0F.WIG 6A /r")]
        vpunpckhdq_ymm_ymm_r16 = 5273,

        /// <summary>
        /// vpunpckhdq ymm, ymm, ymm | EVEX.256.66.0F.W0 6A /r | Interleave high-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq ymm, ymm, ymm","EVEX.256.66.0F.W0 6A /r")]
        vpunpckhdq_ymm_ymm_ymm = 5274,

        /// <summary>
        /// vpunpckhdq zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F.W0 6A /r | Interleave high-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F.W0 6A /r")]
        vpunpckhdq_zmm_k1z_zmm_m32bcst = 5275,

        /// <summary>
        /// vpunpckhdq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W0 6A /r | Interleave high-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W0 6A /r")]
        vpunpckhdq_zmm_k1z_zmm_m512 = 5276,

        /// <summary>
        /// vpunpckhdq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W0 6A /r | Interleave high-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W0 6A /r")]
        vpunpckhdq_zmm_k1z_zmm_zmm = 5277,

        /// <summary>
        /// vpunpckhdq zmm, zmm, m32bcst | EVEX.512.66.0F.W0 6A /r | Interleave high-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq zmm, zmm, m32bcst","EVEX.512.66.0F.W0 6A /r")]
        vpunpckhdq_zmm_zmm_m32bcst = 5278,

        /// <summary>
        /// vpunpckhdq zmm, zmm, m512 | EVEX.512.66.0F.W0 6A /r | Interleave high-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq zmm, zmm, m512","EVEX.512.66.0F.W0 6A /r")]
        vpunpckhdq_zmm_zmm_m512 = 5279,

        /// <summary>
        /// vpunpckhdq zmm, zmm, zmm | EVEX.512.66.0F.W0 6A /r | Interleave high-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhdq zmm, zmm, zmm","EVEX.512.66.0F.W0 6A /r")]
        vpunpckhdq_zmm_zmm_zmm = 5280,

        /// <summary>
        /// vpunpckhqdq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 6D /r | Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 6D /r")]
        vpunpckhqdq_xmm_k1z_xmm_m128 = 5281,

        /// <summary>
        /// vpunpckhqdq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F.W1 6D /r | Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F.W1 6D /r")]
        vpunpckhqdq_xmm_k1z_xmm_m64bcst = 5282,

        /// <summary>
        /// vpunpckhqdq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W1 6D /r | Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W1 6D /r")]
        vpunpckhqdq_xmm_k1z_xmm_xmm = 5283,

        /// <summary>
        /// vpunpckhqdq xmm, xmm, m128 | EVEX.128.66.0F.W1 6D /r | Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq xmm, xmm, m128","EVEX.128.66.0F.W1 6D /r")]
        vpunpckhqdq_xmm_xmm_m128 = 5284,

        /// <summary>
        /// vpunpckhqdq xmm, xmm, m128 | VEX.128.66.0F.WIG 6D /r | Interleave high-order quadword from xmm2 and xmm3/m128 into xmm1 register.
        /// </summary>
        [Symbol("vpunpckhqdq xmm, xmm, m128","VEX.128.66.0F.WIG 6D /r")]
        vpunpckhqdq_xmm_xmm_m128_vex = 5285,

        /// <summary>
        /// vpunpckhqdq xmm, xmm, m64bcst | EVEX.128.66.0F.W1 6D /r | Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq xmm, xmm, m64bcst","EVEX.128.66.0F.W1 6D /r")]
        vpunpckhqdq_xmm_xmm_m64bcst = 5286,

        /// <summary>
        /// vpunpckhqdq xmm, xmm, r8 | VEX.128.66.0F.WIG 6D /r | Interleave high-order quadword from xmm2 and xmm3/m128 into xmm1 register.
        /// </summary>
        [Symbol("vpunpckhqdq xmm, xmm, r8","VEX.128.66.0F.WIG 6D /r")]
        vpunpckhqdq_xmm_xmm_r8 = 5287,

        /// <summary>
        /// vpunpckhqdq xmm, xmm, xmm | EVEX.128.66.0F.W1 6D /r | Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq xmm, xmm, xmm","EVEX.128.66.0F.W1 6D /r")]
        vpunpckhqdq_xmm_xmm_xmm = 5288,

        /// <summary>
        /// vpunpckhqdq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W1 6D /r | Interleave high-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W1 6D /r")]
        vpunpckhqdq_ymm_k1z_ymm_m256 = 5289,

        /// <summary>
        /// vpunpckhqdq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F.W1 6D /r | Interleave high-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F.W1 6D /r")]
        vpunpckhqdq_ymm_k1z_ymm_m64bcst = 5290,

        /// <summary>
        /// vpunpckhqdq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W1 6D /r | Interleave high-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W1 6D /r")]
        vpunpckhqdq_ymm_k1z_ymm_ymm = 5291,

        /// <summary>
        /// vpunpckhqdq ymm, ymm, m256 | EVEX.256.66.0F.W1 6D /r | Interleave high-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq ymm, ymm, m256","EVEX.256.66.0F.W1 6D /r")]
        vpunpckhqdq_ymm_ymm_m256 = 5292,

        /// <summary>
        /// vpunpckhqdq ymm, ymm, m256 | VEX.256.66.0F.WIG 6D /r | Interleave high-order quadword from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpckhqdq ymm, ymm, m256","VEX.256.66.0F.WIG 6D /r")]
        vpunpckhqdq_ymm_ymm_m256_vex = 5293,

        /// <summary>
        /// vpunpckhqdq ymm, ymm, m64bcst | EVEX.256.66.0F.W1 6D /r | Interleave high-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq ymm, ymm, m64bcst","EVEX.256.66.0F.W1 6D /r")]
        vpunpckhqdq_ymm_ymm_m64bcst = 5294,

        /// <summary>
        /// vpunpckhqdq ymm, ymm, r16 | VEX.256.66.0F.WIG 6D /r | Interleave high-order quadword from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpckhqdq ymm, ymm, r16","VEX.256.66.0F.WIG 6D /r")]
        vpunpckhqdq_ymm_ymm_r16 = 5295,

        /// <summary>
        /// vpunpckhqdq ymm, ymm, ymm | EVEX.256.66.0F.W1 6D /r | Interleave high-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq ymm, ymm, ymm","EVEX.256.66.0F.W1 6D /r")]
        vpunpckhqdq_ymm_ymm_ymm = 5296,

        /// <summary>
        /// vpunpckhqdq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W1 6D /r | Interleave high-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W1 6D /r")]
        vpunpckhqdq_zmm_k1z_zmm_m512 = 5297,

        /// <summary>
        /// vpunpckhqdq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F.W1 6D /r | Interleave high-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F.W1 6D /r")]
        vpunpckhqdq_zmm_k1z_zmm_m64bcst = 5298,

        /// <summary>
        /// vpunpckhqdq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W1 6D /r | Interleave high-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W1 6D /r")]
        vpunpckhqdq_zmm_k1z_zmm_zmm = 5299,

        /// <summary>
        /// vpunpckhqdq zmm, zmm, m512 | EVEX.512.66.0F.W1 6D /r | Interleave high-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq zmm, zmm, m512","EVEX.512.66.0F.W1 6D /r")]
        vpunpckhqdq_zmm_zmm_m512 = 5300,

        /// <summary>
        /// vpunpckhqdq zmm, zmm, m64bcst | EVEX.512.66.0F.W1 6D /r | Interleave high-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq zmm, zmm, m64bcst","EVEX.512.66.0F.W1 6D /r")]
        vpunpckhqdq_zmm_zmm_m64bcst = 5301,

        /// <summary>
        /// vpunpckhqdq zmm, zmm, zmm | EVEX.512.66.0F.W1 6D /r | Interleave high-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhqdq zmm, zmm, zmm","EVEX.512.66.0F.W1 6D /r")]
        vpunpckhqdq_zmm_zmm_zmm = 5302,

        /// <summary>
        /// vpunpckhwd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG 69 /r | Interleave high-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhwd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG 69 /r")]
        vpunpckhwd_xmm_k1z_xmm_m128 = 5303,

        /// <summary>
        /// vpunpckhwd xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG 69 /r | Interleave high-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhwd xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG 69 /r")]
        vpunpckhwd_xmm_k1z_xmm_r8 = 5304,

        /// <summary>
        /// vpunpckhwd xmm, xmm, m128 | EVEX.128.66.0F.WIG 69 /r | Interleave high-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhwd xmm, xmm, m128","EVEX.128.66.0F.WIG 69 /r")]
        vpunpckhwd_xmm_xmm_m128 = 5305,

        /// <summary>
        /// vpunpckhwd xmm, xmm, m128 | VEX.128.66.0F.WIG 69 /r | Interleave high-order words from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpckhwd xmm, xmm, m128","VEX.128.66.0F.WIG 69 /r")]
        vpunpckhwd_xmm_xmm_m128_vex = 5306,

        /// <summary>
        /// vpunpckhwd xmm, xmm, r8 | EVEX.128.66.0F.WIG 69 /r | Interleave high-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhwd xmm, xmm, r8","EVEX.128.66.0F.WIG 69 /r")]
        vpunpckhwd_xmm_xmm_r8 = 5307,

        /// <summary>
        /// vpunpckhwd xmm, xmm, r8 | VEX.128.66.0F.WIG 69 /r | Interleave high-order words from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpckhwd xmm, xmm, r8","VEX.128.66.0F.WIG 69 /r")]
        vpunpckhwd_xmm_xmm_r8_vex = 5308,

        /// <summary>
        /// vpunpckhwd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG 69 /r | Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhwd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG 69 /r")]
        vpunpckhwd_ymm_k1z_ymm_m256 = 5309,

        /// <summary>
        /// vpunpckhwd ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG 69 /r | Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhwd ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG 69 /r")]
        vpunpckhwd_ymm_k1z_ymm_r16 = 5310,

        /// <summary>
        /// vpunpckhwd ymm, ymm, m256 | EVEX.256.66.0F.WIG 69 /r | Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhwd ymm, ymm, m256","EVEX.256.66.0F.WIG 69 /r")]
        vpunpckhwd_ymm_ymm_m256 = 5311,

        /// <summary>
        /// vpunpckhwd ymm, ymm, m256 | VEX.256.66.0F.WIG 69 /r | Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpckhwd ymm, ymm, m256","VEX.256.66.0F.WIG 69 /r")]
        vpunpckhwd_ymm_ymm_m256_vex = 5312,

        /// <summary>
        /// vpunpckhwd ymm, ymm, r16 | EVEX.256.66.0F.WIG 69 /r | Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.
        /// </summary>
        [Symbol("vpunpckhwd ymm, ymm, r16","EVEX.256.66.0F.WIG 69 /r")]
        vpunpckhwd_ymm_ymm_r16 = 5313,

        /// <summary>
        /// vpunpckhwd ymm, ymm, r16 | VEX.256.66.0F.WIG 69 /r | Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpckhwd ymm, ymm, r16","VEX.256.66.0F.WIG 69 /r")]
        vpunpckhwd_ymm_ymm_r16_vex = 5314,

        /// <summary>
        /// vpunpckhwd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG 69 /r | Interleave high-order words from zmm2 and zmm3/m512 into zmm1 register.
        /// </summary>
        [Symbol("vpunpckhwd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG 69 /r")]
        vpunpckhwd_zmm_k1z_zmm_m512 = 5315,

        /// <summary>
        /// vpunpckhwd zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG 69 /r | Interleave high-order words from zmm2 and zmm3/m512 into zmm1 register.
        /// </summary>
        [Symbol("vpunpckhwd zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG 69 /r")]
        vpunpckhwd_zmm_k1z_zmm_r32 = 5316,

        /// <summary>
        /// vpunpckhwd zmm, zmm, m512 | EVEX.512.66.0F.WIG 69 /r | Interleave high-order words from zmm2 and zmm3/m512 into zmm1 register.
        /// </summary>
        [Symbol("vpunpckhwd zmm, zmm, m512","EVEX.512.66.0F.WIG 69 /r")]
        vpunpckhwd_zmm_zmm_m512 = 5317,

        /// <summary>
        /// vpunpckhwd zmm, zmm, r32 | EVEX.512.66.0F.WIG 69 /r | Interleave high-order words from zmm2 and zmm3/m512 into zmm1 register.
        /// </summary>
        [Symbol("vpunpckhwd zmm, zmm, r32","EVEX.512.66.0F.WIG 69 /r")]
        vpunpckhwd_zmm_zmm_r32 = 5318,

        /// <summary>
        /// vpunpcklbw xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG 60 /r | Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG 60 /r")]
        vpunpcklbw_xmm_k1z_xmm_m128 = 5319,

        /// <summary>
        /// vpunpcklbw xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG 60 /r | Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG 60 /r")]
        vpunpcklbw_xmm_k1z_xmm_r8 = 5320,

        /// <summary>
        /// vpunpcklbw xmm, xmm, m128 | EVEX.128.66.0F.WIG 60 /r | Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw xmm, xmm, m128","EVEX.128.66.0F.WIG 60 /r")]
        vpunpcklbw_xmm_xmm_m128 = 5321,

        /// <summary>
        /// vpunpcklbw xmm, xmm, m128 | VEX.128.66.0F.WIG 60 /r | Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpcklbw xmm, xmm, m128","VEX.128.66.0F.WIG 60 /r")]
        vpunpcklbw_xmm_xmm_m128_vex = 5322,

        /// <summary>
        /// vpunpcklbw xmm, xmm, r8 | EVEX.128.66.0F.WIG 60 /r | Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw xmm, xmm, r8","EVEX.128.66.0F.WIG 60 /r")]
        vpunpcklbw_xmm_xmm_r8 = 5323,

        /// <summary>
        /// vpunpcklbw xmm, xmm, r8 | VEX.128.66.0F.WIG 60 /r | Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpcklbw xmm, xmm, r8","VEX.128.66.0F.WIG 60 /r")]
        vpunpcklbw_xmm_xmm_r8_vex = 5324,

        /// <summary>
        /// vpunpcklbw ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG 60 /r | Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG 60 /r")]
        vpunpcklbw_ymm_k1z_ymm_m256 = 5325,

        /// <summary>
        /// vpunpcklbw ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG 60 /r | Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG 60 /r")]
        vpunpcklbw_ymm_k1z_ymm_r16 = 5326,

        /// <summary>
        /// vpunpcklbw ymm, ymm, m256 | EVEX.256.66.0F.WIG 60 /r | Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw ymm, ymm, m256","EVEX.256.66.0F.WIG 60 /r")]
        vpunpcklbw_ymm_ymm_m256 = 5327,

        /// <summary>
        /// vpunpcklbw ymm, ymm, m256 | VEX.256.66.0F.WIG 60 /r | Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpcklbw ymm, ymm, m256","VEX.256.66.0F.WIG 60 /r")]
        vpunpcklbw_ymm_ymm_m256_vex = 5328,

        /// <summary>
        /// vpunpcklbw ymm, ymm, r16 | EVEX.256.66.0F.WIG 60 /r | Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw ymm, ymm, r16","EVEX.256.66.0F.WIG 60 /r")]
        vpunpcklbw_ymm_ymm_r16 = 5329,

        /// <summary>
        /// vpunpcklbw ymm, ymm, r16 | VEX.256.66.0F.WIG 60 /r | Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpcklbw ymm, ymm, r16","VEX.256.66.0F.WIG 60 /r")]
        vpunpcklbw_ymm_ymm_r16_vex = 5330,

        /// <summary>
        /// vpunpcklbw zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG 60 /r | Interleave low-order bytes from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG 60 /r")]
        vpunpcklbw_zmm_k1z_zmm_m512 = 5331,

        /// <summary>
        /// vpunpcklbw zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG 60 /r | Interleave low-order bytes from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG 60 /r")]
        vpunpcklbw_zmm_k1z_zmm_r32 = 5332,

        /// <summary>
        /// vpunpcklbw zmm, zmm, m512 | EVEX.512.66.0F.WIG 60 /r | Interleave low-order bytes from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw zmm, zmm, m512","EVEX.512.66.0F.WIG 60 /r")]
        vpunpcklbw_zmm_zmm_m512 = 5333,

        /// <summary>
        /// vpunpcklbw zmm, zmm, r32 | EVEX.512.66.0F.WIG 60 /r | Interleave low-order bytes from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklbw zmm, zmm, r32","EVEX.512.66.0F.WIG 60 /r")]
        vpunpcklbw_zmm_zmm_r32 = 5334,

        /// <summary>
        /// vpunpckldq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 62 /r | Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 62 /r")]
        vpunpckldq_xmm_k1z_xmm_m128 = 5335,

        /// <summary>
        /// vpunpckldq xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F.W0 62 /r | Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F.W0 62 /r")]
        vpunpckldq_xmm_k1z_xmm_m32bcst = 5336,

        /// <summary>
        /// vpunpckldq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W0 62 /r | Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W0 62 /r")]
        vpunpckldq_xmm_k1z_xmm_xmm = 5337,

        /// <summary>
        /// vpunpckldq xmm, xmm, m128 | EVEX.128.66.0F.W0 62 /r | Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq xmm, xmm, m128","EVEX.128.66.0F.W0 62 /r")]
        vpunpckldq_xmm_xmm_m128 = 5338,

        /// <summary>
        /// vpunpckldq xmm, xmm, m128 | VEX.128.66.0F.WIG 62 /r | Interleave low-order doublewords from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpckldq xmm, xmm, m128","VEX.128.66.0F.WIG 62 /r")]
        vpunpckldq_xmm_xmm_m128_vex = 5339,

        /// <summary>
        /// vpunpckldq xmm, xmm, m32bcst | EVEX.128.66.0F.W0 62 /r | Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq xmm, xmm, m32bcst","EVEX.128.66.0F.W0 62 /r")]
        vpunpckldq_xmm_xmm_m32bcst = 5340,

        /// <summary>
        /// vpunpckldq xmm, xmm, r8 | VEX.128.66.0F.WIG 62 /r | Interleave low-order doublewords from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpckldq xmm, xmm, r8","VEX.128.66.0F.WIG 62 /r")]
        vpunpckldq_xmm_xmm_r8 = 5341,

        /// <summary>
        /// vpunpckldq xmm, xmm, xmm | EVEX.128.66.0F.W0 62 /r | Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq xmm, xmm, xmm","EVEX.128.66.0F.W0 62 /r")]
        vpunpckldq_xmm_xmm_xmm = 5342,

        /// <summary>
        /// vpunpckldq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W0 62 /r | Interleave low-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W0 62 /r")]
        vpunpckldq_ymm_k1z_ymm_m256 = 5343,

        /// <summary>
        /// vpunpckldq ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F.W0 62 /r | Interleave low-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F.W0 62 /r")]
        vpunpckldq_ymm_k1z_ymm_m32bcst = 5344,

        /// <summary>
        /// vpunpckldq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W0 62 /r | Interleave low-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W0 62 /r")]
        vpunpckldq_ymm_k1z_ymm_ymm = 5345,

        /// <summary>
        /// vpunpckldq ymm, ymm, m256 | EVEX.256.66.0F.W0 62 /r | Interleave low-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq ymm, ymm, m256","EVEX.256.66.0F.W0 62 /r")]
        vpunpckldq_ymm_ymm_m256 = 5346,

        /// <summary>
        /// vpunpckldq ymm, ymm, m256 | VEX.256.66.0F.WIG 62 /r | Interleave low-order doublewords from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpckldq ymm, ymm, m256","VEX.256.66.0F.WIG 62 /r")]
        vpunpckldq_ymm_ymm_m256_vex = 5347,

        /// <summary>
        /// vpunpckldq ymm, ymm, m32bcst | EVEX.256.66.0F.W0 62 /r | Interleave low-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq ymm, ymm, m32bcst","EVEX.256.66.0F.W0 62 /r")]
        vpunpckldq_ymm_ymm_m32bcst = 5348,

        /// <summary>
        /// vpunpckldq ymm, ymm, r16 | VEX.256.66.0F.WIG 62 /r | Interleave low-order doublewords from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpckldq ymm, ymm, r16","VEX.256.66.0F.WIG 62 /r")]
        vpunpckldq_ymm_ymm_r16 = 5349,

        /// <summary>
        /// vpunpckldq ymm, ymm, ymm | EVEX.256.66.0F.W0 62 /r | Interleave low-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq ymm, ymm, ymm","EVEX.256.66.0F.W0 62 /r")]
        vpunpckldq_ymm_ymm_ymm = 5350,

        /// <summary>
        /// vpunpckldq zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F.W0 62 /r | Interleave low-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F.W0 62 /r")]
        vpunpckldq_zmm_k1z_zmm_m32bcst = 5351,

        /// <summary>
        /// vpunpckldq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W0 62 /r | Interleave low-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W0 62 /r")]
        vpunpckldq_zmm_k1z_zmm_m512 = 5352,

        /// <summary>
        /// vpunpckldq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W0 62 /r | Interleave low-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W0 62 /r")]
        vpunpckldq_zmm_k1z_zmm_zmm = 5353,

        /// <summary>
        /// vpunpckldq zmm, zmm, m32bcst | EVEX.512.66.0F.W0 62 /r | Interleave low-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq zmm, zmm, m32bcst","EVEX.512.66.0F.W0 62 /r")]
        vpunpckldq_zmm_zmm_m32bcst = 5354,

        /// <summary>
        /// vpunpckldq zmm, zmm, m512 | EVEX.512.66.0F.W0 62 /r | Interleave low-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq zmm, zmm, m512","EVEX.512.66.0F.W0 62 /r")]
        vpunpckldq_zmm_zmm_m512 = 5355,

        /// <summary>
        /// vpunpckldq zmm, zmm, zmm | EVEX.512.66.0F.W0 62 /r | Interleave low-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpckldq zmm, zmm, zmm","EVEX.512.66.0F.W0 62 /r")]
        vpunpckldq_zmm_zmm_zmm = 5356,

        /// <summary>
        /// vpunpcklqdq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 6C /r")]
        vpunpcklqdq_xmm_k1z_xmm_m128 = 5357,

        /// <summary>
        /// vpunpcklqdq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F.W1 6C /r")]
        vpunpcklqdq_xmm_k1z_xmm_m64bcst = 5358,

        /// <summary>
        /// vpunpcklqdq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W1 6C /r")]
        vpunpcklqdq_xmm_k1z_xmm_xmm = 5359,

        /// <summary>
        /// vpunpcklqdq xmm, xmm, m128 | EVEX.128.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq xmm, xmm, m128","EVEX.128.66.0F.W1 6C /r")]
        vpunpcklqdq_xmm_xmm_m128 = 5360,

        /// <summary>
        /// vpunpcklqdq xmm, xmm, m128 | VEX.128.66.0F.WIG 6C /r | Interleave low-order quadword from xmm2 and xmm3/m128 into xmm1 register.
        /// </summary>
        [Symbol("vpunpcklqdq xmm, xmm, m128","VEX.128.66.0F.WIG 6C /r")]
        vpunpcklqdq_xmm_xmm_m128_vex = 5361,

        /// <summary>
        /// vpunpcklqdq xmm, xmm, m64bcst | EVEX.128.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq xmm, xmm, m64bcst","EVEX.128.66.0F.W1 6C /r")]
        vpunpcklqdq_xmm_xmm_m64bcst = 5362,

        /// <summary>
        /// vpunpcklqdq xmm, xmm, r8 | VEX.128.66.0F.WIG 6C /r | Interleave low-order quadword from xmm2 and xmm3/m128 into xmm1 register.
        /// </summary>
        [Symbol("vpunpcklqdq xmm, xmm, r8","VEX.128.66.0F.WIG 6C /r")]
        vpunpcklqdq_xmm_xmm_r8 = 5363,

        /// <summary>
        /// vpunpcklqdq xmm, xmm, xmm | EVEX.128.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq xmm, xmm, xmm","EVEX.128.66.0F.W1 6C /r")]
        vpunpcklqdq_xmm_xmm_xmm = 5364,

        /// <summary>
        /// vpunpcklqdq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W1 6C /r | Interleave low-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W1 6C /r")]
        vpunpcklqdq_ymm_k1z_ymm_m256 = 5365,

        /// <summary>
        /// vpunpcklqdq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F.W1 6C /r | Interleave low-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F.W1 6C /r")]
        vpunpcklqdq_ymm_k1z_ymm_m64bcst = 5366,

        /// <summary>
        /// vpunpcklqdq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W1 6C /r | Interleave low-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W1 6C /r")]
        vpunpcklqdq_ymm_k1z_ymm_ymm = 5367,

        /// <summary>
        /// vpunpcklqdq ymm, ymm, m256 | EVEX.256.66.0F.W1 6C /r | Interleave low-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq ymm, ymm, m256","EVEX.256.66.0F.W1 6C /r")]
        vpunpcklqdq_ymm_ymm_m256 = 5368,

        /// <summary>
        /// vpunpcklqdq ymm, ymm, m256 | VEX.256.66.0F.WIG 6C /r | Interleave low-order quadword from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpcklqdq ymm, ymm, m256","VEX.256.66.0F.WIG 6C /r")]
        vpunpcklqdq_ymm_ymm_m256_vex = 5369,

        /// <summary>
        /// vpunpcklqdq ymm, ymm, m64bcst | EVEX.256.66.0F.W1 6C /r | Interleave low-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq ymm, ymm, m64bcst","EVEX.256.66.0F.W1 6C /r")]
        vpunpcklqdq_ymm_ymm_m64bcst = 5370,

        /// <summary>
        /// vpunpcklqdq ymm, ymm, r16 | VEX.256.66.0F.WIG 6C /r | Interleave low-order quadword from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpcklqdq ymm, ymm, r16","VEX.256.66.0F.WIG 6C /r")]
        vpunpcklqdq_ymm_ymm_r16 = 5371,

        /// <summary>
        /// vpunpcklqdq ymm, ymm, ymm | EVEX.256.66.0F.W1 6C /r | Interleave low-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq ymm, ymm, ymm","EVEX.256.66.0F.W1 6C /r")]
        vpunpcklqdq_ymm_ymm_ymm = 5372,

        /// <summary>
        /// vpunpcklqdq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W1 6C /r")]
        vpunpcklqdq_zmm_k1z_zmm_m512 = 5373,

        /// <summary>
        /// vpunpcklqdq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F.W1 6C /r")]
        vpunpcklqdq_zmm_k1z_zmm_m64bcst = 5374,

        /// <summary>
        /// vpunpcklqdq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W1 6C /r")]
        vpunpcklqdq_zmm_k1z_zmm_zmm = 5375,

        /// <summary>
        /// vpunpcklqdq zmm, zmm, m512 | EVEX.512.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq zmm, zmm, m512","EVEX.512.66.0F.W1 6C /r")]
        vpunpcklqdq_zmm_zmm_m512 = 5376,

        /// <summary>
        /// vpunpcklqdq zmm, zmm, m64bcst | EVEX.512.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq zmm, zmm, m64bcst","EVEX.512.66.0F.W1 6C /r")]
        vpunpcklqdq_zmm_zmm_m64bcst = 5377,

        /// <summary>
        /// vpunpcklqdq zmm, zmm, zmm | EVEX.512.66.0F.W1 6C /r | Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklqdq zmm, zmm, zmm","EVEX.512.66.0F.W1 6C /r")]
        vpunpcklqdq_zmm_zmm_zmm = 5378,

        /// <summary>
        /// vpunpcklwd xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.WIG 61 /r | Interleave low-order words from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.WIG 61 /r")]
        vpunpcklwd_xmm_k1z_xmm_m128 = 5379,

        /// <summary>
        /// vpunpcklwd xmm {k1}{z}, xmm, r8 | EVEX.128.66.0F.WIG 61 /r | Interleave low-order words from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd xmm {k1}{z}, xmm, r8","EVEX.128.66.0F.WIG 61 /r")]
        vpunpcklwd_xmm_k1z_xmm_r8 = 5380,

        /// <summary>
        /// vpunpcklwd xmm, xmm, m128 | EVEX.128.66.0F.WIG 61 /r | Interleave low-order words from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd xmm, xmm, m128","EVEX.128.66.0F.WIG 61 /r")]
        vpunpcklwd_xmm_xmm_m128 = 5381,

        /// <summary>
        /// vpunpcklwd xmm, xmm, m128 | VEX.128.66.0F.WIG 61 /r | Interleave low-order words from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpcklwd xmm, xmm, m128","VEX.128.66.0F.WIG 61 /r")]
        vpunpcklwd_xmm_xmm_m128_vex = 5382,

        /// <summary>
        /// vpunpcklwd xmm, xmm, r8 | EVEX.128.66.0F.WIG 61 /r | Interleave low-order words from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd xmm, xmm, r8","EVEX.128.66.0F.WIG 61 /r")]
        vpunpcklwd_xmm_xmm_r8 = 5383,

        /// <summary>
        /// vpunpcklwd xmm, xmm, r8 | VEX.128.66.0F.WIG 61 /r | Interleave low-order words from xmm2 and xmm3/m128 into xmm1.
        /// </summary>
        [Symbol("vpunpcklwd xmm, xmm, r8","VEX.128.66.0F.WIG 61 /r")]
        vpunpcklwd_xmm_xmm_r8_vex = 5384,

        /// <summary>
        /// vpunpcklwd ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.WIG 61 /r | Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.WIG 61 /r")]
        vpunpcklwd_ymm_k1z_ymm_m256 = 5385,

        /// <summary>
        /// vpunpcklwd ymm {k1}{z}, ymm, r16 | EVEX.256.66.0F.WIG 61 /r | Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd ymm {k1}{z}, ymm, r16","EVEX.256.66.0F.WIG 61 /r")]
        vpunpcklwd_ymm_k1z_ymm_r16 = 5386,

        /// <summary>
        /// vpunpcklwd ymm, ymm, m256 | EVEX.256.66.0F.WIG 61 /r | Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd ymm, ymm, m256","EVEX.256.66.0F.WIG 61 /r")]
        vpunpcklwd_ymm_ymm_m256 = 5387,

        /// <summary>
        /// vpunpcklwd ymm, ymm, m256 | VEX.256.66.0F.WIG 61 /r | Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpcklwd ymm, ymm, m256","VEX.256.66.0F.WIG 61 /r")]
        vpunpcklwd_ymm_ymm_m256_vex = 5388,

        /// <summary>
        /// vpunpcklwd ymm, ymm, r16 | EVEX.256.66.0F.WIG 61 /r | Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd ymm, ymm, r16","EVEX.256.66.0F.WIG 61 /r")]
        vpunpcklwd_ymm_ymm_r16 = 5389,

        /// <summary>
        /// vpunpcklwd ymm, ymm, r16 | VEX.256.66.0F.WIG 61 /r | Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register.
        /// </summary>
        [Symbol("vpunpcklwd ymm, ymm, r16","VEX.256.66.0F.WIG 61 /r")]
        vpunpcklwd_ymm_ymm_r16_vex = 5390,

        /// <summary>
        /// vpunpcklwd zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.WIG 61 /r | Interleave low-order words from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.WIG 61 /r")]
        vpunpcklwd_zmm_k1z_zmm_m512 = 5391,

        /// <summary>
        /// vpunpcklwd zmm {k1}{z}, zmm, r32 | EVEX.512.66.0F.WIG 61 /r | Interleave low-order words from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd zmm {k1}{z}, zmm, r32","EVEX.512.66.0F.WIG 61 /r")]
        vpunpcklwd_zmm_k1z_zmm_r32 = 5392,

        /// <summary>
        /// vpunpcklwd zmm, zmm, m512 | EVEX.512.66.0F.WIG 61 /r | Interleave low-order words from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd zmm, zmm, m512","EVEX.512.66.0F.WIG 61 /r")]
        vpunpcklwd_zmm_zmm_m512 = 5393,

        /// <summary>
        /// vpunpcklwd zmm, zmm, r32 | EVEX.512.66.0F.WIG 61 /r | Interleave low-order words from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.
        /// </summary>
        [Symbol("vpunpcklwd zmm, zmm, r32","EVEX.512.66.0F.WIG 61 /r")]
        vpunpcklwd_zmm_zmm_r32 = 5394,

        /// <summary>
        /// vpxor xmm, xmm, m128 | VEX.128.66.0F.WIG EF /r | Bitwise XOR of xmm3/m128 and xmm2.
        /// </summary>
        [Symbol("vpxor xmm, xmm, m128","VEX.128.66.0F.WIG EF /r")]
        vpxor_xmm_xmm_m128 = 5395,

        /// <summary>
        /// vpxor xmm, xmm, r8 | VEX.128.66.0F.WIG EF /r | Bitwise XOR of xmm3/m128 and xmm2.
        /// </summary>
        [Symbol("vpxor xmm, xmm, r8","VEX.128.66.0F.WIG EF /r")]
        vpxor_xmm_xmm_r8 = 5396,

        /// <summary>
        /// vpxor ymm, ymm, m256 | VEX.256.66.0F.WIG EF /r | Bitwise XOR of ymm3/m256 and ymm2.
        /// </summary>
        [Symbol("vpxor ymm, ymm, m256","VEX.256.66.0F.WIG EF /r")]
        vpxor_ymm_ymm_m256 = 5397,

        /// <summary>
        /// vpxor ymm, ymm, r16 | VEX.256.66.0F.WIG EF /r | Bitwise XOR of ymm3/m256 and ymm2.
        /// </summary>
        [Symbol("vpxor ymm, ymm, r16","VEX.256.66.0F.WIG EF /r")]
        vpxor_ymm_ymm_r16 = 5398,

        /// <summary>
        /// vpxord xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxord xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W0 EF /r")]
        vpxord_xmm_k1z_xmm_m128 = 5399,

        /// <summary>
        /// vpxord xmm {k1}{z}, xmm, m32bcst | EVEX.128.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxord xmm {k1}{z}, xmm, m32bcst","EVEX.128.66.0F.W0 EF /r")]
        vpxord_xmm_k1z_xmm_m32bcst = 5400,

        /// <summary>
        /// vpxord xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxord xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W0 EF /r")]
        vpxord_xmm_k1z_xmm_xmm = 5401,

        /// <summary>
        /// vpxord xmm, xmm, m128 | EVEX.128.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxord xmm, xmm, m128","EVEX.128.66.0F.W0 EF /r")]
        vpxord_xmm_xmm_m128 = 5402,

        /// <summary>
        /// vpxord xmm, xmm, m32bcst | EVEX.128.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxord xmm, xmm, m32bcst","EVEX.128.66.0F.W0 EF /r")]
        vpxord_xmm_xmm_m32bcst = 5403,

        /// <summary>
        /// vpxord xmm, xmm, xmm | EVEX.128.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxord xmm, xmm, xmm","EVEX.128.66.0F.W0 EF /r")]
        vpxord_xmm_xmm_xmm = 5404,

        /// <summary>
        /// vpxord ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxord ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W0 EF /r")]
        vpxord_ymm_k1z_ymm_m256 = 5405,

        /// <summary>
        /// vpxord ymm {k1}{z}, ymm, m32bcst | EVEX.256.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxord ymm {k1}{z}, ymm, m32bcst","EVEX.256.66.0F.W0 EF /r")]
        vpxord_ymm_k1z_ymm_m32bcst = 5406,

        /// <summary>
        /// vpxord ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxord ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W0 EF /r")]
        vpxord_ymm_k1z_ymm_ymm = 5407,

        /// <summary>
        /// vpxord ymm, ymm, m256 | EVEX.256.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxord ymm, ymm, m256","EVEX.256.66.0F.W0 EF /r")]
        vpxord_ymm_ymm_m256 = 5408,

        /// <summary>
        /// vpxord ymm, ymm, m32bcst | EVEX.256.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxord ymm, ymm, m32bcst","EVEX.256.66.0F.W0 EF /r")]
        vpxord_ymm_ymm_m32bcst = 5409,

        /// <summary>
        /// vpxord ymm, ymm, ymm | EVEX.256.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxord ymm, ymm, ymm","EVEX.256.66.0F.W0 EF /r")]
        vpxord_ymm_ymm_ymm = 5410,

        /// <summary>
        /// vpxord zmm {k1}{z}, zmm, m32bcst | EVEX.512.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpxord zmm {k1}{z}, zmm, m32bcst","EVEX.512.66.0F.W0 EF /r")]
        vpxord_zmm_k1z_zmm_m32bcst = 5411,

        /// <summary>
        /// vpxord zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpxord zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W0 EF /r")]
        vpxord_zmm_k1z_zmm_m512 = 5412,

        /// <summary>
        /// vpxord zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpxord zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W0 EF /r")]
        vpxord_zmm_k1z_zmm_zmm = 5413,

        /// <summary>
        /// vpxord zmm, zmm, m32bcst | EVEX.512.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpxord zmm, zmm, m32bcst","EVEX.512.66.0F.W0 EF /r")]
        vpxord_zmm_zmm_m32bcst = 5414,

        /// <summary>
        /// vpxord zmm, zmm, m512 | EVEX.512.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpxord zmm, zmm, m512","EVEX.512.66.0F.W0 EF /r")]
        vpxord_zmm_zmm_m512 = 5415,

        /// <summary>
        /// vpxord zmm, zmm, zmm | EVEX.512.66.0F.W0 EF /r | Bitwise XOR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.
        /// </summary>
        [Symbol("vpxord zmm, zmm, zmm","EVEX.512.66.0F.W0 EF /r")]
        vpxord_zmm_zmm_zmm = 5416,

        /// <summary>
        /// vpxorq xmm {k1}{z}, xmm, m128 | EVEX.128.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxorq xmm {k1}{z}, xmm, m128","EVEX.128.66.0F.W1 EF /r")]
        vpxorq_xmm_k1z_xmm_m128 = 5417,

        /// <summary>
        /// vpxorq xmm {k1}{z}, xmm, m64bcst | EVEX.128.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxorq xmm {k1}{z}, xmm, m64bcst","EVEX.128.66.0F.W1 EF /r")]
        vpxorq_xmm_k1z_xmm_m64bcst = 5418,

        /// <summary>
        /// vpxorq xmm {k1}{z}, xmm, xmm | EVEX.128.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxorq xmm {k1}{z}, xmm, xmm","EVEX.128.66.0F.W1 EF /r")]
        vpxorq_xmm_k1z_xmm_xmm = 5419,

        /// <summary>
        /// vpxorq xmm, xmm, m128 | EVEX.128.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxorq xmm, xmm, m128","EVEX.128.66.0F.W1 EF /r")]
        vpxorq_xmm_xmm_m128 = 5420,

        /// <summary>
        /// vpxorq xmm, xmm, m64bcst | EVEX.128.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxorq xmm, xmm, m64bcst","EVEX.128.66.0F.W1 EF /r")]
        vpxorq_xmm_xmm_m64bcst = 5421,

        /// <summary>
        /// vpxorq xmm, xmm, xmm | EVEX.128.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in xmm2 and xmm3/m128 using writemask k1.
        /// </summary>
        [Symbol("vpxorq xmm, xmm, xmm","EVEX.128.66.0F.W1 EF /r")]
        vpxorq_xmm_xmm_xmm = 5422,

        /// <summary>
        /// vpxorq ymm {k1}{z}, ymm, m256 | EVEX.256.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxorq ymm {k1}{z}, ymm, m256","EVEX.256.66.0F.W1 EF /r")]
        vpxorq_ymm_k1z_ymm_m256 = 5423,

        /// <summary>
        /// vpxorq ymm {k1}{z}, ymm, m64bcst | EVEX.256.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxorq ymm {k1}{z}, ymm, m64bcst","EVEX.256.66.0F.W1 EF /r")]
        vpxorq_ymm_k1z_ymm_m64bcst = 5424,

        /// <summary>
        /// vpxorq ymm {k1}{z}, ymm, ymm | EVEX.256.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxorq ymm {k1}{z}, ymm, ymm","EVEX.256.66.0F.W1 EF /r")]
        vpxorq_ymm_k1z_ymm_ymm = 5425,

        /// <summary>
        /// vpxorq ymm, ymm, m256 | EVEX.256.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxorq ymm, ymm, m256","EVEX.256.66.0F.W1 EF /r")]
        vpxorq_ymm_ymm_m256 = 5426,

        /// <summary>
        /// vpxorq ymm, ymm, m64bcst | EVEX.256.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxorq ymm, ymm, m64bcst","EVEX.256.66.0F.W1 EF /r")]
        vpxorq_ymm_ymm_m64bcst = 5427,

        /// <summary>
        /// vpxorq ymm, ymm, ymm | EVEX.256.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in ymm2 and ymm3/m256 using writemask k1.
        /// </summary>
        [Symbol("vpxorq ymm, ymm, ymm","EVEX.256.66.0F.W1 EF /r")]
        vpxorq_ymm_ymm_ymm = 5428,

        /// <summary>
        /// vpxorq zmm {k1}{z}, zmm, m512 | EVEX.512.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpxorq zmm {k1}{z}, zmm, m512","EVEX.512.66.0F.W1 EF /r")]
        vpxorq_zmm_k1z_zmm_m512 = 5429,

        /// <summary>
        /// vpxorq zmm {k1}{z}, zmm, m64bcst | EVEX.512.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpxorq zmm {k1}{z}, zmm, m64bcst","EVEX.512.66.0F.W1 EF /r")]
        vpxorq_zmm_k1z_zmm_m64bcst = 5430,

        /// <summary>
        /// vpxorq zmm {k1}{z}, zmm, zmm | EVEX.512.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpxorq zmm {k1}{z}, zmm, zmm","EVEX.512.66.0F.W1 EF /r")]
        vpxorq_zmm_k1z_zmm_zmm = 5431,

        /// <summary>
        /// vpxorq zmm, zmm, m512 | EVEX.512.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpxorq zmm, zmm, m512","EVEX.512.66.0F.W1 EF /r")]
        vpxorq_zmm_zmm_m512 = 5432,

        /// <summary>
        /// vpxorq zmm, zmm, m64bcst | EVEX.512.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpxorq zmm, zmm, m64bcst","EVEX.512.66.0F.W1 EF /r")]
        vpxorq_zmm_zmm_m64bcst = 5433,

        /// <summary>
        /// vpxorq zmm, zmm, zmm | EVEX.512.66.0F.W1 EF /r | Bitwise XOR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.
        /// </summary>
        [Symbol("vpxorq zmm, zmm, zmm","EVEX.512.66.0F.W1 EF /r")]
        vpxorq_zmm_zmm_zmm = 5434,

        /// <summary>
        /// xbegin rel16 | C7 F8 | Specifies the start of an RTM region. Provides a 16-bit relative offset to compute the address of the fallback instruction address at which execution resumes following an RTM abort.
        /// </summary>
        [Symbol("xbegin rel16","C7 F8")]
        xbegin_rel16 = 5435,

        /// <summary>
        /// xbegin rel32 | C7 F8 | Specifies the start of an RTM region. Provides a 32-bit relative offset to compute the address of the fallback instruction address at which execution resumes following an RTM abort.
        /// </summary>
        [Symbol("xbegin rel32","C7 F8")]
        xbegin_rel32 = 5436,

        /// <summary>
        /// xchg AX, r16 | 90 +rw | Exchange r16 with AX.
        /// </summary>
        [Symbol("xchg AX, r16","90 +rw")]
        xchg_AX_r16 = 5437,

        /// <summary>
        /// xchg EAX, r32 | 90 +rd | Exchange r32 with EAX.
        /// </summary>
        [Symbol("xchg EAX, r32","90 +rd")]
        xchg_EAX_r32 = 5438,

        /// <summary>
        /// xchg m16, r16 | 87 /r | Exchange r16 with word from r/m16.
        /// </summary>
        [Symbol("xchg m16, r16","87 /r")]
        xchg_m16_r16 = 5439,

        /// <summary>
        /// xchg m32, r32 | 87 /r | Exchange r32 with doubleword from r/m32.
        /// </summary>
        [Symbol("xchg m32, r32","87 /r")]
        xchg_m32_r32 = 5440,

        /// <summary>
        /// xchg m64, r64 | REX.W + 87 /r | Exchange r64 with quadword from r/m64.
        /// </summary>
        [Symbol("xchg m64, r64","REX.W + 87 /r")]
        xchg_m64_r64 = 5441,

        /// <summary>
        /// xchg m8, r8 | 86 /r | Exchange r8 (byte register) with byte from r/m8.
        /// </summary>
        [Symbol("xchg m8, r8","86 /r")]
        xchg_m8_r8 = 5442,

        /// <summary>
        /// xchg m8, r8 | REX + 86 /r | Exchange r8 (byte register) with byte from r/m8.
        /// </summary>
        [Symbol("xchg m8, r8","REX + 86 /r")]
        xchg_m8_r8_rex = 5443,

        /// <summary>
        /// xchg r16, AX | 90 +rw | Exchange AX with r16.
        /// </summary>
        [Symbol("xchg r16, AX","90 +rw")]
        xchg_r16_AX = 5444,

        /// <summary>
        /// xchg r16, m16 | 87 /r | Exchange word from r/m16 with r16.
        /// </summary>
        [Symbol("xchg r16, m16","87 /r")]
        xchg_r16_m16 = 5445,

        /// <summary>
        /// xchg r16, r16 | 87 /r | Exchange r16 with word from r/m16.
        /// </summary>
        [Symbol("xchg r16, r16","87 /r")]
        xchg_r16_r16 = 5446,

        /// <summary>
        /// xchg r32, EAX | 90 +rd | Exchange EAX with r32.
        /// </summary>
        [Symbol("xchg r32, EAX","90 +rd")]
        xchg_r32_EAX = 5447,

        /// <summary>
        /// xchg r32, m32 | 87 /r | Exchange doubleword from r/m32 with r32.
        /// </summary>
        [Symbol("xchg r32, m32","87 /r")]
        xchg_r32_m32 = 5448,

        /// <summary>
        /// xchg r32, r32 | 87 /r | Exchange r32 with doubleword from r/m32.
        /// </summary>
        [Symbol("xchg r32, r32","87 /r")]
        xchg_r32_r32 = 5449,

        /// <summary>
        /// xchg r64, m64 | REX.W + 87 /r | Exchange quadword from r/m64 with r64.
        /// </summary>
        [Symbol("xchg r64, m64","REX.W + 87 /r")]
        xchg_r64_m64 = 5450,

        /// <summary>
        /// xchg r64, r64 | REX.W + 87 /r | Exchange r64 with quadword from r/m64.
        /// </summary>
        [Symbol("xchg r64, r64","REX.W + 87 /r")]
        xchg_r64_r64 = 5451,

        /// <summary>
        /// xchg r64, RAX | REX.W + 90 +rd | Exchange RAX with r64.
        /// </summary>
        [Symbol("xchg r64, RAX","REX.W + 90 +rd")]
        xchg_r64_RAX = 5452,

        /// <summary>
        /// xchg r8, m8 | 86 /r | Exchange byte from r/m8 with r8 (byte register).
        /// </summary>
        [Symbol("xchg r8, m8","86 /r")]
        xchg_r8_m8 = 5453,

        /// <summary>
        /// xchg r8, m8 | REX + 86 /r | Exchange byte from r/m8 with r8 (byte register).
        /// </summary>
        [Symbol("xchg r8, m8","REX + 86 /r")]
        xchg_r8_m8_rex = 5454,

        /// <summary>
        /// xchg r8, r8 | 86 /r | Exchange r8 (byte register) with byte from r/m8.
        /// </summary>
        [Symbol("xchg r8, r8","86 /r")]
        xchg_r8_r8 = 5455,

        /// <summary>
        /// xchg r8, r8 | REX + 86 /r | Exchange r8 (byte register) with byte from r/m8.
        /// </summary>
        [Symbol("xchg r8, r8","REX + 86 /r")]
        xchg_r8_r8_rex = 5456,

        /// <summary>
        /// xchg RAX, r64 | REX.W + 90 +rd | Exchange r64 with RAX.
        /// </summary>
        [Symbol("xchg RAX, r64","REX.W + 90 +rd")]
        xchg_RAX_r64 = 5457,

        /// <summary>
        /// xgetbv | NP 0F 01 D0 | Reads an XCR specified by ECX into EDX:EAX.
        /// </summary>
        [Symbol("xgetbv","NP 0F 01 D0")]
        xgetbv = 5458,

        /// <summary>
        /// xlat m8 | D7 | Set AL to memory byte DS:[(E)BX + unsigned AL].
        /// </summary>
        [Symbol("xlat m8","D7")]
        xlat_m8 = 5459,

        /// <summary>
        /// xlatb | D7 | Set AL to memory byte DS:[(E)BX + unsigned AL].
        /// </summary>
        [Symbol("xlatb","D7")]
        xlatb = 5460,

        /// <summary>
        /// xlatb | REX.W + D7 | Set AL to memory byte [RBX + unsigned AL].
        /// </summary>
        [Symbol("xlatb","REX.W + D7")]
        xlatb_rex = 5461,

        /// <summary>
        /// xor AL, imm8 | 34 ib | AL XOR imm8.
        /// </summary>
        [Symbol("xor AL, imm8","34 ib")]
        xor_AL_imm8 = 5462,

        /// <summary>
        /// xor AX, imm16 | 35 iw | AX XOR imm16.
        /// </summary>
        [Symbol("xor AX, imm16","35 iw")]
        xor_AX_imm16 = 5463,

        /// <summary>
        /// xor EAX, imm32 | 35 id | EAX XOR imm32.
        /// </summary>
        [Symbol("xor EAX, imm32","35 id")]
        xor_EAX_imm32 = 5464,

        /// <summary>
        /// xor m16, imm16 | 81 /6 iw | r/m16 XOR imm16.
        /// </summary>
        [Symbol("xor m16, imm16","81 /6 iw")]
        xor_m16_imm16 = 5465,

        /// <summary>
        /// xor m16, imm8 | 83 /6 ib | r/m16 XOR imm8 (sign-extended).
        /// </summary>
        [Symbol("xor m16, imm8","83 /6 ib")]
        xor_m16_imm8 = 5466,

        /// <summary>
        /// xor m16, r16 | 31 /r | r/m16 XOR r16.
        /// </summary>
        [Symbol("xor m16, r16","31 /r")]
        xor_m16_r16 = 5467,

        /// <summary>
        /// xor m32, imm32 | 81 /6 id | r/m32 XOR imm32.
        /// </summary>
        [Symbol("xor m32, imm32","81 /6 id")]
        xor_m32_imm32 = 5468,

        /// <summary>
        /// xor m32, imm8 | 83 /6 ib | r/m32 XOR imm8 (sign-extended).
        /// </summary>
        [Symbol("xor m32, imm8","83 /6 ib")]
        xor_m32_imm8 = 5469,

        /// <summary>
        /// xor m32, r32 | 31 /r | r/m32 XOR r32.
        /// </summary>
        [Symbol("xor m32, r32","31 /r")]
        xor_m32_r32 = 5470,

        /// <summary>
        /// xor m64, imm32 | REX.W + 81 /6 id | r/m64 XOR imm32 (sign-extended).
        /// </summary>
        [Symbol("xor m64, imm32","REX.W + 81 /6 id")]
        xor_m64_imm32 = 5471,

        /// <summary>
        /// xor m64, imm8 | REX.W + 83 /6 ib | r/m64 XOR imm8 (sign-extended).
        /// </summary>
        [Symbol("xor m64, imm8","REX.W + 83 /6 ib")]
        xor_m64_imm8 = 5472,

        /// <summary>
        /// xor m64, r64 | REX.W + 31 /r | r/m64 XOR r64.
        /// </summary>
        [Symbol("xor m64, r64","REX.W + 31 /r")]
        xor_m64_r64 = 5473,

        /// <summary>
        /// xor m8, imm8 | 80 /6 ib | r/m8 XOR imm8.
        /// </summary>
        [Symbol("xor m8, imm8","80 /6 ib")]
        xor_m8_imm8 = 5474,

        /// <summary>
        /// xor m8, imm8 | REX + 80 /6 ib | r/m8 XOR imm8.
        /// </summary>
        [Symbol("xor m8, imm8","REX + 80 /6 ib")]
        xor_m8_imm8_rex = 5475,

        /// <summary>
        /// xor m8, r8 | REX + 30 /r | r/m8 XOR r8.
        /// </summary>
        [Symbol("xor m8, r8","REX + 30 /r")]
        xor_m8_r8 = 5476,

        /// <summary>
        /// xor m8, r8 | 30 /r | r/m8 XOR r8.
        /// </summary>
        [Symbol("xor m8, r8","30 /r")]
        xor_m8_r8_x30 = 5477,

        /// <summary>
        /// xor r16, imm16 | 81 /6 iw | r/m16 XOR imm16.
        /// </summary>
        [Symbol("xor r16, imm16","81 /6 iw")]
        xor_r16_imm16 = 5478,

        /// <summary>
        /// xor r16, imm8 | 83 /6 ib | r/m16 XOR imm8 (sign-extended).
        /// </summary>
        [Symbol("xor r16, imm8","83 /6 ib")]
        xor_r16_imm8 = 5479,

        /// <summary>
        /// xor r16, m16 | 33 /r | r16 XOR r/m16.
        /// </summary>
        [Symbol("xor r16, m16","33 /r")]
        xor_r16_m16 = 5480,

        /// <summary>
        /// xor r16, r16 | 31 /r | r/m16 XOR r16.
        /// </summary>
        [Symbol("xor r16, r16","31 /r")]
        xor_r16_r16 = 5481,

        /// <summary>
        /// xor r16, r16 | 33 /r | r16 XOR r/m16.
        /// </summary>
        [Symbol("xor r16, r16","33 /r")]
        xor_r16_r16_x33 = 5482,

        /// <summary>
        /// xor r32, imm32 | 81 /6 id | r/m32 XOR imm32.
        /// </summary>
        [Symbol("xor r32, imm32","81 /6 id")]
        xor_r32_imm32 = 5483,

        /// <summary>
        /// xor r32, imm8 | 83 /6 ib | r/m32 XOR imm8 (sign-extended).
        /// </summary>
        [Symbol("xor r32, imm8","83 /6 ib")]
        xor_r32_imm8 = 5484,

        /// <summary>
        /// xor r32, m32 | 33 /r | r32 XOR r/m32.
        /// </summary>
        [Symbol("xor r32, m32","33 /r")]
        xor_r32_m32 = 5485,

        /// <summary>
        /// xor r32, r32 | 31 /r | r/m32 XOR r32.
        /// </summary>
        [Symbol("xor r32, r32","31 /r")]
        xor_r32_r32 = 5486,

        /// <summary>
        /// xor r32, r32 | 33 /r | r32 XOR r/m32.
        /// </summary>
        [Symbol("xor r32, r32","33 /r")]
        xor_r32_r32_x33 = 5487,

        /// <summary>
        /// xor r64, imm32 | REX.W + 81 /6 id | r/m64 XOR imm32 (sign-extended).
        /// </summary>
        [Symbol("xor r64, imm32","REX.W + 81 /6 id")]
        xor_r64_imm32 = 5488,

        /// <summary>
        /// xor r64, imm8 | REX.W + 83 /6 ib | r/m64 XOR imm8 (sign-extended).
        /// </summary>
        [Symbol("xor r64, imm8","REX.W + 83 /6 ib")]
        xor_r64_imm8 = 5489,

        /// <summary>
        /// xor r64, m64 | REX.W + 33 /r | r64 XOR r/m64.
        /// </summary>
        [Symbol("xor r64, m64","REX.W + 33 /r")]
        xor_r64_m64 = 5490,

        /// <summary>
        /// xor r64, r64 | REX.W + 31 /r | r/m64 XOR r64.
        /// </summary>
        [Symbol("xor r64, r64","REX.W + 31 /r")]
        xor_r64_r64 = 5491,

        /// <summary>
        /// xor r64, r64 | REX.W + 33 /r | r64 XOR r/m64.
        /// </summary>
        [Symbol("xor r64, r64","REX.W + 33 /r")]
        xor_r64_r64_x33 = 5492,

        /// <summary>
        /// xor r8, imm8 | 80 /6 ib | r/m8 XOR imm8.
        /// </summary>
        [Symbol("xor r8, imm8","80 /6 ib")]
        xor_r8_imm8 = 5493,

        /// <summary>
        /// xor r8, imm8 | REX + 80 /6 ib | r/m8 XOR imm8.
        /// </summary>
        [Symbol("xor r8, imm8","REX + 80 /6 ib")]
        xor_r8_imm8_rex = 5494,

        /// <summary>
        /// xor r8, m8 | 32 /r | r8 XOR r/m8.
        /// </summary>
        [Symbol("xor r8, m8","32 /r")]
        xor_r8_m8 = 5495,

        /// <summary>
        /// xor r8, m8 | REX + 32 /r | r8 XOR r/m8.
        /// </summary>
        [Symbol("xor r8, m8","REX + 32 /r")]
        xor_r8_m8_rex = 5496,

        /// <summary>
        /// xor r8, r8 | REX + 30 /r | r/m8 XOR r8.
        /// </summary>
        [Symbol("xor r8, r8","REX + 30 /r")]
        xor_r8_r8 = 5497,

        /// <summary>
        /// xor r8, r8 | 30 /r | r/m8 XOR r8.
        /// </summary>
        [Symbol("xor r8, r8","30 /r")]
        xor_r8_r8_x30 = 5498,

        /// <summary>
        /// xor r8, r8 | 32 /r | r8 XOR r/m8.
        /// </summary>
        [Symbol("xor r8, r8","32 /r")]
        xor_r8_r8_x32 = 5499,

        /// <summary>
        /// xor RAX, imm32 | REX.W + 35 id | RAX XOR imm32 (sign-extended).
        /// </summary>
        [Symbol("xor RAX, imm32","REX.W + 35 id")]
        xor_RAX_imm32 = 5500,

        /// <summary>
        /// xsave mem | NP 0F AE /4 | Save state components specified by EDX:EAX to mem.
        /// </summary>
        [Symbol("xsave mem","NP 0F AE /4")]
        xsave_mem = 5501,

        /// <summary>
        /// xsave64 mem | NP REX.W + 0F AE /4 | Save state components specified by EDX:EAX to mem.
        /// </summary>
        [Symbol("xsave64 mem","NP REX.W + 0F AE /4")]
        xsave64_mem = 5502,

        /// <summary>
        /// xsavec mem | NP 0F C7 /4 | Save state components specified by EDX:EAX to mem with compaction.
        /// </summary>
        [Symbol("xsavec mem","NP 0F C7 /4")]
        xsavec_mem = 5503,

        /// <summary>
        /// xsavec64 mem | NP REX.W + 0F C7 /4 | Save state components specified by EDX:EAX to mem with compaction.
        /// </summary>
        [Symbol("xsavec64 mem","NP REX.W + 0F C7 /4")]
        xsavec64_mem = 5504,

        /// <summary>
        /// xsetbv | NP 0F 01 D1 | Write the value in EDX:EAX to the XCR specified by ECX.
        /// </summary>
        [Symbol("xsetbv","NP 0F 01 D1")]
        xsetbv = 5505,
    }
}

